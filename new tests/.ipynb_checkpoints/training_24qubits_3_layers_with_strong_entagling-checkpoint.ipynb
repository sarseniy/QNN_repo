{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd6e9a6",
   "metadata": {
    "id": "4fd6e9a6"
   },
   "source": [
    "# Satifsying requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1b8b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55d1b8b4",
    "outputId": "d6f2cb29-3894-412c-8cbc-e846998c6962"
   },
   "outputs": [],
   "source": [
    "!pip install pennylane --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11760f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce11760f",
    "outputId": "5da30c23-33c4-4c0a-fe9c-58bb05319786"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25b8a9e",
   "metadata": {
    "id": "a25b8a9e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc1b4e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dc1b4e5",
    "outputId": "4ba9778d-35b6-457e-d8b4-e9c59969fc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653bc14",
   "metadata": {
    "id": "e653bc14"
   },
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a22a6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467,
     "referenced_widgets": [
      "df69f8986a7b46df869d78996f9a92bf",
      "3c55b6cc69fe4e71bfefdfafe172e1f4",
      "53264b907c324fd2903f6a33df4024eb",
      "fe3e249b5f1947ec9fc496ab71992860",
      "5f557bc2ab954fcdbb3145c5ae1cd1fe",
      "ca79710ed42844eda53edd54ad1cce9e",
      "3629620f44dc4eec928e8285f4e292c7",
      "d8d21603da7146628c7025db753adeb3",
      "f4bb69ed5dcf45cabca0294b04062d68",
      "4b9f9045a6a64724b75bed3bdf4825e5",
      "831588c036b84ba5919552e1c0ffaf95",
      "c7dfb28ce1ec490bbbc71bbf8f8bc7bb",
      "fc29fb7181a64867aa764553a94327cf",
      "4d29ed3d913f4c3dadd8aa28ffdf60ab",
      "739c6da6cd64446686e87fd499fc4e8c",
      "2454c06e04cc44a59af6a54edf771dcf",
      "7598f22b00ca4188abd0e988d87c8717",
      "1fb4ea8439054fbeaab29cbbdd8d8c62",
      "ae7d8308ff8541d082c143732f92bce6",
      "1784bfcf80e54eb1a3b7873cd36494b1",
      "f1cb6810b0f0425c925092fd2c564460",
      "d31e57f44fef4cd99cbda543609a5363",
      "42c3a0dfb96d4d0a9cbcfbefdb88634a",
      "fb3c5d28cc434035936450f03eaab7d4",
      "b7381bd873134277869b9bf86f7f6cde",
      "92a84a7a4c1a49fca9c649540174de1a",
      "973a9057772b4a33bebe1c71b2548322",
      "a2b522fb50d54cecaead8906ecc2c88f",
      "4ee572a2f86844b38f1475756d831d7e",
      "a5767d4185754f1f82e22dc55b9b659e",
      "2bae88a771624fce8a7195ab2d3790e1",
      "656d789dd50d4d7c95121ee911a0315e",
      "bcaf3aab2df24777bb896394049144d2",
      "7192858941cb47649969779dc0e63c91",
      "0de84b8c5dde45b68b6fe495e3978524",
      "664e26cb5e91441d8360e652dc6f3f13",
      "ba90ae57f0bf4101b5306b32401f5ca6",
      "585d33ea2f6c4c6f866ab5eaf500a486",
      "611e4230f7284f56a36e03b6cab128bb",
      "dbeac195f2cf4776b6c95dedda39513c",
      "dc04c3799392479f84746241eac0c9bc",
      "9a0d229daebc428d8d0bea6db980845f",
      "00cd50cc19624ebf946c288dcf96ca77",
      "4472460dcaf349e282e8505097ac56db"
     ]
    },
    "id": "33a22a6f",
    "outputId": "d99650b6-68ff-4c1e-bf7c-3ac0dc41c7c3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc58f39544c042c5a1193e49858dba17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4193b41deae43b3805f9084acb885c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffef1a883ef4aeb8a5d43b2e8352e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa30ec38a04486d973033caf0816e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OLEG\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ce5a95",
   "metadata": {
    "id": "09ce5a95"
   },
   "source": [
    "# Preparing data with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd1531f",
   "metadata": {
    "id": "0cd1531f"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=80, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1,\n",
    "                                          pin_memory=True),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1,\n",
    "                                          pin_memory=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dada402",
   "metadata": {
    "id": "3dada402"
   },
   "source": [
    "# Defining a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "121f2af3",
   "metadata": {
    "id": "121f2af3"
   },
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(features=inputs, wires=range(n_qubits))\n",
    "    \n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    \n",
    "    return [qml.expval(qml.PauliY(wires=i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e8604a",
   "metadata": {
    "id": "f8e8604a"
   },
   "outputs": [],
   "source": [
    "n_layers = 4\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67b30b7",
   "metadata": {
    "id": "a67b30b7"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HybridNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,    \n",
    "            ),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),                \n",
    "        )\n",
    "        self.fc_1 = nn.Linear(32 * 7 * 7, 16)\n",
    "        \n",
    "        # LIST USAGE?\n",
    "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        \n",
    "        self.qlayer_1.to(device)\n",
    "        self.qlayer_2.to(device)\n",
    "        self.qlayer_3.to(device)\n",
    "        self.qlayer_4.to(device)\n",
    "        \n",
    "        self.fc_2 = nn.Linear(16, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        x = self.fc_1(x)\n",
    "        #print('Before split')\n",
    "        x_1, x_2, x_3, x_4 = torch.split(x, 4, dim=1) # second argument is number of elements in one new tensor\n",
    "        #print('After split')\n",
    "        #x = torch.Tensor(0)\n",
    "        \n",
    "        x_1 = self.qlayer_1(x_1)\n",
    "        x_2 = self.qlayer_2(x_2)\n",
    "        x_3 = self.qlayer_3(x_3)\n",
    "        x_4 = self.qlayer_4(x_4)\n",
    "        \n",
    "        #print(x.device)\n",
    "        \n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        logits = self.fc_2(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3df4eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db3df4eb",
    "outputId": "9eddce9b-8bf3-4fb1-8d8f-12fbb55c6b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_1): Linear(in_features=1568, out_features=16, bias=True)\n",
      "  (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_3): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_4): <Quantum Torch Layer: func=qnode>\n",
      "  (fc_2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hnn = HybridNN()\n",
    "hnn = hnn.to(device)\n",
    "print(hnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cbe6",
   "metadata": {
    "id": "6809cbe6"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a415a96",
   "metadata": {
    "id": "1a415a96"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df9aafa9",
   "metadata": {
    "id": "df9aafa9"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(hnn.parameters(), lr = 0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cc5c6d9",
   "metadata": {
    "id": "7cc5c6d9"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train(num_epochs, model, loaders):\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in trange(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            b_x, b_y = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(b_x)             \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            loss.backward()               \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 10 >= 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20f9ed6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "a2db74a18ce8412399aba11b3bab930b",
      "9002f4b1af6d4c03b8f53fecdffaa3b0",
      "aa56b1689edb4a75aa4af965407467e6",
      "8b99aefdd9a247678de2cefd312207bb",
      "0a0c3aa1494d454b85ce6083f2c98234",
      "0aa6d7245fc747b58457668a840cd66b",
      "df312d8125694913844f2856ee295e67",
      "70629c93466c490cb4d10c7ba2e41d62",
      "7081d0216eb6473fae87f7331becfb53",
      "979724284c094071b6c3143666a2a8d5",
      "7ca85bfb648a4586ab15f601f45bd7c2"
     ]
    },
    "id": "20f9ed6c",
    "outputId": "3b1078fe-8904-4227-b481-0d9b43a61f33",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63144bb8544a465f92c04eacfa950b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/750], Loss: 2.3065\n",
      "Epoch [1/10], Step [2/750], Loss: 2.3337\n",
      "Epoch [1/10], Step [3/750], Loss: 2.3223\n",
      "Epoch [1/10], Step [4/750], Loss: 2.3139\n",
      "Epoch [1/10], Step [5/750], Loss: 2.2920\n",
      "Epoch [1/10], Step [6/750], Loss: 2.3268\n",
      "Epoch [1/10], Step [7/750], Loss: 2.3550\n",
      "Epoch [1/10], Step [8/750], Loss: 2.3303\n",
      "Epoch [1/10], Step [9/750], Loss: 2.3282\n",
      "Epoch [1/10], Step [10/750], Loss: 2.3036\n",
      "Epoch [1/10], Step [11/750], Loss: 2.3068\n",
      "Epoch [1/10], Step [12/750], Loss: 2.3012\n",
      "Epoch [1/10], Step [13/750], Loss: 2.2896\n",
      "Epoch [1/10], Step [14/750], Loss: 2.2757\n",
      "Epoch [1/10], Step [15/750], Loss: 2.2919\n",
      "Epoch [1/10], Step [16/750], Loss: 2.2775\n",
      "Epoch [1/10], Step [17/750], Loss: 2.2916\n",
      "Epoch [1/10], Step [18/750], Loss: 2.3085\n",
      "Epoch [1/10], Step [19/750], Loss: 2.3402\n",
      "Epoch [1/10], Step [20/750], Loss: 2.2993\n",
      "Epoch [1/10], Step [21/750], Loss: 2.3222\n",
      "Epoch [1/10], Step [22/750], Loss: 2.3096\n",
      "Epoch [1/10], Step [23/750], Loss: 2.3076\n",
      "Epoch [1/10], Step [24/750], Loss: 2.2927\n",
      "Epoch [1/10], Step [25/750], Loss: 2.3207\n",
      "Epoch [1/10], Step [26/750], Loss: 2.3121\n",
      "Epoch [1/10], Step [27/750], Loss: 2.2922\n",
      "Epoch [1/10], Step [28/750], Loss: 2.3095\n",
      "Epoch [1/10], Step [29/750], Loss: 2.3357\n",
      "Epoch [1/10], Step [30/750], Loss: 2.3072\n",
      "Epoch [1/10], Step [31/750], Loss: 2.3262\n",
      "Epoch [1/10], Step [32/750], Loss: 2.2958\n",
      "Epoch [1/10], Step [33/750], Loss: 2.3289\n",
      "Epoch [1/10], Step [34/750], Loss: 2.3119\n",
      "Epoch [1/10], Step [35/750], Loss: 2.2998\n",
      "Epoch [1/10], Step [36/750], Loss: 2.3175\n",
      "Epoch [1/10], Step [37/750], Loss: 2.3249\n",
      "Epoch [1/10], Step [38/750], Loss: 2.3146\n",
      "Epoch [1/10], Step [39/750], Loss: 2.3060\n",
      "Epoch [1/10], Step [40/750], Loss: 2.3145\n",
      "Epoch [1/10], Step [41/750], Loss: 2.3155\n",
      "Epoch [1/10], Step [42/750], Loss: 2.3239\n",
      "Epoch [1/10], Step [43/750], Loss: 2.2996\n",
      "Epoch [1/10], Step [44/750], Loss: 2.3250\n",
      "Epoch [1/10], Step [45/750], Loss: 2.2944\n",
      "Epoch [1/10], Step [46/750], Loss: 2.2862\n",
      "Epoch [1/10], Step [47/750], Loss: 2.3073\n",
      "Epoch [1/10], Step [48/750], Loss: 2.3134\n",
      "Epoch [1/10], Step [49/750], Loss: 2.3079\n",
      "Epoch [1/10], Step [50/750], Loss: 2.2957\n",
      "Epoch [1/10], Step [51/750], Loss: 2.3136\n",
      "Epoch [1/10], Step [52/750], Loss: 2.3043\n",
      "Epoch [1/10], Step [53/750], Loss: 2.3303\n",
      "Epoch [1/10], Step [54/750], Loss: 2.3255\n",
      "Epoch [1/10], Step [55/750], Loss: 2.3011\n",
      "Epoch [1/10], Step [56/750], Loss: 2.3051\n",
      "Epoch [1/10], Step [57/750], Loss: 2.3155\n",
      "Epoch [1/10], Step [58/750], Loss: 2.2945\n",
      "Epoch [1/10], Step [59/750], Loss: 2.3065\n",
      "Epoch [1/10], Step [60/750], Loss: 2.3152\n",
      "Epoch [1/10], Step [61/750], Loss: 2.3228\n",
      "Epoch [1/10], Step [62/750], Loss: 2.3147\n",
      "Epoch [1/10], Step [63/750], Loss: 2.3040\n",
      "Epoch [1/10], Step [64/750], Loss: 2.2928\n",
      "Epoch [1/10], Step [65/750], Loss: 2.3415\n",
      "Epoch [1/10], Step [66/750], Loss: 2.3044\n",
      "Epoch [1/10], Step [67/750], Loss: 2.3101\n",
      "Epoch [1/10], Step [68/750], Loss: 2.3024\n",
      "Epoch [1/10], Step [69/750], Loss: 2.3278\n",
      "Epoch [1/10], Step [70/750], Loss: 2.3193\n",
      "Epoch [1/10], Step [71/750], Loss: 2.3049\n",
      "Epoch [1/10], Step [72/750], Loss: 2.2932\n",
      "Epoch [1/10], Step [73/750], Loss: 2.2932\n",
      "Epoch [1/10], Step [74/750], Loss: 2.3127\n",
      "Epoch [1/10], Step [75/750], Loss: 2.3011\n",
      "Epoch [1/10], Step [76/750], Loss: 2.3150\n",
      "Epoch [1/10], Step [77/750], Loss: 2.2907\n",
      "Epoch [1/10], Step [78/750], Loss: 2.2979\n",
      "Epoch [1/10], Step [79/750], Loss: 2.2978\n",
      "Epoch [1/10], Step [80/750], Loss: 2.2911\n",
      "Epoch [1/10], Step [81/750], Loss: 2.3124\n",
      "Epoch [1/10], Step [82/750], Loss: 2.3277\n",
      "Epoch [1/10], Step [83/750], Loss: 2.2939\n",
      "Epoch [1/10], Step [84/750], Loss: 2.2812\n",
      "Epoch [1/10], Step [85/750], Loss: 2.3133\n",
      "Epoch [1/10], Step [86/750], Loss: 2.3016\n",
      "Epoch [1/10], Step [87/750], Loss: 2.3265\n",
      "Epoch [1/10], Step [88/750], Loss: 2.3162\n",
      "Epoch [1/10], Step [89/750], Loss: 2.3336\n",
      "Epoch [1/10], Step [90/750], Loss: 2.3117\n",
      "Epoch [1/10], Step [91/750], Loss: 2.3391\n",
      "Epoch [1/10], Step [92/750], Loss: 2.3203\n",
      "Epoch [1/10], Step [93/750], Loss: 2.3157\n",
      "Epoch [1/10], Step [94/750], Loss: 2.3219\n",
      "Epoch [1/10], Step [95/750], Loss: 2.2966\n",
      "Epoch [1/10], Step [96/750], Loss: 2.3322\n",
      "Epoch [1/10], Step [97/750], Loss: 2.2985\n",
      "Epoch [1/10], Step [98/750], Loss: 2.3056\n",
      "Epoch [1/10], Step [99/750], Loss: 2.2932\n",
      "Epoch [1/10], Step [100/750], Loss: 2.3141\n",
      "Epoch [1/10], Step [101/750], Loss: 2.2840\n",
      "Epoch [1/10], Step [102/750], Loss: 2.2935\n",
      "Epoch [1/10], Step [103/750], Loss: 2.3132\n",
      "Epoch [1/10], Step [104/750], Loss: 2.2998\n",
      "Epoch [1/10], Step [105/750], Loss: 2.3121\n",
      "Epoch [1/10], Step [106/750], Loss: 2.2862\n",
      "Epoch [1/10], Step [107/750], Loss: 2.2969\n",
      "Epoch [1/10], Step [108/750], Loss: 2.2994\n",
      "Epoch [1/10], Step [109/750], Loss: 2.3070\n",
      "Epoch [1/10], Step [110/750], Loss: 2.3123\n",
      "Epoch [1/10], Step [111/750], Loss: 2.3352\n",
      "Epoch [1/10], Step [112/750], Loss: 2.3073\n",
      "Epoch [1/10], Step [113/750], Loss: 2.2927\n",
      "Epoch [1/10], Step [114/750], Loss: 2.3023\n",
      "Epoch [1/10], Step [115/750], Loss: 2.2813\n",
      "Epoch [1/10], Step [116/750], Loss: 2.3023\n",
      "Epoch [1/10], Step [117/750], Loss: 2.3335\n",
      "Epoch [1/10], Step [118/750], Loss: 2.2987\n",
      "Epoch [1/10], Step [119/750], Loss: 2.2858\n",
      "Epoch [1/10], Step [120/750], Loss: 2.2984\n",
      "Epoch [1/10], Step [121/750], Loss: 2.2988\n",
      "Epoch [1/10], Step [122/750], Loss: 2.3487\n",
      "Epoch [1/10], Step [123/750], Loss: 2.3047\n",
      "Epoch [1/10], Step [124/750], Loss: 2.3317\n",
      "Epoch [1/10], Step [125/750], Loss: 2.3092\n",
      "Epoch [1/10], Step [126/750], Loss: 2.2940\n",
      "Epoch [1/10], Step [127/750], Loss: 2.2958\n",
      "Epoch [1/10], Step [128/750], Loss: 2.3225\n",
      "Epoch [1/10], Step [129/750], Loss: 2.3122\n",
      "Epoch [1/10], Step [130/750], Loss: 2.3054\n",
      "Epoch [1/10], Step [131/750], Loss: 2.3076\n",
      "Epoch [1/10], Step [132/750], Loss: 2.2968\n",
      "Epoch [1/10], Step [133/750], Loss: 2.3113\n",
      "Epoch [1/10], Step [134/750], Loss: 2.3139\n",
      "Epoch [1/10], Step [135/750], Loss: 2.2927\n",
      "Epoch [1/10], Step [136/750], Loss: 2.2912\n",
      "Epoch [1/10], Step [137/750], Loss: 2.3021\n",
      "Epoch [1/10], Step [138/750], Loss: 2.2943\n",
      "Epoch [1/10], Step [139/750], Loss: 2.3051\n",
      "Epoch [1/10], Step [140/750], Loss: 2.3105\n",
      "Epoch [1/10], Step [141/750], Loss: 2.3133\n",
      "Epoch [1/10], Step [142/750], Loss: 2.3360\n",
      "Epoch [1/10], Step [143/750], Loss: 2.3099\n",
      "Epoch [1/10], Step [144/750], Loss: 2.3171\n",
      "Epoch [1/10], Step [145/750], Loss: 2.3047\n",
      "Epoch [1/10], Step [146/750], Loss: 2.2970\n",
      "Epoch [1/10], Step [147/750], Loss: 2.2901\n",
      "Epoch [1/10], Step [148/750], Loss: 2.3092\n",
      "Epoch [1/10], Step [149/750], Loss: 2.3332\n",
      "Epoch [1/10], Step [150/750], Loss: 2.3155\n",
      "Epoch [1/10], Step [151/750], Loss: 2.3138\n",
      "Epoch [1/10], Step [152/750], Loss: 2.2959\n",
      "Epoch [1/10], Step [153/750], Loss: 2.3116\n",
      "Epoch [1/10], Step [154/750], Loss: 2.3064\n",
      "Epoch [1/10], Step [155/750], Loss: 2.2951\n",
      "Epoch [1/10], Step [156/750], Loss: 2.2994\n",
      "Epoch [1/10], Step [157/750], Loss: 2.2943\n",
      "Epoch [1/10], Step [158/750], Loss: 2.3186\n",
      "Epoch [1/10], Step [159/750], Loss: 2.3052\n",
      "Epoch [1/10], Step [160/750], Loss: 2.3328\n",
      "Epoch [1/10], Step [161/750], Loss: 2.2885\n",
      "Epoch [1/10], Step [162/750], Loss: 2.3251\n",
      "Epoch [1/10], Step [163/750], Loss: 2.3057\n",
      "Epoch [1/10], Step [164/750], Loss: 2.3036\n",
      "Epoch [1/10], Step [165/750], Loss: 2.3091\n",
      "Epoch [1/10], Step [166/750], Loss: 2.3001\n",
      "Epoch [1/10], Step [167/750], Loss: 2.2955\n",
      "Epoch [1/10], Step [168/750], Loss: 2.3040\n",
      "Epoch [1/10], Step [169/750], Loss: 2.3031\n",
      "Epoch [1/10], Step [170/750], Loss: 2.3089\n",
      "Epoch [1/10], Step [171/750], Loss: 2.3192\n",
      "Epoch [1/10], Step [172/750], Loss: 2.3039\n",
      "Epoch [1/10], Step [173/750], Loss: 2.3101\n",
      "Epoch [1/10], Step [174/750], Loss: 2.3219\n",
      "Epoch [1/10], Step [175/750], Loss: 2.3093\n",
      "Epoch [1/10], Step [176/750], Loss: 2.3027\n",
      "Epoch [1/10], Step [177/750], Loss: 2.2924\n",
      "Epoch [1/10], Step [178/750], Loss: 2.3181\n",
      "Epoch [1/10], Step [179/750], Loss: 2.3232\n",
      "Epoch [1/10], Step [180/750], Loss: 2.2877\n",
      "Epoch [1/10], Step [181/750], Loss: 2.3031\n",
      "Epoch [1/10], Step [182/750], Loss: 2.3051\n",
      "Epoch [1/10], Step [183/750], Loss: 2.2957\n",
      "Epoch [1/10], Step [184/750], Loss: 2.3002\n",
      "Epoch [1/10], Step [185/750], Loss: 2.3012\n",
      "Epoch [1/10], Step [186/750], Loss: 2.3061\n",
      "Epoch [1/10], Step [187/750], Loss: 2.3062\n",
      "Epoch [1/10], Step [188/750], Loss: 2.3094\n",
      "Epoch [1/10], Step [189/750], Loss: 2.3034\n",
      "Epoch [1/10], Step [190/750], Loss: 2.2757\n",
      "Epoch [1/10], Step [191/750], Loss: 2.2907\n",
      "Epoch [1/10], Step [192/750], Loss: 2.2964\n",
      "Epoch [1/10], Step [193/750], Loss: 2.2758\n",
      "Epoch [1/10], Step [194/750], Loss: 2.3144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [195/750], Loss: 2.2771\n",
      "Epoch [1/10], Step [196/750], Loss: 2.2900\n",
      "Epoch [1/10], Step [197/750], Loss: 2.2959\n",
      "Epoch [1/10], Step [198/750], Loss: 2.2908\n",
      "Epoch [1/10], Step [199/750], Loss: 2.3200\n",
      "Epoch [1/10], Step [200/750], Loss: 2.2952\n",
      "Epoch [1/10], Step [201/750], Loss: 2.3165\n",
      "Epoch [1/10], Step [202/750], Loss: 2.3062\n",
      "Epoch [1/10], Step [203/750], Loss: 2.2935\n",
      "Epoch [1/10], Step [204/750], Loss: 2.3076\n",
      "Epoch [1/10], Step [205/750], Loss: 2.3355\n",
      "Epoch [1/10], Step [206/750], Loss: 2.2897\n",
      "Epoch [1/10], Step [207/750], Loss: 2.3061\n",
      "Epoch [1/10], Step [208/750], Loss: 2.3267\n",
      "Epoch [1/10], Step [209/750], Loss: 2.3014\n",
      "Epoch [1/10], Step [210/750], Loss: 2.2986\n",
      "Epoch [1/10], Step [211/750], Loss: 2.2916\n",
      "Epoch [1/10], Step [212/750], Loss: 2.3219\n",
      "Epoch [1/10], Step [213/750], Loss: 2.2953\n",
      "Epoch [1/10], Step [214/750], Loss: 2.2941\n",
      "Epoch [1/10], Step [215/750], Loss: 2.2706\n",
      "Epoch [1/10], Step [216/750], Loss: 2.2949\n",
      "Epoch [1/10], Step [217/750], Loss: 2.2886\n",
      "Epoch [1/10], Step [218/750], Loss: 2.3159\n",
      "Epoch [1/10], Step [219/750], Loss: 2.2774\n",
      "Epoch [1/10], Step [220/750], Loss: 2.3129\n",
      "Epoch [1/10], Step [221/750], Loss: 2.2728\n",
      "Epoch [1/10], Step [222/750], Loss: 2.3069\n",
      "Epoch [1/10], Step [223/750], Loss: 2.3130\n",
      "Epoch [1/10], Step [224/750], Loss: 2.3107\n",
      "Epoch [1/10], Step [225/750], Loss: 2.3044\n",
      "Epoch [1/10], Step [226/750], Loss: 2.3120\n",
      "Epoch [1/10], Step [227/750], Loss: 2.2903\n",
      "Epoch [1/10], Step [228/750], Loss: 2.2978\n",
      "Epoch [1/10], Step [229/750], Loss: 2.3044\n",
      "Epoch [1/10], Step [230/750], Loss: 2.2945\n",
      "Epoch [1/10], Step [231/750], Loss: 2.3224\n",
      "Epoch [1/10], Step [232/750], Loss: 2.2995\n",
      "Epoch [1/10], Step [233/750], Loss: 2.2997\n",
      "Epoch [1/10], Step [234/750], Loss: 2.2977\n",
      "Epoch [1/10], Step [235/750], Loss: 2.3307\n",
      "Epoch [1/10], Step [236/750], Loss: 2.3124\n",
      "Epoch [1/10], Step [237/750], Loss: 2.3246\n",
      "Epoch [1/10], Step [238/750], Loss: 2.3056\n",
      "Epoch [1/10], Step [239/750], Loss: 2.3373\n",
      "Epoch [1/10], Step [240/750], Loss: 2.2934\n",
      "Epoch [1/10], Step [241/750], Loss: 2.2940\n",
      "Epoch [1/10], Step [242/750], Loss: 2.3046\n",
      "Epoch [1/10], Step [243/750], Loss: 2.3153\n",
      "Epoch [1/10], Step [244/750], Loss: 2.3086\n",
      "Epoch [1/10], Step [245/750], Loss: 2.3110\n",
      "Epoch [1/10], Step [246/750], Loss: 2.3146\n",
      "Epoch [1/10], Step [247/750], Loss: 2.3011\n",
      "Epoch [1/10], Step [248/750], Loss: 2.3053\n",
      "Epoch [1/10], Step [249/750], Loss: 2.3066\n",
      "Epoch [1/10], Step [250/750], Loss: 2.2835\n",
      "Epoch [1/10], Step [251/750], Loss: 2.2898\n",
      "Epoch [1/10], Step [252/750], Loss: 2.3069\n",
      "Epoch [1/10], Step [253/750], Loss: 2.2890\n",
      "Epoch [1/10], Step [254/750], Loss: 2.2846\n",
      "Epoch [1/10], Step [255/750], Loss: 2.3133\n",
      "Epoch [1/10], Step [256/750], Loss: 2.3145\n",
      "Epoch [1/10], Step [257/750], Loss: 2.3136\n",
      "Epoch [1/10], Step [258/750], Loss: 2.3030\n",
      "Epoch [1/10], Step [259/750], Loss: 2.2863\n",
      "Epoch [1/10], Step [260/750], Loss: 2.3088\n",
      "Epoch [1/10], Step [261/750], Loss: 2.3094\n",
      "Epoch [1/10], Step [262/750], Loss: 2.2904\n",
      "Epoch [1/10], Step [263/750], Loss: 2.2964\n",
      "Epoch [1/10], Step [264/750], Loss: 2.2905\n",
      "Epoch [1/10], Step [265/750], Loss: 2.2964\n",
      "Epoch [1/10], Step [266/750], Loss: 2.3204\n",
      "Epoch [1/10], Step [267/750], Loss: 2.2970\n",
      "Epoch [1/10], Step [268/750], Loss: 2.2887\n",
      "Epoch [1/10], Step [269/750], Loss: 2.2822\n",
      "Epoch [1/10], Step [270/750], Loss: 2.2799\n",
      "Epoch [1/10], Step [271/750], Loss: 2.2954\n",
      "Epoch [1/10], Step [272/750], Loss: 2.3041\n",
      "Epoch [1/10], Step [273/750], Loss: 2.3032\n",
      "Epoch [1/10], Step [274/750], Loss: 2.2759\n",
      "Epoch [1/10], Step [275/750], Loss: 2.2997\n",
      "Epoch [1/10], Step [276/750], Loss: 2.2905\n",
      "Epoch [1/10], Step [277/750], Loss: 2.2676\n",
      "Epoch [1/10], Step [278/750], Loss: 2.2769\n",
      "Epoch [1/10], Step [279/750], Loss: 2.2984\n",
      "Epoch [1/10], Step [280/750], Loss: 2.2894\n",
      "Epoch [1/10], Step [281/750], Loss: 2.2843\n",
      "Epoch [1/10], Step [282/750], Loss: 2.2945\n",
      "Epoch [1/10], Step [283/750], Loss: 2.2867\n",
      "Epoch [1/10], Step [284/750], Loss: 2.2812\n",
      "Epoch [1/10], Step [285/750], Loss: 2.2861\n",
      "Epoch [1/10], Step [286/750], Loss: 2.2773\n",
      "Epoch [1/10], Step [287/750], Loss: 2.2894\n",
      "Epoch [1/10], Step [288/750], Loss: 2.3053\n",
      "Epoch [1/10], Step [289/750], Loss: 2.2631\n",
      "Epoch [1/10], Step [290/750], Loss: 2.2905\n",
      "Epoch [1/10], Step [291/750], Loss: 2.2885\n",
      "Epoch [1/10], Step [292/750], Loss: 2.2866\n",
      "Epoch [1/10], Step [293/750], Loss: 2.3115\n",
      "Epoch [1/10], Step [294/750], Loss: 2.3060\n",
      "Epoch [1/10], Step [295/750], Loss: 2.2744\n",
      "Epoch [1/10], Step [296/750], Loss: 2.2843\n",
      "Epoch [1/10], Step [297/750], Loss: 2.3493\n",
      "Epoch [1/10], Step [298/750], Loss: 2.2988\n",
      "Epoch [1/10], Step [299/750], Loss: 2.3012\n",
      "Epoch [1/10], Step [300/750], Loss: 2.3167\n",
      "Epoch [1/10], Step [301/750], Loss: 2.3181\n",
      "Epoch [1/10], Step [302/750], Loss: 2.3013\n",
      "Epoch [1/10], Step [303/750], Loss: 2.2993\n",
      "Epoch [1/10], Step [304/750], Loss: 2.3344\n",
      "Epoch [1/10], Step [305/750], Loss: 2.3164\n",
      "Epoch [1/10], Step [306/750], Loss: 2.2931\n",
      "Epoch [1/10], Step [307/750], Loss: 2.3195\n",
      "Epoch [1/10], Step [308/750], Loss: 2.3123\n",
      "Epoch [1/10], Step [309/750], Loss: 2.3098\n",
      "Epoch [1/10], Step [310/750], Loss: 2.3195\n",
      "Epoch [1/10], Step [311/750], Loss: 2.3049\n",
      "Epoch [1/10], Step [312/750], Loss: 2.3050\n",
      "Epoch [1/10], Step [313/750], Loss: 2.3294\n",
      "Epoch [1/10], Step [314/750], Loss: 2.3002\n",
      "Epoch [1/10], Step [315/750], Loss: 2.2980\n",
      "Epoch [1/10], Step [316/750], Loss: 2.2967\n",
      "Epoch [1/10], Step [317/750], Loss: 2.3149\n",
      "Epoch [1/10], Step [318/750], Loss: 2.3120\n",
      "Epoch [1/10], Step [319/750], Loss: 2.3084\n",
      "Epoch [1/10], Step [320/750], Loss: 2.3128\n",
      "Epoch [1/10], Step [321/750], Loss: 2.3039\n",
      "Epoch [1/10], Step [322/750], Loss: 2.2922\n",
      "Epoch [1/10], Step [323/750], Loss: 2.3092\n",
      "Epoch [1/10], Step [324/750], Loss: 2.2867\n",
      "Epoch [1/10], Step [325/750], Loss: 2.2880\n",
      "Epoch [1/10], Step [326/750], Loss: 2.2775\n",
      "Epoch [1/10], Step [327/750], Loss: 2.2843\n",
      "Epoch [1/10], Step [328/750], Loss: 2.3098\n",
      "Epoch [1/10], Step [329/750], Loss: 2.3061\n",
      "Epoch [1/10], Step [330/750], Loss: 2.3182\n",
      "Epoch [1/10], Step [331/750], Loss: 2.3303\n",
      "Epoch [1/10], Step [332/750], Loss: 2.3152\n",
      "Epoch [1/10], Step [333/750], Loss: 2.3105\n",
      "Epoch [1/10], Step [334/750], Loss: 2.2965\n",
      "Epoch [1/10], Step [335/750], Loss: 2.3305\n",
      "Epoch [1/10], Step [336/750], Loss: 2.2881\n",
      "Epoch [1/10], Step [337/750], Loss: 2.2874\n",
      "Epoch [1/10], Step [338/750], Loss: 2.2982\n",
      "Epoch [1/10], Step [339/750], Loss: 2.3196\n",
      "Epoch [1/10], Step [340/750], Loss: 2.2703\n",
      "Epoch [1/10], Step [341/750], Loss: 2.3134\n",
      "Epoch [1/10], Step [342/750], Loss: 2.3083\n",
      "Epoch [1/10], Step [343/750], Loss: 2.2809\n",
      "Epoch [1/10], Step [344/750], Loss: 2.3039\n",
      "Epoch [1/10], Step [345/750], Loss: 2.2919\n",
      "Epoch [1/10], Step [346/750], Loss: 2.3164\n",
      "Epoch [1/10], Step [347/750], Loss: 2.3270\n",
      "Epoch [1/10], Step [348/750], Loss: 2.3213\n",
      "Epoch [1/10], Step [349/750], Loss: 2.2837\n",
      "Epoch [1/10], Step [350/750], Loss: 2.3174\n",
      "Epoch [1/10], Step [351/750], Loss: 2.3163\n",
      "Epoch [1/10], Step [352/750], Loss: 2.3078\n",
      "Epoch [1/10], Step [353/750], Loss: 2.3024\n",
      "Epoch [1/10], Step [354/750], Loss: 2.2968\n",
      "Epoch [1/10], Step [355/750], Loss: 2.2977\n",
      "Epoch [1/10], Step [356/750], Loss: 2.3134\n",
      "Epoch [1/10], Step [357/750], Loss: 2.2980\n",
      "Epoch [1/10], Step [358/750], Loss: 2.2989\n",
      "Epoch [1/10], Step [359/750], Loss: 2.2989\n",
      "Epoch [1/10], Step [360/750], Loss: 2.3234\n",
      "Epoch [1/10], Step [361/750], Loss: 2.2746\n",
      "Epoch [1/10], Step [362/750], Loss: 2.3087\n",
      "Epoch [1/10], Step [363/750], Loss: 2.3112\n",
      "Epoch [1/10], Step [364/750], Loss: 2.3047\n",
      "Epoch [1/10], Step [365/750], Loss: 2.3042\n",
      "Epoch [1/10], Step [366/750], Loss: 2.3247\n",
      "Epoch [1/10], Step [367/750], Loss: 2.3093\n",
      "Epoch [1/10], Step [368/750], Loss: 2.2838\n",
      "Epoch [1/10], Step [369/750], Loss: 2.3099\n",
      "Epoch [1/10], Step [370/750], Loss: 2.3164\n",
      "Epoch [1/10], Step [371/750], Loss: 2.3031\n",
      "Epoch [1/10], Step [372/750], Loss: 2.3418\n",
      "Epoch [1/10], Step [373/750], Loss: 2.3255\n",
      "Epoch [1/10], Step [374/750], Loss: 2.3091\n",
      "Epoch [1/10], Step [375/750], Loss: 2.2988\n",
      "Epoch [1/10], Step [376/750], Loss: 2.2976\n",
      "Epoch [1/10], Step [377/750], Loss: 2.3063\n",
      "Epoch [1/10], Step [378/750], Loss: 2.3133\n",
      "Epoch [1/10], Step [379/750], Loss: 2.2850\n",
      "Epoch [1/10], Step [380/750], Loss: 2.2965\n",
      "Epoch [1/10], Step [381/750], Loss: 2.2854\n",
      "Epoch [1/10], Step [382/750], Loss: 2.3095\n",
      "Epoch [1/10], Step [383/750], Loss: 2.2969\n",
      "Epoch [1/10], Step [384/750], Loss: 2.3338\n",
      "Epoch [1/10], Step [385/750], Loss: 2.3224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [386/750], Loss: 2.2936\n",
      "Epoch [1/10], Step [387/750], Loss: 2.3101\n",
      "Epoch [1/10], Step [388/750], Loss: 2.3073\n",
      "Epoch [1/10], Step [389/750], Loss: 2.3123\n",
      "Epoch [1/10], Step [390/750], Loss: 2.3046\n",
      "Epoch [1/10], Step [391/750], Loss: 2.3341\n",
      "Epoch [1/10], Step [392/750], Loss: 2.2924\n",
      "Epoch [1/10], Step [393/750], Loss: 2.3058\n",
      "Epoch [1/10], Step [394/750], Loss: 2.3113\n",
      "Epoch [1/10], Step [395/750], Loss: 2.3195\n",
      "Epoch [1/10], Step [396/750], Loss: 2.2928\n",
      "Epoch [1/10], Step [397/750], Loss: 2.3184\n",
      "Epoch [1/10], Step [398/750], Loss: 2.3230\n",
      "Epoch [1/10], Step [399/750], Loss: 2.3165\n",
      "Epoch [1/10], Step [400/750], Loss: 2.2860\n",
      "Epoch [1/10], Step [401/750], Loss: 2.2897\n",
      "Epoch [1/10], Step [402/750], Loss: 2.3036\n",
      "Epoch [1/10], Step [403/750], Loss: 2.2988\n",
      "Epoch [1/10], Step [404/750], Loss: 2.3194\n",
      "Epoch [1/10], Step [405/750], Loss: 2.2832\n",
      "Epoch [1/10], Step [406/750], Loss: 2.2914\n",
      "Epoch [1/10], Step [407/750], Loss: 2.3129\n",
      "Epoch [1/10], Step [408/750], Loss: 2.3012\n",
      "Epoch [1/10], Step [409/750], Loss: 2.3239\n",
      "Epoch [1/10], Step [410/750], Loss: 2.3138\n",
      "Epoch [1/10], Step [411/750], Loss: 2.3117\n",
      "Epoch [1/10], Step [412/750], Loss: 2.2776\n",
      "Epoch [1/10], Step [413/750], Loss: 2.3054\n",
      "Epoch [1/10], Step [414/750], Loss: 2.2886\n",
      "Epoch [1/10], Step [415/750], Loss: 2.2854\n",
      "Epoch [1/10], Step [416/750], Loss: 2.2772\n",
      "Epoch [1/10], Step [417/750], Loss: 2.2793\n",
      "Epoch [1/10], Step [418/750], Loss: 2.2756\n",
      "Epoch [1/10], Step [419/750], Loss: 2.2545\n",
      "Epoch [1/10], Step [420/750], Loss: 2.2552\n",
      "Epoch [1/10], Step [421/750], Loss: 2.2496\n",
      "Epoch [1/10], Step [422/750], Loss: 2.1998\n",
      "Epoch [1/10], Step [423/750], Loss: 2.2004\n",
      "Epoch [1/10], Step [424/750], Loss: 2.2325\n",
      "Epoch [1/10], Step [425/750], Loss: 2.1566\n",
      "Epoch [1/10], Step [426/750], Loss: 2.2153\n",
      "Epoch [1/10], Step [427/750], Loss: 2.1529\n",
      "Epoch [1/10], Step [428/750], Loss: 2.1309\n",
      "Epoch [1/10], Step [429/750], Loss: 2.3330\n",
      "Epoch [1/10], Step [430/750], Loss: 2.1055\n",
      "Epoch [1/10], Step [431/750], Loss: 2.4508\n",
      "Epoch [1/10], Step [432/750], Loss: 2.3170\n",
      "Epoch [1/10], Step [433/750], Loss: 2.3584\n",
      "Epoch [1/10], Step [434/750], Loss: 2.2919\n",
      "Epoch [1/10], Step [435/750], Loss: 2.2787\n",
      "Epoch [1/10], Step [436/750], Loss: 2.3402\n",
      "Epoch [1/10], Step [437/750], Loss: 2.2808\n",
      "Epoch [1/10], Step [438/750], Loss: 2.3289\n",
      "Epoch [1/10], Step [439/750], Loss: 2.3326\n",
      "Epoch [1/10], Step [440/750], Loss: 2.3376\n",
      "Epoch [1/10], Step [441/750], Loss: 2.3053\n",
      "Epoch [1/10], Step [442/750], Loss: 2.2982\n",
      "Epoch [1/10], Step [443/750], Loss: 2.3109\n",
      "Epoch [1/10], Step [444/750], Loss: 2.3076\n",
      "Epoch [1/10], Step [445/750], Loss: 2.3121\n",
      "Epoch [1/10], Step [446/750], Loss: 2.3381\n",
      "Epoch [1/10], Step [447/750], Loss: 2.2865\n",
      "Epoch [1/10], Step [448/750], Loss: 2.3035\n",
      "Epoch [1/10], Step [449/750], Loss: 2.3243\n",
      "Epoch [1/10], Step [450/750], Loss: 2.2885\n",
      "Epoch [1/10], Step [451/750], Loss: 2.3258\n",
      "Epoch [1/10], Step [452/750], Loss: 2.3167\n",
      "Epoch [1/10], Step [453/750], Loss: 2.3149\n",
      "Epoch [1/10], Step [454/750], Loss: 2.3130\n",
      "Epoch [1/10], Step [455/750], Loss: 2.2927\n",
      "Epoch [1/10], Step [456/750], Loss: 2.3195\n",
      "Epoch [1/10], Step [457/750], Loss: 2.3011\n",
      "Epoch [1/10], Step [458/750], Loss: 2.2893\n",
      "Epoch [1/10], Step [459/750], Loss: 2.3083\n",
      "Epoch [1/10], Step [460/750], Loss: 2.3042\n",
      "Epoch [1/10], Step [461/750], Loss: 2.3016\n",
      "Epoch [1/10], Step [462/750], Loss: 2.2994\n",
      "Epoch [1/10], Step [463/750], Loss: 2.3140\n",
      "Epoch [1/10], Step [464/750], Loss: 2.3002\n",
      "Epoch [1/10], Step [465/750], Loss: 2.3093\n",
      "Epoch [1/10], Step [466/750], Loss: 2.2992\n",
      "Epoch [1/10], Step [467/750], Loss: 2.3140\n",
      "Epoch [1/10], Step [468/750], Loss: 2.2962\n",
      "Epoch [1/10], Step [469/750], Loss: 2.3302\n",
      "Epoch [1/10], Step [470/750], Loss: 2.3188\n",
      "Epoch [1/10], Step [471/750], Loss: 2.2863\n",
      "Epoch [1/10], Step [472/750], Loss: 2.2982\n",
      "Epoch [1/10], Step [473/750], Loss: 2.3183\n",
      "Epoch [1/10], Step [474/750], Loss: 2.3004\n",
      "Epoch [1/10], Step [475/750], Loss: 2.3122\n",
      "Epoch [1/10], Step [476/750], Loss: 2.3373\n",
      "Epoch [1/10], Step [477/750], Loss: 2.3145\n",
      "Epoch [1/10], Step [478/750], Loss: 2.3121\n",
      "Epoch [1/10], Step [479/750], Loss: 2.2995\n",
      "Epoch [1/10], Step [480/750], Loss: 2.3079\n",
      "Epoch [1/10], Step [481/750], Loss: 2.3043\n",
      "Epoch [1/10], Step [482/750], Loss: 2.3047\n",
      "Epoch [1/10], Step [483/750], Loss: 2.2928\n",
      "Epoch [1/10], Step [484/750], Loss: 2.3111\n",
      "Epoch [1/10], Step [485/750], Loss: 2.3158\n",
      "Epoch [1/10], Step [486/750], Loss: 2.3106\n",
      "Epoch [1/10], Step [487/750], Loss: 2.2965\n",
      "Epoch [1/10], Step [488/750], Loss: 2.2933\n",
      "Epoch [1/10], Step [489/750], Loss: 2.3088\n",
      "Epoch [1/10], Step [490/750], Loss: 2.2958\n",
      "Epoch [1/10], Step [491/750], Loss: 2.3101\n",
      "Epoch [1/10], Step [492/750], Loss: 2.3149\n",
      "Epoch [1/10], Step [493/750], Loss: 2.3106\n",
      "Epoch [1/10], Step [494/750], Loss: 2.3154\n",
      "Epoch [1/10], Step [495/750], Loss: 2.3024\n",
      "Epoch [1/10], Step [496/750], Loss: 2.2941\n",
      "Epoch [1/10], Step [497/750], Loss: 2.3093\n",
      "Epoch [1/10], Step [498/750], Loss: 2.3076\n",
      "Epoch [1/10], Step [499/750], Loss: 2.3003\n",
      "Epoch [1/10], Step [500/750], Loss: 2.2986\n",
      "Epoch [1/10], Step [501/750], Loss: 2.2850\n",
      "Epoch [1/10], Step [502/750], Loss: 2.3072\n",
      "Epoch [1/10], Step [503/750], Loss: 2.3130\n",
      "Epoch [1/10], Step [504/750], Loss: 2.2909\n",
      "Epoch [1/10], Step [505/750], Loss: 2.3103\n",
      "Epoch [1/10], Step [506/750], Loss: 2.2970\n",
      "Epoch [1/10], Step [507/750], Loss: 2.3044\n",
      "Epoch [1/10], Step [508/750], Loss: 2.3201\n",
      "Epoch [1/10], Step [509/750], Loss: 2.3065\n",
      "Epoch [1/10], Step [510/750], Loss: 2.2879\n",
      "Epoch [1/10], Step [511/750], Loss: 2.3087\n",
      "Epoch [1/10], Step [512/750], Loss: 2.2903\n",
      "Epoch [1/10], Step [513/750], Loss: 2.2958\n",
      "Epoch [1/10], Step [514/750], Loss: 2.2973\n",
      "Epoch [1/10], Step [515/750], Loss: 2.3143\n",
      "Epoch [1/10], Step [516/750], Loss: 2.3066\n",
      "Epoch [1/10], Step [517/750], Loss: 2.3010\n",
      "Epoch [1/10], Step [518/750], Loss: 2.2704\n",
      "Epoch [1/10], Step [519/750], Loss: 2.2784\n",
      "Epoch [1/10], Step [520/750], Loss: 2.2514\n",
      "Epoch [1/10], Step [521/750], Loss: 2.2638\n",
      "Epoch [1/10], Step [522/750], Loss: 2.2887\n",
      "Epoch [1/10], Step [523/750], Loss: 2.2505\n",
      "Epoch [1/10], Step [524/750], Loss: 2.2429\n",
      "Epoch [1/10], Step [525/750], Loss: 2.2304\n",
      "Epoch [1/10], Step [526/750], Loss: 2.2328\n",
      "Epoch [1/10], Step [527/750], Loss: 2.2275\n",
      "Epoch [1/10], Step [528/750], Loss: 2.2045\n",
      "Epoch [1/10], Step [529/750], Loss: 2.1457\n",
      "Epoch [1/10], Step [530/750], Loss: 2.1364\n",
      "Epoch [1/10], Step [531/750], Loss: 2.1299\n",
      "Epoch [1/10], Step [532/750], Loss: 2.1031\n",
      "Epoch [1/10], Step [533/750], Loss: 2.0914\n",
      "Epoch [1/10], Step [534/750], Loss: 2.1379\n",
      "Epoch [1/10], Step [535/750], Loss: 2.0567\n",
      "Epoch [1/10], Step [536/750], Loss: 2.1030\n",
      "Epoch [1/10], Step [537/750], Loss: 2.0438\n",
      "Epoch [1/10], Step [538/750], Loss: 2.0993\n",
      "Epoch [1/10], Step [539/750], Loss: 2.0116\n",
      "Epoch [1/10], Step [540/750], Loss: 2.0098\n",
      "Epoch [1/10], Step [541/750], Loss: 1.9643\n",
      "Epoch [1/10], Step [542/750], Loss: 1.9975\n",
      "Epoch [1/10], Step [543/750], Loss: 1.9607\n",
      "Epoch [1/10], Step [544/750], Loss: 1.9222\n",
      "Epoch [1/10], Step [545/750], Loss: 2.0485\n",
      "Epoch [1/10], Step [546/750], Loss: 1.9080\n",
      "Epoch [1/10], Step [547/750], Loss: 1.9144\n",
      "Epoch [1/10], Step [548/750], Loss: 1.9408\n",
      "Epoch [1/10], Step [549/750], Loss: 1.9498\n",
      "Epoch [1/10], Step [550/750], Loss: 1.9697\n",
      "Epoch [1/10], Step [551/750], Loss: 1.8678\n",
      "Epoch [1/10], Step [552/750], Loss: 1.7765\n",
      "Epoch [1/10], Step [553/750], Loss: 1.9245\n",
      "Epoch [1/10], Step [554/750], Loss: 1.8686\n",
      "Epoch [1/10], Step [555/750], Loss: 1.7848\n",
      "Epoch [1/10], Step [556/750], Loss: 1.7525\n",
      "Epoch [1/10], Step [557/750], Loss: 1.8250\n",
      "Epoch [1/10], Step [558/750], Loss: 1.8219\n",
      "Epoch [1/10], Step [559/750], Loss: 1.7196\n",
      "Epoch [1/10], Step [560/750], Loss: 1.9220\n",
      "Epoch [1/10], Step [561/750], Loss: 1.8525\n",
      "Epoch [1/10], Step [562/750], Loss: 1.9249\n",
      "Epoch [1/10], Step [563/750], Loss: 1.7161\n",
      "Epoch [1/10], Step [564/750], Loss: 1.7930\n",
      "Epoch [1/10], Step [565/750], Loss: 1.8202\n",
      "Epoch [1/10], Step [566/750], Loss: 1.6785\n",
      "Epoch [1/10], Step [567/750], Loss: 1.7646\n",
      "Epoch [1/10], Step [568/750], Loss: 1.6723\n",
      "Epoch [1/10], Step [569/750], Loss: 1.6611\n",
      "Epoch [1/10], Step [570/750], Loss: 1.7577\n",
      "Epoch [1/10], Step [571/750], Loss: 1.7437\n",
      "Epoch [1/10], Step [572/750], Loss: 1.6302\n",
      "Epoch [1/10], Step [573/750], Loss: 1.5466\n",
      "Epoch [1/10], Step [574/750], Loss: 1.6111\n",
      "Epoch [1/10], Step [575/750], Loss: 1.6062\n",
      "Epoch [1/10], Step [576/750], Loss: 1.5534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [577/750], Loss: 1.3545\n",
      "Epoch [1/10], Step [578/750], Loss: 1.4237\n",
      "Epoch [1/10], Step [579/750], Loss: 1.5933\n",
      "Epoch [1/10], Step [580/750], Loss: 1.5615\n",
      "Epoch [1/10], Step [581/750], Loss: 1.4054\n",
      "Epoch [1/10], Step [582/750], Loss: 1.3799\n",
      "Epoch [1/10], Step [583/750], Loss: 1.4223\n",
      "Epoch [1/10], Step [584/750], Loss: 1.5746\n",
      "Epoch [1/10], Step [585/750], Loss: 1.2518\n",
      "Epoch [1/10], Step [586/750], Loss: 1.4110\n",
      "Epoch [1/10], Step [587/750], Loss: 1.3898\n",
      "Epoch [1/10], Step [588/750], Loss: 1.2303\n",
      "Epoch [1/10], Step [589/750], Loss: 1.2305\n",
      "Epoch [1/10], Step [590/750], Loss: 1.2329\n",
      "Epoch [1/10], Step [591/750], Loss: 1.1342\n",
      "Epoch [1/10], Step [592/750], Loss: 1.0177\n",
      "Epoch [1/10], Step [593/750], Loss: 1.0425\n",
      "Epoch [1/10], Step [594/750], Loss: 1.1719\n",
      "Epoch [1/10], Step [595/750], Loss: 0.9923\n",
      "Epoch [1/10], Step [596/750], Loss: 1.0732\n",
      "Epoch [1/10], Step [597/750], Loss: 1.1644\n",
      "Epoch [1/10], Step [598/750], Loss: 1.0897\n",
      "Epoch [1/10], Step [599/750], Loss: 1.1435\n",
      "Epoch [1/10], Step [600/750], Loss: 0.9839\n",
      "Epoch [1/10], Step [601/750], Loss: 0.8608\n",
      "Epoch [1/10], Step [602/750], Loss: 0.9091\n",
      "Epoch [1/10], Step [603/750], Loss: 1.0638\n",
      "Epoch [1/10], Step [604/750], Loss: 0.7684\n",
      "Epoch [1/10], Step [605/750], Loss: 0.7474\n",
      "Epoch [1/10], Step [606/750], Loss: 1.0161\n",
      "Epoch [1/10], Step [607/750], Loss: 0.6197\n",
      "Epoch [1/10], Step [608/750], Loss: 0.8827\n",
      "Epoch [1/10], Step [609/750], Loss: 0.6876\n",
      "Epoch [1/10], Step [610/750], Loss: 0.9512\n",
      "Epoch [1/10], Step [611/750], Loss: 0.7429\n",
      "Epoch [1/10], Step [612/750], Loss: 0.8493\n",
      "Epoch [1/10], Step [613/750], Loss: 0.7863\n",
      "Epoch [1/10], Step [614/750], Loss: 0.7774\n",
      "Epoch [1/10], Step [615/750], Loss: 0.7766\n",
      "Epoch [1/10], Step [616/750], Loss: 0.7201\n",
      "Epoch [1/10], Step [617/750], Loss: 0.7171\n",
      "Epoch [1/10], Step [618/750], Loss: 0.6725\n",
      "Epoch [1/10], Step [619/750], Loss: 0.7757\n",
      "Epoch [1/10], Step [620/750], Loss: 0.5672\n",
      "Epoch [1/10], Step [621/750], Loss: 0.6400\n",
      "Epoch [1/10], Step [622/750], Loss: 0.6647\n",
      "Epoch [1/10], Step [623/750], Loss: 0.5188\n",
      "Epoch [1/10], Step [624/750], Loss: 0.5651\n",
      "Epoch [1/10], Step [625/750], Loss: 0.7530\n",
      "Epoch [1/10], Step [626/750], Loss: 0.6771\n",
      "Epoch [1/10], Step [627/750], Loss: 0.5000\n",
      "Epoch [1/10], Step [628/750], Loss: 0.6953\n",
      "Epoch [1/10], Step [629/750], Loss: 0.6518\n",
      "Epoch [1/10], Step [630/750], Loss: 0.4777\n",
      "Epoch [1/10], Step [631/750], Loss: 0.5429\n",
      "Epoch [1/10], Step [632/750], Loss: 0.4891\n",
      "Epoch [1/10], Step [633/750], Loss: 0.4578\n",
      "Epoch [1/10], Step [634/750], Loss: 0.5447\n",
      "Epoch [1/10], Step [635/750], Loss: 0.5619\n",
      "Epoch [1/10], Step [636/750], Loss: 0.4200\n",
      "Epoch [1/10], Step [637/750], Loss: 0.4850\n",
      "Epoch [1/10], Step [638/750], Loss: 0.4565\n",
      "Epoch [1/10], Step [639/750], Loss: 0.5599\n",
      "Epoch [1/10], Step [640/750], Loss: 0.4145\n",
      "Epoch [1/10], Step [641/750], Loss: 0.3353\n",
      "Epoch [1/10], Step [642/750], Loss: 0.4135\n",
      "Epoch [1/10], Step [643/750], Loss: 0.4115\n",
      "Epoch [1/10], Step [644/750], Loss: 0.4324\n",
      "Epoch [1/10], Step [645/750], Loss: 0.2866\n",
      "Epoch [1/10], Step [646/750], Loss: 0.5929\n",
      "Epoch [1/10], Step [647/750], Loss: 0.4416\n",
      "Epoch [1/10], Step [648/750], Loss: 0.2942\n",
      "Epoch [1/10], Step [649/750], Loss: 0.4324\n",
      "Epoch [1/10], Step [650/750], Loss: 0.4416\n",
      "Epoch [1/10], Step [651/750], Loss: 0.4377\n",
      "Epoch [1/10], Step [652/750], Loss: 0.5594\n",
      "Epoch [1/10], Step [653/750], Loss: 0.3634\n",
      "Epoch [1/10], Step [654/750], Loss: 0.2709\n",
      "Epoch [1/10], Step [655/750], Loss: 0.4083\n",
      "Epoch [1/10], Step [656/750], Loss: 0.3980\n",
      "Epoch [1/10], Step [657/750], Loss: 0.3075\n",
      "Epoch [1/10], Step [658/750], Loss: 0.3509\n",
      "Epoch [1/10], Step [659/750], Loss: 0.4493\n",
      "Epoch [1/10], Step [660/750], Loss: 0.6562\n",
      "Epoch [1/10], Step [661/750], Loss: 0.3175\n",
      "Epoch [1/10], Step [662/750], Loss: 0.3895\n",
      "Epoch [1/10], Step [663/750], Loss: 0.4277\n",
      "Epoch [1/10], Step [664/750], Loss: 0.3352\n",
      "Epoch [1/10], Step [665/750], Loss: 0.3411\n",
      "Epoch [1/10], Step [666/750], Loss: 0.2975\n",
      "Epoch [1/10], Step [667/750], Loss: 0.2859\n",
      "Epoch [1/10], Step [668/750], Loss: 0.4430\n",
      "Epoch [1/10], Step [669/750], Loss: 0.2492\n",
      "Epoch [1/10], Step [670/750], Loss: 0.3264\n",
      "Epoch [1/10], Step [671/750], Loss: 0.3972\n",
      "Epoch [1/10], Step [672/750], Loss: 0.4320\n",
      "Epoch [1/10], Step [673/750], Loss: 0.3016\n",
      "Epoch [1/10], Step [674/750], Loss: 0.2887\n",
      "Epoch [1/10], Step [675/750], Loss: 0.5395\n",
      "Epoch [1/10], Step [676/750], Loss: 0.2975\n",
      "Epoch [1/10], Step [677/750], Loss: 0.1567\n",
      "Epoch [1/10], Step [678/750], Loss: 0.2500\n",
      "Epoch [1/10], Step [679/750], Loss: 0.3012\n",
      "Epoch [1/10], Step [680/750], Loss: 0.3476\n",
      "Epoch [1/10], Step [681/750], Loss: 0.3009\n",
      "Epoch [1/10], Step [682/750], Loss: 0.2719\n",
      "Epoch [1/10], Step [683/750], Loss: 0.2443\n",
      "Epoch [1/10], Step [684/750], Loss: 0.3772\n",
      "Epoch [1/10], Step [685/750], Loss: 0.4448\n",
      "Epoch [1/10], Step [686/750], Loss: 0.3273\n",
      "Epoch [1/10], Step [687/750], Loss: 0.2839\n",
      "Epoch [1/10], Step [688/750], Loss: 0.3886\n",
      "Epoch [1/10], Step [689/750], Loss: 0.4810\n",
      "Epoch [1/10], Step [690/750], Loss: 0.3399\n",
      "Epoch [1/10], Step [691/750], Loss: 0.3422\n",
      "Epoch [1/10], Step [692/750], Loss: 0.3106\n",
      "Epoch [1/10], Step [693/750], Loss: 0.4155\n",
      "Epoch [1/10], Step [694/750], Loss: 0.3170\n",
      "Epoch [1/10], Step [695/750], Loss: 0.2781\n",
      "Epoch [1/10], Step [696/750], Loss: 0.3519\n",
      "Epoch [1/10], Step [697/750], Loss: 0.2923\n",
      "Epoch [1/10], Step [698/750], Loss: 0.3559\n",
      "Epoch [1/10], Step [699/750], Loss: 0.3054\n",
      "Epoch [1/10], Step [700/750], Loss: 0.3625\n",
      "Epoch [1/10], Step [701/750], Loss: 0.2110\n",
      "Epoch [1/10], Step [702/750], Loss: 0.3116\n",
      "Epoch [1/10], Step [703/750], Loss: 0.2312\n",
      "Epoch [1/10], Step [704/750], Loss: 0.3990\n",
      "Epoch [1/10], Step [705/750], Loss: 0.2759\n",
      "Epoch [1/10], Step [706/750], Loss: 0.2281\n",
      "Epoch [1/10], Step [707/750], Loss: 0.2348\n",
      "Epoch [1/10], Step [708/750], Loss: 0.1774\n",
      "Epoch [1/10], Step [709/750], Loss: 0.1181\n",
      "Epoch [1/10], Step [710/750], Loss: 0.3981\n",
      "Epoch [1/10], Step [711/750], Loss: 0.3414\n",
      "Epoch [1/10], Step [712/750], Loss: 0.2312\n",
      "Epoch [1/10], Step [713/750], Loss: 0.3464\n",
      "Epoch [1/10], Step [714/750], Loss: 0.2834\n",
      "Epoch [1/10], Step [715/750], Loss: 0.2694\n",
      "Epoch [1/10], Step [716/750], Loss: 0.3557\n",
      "Epoch [1/10], Step [717/750], Loss: 0.2221\n",
      "Epoch [1/10], Step [718/750], Loss: 0.4550\n",
      "Epoch [1/10], Step [719/750], Loss: 0.1620\n",
      "Epoch [1/10], Step [720/750], Loss: 0.2917\n",
      "Epoch [1/10], Step [721/750], Loss: 0.3352\n",
      "Epoch [1/10], Step [722/750], Loss: 0.2796\n",
      "Epoch [1/10], Step [723/750], Loss: 0.3181\n",
      "Epoch [1/10], Step [724/750], Loss: 0.2773\n",
      "Epoch [1/10], Step [725/750], Loss: 0.4912\n",
      "Epoch [1/10], Step [726/750], Loss: 0.2356\n",
      "Epoch [1/10], Step [727/750], Loss: 0.3616\n",
      "Epoch [1/10], Step [728/750], Loss: 0.4050\n",
      "Epoch [1/10], Step [729/750], Loss: 0.2579\n",
      "Epoch [1/10], Step [730/750], Loss: 0.3827\n",
      "Epoch [1/10], Step [731/750], Loss: 0.2046\n",
      "Epoch [1/10], Step [732/750], Loss: 0.3640\n",
      "Epoch [1/10], Step [733/750], Loss: 0.1430\n",
      "Epoch [1/10], Step [734/750], Loss: 0.2295\n",
      "Epoch [1/10], Step [735/750], Loss: 0.3070\n",
      "Epoch [1/10], Step [736/750], Loss: 0.3135\n",
      "Epoch [1/10], Step [737/750], Loss: 0.2852\n",
      "Epoch [1/10], Step [738/750], Loss: 0.2507\n",
      "Epoch [1/10], Step [739/750], Loss: 0.2275\n",
      "Epoch [1/10], Step [740/750], Loss: 0.2754\n",
      "Epoch [1/10], Step [741/750], Loss: 0.2777\n",
      "Epoch [1/10], Step [742/750], Loss: 0.3599\n",
      "Epoch [1/10], Step [743/750], Loss: 0.2220\n",
      "Epoch [1/10], Step [744/750], Loss: 0.2777\n",
      "Epoch [1/10], Step [745/750], Loss: 0.1774\n",
      "Epoch [1/10], Step [746/750], Loss: 0.1750\n",
      "Epoch [1/10], Step [747/750], Loss: 0.2859\n",
      "Epoch [1/10], Step [748/750], Loss: 0.1167\n",
      "Epoch [1/10], Step [749/750], Loss: 0.2239\n",
      "Epoch [1/10], Step [750/750], Loss: 0.2412\n",
      "\n",
      "\n",
      "Epoch [2/10], Step [1/750], Loss: 0.2306\n",
      "Epoch [2/10], Step [2/750], Loss: 0.2264\n",
      "Epoch [2/10], Step [3/750], Loss: 0.1646\n",
      "Epoch [2/10], Step [4/750], Loss: 0.3287\n",
      "Epoch [2/10], Step [5/750], Loss: 0.1977\n",
      "Epoch [2/10], Step [6/750], Loss: 0.1133\n",
      "Epoch [2/10], Step [7/750], Loss: 0.1797\n",
      "Epoch [2/10], Step [8/750], Loss: 0.2409\n",
      "Epoch [2/10], Step [9/750], Loss: 0.1333\n",
      "Epoch [2/10], Step [10/750], Loss: 0.2028\n",
      "Epoch [2/10], Step [11/750], Loss: 0.4284\n",
      "Epoch [2/10], Step [12/750], Loss: 0.2238\n",
      "Epoch [2/10], Step [13/750], Loss: 0.3294\n",
      "Epoch [2/10], Step [14/750], Loss: 0.3216\n",
      "Epoch [2/10], Step [15/750], Loss: 0.3429\n",
      "Epoch [2/10], Step [16/750], Loss: 0.1958\n",
      "Epoch [2/10], Step [17/750], Loss: 0.1223\n",
      "Epoch [2/10], Step [18/750], Loss: 0.1792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [19/750], Loss: 0.1904\n",
      "Epoch [2/10], Step [20/750], Loss: 0.2470\n",
      "Epoch [2/10], Step [21/750], Loss: 0.1969\n",
      "Epoch [2/10], Step [22/750], Loss: 0.2551\n",
      "Epoch [2/10], Step [23/750], Loss: 0.3907\n",
      "Epoch [2/10], Step [24/750], Loss: 0.2097\n",
      "Epoch [2/10], Step [25/750], Loss: 0.2837\n",
      "Epoch [2/10], Step [26/750], Loss: 0.1640\n",
      "Epoch [2/10], Step [27/750], Loss: 0.1918\n",
      "Epoch [2/10], Step [28/750], Loss: 0.2699\n",
      "Epoch [2/10], Step [29/750], Loss: 0.2699\n",
      "Epoch [2/10], Step [30/750], Loss: 0.2024\n",
      "Epoch [2/10], Step [31/750], Loss: 0.2806\n",
      "Epoch [2/10], Step [32/750], Loss: 0.1683\n",
      "Epoch [2/10], Step [33/750], Loss: 0.2571\n",
      "Epoch [2/10], Step [34/750], Loss: 0.3458\n",
      "Epoch [2/10], Step [35/750], Loss: 0.2169\n",
      "Epoch [2/10], Step [36/750], Loss: 0.3032\n",
      "Epoch [2/10], Step [37/750], Loss: 0.1485\n",
      "Epoch [2/10], Step [38/750], Loss: 0.3964\n",
      "Epoch [2/10], Step [39/750], Loss: 0.2321\n",
      "Epoch [2/10], Step [40/750], Loss: 0.2198\n",
      "Epoch [2/10], Step [41/750], Loss: 0.2295\n",
      "Epoch [2/10], Step [42/750], Loss: 0.1917\n",
      "Epoch [2/10], Step [43/750], Loss: 0.2196\n",
      "Epoch [2/10], Step [44/750], Loss: 0.2457\n",
      "Epoch [2/10], Step [45/750], Loss: 0.2992\n",
      "Epoch [2/10], Step [46/750], Loss: 0.2901\n",
      "Epoch [2/10], Step [47/750], Loss: 0.2994\n",
      "Epoch [2/10], Step [48/750], Loss: 0.2389\n",
      "Epoch [2/10], Step [49/750], Loss: 0.2421\n",
      "Epoch [2/10], Step [50/750], Loss: 0.3135\n",
      "Epoch [2/10], Step [51/750], Loss: 0.2551\n",
      "Epoch [2/10], Step [52/750], Loss: 0.1678\n",
      "Epoch [2/10], Step [53/750], Loss: 0.1834\n",
      "Epoch [2/10], Step [54/750], Loss: 0.2490\n",
      "Epoch [2/10], Step [55/750], Loss: 0.3086\n",
      "Epoch [2/10], Step [56/750], Loss: 0.2668\n",
      "Epoch [2/10], Step [57/750], Loss: 0.2290\n",
      "Epoch [2/10], Step [58/750], Loss: 0.2975\n",
      "Epoch [2/10], Step [59/750], Loss: 0.1410\n",
      "Epoch [2/10], Step [60/750], Loss: 0.2140\n",
      "Epoch [2/10], Step [61/750], Loss: 0.2254\n",
      "Epoch [2/10], Step [62/750], Loss: 0.2199\n",
      "Epoch [2/10], Step [63/750], Loss: 0.2544\n",
      "Epoch [2/10], Step [64/750], Loss: 0.2512\n",
      "Epoch [2/10], Step [65/750], Loss: 0.1776\n",
      "Epoch [2/10], Step [66/750], Loss: 0.2261\n",
      "Epoch [2/10], Step [67/750], Loss: 0.2056\n",
      "Epoch [2/10], Step [68/750], Loss: 0.1310\n",
      "Epoch [2/10], Step [69/750], Loss: 0.2968\n",
      "Epoch [2/10], Step [70/750], Loss: 0.2245\n",
      "Epoch [2/10], Step [71/750], Loss: 0.2418\n",
      "Epoch [2/10], Step [72/750], Loss: 0.2607\n",
      "Epoch [2/10], Step [73/750], Loss: 0.2274\n",
      "Epoch [2/10], Step [74/750], Loss: 0.2666\n",
      "Epoch [2/10], Step [75/750], Loss: 0.1792\n",
      "Epoch [2/10], Step [76/750], Loss: 0.3473\n",
      "Epoch [2/10], Step [77/750], Loss: 0.2703\n",
      "Epoch [2/10], Step [78/750], Loss: 0.2776\n",
      "Epoch [2/10], Step [79/750], Loss: 0.2237\n",
      "Epoch [2/10], Step [80/750], Loss: 0.1543\n",
      "Epoch [2/10], Step [81/750], Loss: 0.2476\n",
      "Epoch [2/10], Step [82/750], Loss: 0.2086\n",
      "Epoch [2/10], Step [83/750], Loss: 0.1655\n",
      "Epoch [2/10], Step [84/750], Loss: 0.1011\n",
      "Epoch [2/10], Step [85/750], Loss: 0.1560\n",
      "Epoch [2/10], Step [86/750], Loss: 0.1758\n",
      "Epoch [2/10], Step [87/750], Loss: 0.1846\n",
      "Epoch [2/10], Step [88/750], Loss: 0.2538\n",
      "Epoch [2/10], Step [89/750], Loss: 0.1783\n",
      "Epoch [2/10], Step [90/750], Loss: 0.2109\n",
      "Epoch [2/10], Step [91/750], Loss: 0.2636\n",
      "Epoch [2/10], Step [92/750], Loss: 0.2699\n",
      "Epoch [2/10], Step [93/750], Loss: 0.1188\n",
      "Epoch [2/10], Step [94/750], Loss: 0.1422\n",
      "Epoch [2/10], Step [95/750], Loss: 0.2438\n",
      "Epoch [2/10], Step [96/750], Loss: 0.0993\n",
      "Epoch [2/10], Step [97/750], Loss: 0.2328\n",
      "Epoch [2/10], Step [98/750], Loss: 0.1760\n",
      "Epoch [2/10], Step [99/750], Loss: 0.2078\n",
      "Epoch [2/10], Step [100/750], Loss: 0.1583\n",
      "Epoch [2/10], Step [101/750], Loss: 0.2642\n",
      "Epoch [2/10], Step [102/750], Loss: 0.2366\n",
      "Epoch [2/10], Step [103/750], Loss: 0.2222\n",
      "Epoch [2/10], Step [104/750], Loss: 0.2138\n",
      "Epoch [2/10], Step [105/750], Loss: 0.0725\n",
      "Epoch [2/10], Step [106/750], Loss: 0.2925\n",
      "Epoch [2/10], Step [107/750], Loss: 0.1302\n",
      "Epoch [2/10], Step [108/750], Loss: 0.2529\n",
      "Epoch [2/10], Step [109/750], Loss: 0.1119\n",
      "Epoch [2/10], Step [110/750], Loss: 0.1684\n",
      "Epoch [2/10], Step [111/750], Loss: 0.3384\n",
      "Epoch [2/10], Step [112/750], Loss: 0.0736\n",
      "Epoch [2/10], Step [113/750], Loss: 0.2198\n",
      "Epoch [2/10], Step [114/750], Loss: 0.1351\n",
      "Epoch [2/10], Step [115/750], Loss: 0.1551\n",
      "Epoch [2/10], Step [116/750], Loss: 0.1057\n",
      "Epoch [2/10], Step [117/750], Loss: 0.2662\n",
      "Epoch [2/10], Step [118/750], Loss: 0.1300\n",
      "Epoch [2/10], Step [119/750], Loss: 0.2046\n",
      "Epoch [2/10], Step [120/750], Loss: 0.1754\n",
      "Epoch [2/10], Step [121/750], Loss: 0.1666\n",
      "Epoch [2/10], Step [122/750], Loss: 0.2024\n",
      "Epoch [2/10], Step [123/750], Loss: 0.2066\n",
      "Epoch [2/10], Step [124/750], Loss: 0.2554\n",
      "Epoch [2/10], Step [125/750], Loss: 0.1480\n",
      "Epoch [2/10], Step [126/750], Loss: 0.1440\n",
      "Epoch [2/10], Step [127/750], Loss: 0.1236\n",
      "Epoch [2/10], Step [128/750], Loss: 0.1935\n",
      "Epoch [2/10], Step [129/750], Loss: 0.1876\n",
      "Epoch [2/10], Step [130/750], Loss: 0.2471\n",
      "Epoch [2/10], Step [131/750], Loss: 0.2682\n",
      "Epoch [2/10], Step [132/750], Loss: 0.2758\n",
      "Epoch [2/10], Step [133/750], Loss: 0.1604\n",
      "Epoch [2/10], Step [134/750], Loss: 0.2405\n",
      "Epoch [2/10], Step [135/750], Loss: 0.1914\n",
      "Epoch [2/10], Step [136/750], Loss: 0.3519\n",
      "Epoch [2/10], Step [137/750], Loss: 0.1648\n",
      "Epoch [2/10], Step [138/750], Loss: 0.1887\n",
      "Epoch [2/10], Step [139/750], Loss: 0.1559\n",
      "Epoch [2/10], Step [140/750], Loss: 0.1947\n",
      "Epoch [2/10], Step [141/750], Loss: 0.1539\n",
      "Epoch [2/10], Step [142/750], Loss: 0.2371\n",
      "Epoch [2/10], Step [143/750], Loss: 0.1604\n",
      "Epoch [2/10], Step [144/750], Loss: 0.3060\n",
      "Epoch [2/10], Step [145/750], Loss: 0.1795\n",
      "Epoch [2/10], Step [146/750], Loss: 0.1675\n",
      "Epoch [2/10], Step [147/750], Loss: 0.1863\n",
      "Epoch [2/10], Step [148/750], Loss: 0.1797\n",
      "Epoch [2/10], Step [149/750], Loss: 0.1477\n",
      "Epoch [2/10], Step [150/750], Loss: 0.1189\n",
      "Epoch [2/10], Step [151/750], Loss: 0.2016\n",
      "Epoch [2/10], Step [152/750], Loss: 0.2298\n",
      "Epoch [2/10], Step [153/750], Loss: 0.2411\n",
      "Epoch [2/10], Step [154/750], Loss: 0.1542\n",
      "Epoch [2/10], Step [155/750], Loss: 0.1516\n",
      "Epoch [2/10], Step [156/750], Loss: 0.0626\n",
      "Epoch [2/10], Step [157/750], Loss: 0.1977\n",
      "Epoch [2/10], Step [158/750], Loss: 0.1769\n",
      "Epoch [2/10], Step [159/750], Loss: 0.1914\n",
      "Epoch [2/10], Step [160/750], Loss: 0.1144\n",
      "Epoch [2/10], Step [161/750], Loss: 0.2082\n",
      "Epoch [2/10], Step [162/750], Loss: 0.2405\n",
      "Epoch [2/10], Step [163/750], Loss: 0.1366\n",
      "Epoch [2/10], Step [164/750], Loss: 0.0970\n",
      "Epoch [2/10], Step [165/750], Loss: 0.1551\n",
      "Epoch [2/10], Step [166/750], Loss: 0.1594\n",
      "Epoch [2/10], Step [167/750], Loss: 0.1697\n",
      "Epoch [2/10], Step [168/750], Loss: 0.2744\n",
      "Epoch [2/10], Step [169/750], Loss: 0.1876\n",
      "Epoch [2/10], Step [170/750], Loss: 0.2470\n",
      "Epoch [2/10], Step [171/750], Loss: 0.2127\n",
      "Epoch [2/10], Step [172/750], Loss: 0.1840\n",
      "Epoch [2/10], Step [173/750], Loss: 0.1102\n",
      "Epoch [2/10], Step [174/750], Loss: 0.1987\n",
      "Epoch [2/10], Step [175/750], Loss: 0.2598\n",
      "Epoch [2/10], Step [176/750], Loss: 0.2089\n",
      "Epoch [2/10], Step [177/750], Loss: 0.1772\n",
      "Epoch [2/10], Step [178/750], Loss: 0.2472\n",
      "Epoch [2/10], Step [179/750], Loss: 0.1097\n",
      "Epoch [2/10], Step [180/750], Loss: 0.2378\n",
      "Epoch [2/10], Step [181/750], Loss: 0.1919\n",
      "Epoch [2/10], Step [182/750], Loss: 0.0972\n",
      "Epoch [2/10], Step [183/750], Loss: 0.1950\n",
      "Epoch [2/10], Step [184/750], Loss: 0.1693\n",
      "Epoch [2/10], Step [185/750], Loss: 0.1336\n",
      "Epoch [2/10], Step [186/750], Loss: 0.1471\n",
      "Epoch [2/10], Step [187/750], Loss: 0.1788\n",
      "Epoch [2/10], Step [188/750], Loss: 0.1190\n",
      "Epoch [2/10], Step [189/750], Loss: 0.2885\n",
      "Epoch [2/10], Step [190/750], Loss: 0.3597\n",
      "Epoch [2/10], Step [191/750], Loss: 0.1958\n",
      "Epoch [2/10], Step [192/750], Loss: 0.1550\n",
      "Epoch [2/10], Step [193/750], Loss: 0.0415\n",
      "Epoch [2/10], Step [194/750], Loss: 0.1736\n",
      "Epoch [2/10], Step [195/750], Loss: 0.1897\n",
      "Epoch [2/10], Step [196/750], Loss: 0.2021\n",
      "Epoch [2/10], Step [197/750], Loss: 0.1675\n",
      "Epoch [2/10], Step [198/750], Loss: 0.1687\n",
      "Epoch [2/10], Step [199/750], Loss: 0.1943\n",
      "Epoch [2/10], Step [200/750], Loss: 0.1994\n",
      "Epoch [2/10], Step [201/750], Loss: 0.1873\n",
      "Epoch [2/10], Step [202/750], Loss: 0.1505\n",
      "Epoch [2/10], Step [203/750], Loss: 0.2236\n",
      "Epoch [2/10], Step [204/750], Loss: 0.1151\n",
      "Epoch [2/10], Step [205/750], Loss: 0.2194\n",
      "Epoch [2/10], Step [206/750], Loss: 0.1402\n",
      "Epoch [2/10], Step [207/750], Loss: 0.1229\n",
      "Epoch [2/10], Step [208/750], Loss: 0.1032\n",
      "Epoch [2/10], Step [209/750], Loss: 0.1683\n",
      "Epoch [2/10], Step [210/750], Loss: 0.1441\n",
      "Epoch [2/10], Step [211/750], Loss: 0.1066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [212/750], Loss: 0.1046\n",
      "Epoch [2/10], Step [213/750], Loss: 0.0861\n",
      "Epoch [2/10], Step [214/750], Loss: 0.1569\n",
      "Epoch [2/10], Step [215/750], Loss: 0.2906\n",
      "Epoch [2/10], Step [216/750], Loss: 0.1742\n",
      "Epoch [2/10], Step [217/750], Loss: 0.0585\n",
      "Epoch [2/10], Step [218/750], Loss: 0.0781\n",
      "Epoch [2/10], Step [219/750], Loss: 0.1096\n",
      "Epoch [2/10], Step [220/750], Loss: 0.2526\n",
      "Epoch [2/10], Step [221/750], Loss: 0.0723\n",
      "Epoch [2/10], Step [222/750], Loss: 0.1298\n",
      "Epoch [2/10], Step [223/750], Loss: 0.1234\n",
      "Epoch [2/10], Step [224/750], Loss: 0.2062\n",
      "Epoch [2/10], Step [225/750], Loss: 0.1539\n",
      "Epoch [2/10], Step [226/750], Loss: 0.1556\n",
      "Epoch [2/10], Step [227/750], Loss: 0.2143\n",
      "Epoch [2/10], Step [228/750], Loss: 0.1553\n",
      "Epoch [2/10], Step [229/750], Loss: 0.1941\n",
      "Epoch [2/10], Step [230/750], Loss: 0.0609\n",
      "Epoch [2/10], Step [231/750], Loss: 0.2267\n",
      "Epoch [2/10], Step [232/750], Loss: 0.1557\n",
      "Epoch [2/10], Step [233/750], Loss: 0.3113\n",
      "Epoch [2/10], Step [234/750], Loss: 0.1549\n",
      "Epoch [2/10], Step [235/750], Loss: 0.1318\n",
      "Epoch [2/10], Step [236/750], Loss: 0.2174\n",
      "Epoch [2/10], Step [237/750], Loss: 0.3182\n",
      "Epoch [2/10], Step [238/750], Loss: 0.1379\n",
      "Epoch [2/10], Step [239/750], Loss: 0.1063\n",
      "Epoch [2/10], Step [240/750], Loss: 0.1730\n",
      "Epoch [2/10], Step [241/750], Loss: 0.0437\n",
      "Epoch [2/10], Step [242/750], Loss: 0.1457\n",
      "Epoch [2/10], Step [243/750], Loss: 0.1103\n",
      "Epoch [2/10], Step [244/750], Loss: 0.1774\n",
      "Epoch [2/10], Step [245/750], Loss: 0.0745\n",
      "Epoch [2/10], Step [246/750], Loss: 0.1578\n",
      "Epoch [2/10], Step [247/750], Loss: 0.1214\n",
      "Epoch [2/10], Step [248/750], Loss: 0.2059\n",
      "Epoch [2/10], Step [249/750], Loss: 0.0886\n",
      "Epoch [2/10], Step [250/750], Loss: 0.1406\n",
      "Epoch [2/10], Step [251/750], Loss: 0.1825\n",
      "Epoch [2/10], Step [252/750], Loss: 0.1493\n",
      "Epoch [2/10], Step [253/750], Loss: 0.1871\n",
      "Epoch [2/10], Step [254/750], Loss: 0.1556\n",
      "Epoch [2/10], Step [255/750], Loss: 0.1167\n",
      "Epoch [2/10], Step [256/750], Loss: 0.2420\n",
      "Epoch [2/10], Step [257/750], Loss: 0.1069\n",
      "Epoch [2/10], Step [258/750], Loss: 0.1685\n",
      "Epoch [2/10], Step [259/750], Loss: 0.1140\n",
      "Epoch [2/10], Step [260/750], Loss: 0.0571\n",
      "Epoch [2/10], Step [261/750], Loss: 0.0946\n",
      "Epoch [2/10], Step [262/750], Loss: 0.1806\n",
      "Epoch [2/10], Step [263/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [264/750], Loss: 0.0686\n",
      "Epoch [2/10], Step [265/750], Loss: 0.1469\n",
      "Epoch [2/10], Step [266/750], Loss: 0.2378\n",
      "Epoch [2/10], Step [267/750], Loss: 0.2791\n",
      "Epoch [2/10], Step [268/750], Loss: 0.1841\n",
      "Epoch [2/10], Step [269/750], Loss: 0.0843\n",
      "Epoch [2/10], Step [270/750], Loss: 0.1381\n",
      "Epoch [2/10], Step [271/750], Loss: 0.1475\n",
      "Epoch [2/10], Step [272/750], Loss: 0.1553\n",
      "Epoch [2/10], Step [273/750], Loss: 0.2252\n",
      "Epoch [2/10], Step [274/750], Loss: 0.1443\n",
      "Epoch [2/10], Step [275/750], Loss: 0.1228\n",
      "Epoch [2/10], Step [276/750], Loss: 0.2335\n",
      "Epoch [2/10], Step [277/750], Loss: 0.1210\n",
      "Epoch [2/10], Step [278/750], Loss: 0.1997\n",
      "Epoch [2/10], Step [279/750], Loss: 0.1419\n",
      "Epoch [2/10], Step [280/750], Loss: 0.0831\n",
      "Epoch [2/10], Step [281/750], Loss: 0.1727\n",
      "Epoch [2/10], Step [282/750], Loss: 0.1441\n",
      "Epoch [2/10], Step [283/750], Loss: 0.0768\n",
      "Epoch [2/10], Step [284/750], Loss: 0.1005\n",
      "Epoch [2/10], Step [285/750], Loss: 0.2009\n",
      "Epoch [2/10], Step [286/750], Loss: 0.0718\n",
      "Epoch [2/10], Step [287/750], Loss: 0.1170\n",
      "Epoch [2/10], Step [288/750], Loss: 0.0867\n",
      "Epoch [2/10], Step [289/750], Loss: 0.1272\n",
      "Epoch [2/10], Step [290/750], Loss: 0.0937\n",
      "Epoch [2/10], Step [291/750], Loss: 0.0656\n",
      "Epoch [2/10], Step [292/750], Loss: 0.1030\n",
      "Epoch [2/10], Step [293/750], Loss: 0.1287\n",
      "Epoch [2/10], Step [294/750], Loss: 0.0776\n",
      "Epoch [2/10], Step [295/750], Loss: 0.0897\n",
      "Epoch [2/10], Step [296/750], Loss: 0.1024\n",
      "Epoch [2/10], Step [297/750], Loss: 0.2206\n",
      "Epoch [2/10], Step [298/750], Loss: 0.0886\n",
      "Epoch [2/10], Step [299/750], Loss: 0.1238\n",
      "Epoch [2/10], Step [300/750], Loss: 0.1768\n",
      "Epoch [2/10], Step [301/750], Loss: 0.1651\n",
      "Epoch [2/10], Step [302/750], Loss: 0.0880\n",
      "Epoch [2/10], Step [303/750], Loss: 0.1610\n",
      "Epoch [2/10], Step [304/750], Loss: 0.1196\n",
      "Epoch [2/10], Step [305/750], Loss: 0.1083\n",
      "Epoch [2/10], Step [306/750], Loss: 0.0968\n",
      "Epoch [2/10], Step [307/750], Loss: 0.1249\n",
      "Epoch [2/10], Step [308/750], Loss: 0.1732\n",
      "Epoch [2/10], Step [309/750], Loss: 0.2523\n",
      "Epoch [2/10], Step [310/750], Loss: 0.1171\n",
      "Epoch [2/10], Step [311/750], Loss: 0.1370\n",
      "Epoch [2/10], Step [312/750], Loss: 0.1142\n",
      "Epoch [2/10], Step [313/750], Loss: 0.2212\n",
      "Epoch [2/10], Step [314/750], Loss: 0.2147\n",
      "Epoch [2/10], Step [315/750], Loss: 0.1059\n",
      "Epoch [2/10], Step [316/750], Loss: 0.0916\n",
      "Epoch [2/10], Step [317/750], Loss: 0.0890\n",
      "Epoch [2/10], Step [318/750], Loss: 0.0847\n",
      "Epoch [2/10], Step [319/750], Loss: 0.1625\n",
      "Epoch [2/10], Step [320/750], Loss: 0.0483\n",
      "Epoch [2/10], Step [321/750], Loss: 0.1067\n",
      "Epoch [2/10], Step [322/750], Loss: 0.1386\n",
      "Epoch [2/10], Step [323/750], Loss: 0.0905\n",
      "Epoch [2/10], Step [324/750], Loss: 0.0843\n",
      "Epoch [2/10], Step [325/750], Loss: 0.0876\n",
      "Epoch [2/10], Step [326/750], Loss: 0.1389\n",
      "Epoch [2/10], Step [327/750], Loss: 0.0770\n",
      "Epoch [2/10], Step [328/750], Loss: 0.1946\n",
      "Epoch [2/10], Step [329/750], Loss: 0.0706\n",
      "Epoch [2/10], Step [330/750], Loss: 0.1588\n",
      "Epoch [2/10], Step [331/750], Loss: 0.1134\n",
      "Epoch [2/10], Step [332/750], Loss: 0.0344\n",
      "Epoch [2/10], Step [333/750], Loss: 0.1175\n",
      "Epoch [2/10], Step [334/750], Loss: 0.1653\n",
      "Epoch [2/10], Step [335/750], Loss: 0.0405\n",
      "Epoch [2/10], Step [336/750], Loss: 0.0923\n",
      "Epoch [2/10], Step [337/750], Loss: 0.1487\n",
      "Epoch [2/10], Step [338/750], Loss: 0.0989\n",
      "Epoch [2/10], Step [339/750], Loss: 0.1613\n",
      "Epoch [2/10], Step [340/750], Loss: 0.1471\n",
      "Epoch [2/10], Step [341/750], Loss: 0.1241\n",
      "Epoch [2/10], Step [342/750], Loss: 0.1351\n",
      "Epoch [2/10], Step [343/750], Loss: 0.1460\n",
      "Epoch [2/10], Step [344/750], Loss: 0.2157\n",
      "Epoch [2/10], Step [345/750], Loss: 0.0994\n",
      "Epoch [2/10], Step [346/750], Loss: 0.1182\n",
      "Epoch [2/10], Step [347/750], Loss: 0.1787\n",
      "Epoch [2/10], Step [348/750], Loss: 0.0669\n",
      "Epoch [2/10], Step [349/750], Loss: 0.0698\n",
      "Epoch [2/10], Step [350/750], Loss: 0.0651\n",
      "Epoch [2/10], Step [351/750], Loss: 0.1655\n",
      "Epoch [2/10], Step [352/750], Loss: 0.1933\n",
      "Epoch [2/10], Step [353/750], Loss: 0.1431\n",
      "Epoch [2/10], Step [354/750], Loss: 0.2121\n",
      "Epoch [2/10], Step [355/750], Loss: 0.2873\n",
      "Epoch [2/10], Step [356/750], Loss: 0.1488\n",
      "Epoch [2/10], Step [357/750], Loss: 0.0635\n",
      "Epoch [2/10], Step [358/750], Loss: 0.0960\n",
      "Epoch [2/10], Step [359/750], Loss: 0.0981\n",
      "Epoch [2/10], Step [360/750], Loss: 0.1267\n",
      "Epoch [2/10], Step [361/750], Loss: 0.1123\n",
      "Epoch [2/10], Step [362/750], Loss: 0.1011\n",
      "Epoch [2/10], Step [363/750], Loss: 0.2050\n",
      "Epoch [2/10], Step [364/750], Loss: 0.1557\n",
      "Epoch [2/10], Step [365/750], Loss: 0.1443\n",
      "Epoch [2/10], Step [366/750], Loss: 0.1832\n",
      "Epoch [2/10], Step [367/750], Loss: 0.1689\n",
      "Epoch [2/10], Step [368/750], Loss: 0.1142\n",
      "Epoch [2/10], Step [369/750], Loss: 0.1030\n",
      "Epoch [2/10], Step [370/750], Loss: 0.1581\n",
      "Epoch [2/10], Step [371/750], Loss: 0.2433\n",
      "Epoch [2/10], Step [372/750], Loss: 0.1681\n",
      "Epoch [2/10], Step [373/750], Loss: 0.1601\n",
      "Epoch [2/10], Step [374/750], Loss: 0.1376\n",
      "Epoch [2/10], Step [375/750], Loss: 0.0829\n",
      "Epoch [2/10], Step [376/750], Loss: 0.1174\n",
      "Epoch [2/10], Step [377/750], Loss: 0.1058\n",
      "Epoch [2/10], Step [378/750], Loss: 0.1059\n",
      "Epoch [2/10], Step [379/750], Loss: 0.1227\n",
      "Epoch [2/10], Step [380/750], Loss: 0.0594\n",
      "Epoch [2/10], Step [381/750], Loss: 0.0592\n",
      "Epoch [2/10], Step [382/750], Loss: 0.0472\n",
      "Epoch [2/10], Step [383/750], Loss: 0.1303\n",
      "Epoch [2/10], Step [384/750], Loss: 0.1217\n",
      "Epoch [2/10], Step [385/750], Loss: 0.2537\n",
      "Epoch [2/10], Step [386/750], Loss: 0.1355\n",
      "Epoch [2/10], Step [387/750], Loss: 0.2157\n",
      "Epoch [2/10], Step [388/750], Loss: 0.1461\n",
      "Epoch [2/10], Step [389/750], Loss: 0.1744\n",
      "Epoch [2/10], Step [390/750], Loss: 0.1485\n",
      "Epoch [2/10], Step [391/750], Loss: 0.0278\n",
      "Epoch [2/10], Step [392/750], Loss: 0.1310\n",
      "Epoch [2/10], Step [393/750], Loss: 0.3163\n",
      "Epoch [2/10], Step [394/750], Loss: 0.1215\n",
      "Epoch [2/10], Step [395/750], Loss: 0.0732\n",
      "Epoch [2/10], Step [396/750], Loss: 0.1220\n",
      "Epoch [2/10], Step [397/750], Loss: 0.1329\n",
      "Epoch [2/10], Step [398/750], Loss: 0.1026\n",
      "Epoch [2/10], Step [399/750], Loss: 0.1137\n",
      "Epoch [2/10], Step [400/750], Loss: 0.0644\n",
      "Epoch [2/10], Step [401/750], Loss: 0.1925\n",
      "Epoch [2/10], Step [402/750], Loss: 0.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [403/750], Loss: 0.1738\n",
      "Epoch [2/10], Step [404/750], Loss: 0.1876\n",
      "Epoch [2/10], Step [405/750], Loss: 0.1947\n",
      "Epoch [2/10], Step [406/750], Loss: 0.0978\n",
      "Epoch [2/10], Step [407/750], Loss: 0.0952\n",
      "Epoch [2/10], Step [408/750], Loss: 0.1366\n",
      "Epoch [2/10], Step [409/750], Loss: 0.1206\n",
      "Epoch [2/10], Step [410/750], Loss: 0.1181\n",
      "Epoch [2/10], Step [411/750], Loss: 0.1857\n",
      "Epoch [2/10], Step [412/750], Loss: 0.2928\n",
      "Epoch [2/10], Step [413/750], Loss: 0.0680\n",
      "Epoch [2/10], Step [414/750], Loss: 0.1216\n",
      "Epoch [2/10], Step [415/750], Loss: 0.0800\n",
      "Epoch [2/10], Step [416/750], Loss: 0.0754\n",
      "Epoch [2/10], Step [417/750], Loss: 0.1759\n",
      "Epoch [2/10], Step [418/750], Loss: 0.1098\n",
      "Epoch [2/10], Step [419/750], Loss: 0.0670\n",
      "Epoch [2/10], Step [420/750], Loss: 0.1037\n",
      "Epoch [2/10], Step [421/750], Loss: 0.1536\n",
      "Epoch [2/10], Step [422/750], Loss: 0.1013\n",
      "Epoch [2/10], Step [423/750], Loss: 0.1039\n",
      "Epoch [2/10], Step [424/750], Loss: 0.1073\n",
      "Epoch [2/10], Step [425/750], Loss: 0.2407\n",
      "Epoch [2/10], Step [426/750], Loss: 0.1575\n",
      "Epoch [2/10], Step [427/750], Loss: 0.0442\n",
      "Epoch [2/10], Step [428/750], Loss: 0.1859\n",
      "Epoch [2/10], Step [429/750], Loss: 0.1022\n",
      "Epoch [2/10], Step [430/750], Loss: 0.1111\n",
      "Epoch [2/10], Step [431/750], Loss: 0.1181\n",
      "Epoch [2/10], Step [432/750], Loss: 0.0947\n",
      "Epoch [2/10], Step [433/750], Loss: 0.1266\n",
      "Epoch [2/10], Step [434/750], Loss: 0.1077\n",
      "Epoch [2/10], Step [435/750], Loss: 0.1226\n",
      "Epoch [2/10], Step [436/750], Loss: 0.0856\n",
      "Epoch [2/10], Step [437/750], Loss: 0.3908\n",
      "Epoch [2/10], Step [438/750], Loss: 0.1682\n",
      "Epoch [2/10], Step [439/750], Loss: 0.0711\n",
      "Epoch [2/10], Step [440/750], Loss: 0.1949\n",
      "Epoch [2/10], Step [441/750], Loss: 0.1066\n",
      "Epoch [2/10], Step [442/750], Loss: 0.2017\n",
      "Epoch [2/10], Step [443/750], Loss: 0.0897\n",
      "Epoch [2/10], Step [444/750], Loss: 0.1469\n",
      "Epoch [2/10], Step [445/750], Loss: 0.1228\n",
      "Epoch [2/10], Step [446/750], Loss: 0.1314\n",
      "Epoch [2/10], Step [447/750], Loss: 0.2076\n",
      "Epoch [2/10], Step [448/750], Loss: 0.1706\n",
      "Epoch [2/10], Step [449/750], Loss: 0.2879\n",
      "Epoch [2/10], Step [450/750], Loss: 0.0966\n",
      "Epoch [2/10], Step [451/750], Loss: 0.0739\n",
      "Epoch [2/10], Step [452/750], Loss: 0.0691\n",
      "Epoch [2/10], Step [453/750], Loss: 0.0994\n",
      "Epoch [2/10], Step [454/750], Loss: 0.0936\n",
      "Epoch [2/10], Step [455/750], Loss: 0.0701\n",
      "Epoch [2/10], Step [456/750], Loss: 0.0395\n",
      "Epoch [2/10], Step [457/750], Loss: 0.1452\n",
      "Epoch [2/10], Step [458/750], Loss: 0.1191\n",
      "Epoch [2/10], Step [459/750], Loss: 0.1392\n",
      "Epoch [2/10], Step [460/750], Loss: 0.2004\n",
      "Epoch [2/10], Step [461/750], Loss: 0.1222\n",
      "Epoch [2/10], Step [462/750], Loss: 0.2269\n",
      "Epoch [2/10], Step [463/750], Loss: 0.2042\n",
      "Epoch [2/10], Step [464/750], Loss: 0.1216\n",
      "Epoch [2/10], Step [465/750], Loss: 0.1021\n",
      "Epoch [2/10], Step [466/750], Loss: 0.2993\n",
      "Epoch [2/10], Step [467/750], Loss: 0.1346\n",
      "Epoch [2/10], Step [468/750], Loss: 0.0834\n",
      "Epoch [2/10], Step [469/750], Loss: 0.1280\n",
      "Epoch [2/10], Step [470/750], Loss: 0.0817\n",
      "Epoch [2/10], Step [471/750], Loss: 0.1670\n",
      "Epoch [2/10], Step [472/750], Loss: 0.0604\n",
      "Epoch [2/10], Step [473/750], Loss: 0.2201\n",
      "Epoch [2/10], Step [474/750], Loss: 0.1353\n",
      "Epoch [2/10], Step [475/750], Loss: 0.1056\n",
      "Epoch [2/10], Step [476/750], Loss: 0.1136\n",
      "Epoch [2/10], Step [477/750], Loss: 0.1145\n",
      "Epoch [2/10], Step [478/750], Loss: 0.1421\n",
      "Epoch [2/10], Step [479/750], Loss: 0.1217\n",
      "Epoch [2/10], Step [480/750], Loss: 0.0968\n",
      "Epoch [2/10], Step [481/750], Loss: 0.2114\n",
      "Epoch [2/10], Step [482/750], Loss: 0.1506\n",
      "Epoch [2/10], Step [483/750], Loss: 0.1289\n",
      "Epoch [2/10], Step [484/750], Loss: 0.0927\n",
      "Epoch [2/10], Step [485/750], Loss: 0.0782\n",
      "Epoch [2/10], Step [486/750], Loss: 0.1823\n",
      "Epoch [2/10], Step [487/750], Loss: 0.1717\n",
      "Epoch [2/10], Step [488/750], Loss: 0.0405\n",
      "Epoch [2/10], Step [489/750], Loss: 0.0977\n",
      "Epoch [2/10], Step [490/750], Loss: 0.1366\n",
      "Epoch [2/10], Step [491/750], Loss: 0.0437\n",
      "Epoch [2/10], Step [492/750], Loss: 0.0736\n",
      "Epoch [2/10], Step [493/750], Loss: 0.1885\n",
      "Epoch [2/10], Step [494/750], Loss: 0.0876\n",
      "Epoch [2/10], Step [495/750], Loss: 0.3011\n",
      "Epoch [2/10], Step [496/750], Loss: 0.0975\n",
      "Epoch [2/10], Step [497/750], Loss: 0.1528\n",
      "Epoch [2/10], Step [498/750], Loss: 0.2981\n",
      "Epoch [2/10], Step [499/750], Loss: 0.2054\n",
      "Epoch [2/10], Step [500/750], Loss: 0.1034\n",
      "Epoch [2/10], Step [501/750], Loss: 0.1190\n",
      "Epoch [2/10], Step [502/750], Loss: 0.1947\n",
      "Epoch [2/10], Step [503/750], Loss: 0.1378\n",
      "Epoch [2/10], Step [504/750], Loss: 0.1782\n",
      "Epoch [2/10], Step [505/750], Loss: 0.1296\n",
      "Epoch [2/10], Step [506/750], Loss: 0.1893\n",
      "Epoch [2/10], Step [507/750], Loss: 0.1380\n",
      "Epoch [2/10], Step [508/750], Loss: 0.1459\n",
      "Epoch [2/10], Step [509/750], Loss: 0.0611\n",
      "Epoch [2/10], Step [510/750], Loss: 0.0942\n",
      "Epoch [2/10], Step [511/750], Loss: 0.1573\n",
      "Epoch [2/10], Step [512/750], Loss: 0.1396\n",
      "Epoch [2/10], Step [513/750], Loss: 0.0763\n",
      "Epoch [2/10], Step [514/750], Loss: 0.0616\n",
      "Epoch [2/10], Step [515/750], Loss: 0.1937\n",
      "Epoch [2/10], Step [516/750], Loss: 0.1163\n",
      "Epoch [2/10], Step [517/750], Loss: 0.1603\n",
      "Epoch [2/10], Step [518/750], Loss: 0.2887\n",
      "Epoch [2/10], Step [519/750], Loss: 0.2563\n",
      "Epoch [2/10], Step [520/750], Loss: 0.0688\n",
      "Epoch [2/10], Step [521/750], Loss: 0.1060\n",
      "Epoch [2/10], Step [522/750], Loss: 0.0366\n",
      "Epoch [2/10], Step [523/750], Loss: 0.1144\n",
      "Epoch [2/10], Step [524/750], Loss: 0.1707\n",
      "Epoch [2/10], Step [525/750], Loss: 0.2031\n",
      "Epoch [2/10], Step [526/750], Loss: 0.0865\n",
      "Epoch [2/10], Step [527/750], Loss: 0.1250\n",
      "Epoch [2/10], Step [528/750], Loss: 0.2297\n",
      "Epoch [2/10], Step [529/750], Loss: 0.0915\n",
      "Epoch [2/10], Step [530/750], Loss: 0.1224\n",
      "Epoch [2/10], Step [531/750], Loss: 0.0959\n",
      "Epoch [2/10], Step [532/750], Loss: 0.0763\n",
      "Epoch [2/10], Step [533/750], Loss: 0.1764\n",
      "Epoch [2/10], Step [534/750], Loss: 0.0781\n",
      "Epoch [2/10], Step [535/750], Loss: 0.1290\n",
      "Epoch [2/10], Step [536/750], Loss: 0.2008\n",
      "Epoch [2/10], Step [537/750], Loss: 0.1634\n",
      "Epoch [2/10], Step [538/750], Loss: 0.2314\n",
      "Epoch [2/10], Step [539/750], Loss: 0.0360\n",
      "Epoch [2/10], Step [540/750], Loss: 0.1532\n",
      "Epoch [2/10], Step [541/750], Loss: 0.0326\n",
      "Epoch [2/10], Step [542/750], Loss: 0.1416\n",
      "Epoch [2/10], Step [543/750], Loss: 0.1220\n",
      "Epoch [2/10], Step [544/750], Loss: 0.1722\n",
      "Epoch [2/10], Step [545/750], Loss: 0.0490\n",
      "Epoch [2/10], Step [546/750], Loss: 0.0601\n",
      "Epoch [2/10], Step [547/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [548/750], Loss: 0.1358\n",
      "Epoch [2/10], Step [549/750], Loss: 0.0909\n",
      "Epoch [2/10], Step [550/750], Loss: 0.1454\n",
      "Epoch [2/10], Step [551/750], Loss: 0.1528\n",
      "Epoch [2/10], Step [552/750], Loss: 0.1213\n",
      "Epoch [2/10], Step [553/750], Loss: 0.0624\n",
      "Epoch [2/10], Step [554/750], Loss: 0.2587\n",
      "Epoch [2/10], Step [555/750], Loss: 0.1786\n",
      "Epoch [2/10], Step [556/750], Loss: 0.1019\n",
      "Epoch [2/10], Step [557/750], Loss: 0.2533\n",
      "Epoch [2/10], Step [558/750], Loss: 0.1092\n",
      "Epoch [2/10], Step [559/750], Loss: 0.1390\n",
      "Epoch [2/10], Step [560/750], Loss: 0.1182\n",
      "Epoch [2/10], Step [561/750], Loss: 0.1157\n",
      "Epoch [2/10], Step [562/750], Loss: 0.2357\n",
      "Epoch [2/10], Step [563/750], Loss: 0.1262\n",
      "Epoch [2/10], Step [564/750], Loss: 0.1481\n",
      "Epoch [2/10], Step [565/750], Loss: 0.1380\n",
      "Epoch [2/10], Step [566/750], Loss: 0.0955\n",
      "Epoch [2/10], Step [567/750], Loss: 0.2446\n",
      "Epoch [2/10], Step [568/750], Loss: 0.1990\n",
      "Epoch [2/10], Step [569/750], Loss: 0.0490\n",
      "Epoch [2/10], Step [570/750], Loss: 0.0964\n",
      "Epoch [2/10], Step [571/750], Loss: 0.0636\n",
      "Epoch [2/10], Step [572/750], Loss: 0.0856\n",
      "Epoch [2/10], Step [573/750], Loss: 0.1477\n",
      "Epoch [2/10], Step [574/750], Loss: 0.1015\n",
      "Epoch [2/10], Step [575/750], Loss: 0.1701\n",
      "Epoch [2/10], Step [576/750], Loss: 0.3223\n",
      "Epoch [2/10], Step [577/750], Loss: 0.1186\n",
      "Epoch [2/10], Step [578/750], Loss: 0.1015\n",
      "Epoch [2/10], Step [579/750], Loss: 0.2570\n",
      "Epoch [2/10], Step [580/750], Loss: 0.3417\n",
      "Epoch [2/10], Step [581/750], Loss: 0.1284\n",
      "Epoch [2/10], Step [582/750], Loss: 0.1726\n",
      "Epoch [2/10], Step [583/750], Loss: 0.0621\n",
      "Epoch [2/10], Step [584/750], Loss: 0.0889\n",
      "Epoch [2/10], Step [585/750], Loss: 0.0261\n",
      "Epoch [2/10], Step [586/750], Loss: 0.1181\n",
      "Epoch [2/10], Step [587/750], Loss: 0.0848\n",
      "Epoch [2/10], Step [588/750], Loss: 0.1087\n",
      "Epoch [2/10], Step [589/750], Loss: 0.0425\n",
      "Epoch [2/10], Step [590/750], Loss: 0.0723\n",
      "Epoch [2/10], Step [591/750], Loss: 0.1128\n",
      "Epoch [2/10], Step [592/750], Loss: 0.2605\n",
      "Epoch [2/10], Step [593/750], Loss: 0.0869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [594/750], Loss: 0.0878\n",
      "Epoch [2/10], Step [595/750], Loss: 0.1967\n",
      "Epoch [2/10], Step [596/750], Loss: 0.1661\n",
      "Epoch [2/10], Step [597/750], Loss: 0.1337\n",
      "Epoch [2/10], Step [598/750], Loss: 0.1373\n",
      "Epoch [2/10], Step [599/750], Loss: 0.0702\n",
      "Epoch [2/10], Step [600/750], Loss: 0.0693\n",
      "Epoch [2/10], Step [601/750], Loss: 0.0449\n",
      "Epoch [2/10], Step [602/750], Loss: 0.0934\n",
      "Epoch [2/10], Step [603/750], Loss: 0.0918\n",
      "Epoch [2/10], Step [604/750], Loss: 0.2555\n",
      "Epoch [2/10], Step [605/750], Loss: 0.0386\n",
      "Epoch [2/10], Step [606/750], Loss: 0.1522\n",
      "Epoch [2/10], Step [607/750], Loss: 0.2560\n",
      "Epoch [2/10], Step [608/750], Loss: 0.0719\n",
      "Epoch [2/10], Step [609/750], Loss: 0.1132\n",
      "Epoch [2/10], Step [610/750], Loss: 0.2592\n",
      "Epoch [2/10], Step [611/750], Loss: 0.1382\n",
      "Epoch [2/10], Step [612/750], Loss: 0.2045\n",
      "Epoch [2/10], Step [613/750], Loss: 0.1390\n",
      "Epoch [2/10], Step [614/750], Loss: 0.1136\n",
      "Epoch [2/10], Step [615/750], Loss: 0.1981\n",
      "Epoch [2/10], Step [616/750], Loss: 0.1010\n",
      "Epoch [2/10], Step [617/750], Loss: 0.2530\n",
      "Epoch [2/10], Step [618/750], Loss: 0.0540\n",
      "Epoch [2/10], Step [619/750], Loss: 0.1110\n",
      "Epoch [2/10], Step [620/750], Loss: 0.2668\n",
      "Epoch [2/10], Step [621/750], Loss: 0.1387\n",
      "Epoch [2/10], Step [622/750], Loss: 0.1004\n",
      "Epoch [2/10], Step [623/750], Loss: 0.0975\n",
      "Epoch [2/10], Step [624/750], Loss: 0.0560\n",
      "Epoch [2/10], Step [625/750], Loss: 0.1401\n",
      "Epoch [2/10], Step [626/750], Loss: 0.1063\n",
      "Epoch [2/10], Step [627/750], Loss: 0.1360\n",
      "Epoch [2/10], Step [628/750], Loss: 0.1815\n",
      "Epoch [2/10], Step [629/750], Loss: 0.0886\n",
      "Epoch [2/10], Step [630/750], Loss: 0.0500\n",
      "Epoch [2/10], Step [631/750], Loss: 0.1272\n",
      "Epoch [2/10], Step [632/750], Loss: 0.2146\n",
      "Epoch [2/10], Step [633/750], Loss: 0.0480\n",
      "Epoch [2/10], Step [634/750], Loss: 0.0899\n",
      "Epoch [2/10], Step [635/750], Loss: 0.2195\n",
      "Epoch [2/10], Step [636/750], Loss: 0.1238\n",
      "Epoch [2/10], Step [637/750], Loss: 0.0745\n",
      "Epoch [2/10], Step [638/750], Loss: 0.1057\n",
      "Epoch [2/10], Step [639/750], Loss: 0.0792\n",
      "Epoch [2/10], Step [640/750], Loss: 0.1491\n",
      "Epoch [2/10], Step [641/750], Loss: 0.3044\n",
      "Epoch [2/10], Step [642/750], Loss: 0.0518\n",
      "Epoch [2/10], Step [643/750], Loss: 0.0916\n",
      "Epoch [2/10], Step [644/750], Loss: 0.1017\n",
      "Epoch [2/10], Step [645/750], Loss: 0.1621\n",
      "Epoch [2/10], Step [646/750], Loss: 0.1496\n",
      "Epoch [2/10], Step [647/750], Loss: 0.1914\n",
      "Epoch [2/10], Step [648/750], Loss: 0.1502\n",
      "Epoch [2/10], Step [649/750], Loss: 0.0834\n",
      "Epoch [2/10], Step [650/750], Loss: 0.1971\n",
      "Epoch [2/10], Step [651/750], Loss: 0.1331\n",
      "Epoch [2/10], Step [652/750], Loss: 0.0682\n",
      "Epoch [2/10], Step [653/750], Loss: 0.1748\n",
      "Epoch [2/10], Step [654/750], Loss: 0.1264\n",
      "Epoch [2/10], Step [655/750], Loss: 0.0892\n",
      "Epoch [2/10], Step [656/750], Loss: 0.2374\n",
      "Epoch [2/10], Step [657/750], Loss: 0.1448\n",
      "Epoch [2/10], Step [658/750], Loss: 0.0550\n",
      "Epoch [2/10], Step [659/750], Loss: 0.0536\n",
      "Epoch [2/10], Step [660/750], Loss: 0.0747\n",
      "Epoch [2/10], Step [661/750], Loss: 0.1576\n",
      "Epoch [2/10], Step [662/750], Loss: 0.1060\n",
      "Epoch [2/10], Step [663/750], Loss: 0.0395\n",
      "Epoch [2/10], Step [664/750], Loss: 0.0952\n",
      "Epoch [2/10], Step [665/750], Loss: 0.1625\n",
      "Epoch [2/10], Step [666/750], Loss: 0.1847\n",
      "Epoch [2/10], Step [667/750], Loss: 0.0901\n",
      "Epoch [2/10], Step [668/750], Loss: 0.0623\n",
      "Epoch [2/10], Step [669/750], Loss: 0.1198\n",
      "Epoch [2/10], Step [670/750], Loss: 0.1618\n",
      "Epoch [2/10], Step [671/750], Loss: 0.1208\n",
      "Epoch [2/10], Step [672/750], Loss: 0.1653\n",
      "Epoch [2/10], Step [673/750], Loss: 0.0718\n",
      "Epoch [2/10], Step [674/750], Loss: 0.0933\n",
      "Epoch [2/10], Step [675/750], Loss: 0.0353\n",
      "Epoch [2/10], Step [676/750], Loss: 0.0697\n",
      "Epoch [2/10], Step [677/750], Loss: 0.0835\n",
      "Epoch [2/10], Step [678/750], Loss: 0.0962\n",
      "Epoch [2/10], Step [679/750], Loss: 0.1020\n",
      "Epoch [2/10], Step [680/750], Loss: 0.1149\n",
      "Epoch [2/10], Step [681/750], Loss: 0.2679\n",
      "Epoch [2/10], Step [682/750], Loss: 0.1175\n",
      "Epoch [2/10], Step [683/750], Loss: 0.1562\n",
      "Epoch [2/10], Step [684/750], Loss: 0.1658\n",
      "Epoch [2/10], Step [685/750], Loss: 0.1773\n",
      "Epoch [2/10], Step [686/750], Loss: 0.1058\n",
      "Epoch [2/10], Step [687/750], Loss: 0.0126\n",
      "Epoch [2/10], Step [688/750], Loss: 0.1100\n",
      "Epoch [2/10], Step [689/750], Loss: 0.0664\n",
      "Epoch [2/10], Step [690/750], Loss: 0.0269\n",
      "Epoch [2/10], Step [691/750], Loss: 0.2087\n",
      "Epoch [2/10], Step [692/750], Loss: 0.0239\n",
      "Epoch [2/10], Step [693/750], Loss: 0.0838\n",
      "Epoch [2/10], Step [694/750], Loss: 0.0988\n",
      "Epoch [2/10], Step [695/750], Loss: 0.0554\n",
      "Epoch [2/10], Step [696/750], Loss: 0.0376\n",
      "Epoch [2/10], Step [697/750], Loss: 0.1750\n",
      "Epoch [2/10], Step [698/750], Loss: 0.1795\n",
      "Epoch [2/10], Step [699/750], Loss: 0.1453\n",
      "Epoch [2/10], Step [700/750], Loss: 0.0750\n",
      "Epoch [2/10], Step [701/750], Loss: 0.0812\n",
      "Epoch [2/10], Step [702/750], Loss: 0.1492\n",
      "Epoch [2/10], Step [703/750], Loss: 0.1811\n",
      "Epoch [2/10], Step [704/750], Loss: 0.0900\n",
      "Epoch [2/10], Step [705/750], Loss: 0.0976\n",
      "Epoch [2/10], Step [706/750], Loss: 0.0934\n",
      "Epoch [2/10], Step [707/750], Loss: 0.0517\n",
      "Epoch [2/10], Step [708/750], Loss: 0.0715\n",
      "Epoch [2/10], Step [709/750], Loss: 0.0512\n",
      "Epoch [2/10], Step [710/750], Loss: 0.0712\n",
      "Epoch [2/10], Step [711/750], Loss: 0.0813\n",
      "Epoch [2/10], Step [712/750], Loss: 0.1420\n",
      "Epoch [2/10], Step [713/750], Loss: 0.0848\n",
      "Epoch [2/10], Step [714/750], Loss: 0.1110\n",
      "Epoch [2/10], Step [715/750], Loss: 0.2083\n",
      "Epoch [2/10], Step [716/750], Loss: 0.0844\n",
      "Epoch [2/10], Step [717/750], Loss: 0.0321\n",
      "Epoch [2/10], Step [718/750], Loss: 0.0882\n",
      "Epoch [2/10], Step [719/750], Loss: 0.0246\n",
      "Epoch [2/10], Step [720/750], Loss: 0.1100\n",
      "Epoch [2/10], Step [721/750], Loss: 0.1834\n",
      "Epoch [2/10], Step [722/750], Loss: 0.0746\n",
      "Epoch [2/10], Step [723/750], Loss: 0.0920\n",
      "Epoch [2/10], Step [724/750], Loss: 0.1248\n",
      "Epoch [2/10], Step [725/750], Loss: 0.1054\n",
      "Epoch [2/10], Step [726/750], Loss: 0.0866\n",
      "Epoch [2/10], Step [727/750], Loss: 0.1057\n",
      "Epoch [2/10], Step [728/750], Loss: 0.0444\n",
      "Epoch [2/10], Step [729/750], Loss: 0.1319\n",
      "Epoch [2/10], Step [730/750], Loss: 0.0315\n",
      "Epoch [2/10], Step [731/750], Loss: 0.0738\n",
      "Epoch [2/10], Step [732/750], Loss: 0.0824\n",
      "Epoch [2/10], Step [733/750], Loss: 0.0847\n",
      "Epoch [2/10], Step [734/750], Loss: 0.1095\n",
      "Epoch [2/10], Step [735/750], Loss: 0.0875\n",
      "Epoch [2/10], Step [736/750], Loss: 0.2313\n",
      "Epoch [2/10], Step [737/750], Loss: 0.0833\n",
      "Epoch [2/10], Step [738/750], Loss: 0.0924\n",
      "Epoch [2/10], Step [739/750], Loss: 0.0713\n",
      "Epoch [2/10], Step [740/750], Loss: 0.0685\n",
      "Epoch [2/10], Step [741/750], Loss: 0.0986\n",
      "Epoch [2/10], Step [742/750], Loss: 0.1236\n",
      "Epoch [2/10], Step [743/750], Loss: 0.2687\n",
      "Epoch [2/10], Step [744/750], Loss: 0.1907\n",
      "Epoch [2/10], Step [745/750], Loss: 0.1019\n",
      "Epoch [2/10], Step [746/750], Loss: 0.0753\n",
      "Epoch [2/10], Step [747/750], Loss: 0.0804\n",
      "Epoch [2/10], Step [748/750], Loss: 0.1669\n",
      "Epoch [2/10], Step [749/750], Loss: 0.1426\n",
      "Epoch [2/10], Step [750/750], Loss: 0.0828\n",
      "\n",
      "\n",
      "Epoch [3/10], Step [1/750], Loss: 0.0910\n",
      "Epoch [3/10], Step [2/750], Loss: 0.1068\n",
      "Epoch [3/10], Step [3/750], Loss: 0.0768\n",
      "Epoch [3/10], Step [4/750], Loss: 0.1758\n",
      "Epoch [3/10], Step [5/750], Loss: 0.1340\n",
      "Epoch [3/10], Step [6/750], Loss: 0.0459\n",
      "Epoch [3/10], Step [7/750], Loss: 0.0972\n",
      "Epoch [3/10], Step [8/750], Loss: 0.1379\n",
      "Epoch [3/10], Step [9/750], Loss: 0.0566\n",
      "Epoch [3/10], Step [10/750], Loss: 0.1173\n",
      "Epoch [3/10], Step [11/750], Loss: 0.0869\n",
      "Epoch [3/10], Step [12/750], Loss: 0.1926\n",
      "Epoch [3/10], Step [13/750], Loss: 0.0493\n",
      "Epoch [3/10], Step [14/750], Loss: 0.1430\n",
      "Epoch [3/10], Step [15/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [16/750], Loss: 0.2715\n",
      "Epoch [3/10], Step [17/750], Loss: 0.0371\n",
      "Epoch [3/10], Step [18/750], Loss: 0.2040\n",
      "Epoch [3/10], Step [19/750], Loss: 0.0498\n",
      "Epoch [3/10], Step [20/750], Loss: 0.0515\n",
      "Epoch [3/10], Step [21/750], Loss: 0.1706\n",
      "Epoch [3/10], Step [22/750], Loss: 0.1082\n",
      "Epoch [3/10], Step [23/750], Loss: 0.0761\n",
      "Epoch [3/10], Step [24/750], Loss: 0.0328\n",
      "Epoch [3/10], Step [25/750], Loss: 0.0553\n",
      "Epoch [3/10], Step [26/750], Loss: 0.1289\n",
      "Epoch [3/10], Step [27/750], Loss: 0.0615\n",
      "Epoch [3/10], Step [28/750], Loss: 0.0542\n",
      "Epoch [3/10], Step [29/750], Loss: 0.1096\n",
      "Epoch [3/10], Step [30/750], Loss: 0.0924\n",
      "Epoch [3/10], Step [31/750], Loss: 0.0405\n",
      "Epoch [3/10], Step [32/750], Loss: 0.2764\n",
      "Epoch [3/10], Step [33/750], Loss: 0.1284\n",
      "Epoch [3/10], Step [34/750], Loss: 0.1573\n",
      "Epoch [3/10], Step [35/750], Loss: 0.0497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [36/750], Loss: 0.0916\n",
      "Epoch [3/10], Step [37/750], Loss: 0.1822\n",
      "Epoch [3/10], Step [38/750], Loss: 0.0600\n",
      "Epoch [3/10], Step [39/750], Loss: 0.1761\n",
      "Epoch [3/10], Step [40/750], Loss: 0.0463\n",
      "Epoch [3/10], Step [41/750], Loss: 0.0454\n",
      "Epoch [3/10], Step [42/750], Loss: 0.0927\n",
      "Epoch [3/10], Step [43/750], Loss: 0.1636\n",
      "Epoch [3/10], Step [44/750], Loss: 0.1590\n",
      "Epoch [3/10], Step [45/750], Loss: 0.1446\n",
      "Epoch [3/10], Step [46/750], Loss: 0.0429\n",
      "Epoch [3/10], Step [47/750], Loss: 0.0564\n",
      "Epoch [3/10], Step [48/750], Loss: 0.0339\n",
      "Epoch [3/10], Step [49/750], Loss: 0.0957\n",
      "Epoch [3/10], Step [50/750], Loss: 0.0980\n",
      "Epoch [3/10], Step [51/750], Loss: 0.0575\n",
      "Epoch [3/10], Step [52/750], Loss: 0.0913\n",
      "Epoch [3/10], Step [53/750], Loss: 0.1165\n",
      "Epoch [3/10], Step [54/750], Loss: 0.1674\n",
      "Epoch [3/10], Step [55/750], Loss: 0.0872\n",
      "Epoch [3/10], Step [56/750], Loss: 0.1405\n",
      "Epoch [3/10], Step [57/750], Loss: 0.0743\n",
      "Epoch [3/10], Step [58/750], Loss: 0.1028\n",
      "Epoch [3/10], Step [59/750], Loss: 0.1177\n",
      "Epoch [3/10], Step [60/750], Loss: 0.1757\n",
      "Epoch [3/10], Step [61/750], Loss: 0.0303\n",
      "Epoch [3/10], Step [62/750], Loss: 0.0524\n",
      "Epoch [3/10], Step [63/750], Loss: 0.1170\n",
      "Epoch [3/10], Step [64/750], Loss: 0.1855\n",
      "Epoch [3/10], Step [65/750], Loss: 0.1289\n",
      "Epoch [3/10], Step [66/750], Loss: 0.1192\n",
      "Epoch [3/10], Step [67/750], Loss: 0.1698\n",
      "Epoch [3/10], Step [68/750], Loss: 0.1325\n",
      "Epoch [3/10], Step [69/750], Loss: 0.1402\n",
      "Epoch [3/10], Step [70/750], Loss: 0.0855\n",
      "Epoch [3/10], Step [71/750], Loss: 0.0955\n",
      "Epoch [3/10], Step [72/750], Loss: 0.1231\n",
      "Epoch [3/10], Step [73/750], Loss: 0.1489\n",
      "Epoch [3/10], Step [74/750], Loss: 0.0781\n",
      "Epoch [3/10], Step [75/750], Loss: 0.1453\n",
      "Epoch [3/10], Step [76/750], Loss: 0.0535\n",
      "Epoch [3/10], Step [77/750], Loss: 0.0706\n",
      "Epoch [3/10], Step [78/750], Loss: 0.1479\n",
      "Epoch [3/10], Step [79/750], Loss: 0.0433\n",
      "Epoch [3/10], Step [80/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [81/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [82/750], Loss: 0.0759\n",
      "Epoch [3/10], Step [83/750], Loss: 0.0473\n",
      "Epoch [3/10], Step [84/750], Loss: 0.1146\n",
      "Epoch [3/10], Step [85/750], Loss: 0.0358\n",
      "Epoch [3/10], Step [86/750], Loss: 0.1662\n",
      "Epoch [3/10], Step [87/750], Loss: 0.0463\n",
      "Epoch [3/10], Step [88/750], Loss: 0.1426\n",
      "Epoch [3/10], Step [89/750], Loss: 0.0343\n",
      "Epoch [3/10], Step [90/750], Loss: 0.0791\n",
      "Epoch [3/10], Step [91/750], Loss: 0.0714\n",
      "Epoch [3/10], Step [92/750], Loss: 0.0742\n",
      "Epoch [3/10], Step [93/750], Loss: 0.1104\n",
      "Epoch [3/10], Step [94/750], Loss: 0.0752\n",
      "Epoch [3/10], Step [95/750], Loss: 0.0595\n",
      "Epoch [3/10], Step [96/750], Loss: 0.1222\n",
      "Epoch [3/10], Step [97/750], Loss: 0.0898\n",
      "Epoch [3/10], Step [98/750], Loss: 0.0533\n",
      "Epoch [3/10], Step [99/750], Loss: 0.0277\n",
      "Epoch [3/10], Step [100/750], Loss: 0.0859\n",
      "Epoch [3/10], Step [101/750], Loss: 0.0541\n",
      "Epoch [3/10], Step [102/750], Loss: 0.0554\n",
      "Epoch [3/10], Step [103/750], Loss: 0.1217\n",
      "Epoch [3/10], Step [104/750], Loss: 0.0635\n",
      "Epoch [3/10], Step [105/750], Loss: 0.0415\n",
      "Epoch [3/10], Step [106/750], Loss: 0.0291\n",
      "Epoch [3/10], Step [107/750], Loss: 0.0512\n",
      "Epoch [3/10], Step [108/750], Loss: 0.1453\n",
      "Epoch [3/10], Step [109/750], Loss: 0.1397\n",
      "Epoch [3/10], Step [110/750], Loss: 0.2446\n",
      "Epoch [3/10], Step [111/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [112/750], Loss: 0.0932\n",
      "Epoch [3/10], Step [113/750], Loss: 0.0655\n",
      "Epoch [3/10], Step [114/750], Loss: 0.0996\n",
      "Epoch [3/10], Step [115/750], Loss: 0.0199\n",
      "Epoch [3/10], Step [116/750], Loss: 0.0352\n",
      "Epoch [3/10], Step [117/750], Loss: 0.0363\n",
      "Epoch [3/10], Step [118/750], Loss: 0.0492\n",
      "Epoch [3/10], Step [119/750], Loss: 0.0796\n",
      "Epoch [3/10], Step [120/750], Loss: 0.0490\n",
      "Epoch [3/10], Step [121/750], Loss: 0.1045\n",
      "Epoch [3/10], Step [122/750], Loss: 0.2240\n",
      "Epoch [3/10], Step [123/750], Loss: 0.1753\n",
      "Epoch [3/10], Step [124/750], Loss: 0.0313\n",
      "Epoch [3/10], Step [125/750], Loss: 0.0750\n",
      "Epoch [3/10], Step [126/750], Loss: 0.0760\n",
      "Epoch [3/10], Step [127/750], Loss: 0.1288\n",
      "Epoch [3/10], Step [128/750], Loss: 0.0496\n",
      "Epoch [3/10], Step [129/750], Loss: 0.2793\n",
      "Epoch [3/10], Step [130/750], Loss: 0.0710\n",
      "Epoch [3/10], Step [131/750], Loss: 0.1279\n",
      "Epoch [3/10], Step [132/750], Loss: 0.2058\n",
      "Epoch [3/10], Step [133/750], Loss: 0.1132\n",
      "Epoch [3/10], Step [134/750], Loss: 0.1277\n",
      "Epoch [3/10], Step [135/750], Loss: 0.1065\n",
      "Epoch [3/10], Step [136/750], Loss: 0.0303\n",
      "Epoch [3/10], Step [137/750], Loss: 0.1781\n",
      "Epoch [3/10], Step [138/750], Loss: 0.1432\n",
      "Epoch [3/10], Step [139/750], Loss: 0.0496\n",
      "Epoch [3/10], Step [140/750], Loss: 0.0353\n",
      "Epoch [3/10], Step [141/750], Loss: 0.0414\n",
      "Epoch [3/10], Step [142/750], Loss: 0.0762\n",
      "Epoch [3/10], Step [143/750], Loss: 0.1707\n",
      "Epoch [3/10], Step [144/750], Loss: 0.0362\n",
      "Epoch [3/10], Step [145/750], Loss: 0.1186\n",
      "Epoch [3/10], Step [146/750], Loss: 0.0893\n",
      "Epoch [3/10], Step [147/750], Loss: 0.1691\n",
      "Epoch [3/10], Step [148/750], Loss: 0.0607\n",
      "Epoch [3/10], Step [149/750], Loss: 0.0992\n",
      "Epoch [3/10], Step [150/750], Loss: 0.2243\n",
      "Epoch [3/10], Step [151/750], Loss: 0.0630\n",
      "Epoch [3/10], Step [152/750], Loss: 0.0548\n",
      "Epoch [3/10], Step [153/750], Loss: 0.0788\n",
      "Epoch [3/10], Step [154/750], Loss: 0.0652\n",
      "Epoch [3/10], Step [155/750], Loss: 0.0359\n",
      "Epoch [3/10], Step [156/750], Loss: 0.1885\n",
      "Epoch [3/10], Step [157/750], Loss: 0.1356\n",
      "Epoch [3/10], Step [158/750], Loss: 0.0847\n",
      "Epoch [3/10], Step [159/750], Loss: 0.0625\n",
      "Epoch [3/10], Step [160/750], Loss: 0.1385\n",
      "Epoch [3/10], Step [161/750], Loss: 0.1231\n",
      "Epoch [3/10], Step [162/750], Loss: 0.0461\n",
      "Epoch [3/10], Step [163/750], Loss: 0.1233\n",
      "Epoch [3/10], Step [164/750], Loss: 0.1185\n",
      "Epoch [3/10], Step [165/750], Loss: 0.0946\n",
      "Epoch [3/10], Step [166/750], Loss: 0.1720\n",
      "Epoch [3/10], Step [167/750], Loss: 0.0269\n",
      "Epoch [3/10], Step [168/750], Loss: 0.0175\n",
      "Epoch [3/10], Step [169/750], Loss: 0.0273\n",
      "Epoch [3/10], Step [170/750], Loss: 0.0838\n",
      "Epoch [3/10], Step [171/750], Loss: 0.0838\n",
      "Epoch [3/10], Step [172/750], Loss: 0.0681\n",
      "Epoch [3/10], Step [173/750], Loss: 0.1783\n",
      "Epoch [3/10], Step [174/750], Loss: 0.1050\n",
      "Epoch [3/10], Step [175/750], Loss: 0.1283\n",
      "Epoch [3/10], Step [176/750], Loss: 0.0344\n",
      "Epoch [3/10], Step [177/750], Loss: 0.0420\n",
      "Epoch [3/10], Step [178/750], Loss: 0.2006\n",
      "Epoch [3/10], Step [179/750], Loss: 0.0431\n",
      "Epoch [3/10], Step [180/750], Loss: 0.0388\n",
      "Epoch [3/10], Step [181/750], Loss: 0.1231\n",
      "Epoch [3/10], Step [182/750], Loss: 0.1030\n",
      "Epoch [3/10], Step [183/750], Loss: 0.1099\n",
      "Epoch [3/10], Step [184/750], Loss: 0.0950\n",
      "Epoch [3/10], Step [185/750], Loss: 0.0569\n",
      "Epoch [3/10], Step [186/750], Loss: 0.1032\n",
      "Epoch [3/10], Step [187/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [188/750], Loss: 0.3447\n",
      "Epoch [3/10], Step [189/750], Loss: 0.0640\n",
      "Epoch [3/10], Step [190/750], Loss: 0.1470\n",
      "Epoch [3/10], Step [191/750], Loss: 0.1218\n",
      "Epoch [3/10], Step [192/750], Loss: 0.1285\n",
      "Epoch [3/10], Step [193/750], Loss: 0.0264\n",
      "Epoch [3/10], Step [194/750], Loss: 0.1592\n",
      "Epoch [3/10], Step [195/750], Loss: 0.0757\n",
      "Epoch [3/10], Step [196/750], Loss: 0.0663\n",
      "Epoch [3/10], Step [197/750], Loss: 0.0173\n",
      "Epoch [3/10], Step [198/750], Loss: 0.1755\n",
      "Epoch [3/10], Step [199/750], Loss: 0.0973\n",
      "Epoch [3/10], Step [200/750], Loss: 0.0450\n",
      "Epoch [3/10], Step [201/750], Loss: 0.1076\n",
      "Epoch [3/10], Step [202/750], Loss: 0.0799\n",
      "Epoch [3/10], Step [203/750], Loss: 0.0666\n",
      "Epoch [3/10], Step [204/750], Loss: 0.0671\n",
      "Epoch [3/10], Step [205/750], Loss: 0.1136\n",
      "Epoch [3/10], Step [206/750], Loss: 0.0520\n",
      "Epoch [3/10], Step [207/750], Loss: 0.0923\n",
      "Epoch [3/10], Step [208/750], Loss: 0.0854\n",
      "Epoch [3/10], Step [209/750], Loss: 0.1077\n",
      "Epoch [3/10], Step [210/750], Loss: 0.0549\n",
      "Epoch [3/10], Step [211/750], Loss: 0.1311\n",
      "Epoch [3/10], Step [212/750], Loss: 0.0750\n",
      "Epoch [3/10], Step [213/750], Loss: 0.0417\n",
      "Epoch [3/10], Step [214/750], Loss: 0.0998\n",
      "Epoch [3/10], Step [215/750], Loss: 0.0459\n",
      "Epoch [3/10], Step [216/750], Loss: 0.0422\n",
      "Epoch [3/10], Step [217/750], Loss: 0.0393\n",
      "Epoch [3/10], Step [218/750], Loss: 0.1682\n",
      "Epoch [3/10], Step [219/750], Loss: 0.1175\n",
      "Epoch [3/10], Step [220/750], Loss: 0.0615\n",
      "Epoch [3/10], Step [221/750], Loss: 0.1548\n",
      "Epoch [3/10], Step [222/750], Loss: 0.0949\n",
      "Epoch [3/10], Step [223/750], Loss: 0.0965\n",
      "Epoch [3/10], Step [224/750], Loss: 0.0583\n",
      "Epoch [3/10], Step [225/750], Loss: 0.0791\n",
      "Epoch [3/10], Step [226/750], Loss: 0.0741\n",
      "Epoch [3/10], Step [227/750], Loss: 0.0423\n",
      "Epoch [3/10], Step [228/750], Loss: 0.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [229/750], Loss: 0.0543\n",
      "Epoch [3/10], Step [230/750], Loss: 0.0518\n",
      "Epoch [3/10], Step [231/750], Loss: 0.0642\n",
      "Epoch [3/10], Step [232/750], Loss: 0.1012\n",
      "Epoch [3/10], Step [233/750], Loss: 0.0957\n",
      "Epoch [3/10], Step [234/750], Loss: 0.0287\n",
      "Epoch [3/10], Step [235/750], Loss: 0.1178\n",
      "Epoch [3/10], Step [236/750], Loss: 0.1777\n",
      "Epoch [3/10], Step [237/750], Loss: 0.1124\n",
      "Epoch [3/10], Step [238/750], Loss: 0.0345\n",
      "Epoch [3/10], Step [239/750], Loss: 0.0757\n",
      "Epoch [3/10], Step [240/750], Loss: 0.0645\n",
      "Epoch [3/10], Step [241/750], Loss: 0.1206\n",
      "Epoch [3/10], Step [242/750], Loss: 0.1167\n",
      "Epoch [3/10], Step [243/750], Loss: 0.0121\n",
      "Epoch [3/10], Step [244/750], Loss: 0.0961\n",
      "Epoch [3/10], Step [245/750], Loss: 0.0620\n",
      "Epoch [3/10], Step [246/750], Loss: 0.1768\n",
      "Epoch [3/10], Step [247/750], Loss: 0.0209\n",
      "Epoch [3/10], Step [248/750], Loss: 0.0176\n",
      "Epoch [3/10], Step [249/750], Loss: 0.0699\n",
      "Epoch [3/10], Step [250/750], Loss: 0.1638\n",
      "Epoch [3/10], Step [251/750], Loss: 0.2227\n",
      "Epoch [3/10], Step [252/750], Loss: 0.1029\n",
      "Epoch [3/10], Step [253/750], Loss: 0.0211\n",
      "Epoch [3/10], Step [254/750], Loss: 0.0594\n",
      "Epoch [3/10], Step [255/750], Loss: 0.0249\n",
      "Epoch [3/10], Step [256/750], Loss: 0.1790\n",
      "Epoch [3/10], Step [257/750], Loss: 0.0712\n",
      "Epoch [3/10], Step [258/750], Loss: 0.1353\n",
      "Epoch [3/10], Step [259/750], Loss: 0.2566\n",
      "Epoch [3/10], Step [260/750], Loss: 0.0829\n",
      "Epoch [3/10], Step [261/750], Loss: 0.0512\n",
      "Epoch [3/10], Step [262/750], Loss: 0.1054\n",
      "Epoch [3/10], Step [263/750], Loss: 0.0144\n",
      "Epoch [3/10], Step [264/750], Loss: 0.0381\n",
      "Epoch [3/10], Step [265/750], Loss: 0.1589\n",
      "Epoch [3/10], Step [266/750], Loss: 0.1328\n",
      "Epoch [3/10], Step [267/750], Loss: 0.0352\n",
      "Epoch [3/10], Step [268/750], Loss: 0.1612\n",
      "Epoch [3/10], Step [269/750], Loss: 0.0978\n",
      "Epoch [3/10], Step [270/750], Loss: 0.0530\n",
      "Epoch [3/10], Step [271/750], Loss: 0.0779\n",
      "Epoch [3/10], Step [272/750], Loss: 0.0974\n",
      "Epoch [3/10], Step [273/750], Loss: 0.1449\n",
      "Epoch [3/10], Step [274/750], Loss: 0.0336\n",
      "Epoch [3/10], Step [275/750], Loss: 0.1736\n",
      "Epoch [3/10], Step [276/750], Loss: 0.0138\n",
      "Epoch [3/10], Step [277/750], Loss: 0.1443\n",
      "Epoch [3/10], Step [278/750], Loss: 0.0327\n",
      "Epoch [3/10], Step [279/750], Loss: 0.0745\n",
      "Epoch [3/10], Step [280/750], Loss: 0.0529\n",
      "Epoch [3/10], Step [281/750], Loss: 0.0597\n",
      "Epoch [3/10], Step [282/750], Loss: 0.1040\n",
      "Epoch [3/10], Step [283/750], Loss: 0.0821\n",
      "Epoch [3/10], Step [284/750], Loss: 0.1637\n",
      "Epoch [3/10], Step [285/750], Loss: 0.1296\n",
      "Epoch [3/10], Step [286/750], Loss: 0.1056\n",
      "Epoch [3/10], Step [287/750], Loss: 0.0464\n",
      "Epoch [3/10], Step [288/750], Loss: 0.1960\n",
      "Epoch [3/10], Step [289/750], Loss: 0.0620\n",
      "Epoch [3/10], Step [290/750], Loss: 0.1216\n",
      "Epoch [3/10], Step [291/750], Loss: 0.2281\n",
      "Epoch [3/10], Step [292/750], Loss: 0.1608\n",
      "Epoch [3/10], Step [293/750], Loss: 0.0709\n",
      "Epoch [3/10], Step [294/750], Loss: 0.0608\n",
      "Epoch [3/10], Step [295/750], Loss: 0.1694\n",
      "Epoch [3/10], Step [296/750], Loss: 0.0818\n",
      "Epoch [3/10], Step [297/750], Loss: 0.1031\n",
      "Epoch [3/10], Step [298/750], Loss: 0.0683\n",
      "Epoch [3/10], Step [299/750], Loss: 0.1994\n",
      "Epoch [3/10], Step [300/750], Loss: 0.0323\n",
      "Epoch [3/10], Step [301/750], Loss: 0.0491\n",
      "Epoch [3/10], Step [302/750], Loss: 0.1749\n",
      "Epoch [3/10], Step [303/750], Loss: 0.0676\n",
      "Epoch [3/10], Step [304/750], Loss: 0.0836\n",
      "Epoch [3/10], Step [305/750], Loss: 0.0804\n",
      "Epoch [3/10], Step [306/750], Loss: 0.0640\n",
      "Epoch [3/10], Step [307/750], Loss: 0.0582\n",
      "Epoch [3/10], Step [308/750], Loss: 0.0168\n",
      "Epoch [3/10], Step [309/750], Loss: 0.0430\n",
      "Epoch [3/10], Step [310/750], Loss: 0.2067\n",
      "Epoch [3/10], Step [311/750], Loss: 0.1866\n",
      "Epoch [3/10], Step [312/750], Loss: 0.0874\n",
      "Epoch [3/10], Step [313/750], Loss: 0.1091\n",
      "Epoch [3/10], Step [314/750], Loss: 0.0808\n",
      "Epoch [3/10], Step [315/750], Loss: 0.0662\n",
      "Epoch [3/10], Step [316/750], Loss: 0.0294\n",
      "Epoch [3/10], Step [317/750], Loss: 0.1132\n",
      "Epoch [3/10], Step [318/750], Loss: 0.0823\n",
      "Epoch [3/10], Step [319/750], Loss: 0.0465\n",
      "Epoch [3/10], Step [320/750], Loss: 0.2340\n",
      "Epoch [3/10], Step [321/750], Loss: 0.1118\n",
      "Epoch [3/10], Step [322/750], Loss: 0.0159\n",
      "Epoch [3/10], Step [323/750], Loss: 0.0766\n",
      "Epoch [3/10], Step [324/750], Loss: 0.0633\n",
      "Epoch [3/10], Step [325/750], Loss: 0.0756\n",
      "Epoch [3/10], Step [326/750], Loss: 0.1763\n",
      "Epoch [3/10], Step [327/750], Loss: 0.1558\n",
      "Epoch [3/10], Step [328/750], Loss: 0.0445\n",
      "Epoch [3/10], Step [329/750], Loss: 0.1129\n",
      "Epoch [3/10], Step [330/750], Loss: 0.0848\n",
      "Epoch [3/10], Step [331/750], Loss: 0.0613\n",
      "Epoch [3/10], Step [332/750], Loss: 0.1841\n",
      "Epoch [3/10], Step [333/750], Loss: 0.0472\n",
      "Epoch [3/10], Step [334/750], Loss: 0.0475\n",
      "Epoch [3/10], Step [335/750], Loss: 0.1218\n",
      "Epoch [3/10], Step [336/750], Loss: 0.0950\n",
      "Epoch [3/10], Step [337/750], Loss: 0.0631\n",
      "Epoch [3/10], Step [338/750], Loss: 0.0226\n",
      "Epoch [3/10], Step [339/750], Loss: 0.0427\n",
      "Epoch [3/10], Step [340/750], Loss: 0.0534\n",
      "Epoch [3/10], Step [341/750], Loss: 0.1534\n",
      "Epoch [3/10], Step [342/750], Loss: 0.0811\n",
      "Epoch [3/10], Step [343/750], Loss: 0.0591\n",
      "Epoch [3/10], Step [344/750], Loss: 0.0753\n",
      "Epoch [3/10], Step [345/750], Loss: 0.0430\n",
      "Epoch [3/10], Step [346/750], Loss: 0.0510\n",
      "Epoch [3/10], Step [347/750], Loss: 0.1385\n",
      "Epoch [3/10], Step [348/750], Loss: 0.1458\n",
      "Epoch [3/10], Step [349/750], Loss: 0.1571\n",
      "Epoch [3/10], Step [350/750], Loss: 0.1385\n",
      "Epoch [3/10], Step [351/750], Loss: 0.0199\n",
      "Epoch [3/10], Step [352/750], Loss: 0.1077\n",
      "Epoch [3/10], Step [353/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [354/750], Loss: 0.0614\n",
      "Epoch [3/10], Step [355/750], Loss: 0.1798\n",
      "Epoch [3/10], Step [356/750], Loss: 0.0246\n",
      "Epoch [3/10], Step [357/750], Loss: 0.0234\n",
      "Epoch [3/10], Step [358/750], Loss: 0.0570\n",
      "Epoch [3/10], Step [359/750], Loss: 0.0236\n",
      "Epoch [3/10], Step [360/750], Loss: 0.0781\n",
      "Epoch [3/10], Step [361/750], Loss: 0.0772\n",
      "Epoch [3/10], Step [362/750], Loss: 0.1426\n",
      "Epoch [3/10], Step [363/750], Loss: 0.0399\n",
      "Epoch [3/10], Step [364/750], Loss: 0.0978\n",
      "Epoch [3/10], Step [365/750], Loss: 0.0352\n",
      "Epoch [3/10], Step [366/750], Loss: 0.0738\n",
      "Epoch [3/10], Step [367/750], Loss: 0.0453\n",
      "Epoch [3/10], Step [368/750], Loss: 0.1273\n",
      "Epoch [3/10], Step [369/750], Loss: 0.0581\n",
      "Epoch [3/10], Step [370/750], Loss: 0.0461\n",
      "Epoch [3/10], Step [371/750], Loss: 0.0517\n",
      "Epoch [3/10], Step [372/750], Loss: 0.1220\n",
      "Epoch [3/10], Step [373/750], Loss: 0.0235\n",
      "Epoch [3/10], Step [374/750], Loss: 0.0901\n",
      "Epoch [3/10], Step [375/750], Loss: 0.3272\n",
      "Epoch [3/10], Step [376/750], Loss: 0.0277\n",
      "Epoch [3/10], Step [377/750], Loss: 0.0472\n",
      "Epoch [3/10], Step [378/750], Loss: 0.0548\n",
      "Epoch [3/10], Step [379/750], Loss: 0.0787\n",
      "Epoch [3/10], Step [380/750], Loss: 0.0542\n",
      "Epoch [3/10], Step [381/750], Loss: 0.0823\n",
      "Epoch [3/10], Step [382/750], Loss: 0.2115\n",
      "Epoch [3/10], Step [383/750], Loss: 0.0760\n",
      "Epoch [3/10], Step [384/750], Loss: 0.1255\n",
      "Epoch [3/10], Step [385/750], Loss: 0.0881\n",
      "Epoch [3/10], Step [386/750], Loss: 0.1134\n",
      "Epoch [3/10], Step [387/750], Loss: 0.1096\n",
      "Epoch [3/10], Step [388/750], Loss: 0.1352\n",
      "Epoch [3/10], Step [389/750], Loss: 0.0244\n",
      "Epoch [3/10], Step [390/750], Loss: 0.1676\n",
      "Epoch [3/10], Step [391/750], Loss: 0.0597\n",
      "Epoch [3/10], Step [392/750], Loss: 0.1766\n",
      "Epoch [3/10], Step [393/750], Loss: 0.0573\n",
      "Epoch [3/10], Step [394/750], Loss: 0.0661\n",
      "Epoch [3/10], Step [395/750], Loss: 0.1099\n",
      "Epoch [3/10], Step [396/750], Loss: 0.1210\n",
      "Epoch [3/10], Step [397/750], Loss: 0.1101\n",
      "Epoch [3/10], Step [398/750], Loss: 0.1023\n",
      "Epoch [3/10], Step [399/750], Loss: 0.0692\n",
      "Epoch [3/10], Step [400/750], Loss: 0.0747\n",
      "Epoch [3/10], Step [401/750], Loss: 0.0148\n",
      "Epoch [3/10], Step [402/750], Loss: 0.1490\n",
      "Epoch [3/10], Step [403/750], Loss: 0.2201\n",
      "Epoch [3/10], Step [404/750], Loss: 0.0573\n",
      "Epoch [3/10], Step [405/750], Loss: 0.0415\n",
      "Epoch [3/10], Step [406/750], Loss: 0.0686\n",
      "Epoch [3/10], Step [407/750], Loss: 0.0885\n",
      "Epoch [3/10], Step [408/750], Loss: 0.1895\n",
      "Epoch [3/10], Step [409/750], Loss: 0.2046\n",
      "Epoch [3/10], Step [410/750], Loss: 0.1426\n",
      "Epoch [3/10], Step [411/750], Loss: 0.0444\n",
      "Epoch [3/10], Step [412/750], Loss: 0.1378\n",
      "Epoch [3/10], Step [413/750], Loss: 0.1107\n",
      "Epoch [3/10], Step [414/750], Loss: 0.0271\n",
      "Epoch [3/10], Step [415/750], Loss: 0.0202\n",
      "Epoch [3/10], Step [416/750], Loss: 0.1547\n",
      "Epoch [3/10], Step [417/750], Loss: 0.0952\n",
      "Epoch [3/10], Step [418/750], Loss: 0.0273\n",
      "Epoch [3/10], Step [419/750], Loss: 0.0663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [420/750], Loss: 0.0995\n",
      "Epoch [3/10], Step [421/750], Loss: 0.0847\n",
      "Epoch [3/10], Step [422/750], Loss: 0.1331\n",
      "Epoch [3/10], Step [423/750], Loss: 0.0272\n",
      "Epoch [3/10], Step [424/750], Loss: 0.0419\n",
      "Epoch [3/10], Step [425/750], Loss: 0.1092\n",
      "Epoch [3/10], Step [426/750], Loss: 0.1638\n",
      "Epoch [3/10], Step [427/750], Loss: 0.0463\n",
      "Epoch [3/10], Step [428/750], Loss: 0.0697\n",
      "Epoch [3/10], Step [429/750], Loss: 0.0345\n",
      "Epoch [3/10], Step [430/750], Loss: 0.1507\n",
      "Epoch [3/10], Step [431/750], Loss: 0.0331\n",
      "Epoch [3/10], Step [432/750], Loss: 0.0638\n",
      "Epoch [3/10], Step [433/750], Loss: 0.1492\n",
      "Epoch [3/10], Step [434/750], Loss: 0.0942\n",
      "Epoch [3/10], Step [435/750], Loss: 0.2812\n",
      "Epoch [3/10], Step [436/750], Loss: 0.1244\n",
      "Epoch [3/10], Step [437/750], Loss: 0.0293\n",
      "Epoch [3/10], Step [438/750], Loss: 0.1162\n",
      "Epoch [3/10], Step [439/750], Loss: 0.1088\n",
      "Epoch [3/10], Step [440/750], Loss: 0.0470\n",
      "Epoch [3/10], Step [441/750], Loss: 0.1156\n",
      "Epoch [3/10], Step [442/750], Loss: 0.1906\n",
      "Epoch [3/10], Step [443/750], Loss: 0.0553\n",
      "Epoch [3/10], Step [444/750], Loss: 0.1121\n",
      "Epoch [3/10], Step [445/750], Loss: 0.0550\n",
      "Epoch [3/10], Step [446/750], Loss: 0.0468\n",
      "Epoch [3/10], Step [447/750], Loss: 0.0406\n",
      "Epoch [3/10], Step [448/750], Loss: 0.0889\n",
      "Epoch [3/10], Step [449/750], Loss: 0.1007\n",
      "Epoch [3/10], Step [450/750], Loss: 0.1019\n",
      "Epoch [3/10], Step [451/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [452/750], Loss: 0.0686\n",
      "Epoch [3/10], Step [453/750], Loss: 0.0521\n",
      "Epoch [3/10], Step [454/750], Loss: 0.0555\n",
      "Epoch [3/10], Step [455/750], Loss: 0.1582\n",
      "Epoch [3/10], Step [456/750], Loss: 0.0738\n",
      "Epoch [3/10], Step [457/750], Loss: 0.1374\n",
      "Epoch [3/10], Step [458/750], Loss: 0.0821\n",
      "Epoch [3/10], Step [459/750], Loss: 0.0248\n",
      "Epoch [3/10], Step [460/750], Loss: 0.0635\n",
      "Epoch [3/10], Step [461/750], Loss: 0.0981\n",
      "Epoch [3/10], Step [462/750], Loss: 0.0847\n",
      "Epoch [3/10], Step [463/750], Loss: 0.0327\n",
      "Epoch [3/10], Step [464/750], Loss: 0.0498\n",
      "Epoch [3/10], Step [465/750], Loss: 0.0486\n",
      "Epoch [3/10], Step [466/750], Loss: 0.0747\n",
      "Epoch [3/10], Step [467/750], Loss: 0.0310\n",
      "Epoch [3/10], Step [468/750], Loss: 0.0468\n",
      "Epoch [3/10], Step [469/750], Loss: 0.1808\n",
      "Epoch [3/10], Step [470/750], Loss: 0.0724\n",
      "Epoch [3/10], Step [471/750], Loss: 0.0534\n",
      "Epoch [3/10], Step [472/750], Loss: 0.0977\n",
      "Epoch [3/10], Step [473/750], Loss: 0.0878\n",
      "Epoch [3/10], Step [474/750], Loss: 0.0365\n",
      "Epoch [3/10], Step [475/750], Loss: 0.0513\n",
      "Epoch [3/10], Step [476/750], Loss: 0.0811\n",
      "Epoch [3/10], Step [477/750], Loss: 0.2312\n",
      "Epoch [3/10], Step [478/750], Loss: 0.1353\n",
      "Epoch [3/10], Step [479/750], Loss: 0.0452\n",
      "Epoch [3/10], Step [480/750], Loss: 0.0270\n",
      "Epoch [3/10], Step [481/750], Loss: 0.2230\n",
      "Epoch [3/10], Step [482/750], Loss: 0.1255\n",
      "Epoch [3/10], Step [483/750], Loss: 0.0889\n",
      "Epoch [3/10], Step [484/750], Loss: 0.0838\n",
      "Epoch [3/10], Step [485/750], Loss: 0.0258\n",
      "Epoch [3/10], Step [486/750], Loss: 0.1026\n",
      "Epoch [3/10], Step [487/750], Loss: 0.0777\n",
      "Epoch [3/10], Step [488/750], Loss: 0.0808\n",
      "Epoch [3/10], Step [489/750], Loss: 0.0688\n",
      "Epoch [3/10], Step [490/750], Loss: 0.0100\n",
      "Epoch [3/10], Step [491/750], Loss: 0.0301\n",
      "Epoch [3/10], Step [492/750], Loss: 0.0545\n",
      "Epoch [3/10], Step [493/750], Loss: 0.1044\n",
      "Epoch [3/10], Step [494/750], Loss: 0.1181\n",
      "Epoch [3/10], Step [495/750], Loss: 0.2431\n",
      "Epoch [3/10], Step [496/750], Loss: 0.1130\n",
      "Epoch [3/10], Step [497/750], Loss: 0.1310\n",
      "Epoch [3/10], Step [498/750], Loss: 0.2680\n",
      "Epoch [3/10], Step [499/750], Loss: 0.0911\n",
      "Epoch [3/10], Step [500/750], Loss: 0.1162\n",
      "Epoch [3/10], Step [501/750], Loss: 0.0919\n",
      "Epoch [3/10], Step [502/750], Loss: 0.0927\n",
      "Epoch [3/10], Step [503/750], Loss: 0.1791\n",
      "Epoch [3/10], Step [504/750], Loss: 0.0457\n",
      "Epoch [3/10], Step [505/750], Loss: 0.0775\n",
      "Epoch [3/10], Step [506/750], Loss: 0.0319\n",
      "Epoch [3/10], Step [507/750], Loss: 0.0576\n",
      "Epoch [3/10], Step [508/750], Loss: 0.0530\n",
      "Epoch [3/10], Step [509/750], Loss: 0.0724\n",
      "Epoch [3/10], Step [510/750], Loss: 0.0480\n",
      "Epoch [3/10], Step [511/750], Loss: 0.0865\n",
      "Epoch [3/10], Step [512/750], Loss: 0.0378\n",
      "Epoch [3/10], Step [513/750], Loss: 0.0525\n",
      "Epoch [3/10], Step [514/750], Loss: 0.1276\n",
      "Epoch [3/10], Step [515/750], Loss: 0.0207\n",
      "Epoch [3/10], Step [516/750], Loss: 0.0460\n",
      "Epoch [3/10], Step [517/750], Loss: 0.0979\n",
      "Epoch [3/10], Step [518/750], Loss: 0.1206\n",
      "Epoch [3/10], Step [519/750], Loss: 0.0388\n",
      "Epoch [3/10], Step [520/750], Loss: 0.1281\n",
      "Epoch [3/10], Step [521/750], Loss: 0.0575\n",
      "Epoch [3/10], Step [522/750], Loss: 0.1014\n",
      "Epoch [3/10], Step [523/750], Loss: 0.0986\n",
      "Epoch [3/10], Step [524/750], Loss: 0.0357\n",
      "Epoch [3/10], Step [525/750], Loss: 0.0225\n",
      "Epoch [3/10], Step [526/750], Loss: 0.1815\n",
      "Epoch [3/10], Step [527/750], Loss: 0.0446\n",
      "Epoch [3/10], Step [528/750], Loss: 0.0488\n",
      "Epoch [3/10], Step [529/750], Loss: 0.0978\n",
      "Epoch [3/10], Step [530/750], Loss: 0.0184\n",
      "Epoch [3/10], Step [531/750], Loss: 0.0400\n",
      "Epoch [3/10], Step [532/750], Loss: 0.0254\n",
      "Epoch [3/10], Step [533/750], Loss: 0.0384\n",
      "Epoch [3/10], Step [534/750], Loss: 0.1901\n",
      "Epoch [3/10], Step [535/750], Loss: 0.0424\n",
      "Epoch [3/10], Step [536/750], Loss: 0.0935\n",
      "Epoch [3/10], Step [537/750], Loss: 0.1656\n",
      "Epoch [3/10], Step [538/750], Loss: 0.1079\n",
      "Epoch [3/10], Step [539/750], Loss: 0.0951\n",
      "Epoch [3/10], Step [540/750], Loss: 0.0902\n",
      "Epoch [3/10], Step [541/750], Loss: 0.1814\n",
      "Epoch [3/10], Step [542/750], Loss: 0.1386\n",
      "Epoch [3/10], Step [543/750], Loss: 0.1308\n",
      "Epoch [3/10], Step [544/750], Loss: 0.0842\n",
      "Epoch [3/10], Step [545/750], Loss: 0.1340\n",
      "Epoch [3/10], Step [546/750], Loss: 0.0221\n",
      "Epoch [3/10], Step [547/750], Loss: 0.0745\n",
      "Epoch [3/10], Step [548/750], Loss: 0.1139\n",
      "Epoch [3/10], Step [549/750], Loss: 0.1612\n",
      "Epoch [3/10], Step [550/750], Loss: 0.3170\n",
      "Epoch [3/10], Step [551/750], Loss: 0.0654\n",
      "Epoch [3/10], Step [552/750], Loss: 0.0746\n",
      "Epoch [3/10], Step [553/750], Loss: 0.0606\n",
      "Epoch [3/10], Step [554/750], Loss: 0.0620\n",
      "Epoch [3/10], Step [555/750], Loss: 0.0154\n",
      "Epoch [3/10], Step [556/750], Loss: 0.0123\n",
      "Epoch [3/10], Step [557/750], Loss: 0.0440\n",
      "Epoch [3/10], Step [558/750], Loss: 0.0454\n",
      "Epoch [3/10], Step [559/750], Loss: 0.0963\n",
      "Epoch [3/10], Step [560/750], Loss: 0.0214\n",
      "Epoch [3/10], Step [561/750], Loss: 0.1009\n",
      "Epoch [3/10], Step [562/750], Loss: 0.0970\n",
      "Epoch [3/10], Step [563/750], Loss: 0.1180\n",
      "Epoch [3/10], Step [564/750], Loss: 0.0900\n",
      "Epoch [3/10], Step [565/750], Loss: 0.1003\n",
      "Epoch [3/10], Step [566/750], Loss: 0.0498\n",
      "Epoch [3/10], Step [567/750], Loss: 0.0634\n",
      "Epoch [3/10], Step [568/750], Loss: 0.1199\n",
      "Epoch [3/10], Step [569/750], Loss: 0.0497\n",
      "Epoch [3/10], Step [570/750], Loss: 0.0689\n",
      "Epoch [3/10], Step [571/750], Loss: 0.1707\n",
      "Epoch [3/10], Step [572/750], Loss: 0.1165\n",
      "Epoch [3/10], Step [573/750], Loss: 0.0930\n",
      "Epoch [3/10], Step [574/750], Loss: 0.0559\n",
      "Epoch [3/10], Step [575/750], Loss: 0.1062\n",
      "Epoch [3/10], Step [576/750], Loss: 0.0898\n",
      "Epoch [3/10], Step [577/750], Loss: 0.0549\n",
      "Epoch [3/10], Step [578/750], Loss: 0.0994\n",
      "Epoch [3/10], Step [579/750], Loss: 0.1127\n",
      "Epoch [3/10], Step [580/750], Loss: 0.0895\n",
      "Epoch [3/10], Step [581/750], Loss: 0.0494\n",
      "Epoch [3/10], Step [582/750], Loss: 0.0967\n",
      "Epoch [3/10], Step [583/750], Loss: 0.0285\n",
      "Epoch [3/10], Step [584/750], Loss: 0.1071\n",
      "Epoch [3/10], Step [585/750], Loss: 0.1092\n",
      "Epoch [3/10], Step [586/750], Loss: 0.0817\n",
      "Epoch [3/10], Step [587/750], Loss: 0.1036\n",
      "Epoch [3/10], Step [588/750], Loss: 0.1627\n",
      "Epoch [3/10], Step [589/750], Loss: 0.0601\n",
      "Epoch [3/10], Step [590/750], Loss: 0.1151\n",
      "Epoch [3/10], Step [591/750], Loss: 0.1229\n",
      "Epoch [3/10], Step [592/750], Loss: 0.0673\n",
      "Epoch [3/10], Step [593/750], Loss: 0.0158\n",
      "Epoch [3/10], Step [594/750], Loss: 0.1606\n",
      "Epoch [3/10], Step [595/750], Loss: 0.0703\n",
      "Epoch [3/10], Step [596/750], Loss: 0.0774\n",
      "Epoch [3/10], Step [597/750], Loss: 0.0988\n",
      "Epoch [3/10], Step [598/750], Loss: 0.0595\n",
      "Epoch [3/10], Step [599/750], Loss: 0.0769\n",
      "Epoch [3/10], Step [600/750], Loss: 0.1234\n",
      "Epoch [3/10], Step [601/750], Loss: 0.1672\n",
      "Epoch [3/10], Step [602/750], Loss: 0.0815\n",
      "Epoch [3/10], Step [603/750], Loss: 0.0816\n",
      "Epoch [3/10], Step [604/750], Loss: 0.0829\n",
      "Epoch [3/10], Step [605/750], Loss: 0.0720\n",
      "Epoch [3/10], Step [606/750], Loss: 0.0819\n",
      "Epoch [3/10], Step [607/750], Loss: 0.1175\n",
      "Epoch [3/10], Step [608/750], Loss: 0.0697\n",
      "Epoch [3/10], Step [609/750], Loss: 0.0988\n",
      "Epoch [3/10], Step [610/750], Loss: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [611/750], Loss: 0.0434\n",
      "Epoch [3/10], Step [612/750], Loss: 0.0761\n",
      "Epoch [3/10], Step [613/750], Loss: 0.0815\n",
      "Epoch [3/10], Step [614/750], Loss: 0.0785\n",
      "Epoch [3/10], Step [615/750], Loss: 0.0705\n",
      "Epoch [3/10], Step [616/750], Loss: 0.0871\n",
      "Epoch [3/10], Step [617/750], Loss: 0.0825\n",
      "Epoch [3/10], Step [618/750], Loss: 0.0302\n",
      "Epoch [3/10], Step [619/750], Loss: 0.0475\n",
      "Epoch [3/10], Step [620/750], Loss: 0.1122\n",
      "Epoch [3/10], Step [621/750], Loss: 0.1508\n",
      "Epoch [3/10], Step [622/750], Loss: 0.0677\n",
      "Epoch [3/10], Step [623/750], Loss: 0.0916\n",
      "Epoch [3/10], Step [624/750], Loss: 0.1241\n",
      "Epoch [3/10], Step [625/750], Loss: 0.1685\n",
      "Epoch [3/10], Step [626/750], Loss: 0.0751\n",
      "Epoch [3/10], Step [627/750], Loss: 0.1364\n",
      "Epoch [3/10], Step [628/750], Loss: 0.0176\n",
      "Epoch [3/10], Step [629/750], Loss: 0.0841\n",
      "Epoch [3/10], Step [630/750], Loss: 0.0260\n",
      "Epoch [3/10], Step [631/750], Loss: 0.1489\n",
      "Epoch [3/10], Step [632/750], Loss: 0.1213\n",
      "Epoch [3/10], Step [633/750], Loss: 0.1065\n",
      "Epoch [3/10], Step [634/750], Loss: 0.0777\n",
      "Epoch [3/10], Step [635/750], Loss: 0.0313\n",
      "Epoch [3/10], Step [636/750], Loss: 0.0431\n",
      "Epoch [3/10], Step [637/750], Loss: 0.1286\n",
      "Epoch [3/10], Step [638/750], Loss: 0.0095\n",
      "Epoch [3/10], Step [639/750], Loss: 0.0266\n",
      "Epoch [3/10], Step [640/750], Loss: 0.0415\n",
      "Epoch [3/10], Step [641/750], Loss: 0.1213\n",
      "Epoch [3/10], Step [642/750], Loss: 0.0479\n",
      "Epoch [3/10], Step [643/750], Loss: 0.1078\n",
      "Epoch [3/10], Step [644/750], Loss: 0.0236\n",
      "Epoch [3/10], Step [645/750], Loss: 0.0876\n",
      "Epoch [3/10], Step [646/750], Loss: 0.0678\n",
      "Epoch [3/10], Step [647/750], Loss: 0.0305\n",
      "Epoch [3/10], Step [648/750], Loss: 0.1307\n",
      "Epoch [3/10], Step [649/750], Loss: 0.0924\n",
      "Epoch [3/10], Step [650/750], Loss: 0.1064\n",
      "Epoch [3/10], Step [651/750], Loss: 0.0635\n",
      "Epoch [3/10], Step [652/750], Loss: 0.0288\n",
      "Epoch [3/10], Step [653/750], Loss: 0.0576\n",
      "Epoch [3/10], Step [654/750], Loss: 0.0417\n",
      "Epoch [3/10], Step [655/750], Loss: 0.1376\n",
      "Epoch [3/10], Step [656/750], Loss: 0.0152\n",
      "Epoch [3/10], Step [657/750], Loss: 0.0621\n",
      "Epoch [3/10], Step [658/750], Loss: 0.1451\n",
      "Epoch [3/10], Step [659/750], Loss: 0.0665\n",
      "Epoch [3/10], Step [660/750], Loss: 0.0658\n",
      "Epoch [3/10], Step [661/750], Loss: 0.1204\n",
      "Epoch [3/10], Step [662/750], Loss: 0.0974\n",
      "Epoch [3/10], Step [663/750], Loss: 0.0589\n",
      "Epoch [3/10], Step [664/750], Loss: 0.1335\n",
      "Epoch [3/10], Step [665/750], Loss: 0.0395\n",
      "Epoch [3/10], Step [666/750], Loss: 0.0724\n",
      "Epoch [3/10], Step [667/750], Loss: 0.1749\n",
      "Epoch [3/10], Step [668/750], Loss: 0.0348\n",
      "Epoch [3/10], Step [669/750], Loss: 0.0218\n",
      "Epoch [3/10], Step [670/750], Loss: 0.0482\n",
      "Epoch [3/10], Step [671/750], Loss: 0.0370\n",
      "Epoch [3/10], Step [672/750], Loss: 0.1536\n",
      "Epoch [3/10], Step [673/750], Loss: 0.0697\n",
      "Epoch [3/10], Step [674/750], Loss: 0.0727\n",
      "Epoch [3/10], Step [675/750], Loss: 0.1114\n",
      "Epoch [3/10], Step [676/750], Loss: 0.0576\n",
      "Epoch [3/10], Step [677/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [678/750], Loss: 0.1601\n",
      "Epoch [3/10], Step [679/750], Loss: 0.1033\n",
      "Epoch [3/10], Step [680/750], Loss: 0.1179\n",
      "Epoch [3/10], Step [681/750], Loss: 0.0439\n",
      "Epoch [3/10], Step [682/750], Loss: 0.0113\n",
      "Epoch [3/10], Step [683/750], Loss: 0.0694\n",
      "Epoch [3/10], Step [684/750], Loss: 0.0715\n",
      "Epoch [3/10], Step [685/750], Loss: 0.0963\n",
      "Epoch [3/10], Step [686/750], Loss: 0.0325\n",
      "Epoch [3/10], Step [687/750], Loss: 0.0203\n",
      "Epoch [3/10], Step [688/750], Loss: 0.0714\n",
      "Epoch [3/10], Step [689/750], Loss: 0.0427\n",
      "Epoch [3/10], Step [690/750], Loss: 0.1246\n",
      "Epoch [3/10], Step [691/750], Loss: 0.0180\n",
      "Epoch [3/10], Step [692/750], Loss: 0.0808\n",
      "Epoch [3/10], Step [693/750], Loss: 0.0946\n",
      "Epoch [3/10], Step [694/750], Loss: 0.0531\n",
      "Epoch [3/10], Step [695/750], Loss: 0.1179\n",
      "Epoch [3/10], Step [696/750], Loss: 0.0575\n",
      "Epoch [3/10], Step [697/750], Loss: 0.0836\n",
      "Epoch [3/10], Step [698/750], Loss: 0.0921\n",
      "Epoch [3/10], Step [699/750], Loss: 0.0311\n",
      "Epoch [3/10], Step [700/750], Loss: 0.0818\n",
      "Epoch [3/10], Step [701/750], Loss: 0.0801\n",
      "Epoch [3/10], Step [702/750], Loss: 0.1435\n",
      "Epoch [3/10], Step [703/750], Loss: 0.1964\n",
      "Epoch [3/10], Step [704/750], Loss: 0.2226\n",
      "Epoch [3/10], Step [705/750], Loss: 0.0526\n",
      "Epoch [3/10], Step [706/750], Loss: 0.0331\n",
      "Epoch [3/10], Step [707/750], Loss: 0.1059\n",
      "Epoch [3/10], Step [708/750], Loss: 0.1593\n",
      "Epoch [3/10], Step [709/750], Loss: 0.0504\n",
      "Epoch [3/10], Step [710/750], Loss: 0.0285\n",
      "Epoch [3/10], Step [711/750], Loss: 0.1116\n",
      "Epoch [3/10], Step [712/750], Loss: 0.0220\n",
      "Epoch [3/10], Step [713/750], Loss: 0.0227\n",
      "Epoch [3/10], Step [714/750], Loss: 0.1518\n",
      "Epoch [3/10], Step [715/750], Loss: 0.2453\n",
      "Epoch [3/10], Step [716/750], Loss: 0.1976\n",
      "Epoch [3/10], Step [717/750], Loss: 0.0541\n",
      "Epoch [3/10], Step [718/750], Loss: 0.0786\n",
      "Epoch [3/10], Step [719/750], Loss: 0.0785\n",
      "Epoch [3/10], Step [720/750], Loss: 0.0594\n",
      "Epoch [3/10], Step [721/750], Loss: 0.0484\n",
      "Epoch [3/10], Step [722/750], Loss: 0.0869\n",
      "Epoch [3/10], Step [723/750], Loss: 0.1496\n",
      "Epoch [3/10], Step [724/750], Loss: 0.0968\n",
      "Epoch [3/10], Step [725/750], Loss: 0.0261\n",
      "Epoch [3/10], Step [726/750], Loss: 0.0141\n",
      "Epoch [3/10], Step [727/750], Loss: 0.2221\n",
      "Epoch [3/10], Step [728/750], Loss: 0.2514\n",
      "Epoch [3/10], Step [729/750], Loss: 0.0657\n",
      "Epoch [3/10], Step [730/750], Loss: 0.1188\n",
      "Epoch [3/10], Step [731/750], Loss: 0.1233\n",
      "Epoch [3/10], Step [732/750], Loss: 0.0830\n",
      "Epoch [3/10], Step [733/750], Loss: 0.0941\n",
      "Epoch [3/10], Step [734/750], Loss: 0.0926\n",
      "Epoch [3/10], Step [735/750], Loss: 0.0456\n",
      "Epoch [3/10], Step [736/750], Loss: 0.0670\n",
      "Epoch [3/10], Step [737/750], Loss: 0.0569\n",
      "Epoch [3/10], Step [738/750], Loss: 0.0991\n",
      "Epoch [3/10], Step [739/750], Loss: 0.0475\n",
      "Epoch [3/10], Step [740/750], Loss: 0.1129\n",
      "Epoch [3/10], Step [741/750], Loss: 0.0299\n",
      "Epoch [3/10], Step [742/750], Loss: 0.0563\n",
      "Epoch [3/10], Step [743/750], Loss: 0.1136\n",
      "Epoch [3/10], Step [744/750], Loss: 0.1390\n",
      "Epoch [3/10], Step [745/750], Loss: 0.0769\n",
      "Epoch [3/10], Step [746/750], Loss: 0.0464\n",
      "Epoch [3/10], Step [747/750], Loss: 0.0740\n",
      "Epoch [3/10], Step [748/750], Loss: 0.0635\n",
      "Epoch [3/10], Step [749/750], Loss: 0.1532\n",
      "Epoch [3/10], Step [750/750], Loss: 0.1166\n",
      "\n",
      "\n",
      "Epoch [4/10], Step [1/750], Loss: 0.0195\n",
      "Epoch [4/10], Step [2/750], Loss: 0.0611\n",
      "Epoch [4/10], Step [3/750], Loss: 0.1804\n",
      "Epoch [4/10], Step [4/750], Loss: 0.0289\n",
      "Epoch [4/10], Step [5/750], Loss: 0.0492\n",
      "Epoch [4/10], Step [6/750], Loss: 0.1843\n",
      "Epoch [4/10], Step [7/750], Loss: 0.0503\n",
      "Epoch [4/10], Step [8/750], Loss: 0.1486\n",
      "Epoch [4/10], Step [9/750], Loss: 0.0266\n",
      "Epoch [4/10], Step [10/750], Loss: 0.0330\n",
      "Epoch [4/10], Step [11/750], Loss: 0.0579\n",
      "Epoch [4/10], Step [12/750], Loss: 0.0623\n",
      "Epoch [4/10], Step [13/750], Loss: 0.0183\n",
      "Epoch [4/10], Step [14/750], Loss: 0.0334\n",
      "Epoch [4/10], Step [15/750], Loss: 0.0652\n",
      "Epoch [4/10], Step [16/750], Loss: 0.1392\n",
      "Epoch [4/10], Step [17/750], Loss: 0.0479\n",
      "Epoch [4/10], Step [18/750], Loss: 0.1114\n",
      "Epoch [4/10], Step [19/750], Loss: 0.1051\n",
      "Epoch [4/10], Step [20/750], Loss: 0.0284\n",
      "Epoch [4/10], Step [21/750], Loss: 0.0664\n",
      "Epoch [4/10], Step [22/750], Loss: 0.0695\n",
      "Epoch [4/10], Step [23/750], Loss: 0.0852\n",
      "Epoch [4/10], Step [24/750], Loss: 0.1318\n",
      "Epoch [4/10], Step [25/750], Loss: 0.1130\n",
      "Epoch [4/10], Step [26/750], Loss: 0.1040\n",
      "Epoch [4/10], Step [27/750], Loss: 0.0996\n",
      "Epoch [4/10], Step [28/750], Loss: 0.0818\n",
      "Epoch [4/10], Step [29/750], Loss: 0.0475\n",
      "Epoch [4/10], Step [30/750], Loss: 0.0205\n",
      "Epoch [4/10], Step [31/750], Loss: 0.0629\n",
      "Epoch [4/10], Step [32/750], Loss: 0.0316\n",
      "Epoch [4/10], Step [33/750], Loss: 0.1054\n",
      "Epoch [4/10], Step [34/750], Loss: 0.0680\n",
      "Epoch [4/10], Step [35/750], Loss: 0.1224\n",
      "Epoch [4/10], Step [36/750], Loss: 0.0536\n",
      "Epoch [4/10], Step [37/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [38/750], Loss: 0.0587\n",
      "Epoch [4/10], Step [39/750], Loss: 0.0436\n",
      "Epoch [4/10], Step [40/750], Loss: 0.1349\n",
      "Epoch [4/10], Step [41/750], Loss: 0.0354\n",
      "Epoch [4/10], Step [42/750], Loss: 0.1030\n",
      "Epoch [4/10], Step [43/750], Loss: 0.0961\n",
      "Epoch [4/10], Step [44/750], Loss: 0.0998\n",
      "Epoch [4/10], Step [45/750], Loss: 0.1381\n",
      "Epoch [4/10], Step [46/750], Loss: 0.0490\n",
      "Epoch [4/10], Step [47/750], Loss: 0.0142\n",
      "Epoch [4/10], Step [48/750], Loss: 0.0680\n",
      "Epoch [4/10], Step [49/750], Loss: 0.0354\n",
      "Epoch [4/10], Step [50/750], Loss: 0.0837\n",
      "Epoch [4/10], Step [51/750], Loss: 0.0903\n",
      "Epoch [4/10], Step [52/750], Loss: 0.0425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [53/750], Loss: 0.0903\n",
      "Epoch [4/10], Step [54/750], Loss: 0.0211\n",
      "Epoch [4/10], Step [55/750], Loss: 0.1639\n",
      "Epoch [4/10], Step [56/750], Loss: 0.0849\n",
      "Epoch [4/10], Step [57/750], Loss: 0.0280\n",
      "Epoch [4/10], Step [58/750], Loss: 0.1908\n",
      "Epoch [4/10], Step [59/750], Loss: 0.0145\n",
      "Epoch [4/10], Step [60/750], Loss: 0.2173\n",
      "Epoch [4/10], Step [61/750], Loss: 0.1912\n",
      "Epoch [4/10], Step [62/750], Loss: 0.0788\n",
      "Epoch [4/10], Step [63/750], Loss: 0.0537\n",
      "Epoch [4/10], Step [64/750], Loss: 0.1137\n",
      "Epoch [4/10], Step [65/750], Loss: 0.1977\n",
      "Epoch [4/10], Step [66/750], Loss: 0.1166\n",
      "Epoch [4/10], Step [67/750], Loss: 0.0236\n",
      "Epoch [4/10], Step [68/750], Loss: 0.0380\n",
      "Epoch [4/10], Step [69/750], Loss: 0.0319\n",
      "Epoch [4/10], Step [70/750], Loss: 0.1745\n",
      "Epoch [4/10], Step [71/750], Loss: 0.0392\n",
      "Epoch [4/10], Step [72/750], Loss: 0.0742\n",
      "Epoch [4/10], Step [73/750], Loss: 0.1300\n",
      "Epoch [4/10], Step [74/750], Loss: 0.0128\n",
      "Epoch [4/10], Step [75/750], Loss: 0.1098\n",
      "Epoch [4/10], Step [76/750], Loss: 0.0308\n",
      "Epoch [4/10], Step [77/750], Loss: 0.0578\n",
      "Epoch [4/10], Step [78/750], Loss: 0.1318\n",
      "Epoch [4/10], Step [79/750], Loss: 0.1345\n",
      "Epoch [4/10], Step [80/750], Loss: 0.1178\n",
      "Epoch [4/10], Step [81/750], Loss: 0.0178\n",
      "Epoch [4/10], Step [82/750], Loss: 0.1697\n",
      "Epoch [4/10], Step [83/750], Loss: 0.0416\n",
      "Epoch [4/10], Step [84/750], Loss: 0.0267\n",
      "Epoch [4/10], Step [85/750], Loss: 0.0772\n",
      "Epoch [4/10], Step [86/750], Loss: 0.1401\n",
      "Epoch [4/10], Step [87/750], Loss: 0.0896\n",
      "Epoch [4/10], Step [88/750], Loss: 0.0543\n",
      "Epoch [4/10], Step [89/750], Loss: 0.0595\n",
      "Epoch [4/10], Step [90/750], Loss: 0.0544\n",
      "Epoch [4/10], Step [91/750], Loss: 0.0493\n",
      "Epoch [4/10], Step [92/750], Loss: 0.0807\n",
      "Epoch [4/10], Step [93/750], Loss: 0.0188\n",
      "Epoch [4/10], Step [94/750], Loss: 0.1488\n",
      "Epoch [4/10], Step [95/750], Loss: 0.0663\n",
      "Epoch [4/10], Step [96/750], Loss: 0.0725\n",
      "Epoch [4/10], Step [97/750], Loss: 0.0727\n",
      "Epoch [4/10], Step [98/750], Loss: 0.0251\n",
      "Epoch [4/10], Step [99/750], Loss: 0.0408\n",
      "Epoch [4/10], Step [100/750], Loss: 0.0841\n",
      "Epoch [4/10], Step [101/750], Loss: 0.0557\n",
      "Epoch [4/10], Step [102/750], Loss: 0.0163\n",
      "Epoch [4/10], Step [103/750], Loss: 0.0876\n",
      "Epoch [4/10], Step [104/750], Loss: 0.0401\n",
      "Epoch [4/10], Step [105/750], Loss: 0.0799\n",
      "Epoch [4/10], Step [106/750], Loss: 0.0457\n",
      "Epoch [4/10], Step [107/750], Loss: 0.0510\n",
      "Epoch [4/10], Step [108/750], Loss: 0.0253\n",
      "Epoch [4/10], Step [109/750], Loss: 0.0869\n",
      "Epoch [4/10], Step [110/750], Loss: 0.0977\n",
      "Epoch [4/10], Step [111/750], Loss: 0.0627\n",
      "Epoch [4/10], Step [112/750], Loss: 0.0641\n",
      "Epoch [4/10], Step [113/750], Loss: 0.0434\n",
      "Epoch [4/10], Step [114/750], Loss: 0.0532\n",
      "Epoch [4/10], Step [115/750], Loss: 0.0735\n",
      "Epoch [4/10], Step [116/750], Loss: 0.0703\n",
      "Epoch [4/10], Step [117/750], Loss: 0.0728\n",
      "Epoch [4/10], Step [118/750], Loss: 0.1001\n",
      "Epoch [4/10], Step [119/750], Loss: 0.0783\n",
      "Epoch [4/10], Step [120/750], Loss: 0.0947\n",
      "Epoch [4/10], Step [121/750], Loss: 0.1028\n",
      "Epoch [4/10], Step [122/750], Loss: 0.0103\n",
      "Epoch [4/10], Step [123/750], Loss: 0.0612\n",
      "Epoch [4/10], Step [124/750], Loss: 0.1552\n",
      "Epoch [4/10], Step [125/750], Loss: 0.0204\n",
      "Epoch [4/10], Step [126/750], Loss: 0.0693\n",
      "Epoch [4/10], Step [127/750], Loss: 0.0991\n",
      "Epoch [4/10], Step [128/750], Loss: 0.0970\n",
      "Epoch [4/10], Step [129/750], Loss: 0.0666\n",
      "Epoch [4/10], Step [130/750], Loss: 0.0378\n",
      "Epoch [4/10], Step [131/750], Loss: 0.1199\n",
      "Epoch [4/10], Step [132/750], Loss: 0.0721\n",
      "Epoch [4/10], Step [133/750], Loss: 0.0411\n",
      "Epoch [4/10], Step [134/750], Loss: 0.0140\n",
      "Epoch [4/10], Step [135/750], Loss: 0.0528\n",
      "Epoch [4/10], Step [136/750], Loss: 0.0687\n",
      "Epoch [4/10], Step [137/750], Loss: 0.0220\n",
      "Epoch [4/10], Step [138/750], Loss: 0.0602\n",
      "Epoch [4/10], Step [139/750], Loss: 0.0852\n",
      "Epoch [4/10], Step [140/750], Loss: 0.0689\n",
      "Epoch [4/10], Step [141/750], Loss: 0.1034\n",
      "Epoch [4/10], Step [142/750], Loss: 0.0619\n",
      "Epoch [4/10], Step [143/750], Loss: 0.0130\n",
      "Epoch [4/10], Step [144/750], Loss: 0.0657\n",
      "Epoch [4/10], Step [145/750], Loss: 0.0697\n",
      "Epoch [4/10], Step [146/750], Loss: 0.1433\n",
      "Epoch [4/10], Step [147/750], Loss: 0.0470\n",
      "Epoch [4/10], Step [148/750], Loss: 0.0465\n",
      "Epoch [4/10], Step [149/750], Loss: 0.0261\n",
      "Epoch [4/10], Step [150/750], Loss: 0.1947\n",
      "Epoch [4/10], Step [151/750], Loss: 0.0295\n",
      "Epoch [4/10], Step [152/750], Loss: 0.1209\n",
      "Epoch [4/10], Step [153/750], Loss: 0.1629\n",
      "Epoch [4/10], Step [154/750], Loss: 0.0226\n",
      "Epoch [4/10], Step [155/750], Loss: 0.0454\n",
      "Epoch [4/10], Step [156/750], Loss: 0.1638\n",
      "Epoch [4/10], Step [157/750], Loss: 0.0554\n",
      "Epoch [4/10], Step [158/750], Loss: 0.0566\n",
      "Epoch [4/10], Step [159/750], Loss: 0.0659\n",
      "Epoch [4/10], Step [160/750], Loss: 0.1571\n",
      "Epoch [4/10], Step [161/750], Loss: 0.1240\n",
      "Epoch [4/10], Step [162/750], Loss: 0.0421\n",
      "Epoch [4/10], Step [163/750], Loss: 0.1282\n",
      "Epoch [4/10], Step [164/750], Loss: 0.0980\n",
      "Epoch [4/10], Step [165/750], Loss: 0.0560\n",
      "Epoch [4/10], Step [166/750], Loss: 0.0212\n",
      "Epoch [4/10], Step [167/750], Loss: 0.0527\n",
      "Epoch [4/10], Step [168/750], Loss: 0.1754\n",
      "Epoch [4/10], Step [169/750], Loss: 0.0212\n",
      "Epoch [4/10], Step [170/750], Loss: 0.0097\n",
      "Epoch [4/10], Step [171/750], Loss: 0.0638\n",
      "Epoch [4/10], Step [172/750], Loss: 0.1520\n",
      "Epoch [4/10], Step [173/750], Loss: 0.0504\n",
      "Epoch [4/10], Step [174/750], Loss: 0.1991\n",
      "Epoch [4/10], Step [175/750], Loss: 0.0638\n",
      "Epoch [4/10], Step [176/750], Loss: 0.0271\n",
      "Epoch [4/10], Step [177/750], Loss: 0.0279\n",
      "Epoch [4/10], Step [178/750], Loss: 0.1741\n",
      "Epoch [4/10], Step [179/750], Loss: 0.2052\n",
      "Epoch [4/10], Step [180/750], Loss: 0.1008\n",
      "Epoch [4/10], Step [181/750], Loss: 0.0212\n",
      "Epoch [4/10], Step [182/750], Loss: 0.0820\n",
      "Epoch [4/10], Step [183/750], Loss: 0.1555\n",
      "Epoch [4/10], Step [184/750], Loss: 0.0472\n",
      "Epoch [4/10], Step [185/750], Loss: 0.0820\n",
      "Epoch [4/10], Step [186/750], Loss: 0.0814\n",
      "Epoch [4/10], Step [187/750], Loss: 0.1187\n",
      "Epoch [4/10], Step [188/750], Loss: 0.1107\n",
      "Epoch [4/10], Step [189/750], Loss: 0.0349\n",
      "Epoch [4/10], Step [190/750], Loss: 0.1765\n",
      "Epoch [4/10], Step [191/750], Loss: 0.1305\n",
      "Epoch [4/10], Step [192/750], Loss: 0.1332\n",
      "Epoch [4/10], Step [193/750], Loss: 0.0293\n",
      "Epoch [4/10], Step [194/750], Loss: 0.0227\n",
      "Epoch [4/10], Step [195/750], Loss: 0.0490\n",
      "Epoch [4/10], Step [196/750], Loss: 0.0189\n",
      "Epoch [4/10], Step [197/750], Loss: 0.0861\n",
      "Epoch [4/10], Step [198/750], Loss: 0.1347\n",
      "Epoch [4/10], Step [199/750], Loss: 0.1224\n",
      "Epoch [4/10], Step [200/750], Loss: 0.0447\n",
      "Epoch [4/10], Step [201/750], Loss: 0.0511\n",
      "Epoch [4/10], Step [202/750], Loss: 0.0195\n",
      "Epoch [4/10], Step [203/750], Loss: 0.0828\n",
      "Epoch [4/10], Step [204/750], Loss: 0.0639\n",
      "Epoch [4/10], Step [205/750], Loss: 0.1251\n",
      "Epoch [4/10], Step [206/750], Loss: 0.0436\n",
      "Epoch [4/10], Step [207/750], Loss: 0.0736\n",
      "Epoch [4/10], Step [208/750], Loss: 0.0794\n",
      "Epoch [4/10], Step [209/750], Loss: 0.0402\n",
      "Epoch [4/10], Step [210/750], Loss: 0.0201\n",
      "Epoch [4/10], Step [211/750], Loss: 0.1203\n",
      "Epoch [4/10], Step [212/750], Loss: 0.0686\n",
      "Epoch [4/10], Step [213/750], Loss: 0.0481\n",
      "Epoch [4/10], Step [214/750], Loss: 0.0400\n",
      "Epoch [4/10], Step [215/750], Loss: 0.1025\n",
      "Epoch [4/10], Step [216/750], Loss: 0.0374\n",
      "Epoch [4/10], Step [217/750], Loss: 0.0661\n",
      "Epoch [4/10], Step [218/750], Loss: 0.0722\n",
      "Epoch [4/10], Step [219/750], Loss: 0.1421\n",
      "Epoch [4/10], Step [220/750], Loss: 0.0506\n",
      "Epoch [4/10], Step [221/750], Loss: 0.1682\n",
      "Epoch [4/10], Step [222/750], Loss: 0.0931\n",
      "Epoch [4/10], Step [223/750], Loss: 0.0769\n",
      "Epoch [4/10], Step [224/750], Loss: 0.0851\n",
      "Epoch [4/10], Step [225/750], Loss: 0.0753\n",
      "Epoch [4/10], Step [226/750], Loss: 0.1198\n",
      "Epoch [4/10], Step [227/750], Loss: 0.0891\n",
      "Epoch [4/10], Step [228/750], Loss: 0.0129\n",
      "Epoch [4/10], Step [229/750], Loss: 0.1010\n",
      "Epoch [4/10], Step [230/750], Loss: 0.0552\n",
      "Epoch [4/10], Step [231/750], Loss: 0.0223\n",
      "Epoch [4/10], Step [232/750], Loss: 0.0450\n",
      "Epoch [4/10], Step [233/750], Loss: 0.0710\n",
      "Epoch [4/10], Step [234/750], Loss: 0.0595\n",
      "Epoch [4/10], Step [235/750], Loss: 0.0315\n",
      "Epoch [4/10], Step [236/750], Loss: 0.0319\n",
      "Epoch [4/10], Step [237/750], Loss: 0.1124\n",
      "Epoch [4/10], Step [238/750], Loss: 0.0887\n",
      "Epoch [4/10], Step [239/750], Loss: 0.0212\n",
      "Epoch [4/10], Step [240/750], Loss: 0.0639\n",
      "Epoch [4/10], Step [241/750], Loss: 0.0657\n",
      "Epoch [4/10], Step [242/750], Loss: 0.0643\n",
      "Epoch [4/10], Step [243/750], Loss: 0.0930\n",
      "Epoch [4/10], Step [244/750], Loss: 0.1097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [245/750], Loss: 0.0645\n",
      "Epoch [4/10], Step [246/750], Loss: 0.0185\n",
      "Epoch [4/10], Step [247/750], Loss: 0.0906\n",
      "Epoch [4/10], Step [248/750], Loss: 0.0837\n",
      "Epoch [4/10], Step [249/750], Loss: 0.1016\n",
      "Epoch [4/10], Step [250/750], Loss: 0.0210\n",
      "Epoch [4/10], Step [251/750], Loss: 0.0940\n",
      "Epoch [4/10], Step [252/750], Loss: 0.0494\n",
      "Epoch [4/10], Step [253/750], Loss: 0.0485\n",
      "Epoch [4/10], Step [254/750], Loss: 0.0874\n",
      "Epoch [4/10], Step [255/750], Loss: 0.0405\n",
      "Epoch [4/10], Step [256/750], Loss: 0.0681\n",
      "Epoch [4/10], Step [257/750], Loss: 0.0452\n",
      "Epoch [4/10], Step [258/750], Loss: 0.0824\n",
      "Epoch [4/10], Step [259/750], Loss: 0.0924\n",
      "Epoch [4/10], Step [260/750], Loss: 0.1595\n",
      "Epoch [4/10], Step [261/750], Loss: 0.0369\n",
      "Epoch [4/10], Step [262/750], Loss: 0.1046\n",
      "Epoch [4/10], Step [263/750], Loss: 0.0416\n",
      "Epoch [4/10], Step [264/750], Loss: 0.0231\n",
      "Epoch [4/10], Step [265/750], Loss: 0.0786\n",
      "Epoch [4/10], Step [266/750], Loss: 0.1942\n",
      "Epoch [4/10], Step [267/750], Loss: 0.1319\n",
      "Epoch [4/10], Step [268/750], Loss: 0.0361\n",
      "Epoch [4/10], Step [269/750], Loss: 0.0761\n",
      "Epoch [4/10], Step [270/750], Loss: 0.1062\n",
      "Epoch [4/10], Step [271/750], Loss: 0.0617\n",
      "Epoch [4/10], Step [272/750], Loss: 0.0631\n",
      "Epoch [4/10], Step [273/750], Loss: 0.0569\n",
      "Epoch [4/10], Step [274/750], Loss: 0.0493\n",
      "Epoch [4/10], Step [275/750], Loss: 0.0602\n",
      "Epoch [4/10], Step [276/750], Loss: 0.0234\n",
      "Epoch [4/10], Step [277/750], Loss: 0.1933\n",
      "Epoch [4/10], Step [278/750], Loss: 0.1092\n",
      "Epoch [4/10], Step [279/750], Loss: 0.0534\n",
      "Epoch [4/10], Step [280/750], Loss: 0.0112\n",
      "Epoch [4/10], Step [281/750], Loss: 0.0455\n",
      "Epoch [4/10], Step [282/750], Loss: 0.0864\n",
      "Epoch [4/10], Step [283/750], Loss: 0.0715\n",
      "Epoch [4/10], Step [284/750], Loss: 0.0927\n",
      "Epoch [4/10], Step [285/750], Loss: 0.0679\n",
      "Epoch [4/10], Step [286/750], Loss: 0.0187\n",
      "Epoch [4/10], Step [287/750], Loss: 0.1008\n",
      "Epoch [4/10], Step [288/750], Loss: 0.1117\n",
      "Epoch [4/10], Step [289/750], Loss: 0.0434\n",
      "Epoch [4/10], Step [290/750], Loss: 0.0396\n",
      "Epoch [4/10], Step [291/750], Loss: 0.1694\n",
      "Epoch [4/10], Step [292/750], Loss: 0.0821\n",
      "Epoch [4/10], Step [293/750], Loss: 0.0605\n",
      "Epoch [4/10], Step [294/750], Loss: 0.0128\n",
      "Epoch [4/10], Step [295/750], Loss: 0.1450\n",
      "Epoch [4/10], Step [296/750], Loss: 0.0689\n",
      "Epoch [4/10], Step [297/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [298/750], Loss: 0.2079\n",
      "Epoch [4/10], Step [299/750], Loss: 0.0613\n",
      "Epoch [4/10], Step [300/750], Loss: 0.1859\n",
      "Epoch [4/10], Step [301/750], Loss: 0.1415\n",
      "Epoch [4/10], Step [302/750], Loss: 0.0747\n",
      "Epoch [4/10], Step [303/750], Loss: 0.1700\n",
      "Epoch [4/10], Step [304/750], Loss: 0.0498\n",
      "Epoch [4/10], Step [305/750], Loss: 0.1252\n",
      "Epoch [4/10], Step [306/750], Loss: 0.0233\n",
      "Epoch [4/10], Step [307/750], Loss: 0.2080\n",
      "Epoch [4/10], Step [308/750], Loss: 0.0392\n",
      "Epoch [4/10], Step [309/750], Loss: 0.0351\n",
      "Epoch [4/10], Step [310/750], Loss: 0.0649\n",
      "Epoch [4/10], Step [311/750], Loss: 0.1584\n",
      "Epoch [4/10], Step [312/750], Loss: 0.1431\n",
      "Epoch [4/10], Step [313/750], Loss: 0.0512\n",
      "Epoch [4/10], Step [314/750], Loss: 0.0466\n",
      "Epoch [4/10], Step [315/750], Loss: 0.0224\n",
      "Epoch [4/10], Step [316/750], Loss: 0.0922\n",
      "Epoch [4/10], Step [317/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [318/750], Loss: 0.1180\n",
      "Epoch [4/10], Step [319/750], Loss: 0.1421\n",
      "Epoch [4/10], Step [320/750], Loss: 0.1471\n",
      "Epoch [4/10], Step [321/750], Loss: 0.1139\n",
      "Epoch [4/10], Step [322/750], Loss: 0.0893\n",
      "Epoch [4/10], Step [323/750], Loss: 0.0874\n",
      "Epoch [4/10], Step [324/750], Loss: 0.1057\n",
      "Epoch [4/10], Step [325/750], Loss: 0.0309\n",
      "Epoch [4/10], Step [326/750], Loss: 0.1246\n",
      "Epoch [4/10], Step [327/750], Loss: 0.0257\n",
      "Epoch [4/10], Step [328/750], Loss: 0.0148\n",
      "Epoch [4/10], Step [329/750], Loss: 0.0745\n",
      "Epoch [4/10], Step [330/750], Loss: 0.1042\n",
      "Epoch [4/10], Step [331/750], Loss: 0.0424\n",
      "Epoch [4/10], Step [332/750], Loss: 0.1043\n",
      "Epoch [4/10], Step [333/750], Loss: 0.1154\n",
      "Epoch [4/10], Step [334/750], Loss: 0.1611\n",
      "Epoch [4/10], Step [335/750], Loss: 0.2111\n",
      "Epoch [4/10], Step [336/750], Loss: 0.0187\n",
      "Epoch [4/10], Step [337/750], Loss: 0.0546\n",
      "Epoch [4/10], Step [338/750], Loss: 0.1304\n",
      "Epoch [4/10], Step [339/750], Loss: 0.0252\n",
      "Epoch [4/10], Step [340/750], Loss: 0.0994\n",
      "Epoch [4/10], Step [341/750], Loss: 0.0257\n",
      "Epoch [4/10], Step [342/750], Loss: 0.0824\n",
      "Epoch [4/10], Step [343/750], Loss: 0.0427\n",
      "Epoch [4/10], Step [344/750], Loss: 0.0612\n",
      "Epoch [4/10], Step [345/750], Loss: 0.1517\n",
      "Epoch [4/10], Step [346/750], Loss: 0.0485\n",
      "Epoch [4/10], Step [347/750], Loss: 0.0169\n",
      "Epoch [4/10], Step [348/750], Loss: 0.0745\n",
      "Epoch [4/10], Step [349/750], Loss: 0.1460\n",
      "Epoch [4/10], Step [350/750], Loss: 0.0436\n",
      "Epoch [4/10], Step [351/750], Loss: 0.0419\n",
      "Epoch [4/10], Step [352/750], Loss: 0.0327\n",
      "Epoch [4/10], Step [353/750], Loss: 0.1059\n",
      "Epoch [4/10], Step [354/750], Loss: 0.0501\n",
      "Epoch [4/10], Step [355/750], Loss: 0.0354\n",
      "Epoch [4/10], Step [356/750], Loss: 0.0300\n",
      "Epoch [4/10], Step [357/750], Loss: 0.0468\n",
      "Epoch [4/10], Step [358/750], Loss: 0.0618\n",
      "Epoch [4/10], Step [359/750], Loss: 0.1146\n",
      "Epoch [4/10], Step [360/750], Loss: 0.0434\n",
      "Epoch [4/10], Step [361/750], Loss: 0.0383\n",
      "Epoch [4/10], Step [362/750], Loss: 0.1108\n",
      "Epoch [4/10], Step [363/750], Loss: 0.0661\n",
      "Epoch [4/10], Step [364/750], Loss: 0.0369\n",
      "Epoch [4/10], Step [365/750], Loss: 0.0120\n",
      "Epoch [4/10], Step [366/750], Loss: 0.1856\n",
      "Epoch [4/10], Step [367/750], Loss: 0.0301\n",
      "Epoch [4/10], Step [368/750], Loss: 0.0506\n",
      "Epoch [4/10], Step [369/750], Loss: 0.0378\n",
      "Epoch [4/10], Step [370/750], Loss: 0.0457\n",
      "Epoch [4/10], Step [371/750], Loss: 0.0125\n",
      "Epoch [4/10], Step [372/750], Loss: 0.0911\n",
      "Epoch [4/10], Step [373/750], Loss: 0.0342\n",
      "Epoch [4/10], Step [374/750], Loss: 0.1262\n",
      "Epoch [4/10], Step [375/750], Loss: 0.0331\n",
      "Epoch [4/10], Step [376/750], Loss: 0.1559\n",
      "Epoch [4/10], Step [377/750], Loss: 0.0649\n",
      "Epoch [4/10], Step [378/750], Loss: 0.1116\n",
      "Epoch [4/10], Step [379/750], Loss: 0.0320\n",
      "Epoch [4/10], Step [380/750], Loss: 0.0638\n",
      "Epoch [4/10], Step [381/750], Loss: 0.0222\n",
      "Epoch [4/10], Step [382/750], Loss: 0.1634\n",
      "Epoch [4/10], Step [383/750], Loss: 0.0126\n",
      "Epoch [4/10], Step [384/750], Loss: 0.0394\n",
      "Epoch [4/10], Step [385/750], Loss: 0.1477\n",
      "Epoch [4/10], Step [386/750], Loss: 0.1158\n",
      "Epoch [4/10], Step [387/750], Loss: 0.0603\n",
      "Epoch [4/10], Step [388/750], Loss: 0.0262\n",
      "Epoch [4/10], Step [389/750], Loss: 0.1623\n",
      "Epoch [4/10], Step [390/750], Loss: 0.0792\n",
      "Epoch [4/10], Step [391/750], Loss: 0.0886\n",
      "Epoch [4/10], Step [392/750], Loss: 0.0885\n",
      "Epoch [4/10], Step [393/750], Loss: 0.0119\n",
      "Epoch [4/10], Step [394/750], Loss: 0.0895\n",
      "Epoch [4/10], Step [395/750], Loss: 0.0627\n",
      "Epoch [4/10], Step [396/750], Loss: 0.0468\n",
      "Epoch [4/10], Step [397/750], Loss: 0.0607\n",
      "Epoch [4/10], Step [398/750], Loss: 0.0184\n",
      "Epoch [4/10], Step [399/750], Loss: 0.0189\n",
      "Epoch [4/10], Step [400/750], Loss: 0.0870\n",
      "Epoch [4/10], Step [401/750], Loss: 0.0397\n",
      "Epoch [4/10], Step [402/750], Loss: 0.1611\n",
      "Epoch [4/10], Step [403/750], Loss: 0.0710\n",
      "Epoch [4/10], Step [404/750], Loss: 0.0357\n",
      "Epoch [4/10], Step [405/750], Loss: 0.0901\n",
      "Epoch [4/10], Step [406/750], Loss: 0.1031\n",
      "Epoch [4/10], Step [407/750], Loss: 0.1050\n",
      "Epoch [4/10], Step [408/750], Loss: 0.0108\n",
      "Epoch [4/10], Step [409/750], Loss: 0.1255\n",
      "Epoch [4/10], Step [410/750], Loss: 0.0143\n",
      "Epoch [4/10], Step [411/750], Loss: 0.1429\n",
      "Epoch [4/10], Step [412/750], Loss: 0.0549\n",
      "Epoch [4/10], Step [413/750], Loss: 0.1225\n",
      "Epoch [4/10], Step [414/750], Loss: 0.0543\n",
      "Epoch [4/10], Step [415/750], Loss: 0.0446\n",
      "Epoch [4/10], Step [416/750], Loss: 0.0285\n",
      "Epoch [4/10], Step [417/750], Loss: 0.0651\n",
      "Epoch [4/10], Step [418/750], Loss: 0.1032\n",
      "Epoch [4/10], Step [419/750], Loss: 0.0922\n",
      "Epoch [4/10], Step [420/750], Loss: 0.0929\n",
      "Epoch [4/10], Step [421/750], Loss: 0.1024\n",
      "Epoch [4/10], Step [422/750], Loss: 0.0741\n",
      "Epoch [4/10], Step [423/750], Loss: 0.0400\n",
      "Epoch [4/10], Step [424/750], Loss: 0.0317\n",
      "Epoch [4/10], Step [425/750], Loss: 0.0991\n",
      "Epoch [4/10], Step [426/750], Loss: 0.0813\n",
      "Epoch [4/10], Step [427/750], Loss: 0.1468\n",
      "Epoch [4/10], Step [428/750], Loss: 0.0246\n",
      "Epoch [4/10], Step [429/750], Loss: 0.2500\n",
      "Epoch [4/10], Step [430/750], Loss: 0.1693\n",
      "Epoch [4/10], Step [431/750], Loss: 0.1896\n",
      "Epoch [4/10], Step [432/750], Loss: 0.0567\n",
      "Epoch [4/10], Step [433/750], Loss: 0.1616\n",
      "Epoch [4/10], Step [434/750], Loss: 0.0944\n",
      "Epoch [4/10], Step [435/750], Loss: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [436/750], Loss: 0.0094\n",
      "Epoch [4/10], Step [437/750], Loss: 0.0368\n",
      "Epoch [4/10], Step [438/750], Loss: 0.0885\n",
      "Epoch [4/10], Step [439/750], Loss: 0.1445\n",
      "Epoch [4/10], Step [440/750], Loss: 0.1041\n",
      "Epoch [4/10], Step [441/750], Loss: 0.0625\n",
      "Epoch [4/10], Step [442/750], Loss: 0.0673\n",
      "Epoch [4/10], Step [443/750], Loss: 0.1150\n",
      "Epoch [4/10], Step [444/750], Loss: 0.0756\n",
      "Epoch [4/10], Step [445/750], Loss: 0.0614\n",
      "Epoch [4/10], Step [446/750], Loss: 0.0295\n",
      "Epoch [4/10], Step [447/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [448/750], Loss: 0.0999\n",
      "Epoch [4/10], Step [449/750], Loss: 0.0812\n",
      "Epoch [4/10], Step [450/750], Loss: 0.0186\n",
      "Epoch [4/10], Step [451/750], Loss: 0.0078\n",
      "Epoch [4/10], Step [452/750], Loss: 0.0295\n",
      "Epoch [4/10], Step [453/750], Loss: 0.0723\n",
      "Epoch [4/10], Step [454/750], Loss: 0.1051\n",
      "Epoch [4/10], Step [455/750], Loss: 0.0823\n",
      "Epoch [4/10], Step [456/750], Loss: 0.0067\n",
      "Epoch [4/10], Step [457/750], Loss: 0.0601\n",
      "Epoch [4/10], Step [458/750], Loss: 0.0634\n",
      "Epoch [4/10], Step [459/750], Loss: 0.1296\n",
      "Epoch [4/10], Step [460/750], Loss: 0.0431\n",
      "Epoch [4/10], Step [461/750], Loss: 0.0905\n",
      "Epoch [4/10], Step [462/750], Loss: 0.0316\n",
      "Epoch [4/10], Step [463/750], Loss: 0.0410\n",
      "Epoch [4/10], Step [464/750], Loss: 0.0107\n",
      "Epoch [4/10], Step [465/750], Loss: 0.0195\n",
      "Epoch [4/10], Step [466/750], Loss: 0.0114\n",
      "Epoch [4/10], Step [467/750], Loss: 0.0160\n",
      "Epoch [4/10], Step [468/750], Loss: 0.0296\n",
      "Epoch [4/10], Step [469/750], Loss: 0.0225\n",
      "Epoch [4/10], Step [470/750], Loss: 0.0472\n",
      "Epoch [4/10], Step [471/750], Loss: 0.1098\n",
      "Epoch [4/10], Step [472/750], Loss: 0.0168\n",
      "Epoch [4/10], Step [473/750], Loss: 0.0573\n",
      "Epoch [4/10], Step [474/750], Loss: 0.1086\n",
      "Epoch [4/10], Step [475/750], Loss: 0.0152\n",
      "Epoch [4/10], Step [476/750], Loss: 0.0794\n",
      "Epoch [4/10], Step [477/750], Loss: 0.0874\n",
      "Epoch [4/10], Step [478/750], Loss: 0.0643\n",
      "Epoch [4/10], Step [479/750], Loss: 0.0949\n",
      "Epoch [4/10], Step [480/750], Loss: 0.0437\n",
      "Epoch [4/10], Step [481/750], Loss: 0.1746\n",
      "Epoch [4/10], Step [482/750], Loss: 0.0444\n",
      "Epoch [4/10], Step [483/750], Loss: 0.0083\n",
      "Epoch [4/10], Step [484/750], Loss: 0.0685\n",
      "Epoch [4/10], Step [485/750], Loss: 0.1372\n",
      "Epoch [4/10], Step [486/750], Loss: 0.0514\n",
      "Epoch [4/10], Step [487/750], Loss: 0.0356\n",
      "Epoch [4/10], Step [488/750], Loss: 0.0193\n",
      "Epoch [4/10], Step [489/750], Loss: 0.2123\n",
      "Epoch [4/10], Step [490/750], Loss: 0.0930\n",
      "Epoch [4/10], Step [491/750], Loss: 0.0385\n",
      "Epoch [4/10], Step [492/750], Loss: 0.0141\n",
      "Epoch [4/10], Step [493/750], Loss: 0.0820\n",
      "Epoch [4/10], Step [494/750], Loss: 0.0512\n",
      "Epoch [4/10], Step [495/750], Loss: 0.0449\n",
      "Epoch [4/10], Step [496/750], Loss: 0.1973\n",
      "Epoch [4/10], Step [497/750], Loss: 0.0868\n",
      "Epoch [4/10], Step [498/750], Loss: 0.0462\n",
      "Epoch [4/10], Step [499/750], Loss: 0.0774\n",
      "Epoch [4/10], Step [500/750], Loss: 0.1054\n",
      "Epoch [4/10], Step [501/750], Loss: 0.0873\n",
      "Epoch [4/10], Step [502/750], Loss: 0.1027\n",
      "Epoch [4/10], Step [503/750], Loss: 0.1523\n",
      "Epoch [4/10], Step [504/750], Loss: 0.0282\n",
      "Epoch [4/10], Step [505/750], Loss: 0.0752\n",
      "Epoch [4/10], Step [506/750], Loss: 0.0411\n",
      "Epoch [4/10], Step [507/750], Loss: 0.0175\n",
      "Epoch [4/10], Step [508/750], Loss: 0.0420\n",
      "Epoch [4/10], Step [509/750], Loss: 0.0290\n",
      "Epoch [4/10], Step [510/750], Loss: 0.0446\n",
      "Epoch [4/10], Step [511/750], Loss: 0.0197\n",
      "Epoch [4/10], Step [512/750], Loss: 0.0348\n",
      "Epoch [4/10], Step [513/750], Loss: 0.0292\n",
      "Epoch [4/10], Step [514/750], Loss: 0.1177\n",
      "Epoch [4/10], Step [515/750], Loss: 0.0265\n",
      "Epoch [4/10], Step [516/750], Loss: 0.0167\n",
      "Epoch [4/10], Step [517/750], Loss: 0.0918\n",
      "Epoch [4/10], Step [518/750], Loss: 0.0445\n",
      "Epoch [4/10], Step [519/750], Loss: 0.0566\n",
      "Epoch [4/10], Step [520/750], Loss: 0.0962\n",
      "Epoch [4/10], Step [521/750], Loss: 0.0375\n",
      "Epoch [4/10], Step [522/750], Loss: 0.0676\n",
      "Epoch [4/10], Step [523/750], Loss: 0.0503\n",
      "Epoch [4/10], Step [524/750], Loss: 0.1728\n",
      "Epoch [4/10], Step [525/750], Loss: 0.0423\n",
      "Epoch [4/10], Step [526/750], Loss: 0.0635\n",
      "Epoch [4/10], Step [527/750], Loss: 0.0876\n",
      "Epoch [4/10], Step [528/750], Loss: 0.0727\n",
      "Epoch [4/10], Step [529/750], Loss: 0.1325\n",
      "Epoch [4/10], Step [530/750], Loss: 0.0886\n",
      "Epoch [4/10], Step [531/750], Loss: 0.0439\n",
      "Epoch [4/10], Step [532/750], Loss: 0.0103\n",
      "Epoch [4/10], Step [533/750], Loss: 0.0521\n",
      "Epoch [4/10], Step [534/750], Loss: 0.0442\n",
      "Epoch [4/10], Step [535/750], Loss: 0.0624\n",
      "Epoch [4/10], Step [536/750], Loss: 0.0312\n",
      "Epoch [4/10], Step [537/750], Loss: 0.1416\n",
      "Epoch [4/10], Step [538/750], Loss: 0.0184\n",
      "Epoch [4/10], Step [539/750], Loss: 0.0306\n",
      "Epoch [4/10], Step [540/750], Loss: 0.1096\n",
      "Epoch [4/10], Step [541/750], Loss: 0.1115\n",
      "Epoch [4/10], Step [542/750], Loss: 0.1020\n",
      "Epoch [4/10], Step [543/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [544/750], Loss: 0.1665\n",
      "Epoch [4/10], Step [545/750], Loss: 0.0256\n",
      "Epoch [4/10], Step [546/750], Loss: 0.0169\n",
      "Epoch [4/10], Step [547/750], Loss: 0.0281\n",
      "Epoch [4/10], Step [548/750], Loss: 0.0734\n",
      "Epoch [4/10], Step [549/750], Loss: 0.0700\n",
      "Epoch [4/10], Step [550/750], Loss: 0.1608\n",
      "Epoch [4/10], Step [551/750], Loss: 0.1410\n",
      "Epoch [4/10], Step [552/750], Loss: 0.0400\n",
      "Epoch [4/10], Step [553/750], Loss: 0.0188\n",
      "Epoch [4/10], Step [554/750], Loss: 0.0671\n",
      "Epoch [4/10], Step [555/750], Loss: 0.0681\n",
      "Epoch [4/10], Step [556/750], Loss: 0.0550\n",
      "Epoch [4/10], Step [557/750], Loss: 0.0160\n",
      "Epoch [4/10], Step [558/750], Loss: 0.0401\n",
      "Epoch [4/10], Step [559/750], Loss: 0.1544\n",
      "Epoch [4/10], Step [560/750], Loss: 0.1541\n",
      "Epoch [4/10], Step [561/750], Loss: 0.1084\n",
      "Epoch [4/10], Step [562/750], Loss: 0.1279\n",
      "Epoch [4/10], Step [563/750], Loss: 0.0598\n",
      "Epoch [4/10], Step [564/750], Loss: 0.1423\n",
      "Epoch [4/10], Step [565/750], Loss: 0.0653\n",
      "Epoch [4/10], Step [566/750], Loss: 0.0509\n",
      "Epoch [4/10], Step [567/750], Loss: 0.0910\n",
      "Epoch [4/10], Step [568/750], Loss: 0.0761\n",
      "Epoch [4/10], Step [569/750], Loss: 0.0206\n",
      "Epoch [4/10], Step [570/750], Loss: 0.0362\n",
      "Epoch [4/10], Step [571/750], Loss: 0.1596\n",
      "Epoch [4/10], Step [572/750], Loss: 0.0666\n",
      "Epoch [4/10], Step [573/750], Loss: 0.1140\n",
      "Epoch [4/10], Step [574/750], Loss: 0.0370\n",
      "Epoch [4/10], Step [575/750], Loss: 0.0771\n",
      "Epoch [4/10], Step [576/750], Loss: 0.0310\n",
      "Epoch [4/10], Step [577/750], Loss: 0.1113\n",
      "Epoch [4/10], Step [578/750], Loss: 0.0542\n",
      "Epoch [4/10], Step [579/750], Loss: 0.0776\n",
      "Epoch [4/10], Step [580/750], Loss: 0.0123\n",
      "Epoch [4/10], Step [581/750], Loss: 0.0150\n",
      "Epoch [4/10], Step [582/750], Loss: 0.0406\n",
      "Epoch [4/10], Step [583/750], Loss: 0.0286\n",
      "Epoch [4/10], Step [584/750], Loss: 0.0418\n",
      "Epoch [4/10], Step [585/750], Loss: 0.0274\n",
      "Epoch [4/10], Step [586/750], Loss: 0.0313\n",
      "Epoch [4/10], Step [587/750], Loss: 0.0807\n",
      "Epoch [4/10], Step [588/750], Loss: 0.0788\n",
      "Epoch [4/10], Step [589/750], Loss: 0.1518\n",
      "Epoch [4/10], Step [590/750], Loss: 0.0638\n",
      "Epoch [4/10], Step [591/750], Loss: 0.1172\n",
      "Epoch [4/10], Step [592/750], Loss: 0.1272\n",
      "Epoch [4/10], Step [593/750], Loss: 0.0880\n",
      "Epoch [4/10], Step [594/750], Loss: 0.0779\n",
      "Epoch [4/10], Step [595/750], Loss: 0.0426\n",
      "Epoch [4/10], Step [596/750], Loss: 0.1454\n",
      "Epoch [4/10], Step [597/750], Loss: 0.1355\n",
      "Epoch [4/10], Step [598/750], Loss: 0.0197\n",
      "Epoch [4/10], Step [599/750], Loss: 0.0419\n",
      "Epoch [4/10], Step [600/750], Loss: 0.0702\n",
      "Epoch [4/10], Step [601/750], Loss: 0.0583\n",
      "Epoch [4/10], Step [602/750], Loss: 0.0365\n",
      "Epoch [4/10], Step [603/750], Loss: 0.0520\n",
      "Epoch [4/10], Step [604/750], Loss: 0.0955\n",
      "Epoch [4/10], Step [605/750], Loss: 0.1002\n",
      "Epoch [4/10], Step [606/750], Loss: 0.1772\n",
      "Epoch [4/10], Step [607/750], Loss: 0.0463\n",
      "Epoch [4/10], Step [608/750], Loss: 0.0347\n",
      "Epoch [4/10], Step [609/750], Loss: 0.1139\n",
      "Epoch [4/10], Step [610/750], Loss: 0.0713\n",
      "Epoch [4/10], Step [611/750], Loss: 0.0406\n",
      "Epoch [4/10], Step [612/750], Loss: 0.1444\n",
      "Epoch [4/10], Step [613/750], Loss: 0.1239\n",
      "Epoch [4/10], Step [614/750], Loss: 0.0274\n",
      "Epoch [4/10], Step [615/750], Loss: 0.1256\n",
      "Epoch [4/10], Step [616/750], Loss: 0.1215\n",
      "Epoch [4/10], Step [617/750], Loss: 0.3194\n",
      "Epoch [4/10], Step [618/750], Loss: 0.0653\n",
      "Epoch [4/10], Step [619/750], Loss: 0.0466\n",
      "Epoch [4/10], Step [620/750], Loss: 0.0655\n",
      "Epoch [4/10], Step [621/750], Loss: 0.0180\n",
      "Epoch [4/10], Step [622/750], Loss: 0.1242\n",
      "Epoch [4/10], Step [623/750], Loss: 0.1198\n",
      "Epoch [4/10], Step [624/750], Loss: 0.0936\n",
      "Epoch [4/10], Step [625/750], Loss: 0.1233\n",
      "Epoch [4/10], Step [626/750], Loss: 0.0304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [627/750], Loss: 0.1542\n",
      "Epoch [4/10], Step [628/750], Loss: 0.1836\n",
      "Epoch [4/10], Step [629/750], Loss: 0.0094\n",
      "Epoch [4/10], Step [630/750], Loss: 0.1437\n",
      "Epoch [4/10], Step [631/750], Loss: 0.0997\n",
      "Epoch [4/10], Step [632/750], Loss: 0.0653\n",
      "Epoch [4/10], Step [633/750], Loss: 0.1269\n",
      "Epoch [4/10], Step [634/750], Loss: 0.0329\n",
      "Epoch [4/10], Step [635/750], Loss: 0.0956\n",
      "Epoch [4/10], Step [636/750], Loss: 0.0384\n",
      "Epoch [4/10], Step [637/750], Loss: 0.1710\n",
      "Epoch [4/10], Step [638/750], Loss: 0.0593\n",
      "Epoch [4/10], Step [639/750], Loss: 0.1965\n",
      "Epoch [4/10], Step [640/750], Loss: 0.0609\n",
      "Epoch [4/10], Step [641/750], Loss: 0.1351\n",
      "Epoch [4/10], Step [642/750], Loss: 0.0487\n",
      "Epoch [4/10], Step [643/750], Loss: 0.1105\n",
      "Epoch [4/10], Step [644/750], Loss: 0.1322\n",
      "Epoch [4/10], Step [645/750], Loss: 0.1033\n",
      "Epoch [4/10], Step [646/750], Loss: 0.0289\n",
      "Epoch [4/10], Step [647/750], Loss: 0.0872\n",
      "Epoch [4/10], Step [648/750], Loss: 0.0526\n",
      "Epoch [4/10], Step [649/750], Loss: 0.1445\n",
      "Epoch [4/10], Step [650/750], Loss: 0.1154\n",
      "Epoch [4/10], Step [651/750], Loss: 0.0567\n",
      "Epoch [4/10], Step [652/750], Loss: 0.0594\n",
      "Epoch [4/10], Step [653/750], Loss: 0.0459\n",
      "Epoch [4/10], Step [654/750], Loss: 0.1322\n",
      "Epoch [4/10], Step [655/750], Loss: 0.1960\n",
      "Epoch [4/10], Step [656/750], Loss: 0.1571\n",
      "Epoch [4/10], Step [657/750], Loss: 0.0595\n",
      "Epoch [4/10], Step [658/750], Loss: 0.1345\n",
      "Epoch [4/10], Step [659/750], Loss: 0.1029\n",
      "Epoch [4/10], Step [660/750], Loss: 0.1249\n",
      "Epoch [4/10], Step [661/750], Loss: 0.0593\n",
      "Epoch [4/10], Step [662/750], Loss: 0.1437\n",
      "Epoch [4/10], Step [663/750], Loss: 0.0832\n",
      "Epoch [4/10], Step [664/750], Loss: 0.1287\n",
      "Epoch [4/10], Step [665/750], Loss: 0.1366\n",
      "Epoch [4/10], Step [666/750], Loss: 0.0575\n",
      "Epoch [4/10], Step [667/750], Loss: 0.0716\n",
      "Epoch [4/10], Step [668/750], Loss: 0.0724\n",
      "Epoch [4/10], Step [669/750], Loss: 0.0945\n",
      "Epoch [4/10], Step [670/750], Loss: 0.0654\n",
      "Epoch [4/10], Step [671/750], Loss: 0.0860\n",
      "Epoch [4/10], Step [672/750], Loss: 0.0472\n",
      "Epoch [4/10], Step [673/750], Loss: 0.0210\n",
      "Epoch [4/10], Step [674/750], Loss: 0.0565\n",
      "Epoch [4/10], Step [675/750], Loss: 0.0849\n",
      "Epoch [4/10], Step [676/750], Loss: 0.1617\n",
      "Epoch [4/10], Step [677/750], Loss: 0.1501\n",
      "Epoch [4/10], Step [678/750], Loss: 0.0637\n",
      "Epoch [4/10], Step [679/750], Loss: 0.0833\n",
      "Epoch [4/10], Step [680/750], Loss: 0.2826\n",
      "Epoch [4/10], Step [681/750], Loss: 0.0980\n",
      "Epoch [4/10], Step [682/750], Loss: 0.0950\n",
      "Epoch [4/10], Step [683/750], Loss: 0.0310\n",
      "Epoch [4/10], Step [684/750], Loss: 0.1041\n",
      "Epoch [4/10], Step [685/750], Loss: 0.0979\n",
      "Epoch [4/10], Step [686/750], Loss: 0.0720\n",
      "Epoch [4/10], Step [687/750], Loss: 0.0683\n",
      "Epoch [4/10], Step [688/750], Loss: 0.0750\n",
      "Epoch [4/10], Step [689/750], Loss: 0.0741\n",
      "Epoch [4/10], Step [690/750], Loss: 0.2557\n",
      "Epoch [4/10], Step [691/750], Loss: 0.0836\n",
      "Epoch [4/10], Step [692/750], Loss: 0.0657\n",
      "Epoch [4/10], Step [693/750], Loss: 0.1337\n",
      "Epoch [4/10], Step [694/750], Loss: 0.0781\n",
      "Epoch [4/10], Step [695/750], Loss: 0.1232\n",
      "Epoch [4/10], Step [696/750], Loss: 0.1292\n",
      "Epoch [4/10], Step [697/750], Loss: 0.0742\n",
      "Epoch [4/10], Step [698/750], Loss: 0.1142\n",
      "Epoch [4/10], Step [699/750], Loss: 0.0851\n",
      "Epoch [4/10], Step [700/750], Loss: 0.0339\n",
      "Epoch [4/10], Step [701/750], Loss: 0.1473\n",
      "Epoch [4/10], Step [702/750], Loss: 0.1235\n",
      "Epoch [4/10], Step [703/750], Loss: 0.0323\n",
      "Epoch [4/10], Step [704/750], Loss: 0.0694\n",
      "Epoch [4/10], Step [705/750], Loss: 0.0999\n",
      "Epoch [4/10], Step [706/750], Loss: 0.1722\n",
      "Epoch [4/10], Step [707/750], Loss: 0.1775\n",
      "Epoch [4/10], Step [708/750], Loss: 0.1083\n",
      "Epoch [4/10], Step [709/750], Loss: 0.0445\n",
      "Epoch [4/10], Step [710/750], Loss: 0.0818\n",
      "Epoch [4/10], Step [711/750], Loss: 0.0869\n",
      "Epoch [4/10], Step [712/750], Loss: 0.1191\n",
      "Epoch [4/10], Step [713/750], Loss: 0.1208\n",
      "Epoch [4/10], Step [714/750], Loss: 0.0280\n",
      "Epoch [4/10], Step [715/750], Loss: 0.0538\n",
      "Epoch [4/10], Step [716/750], Loss: 0.0718\n",
      "Epoch [4/10], Step [717/750], Loss: 0.0447\n",
      "Epoch [4/10], Step [718/750], Loss: 0.1083\n",
      "Epoch [4/10], Step [719/750], Loss: 0.1116\n",
      "Epoch [4/10], Step [720/750], Loss: 0.1715\n",
      "Epoch [4/10], Step [721/750], Loss: 0.0844\n",
      "Epoch [4/10], Step [722/750], Loss: 0.0744\n",
      "Epoch [4/10], Step [723/750], Loss: 0.0471\n",
      "Epoch [4/10], Step [724/750], Loss: 0.0744\n",
      "Epoch [4/10], Step [725/750], Loss: 0.1661\n",
      "Epoch [4/10], Step [726/750], Loss: 0.0391\n",
      "Epoch [4/10], Step [727/750], Loss: 0.0432\n",
      "Epoch [4/10], Step [728/750], Loss: 0.0553\n",
      "Epoch [4/10], Step [729/750], Loss: 0.1204\n",
      "Epoch [4/10], Step [730/750], Loss: 0.1317\n",
      "Epoch [4/10], Step [731/750], Loss: 0.0669\n",
      "Epoch [4/10], Step [732/750], Loss: 0.0950\n",
      "Epoch [4/10], Step [733/750], Loss: 0.0291\n",
      "Epoch [4/10], Step [734/750], Loss: 0.1003\n",
      "Epoch [4/10], Step [735/750], Loss: 0.0500\n",
      "Epoch [4/10], Step [736/750], Loss: 0.0930\n",
      "Epoch [4/10], Step [737/750], Loss: 0.0265\n",
      "Epoch [4/10], Step [738/750], Loss: 0.0360\n",
      "Epoch [4/10], Step [739/750], Loss: 0.1020\n",
      "Epoch [4/10], Step [740/750], Loss: 0.1102\n",
      "Epoch [4/10], Step [741/750], Loss: 0.0806\n",
      "Epoch [4/10], Step [742/750], Loss: 0.0906\n",
      "Epoch [4/10], Step [743/750], Loss: 0.0362\n",
      "Epoch [4/10], Step [744/750], Loss: 0.0399\n",
      "Epoch [4/10], Step [745/750], Loss: 0.0640\n",
      "Epoch [4/10], Step [746/750], Loss: 0.0398\n",
      "Epoch [4/10], Step [747/750], Loss: 0.0788\n",
      "Epoch [4/10], Step [748/750], Loss: 0.0541\n",
      "Epoch [4/10], Step [749/750], Loss: 0.0116\n",
      "Epoch [4/10], Step [750/750], Loss: 0.1157\n",
      "\n",
      "\n",
      "Epoch [5/10], Step [1/750], Loss: 0.0387\n",
      "Epoch [5/10], Step [2/750], Loss: 0.1645\n",
      "Epoch [5/10], Step [3/750], Loss: 0.0414\n",
      "Epoch [5/10], Step [4/750], Loss: 0.0537\n",
      "Epoch [5/10], Step [5/750], Loss: 0.0223\n",
      "Epoch [5/10], Step [6/750], Loss: 0.0980\n",
      "Epoch [5/10], Step [7/750], Loss: 0.0507\n",
      "Epoch [5/10], Step [8/750], Loss: 0.0889\n",
      "Epoch [5/10], Step [9/750], Loss: 0.0657\n",
      "Epoch [5/10], Step [10/750], Loss: 0.0725\n",
      "Epoch [5/10], Step [11/750], Loss: 0.1737\n",
      "Epoch [5/10], Step [12/750], Loss: 0.0245\n",
      "Epoch [5/10], Step [13/750], Loss: 0.0269\n",
      "Epoch [5/10], Step [14/750], Loss: 0.0300\n",
      "Epoch [5/10], Step [15/750], Loss: 0.0631\n",
      "Epoch [5/10], Step [16/750], Loss: 0.1333\n",
      "Epoch [5/10], Step [17/750], Loss: 0.0632\n",
      "Epoch [5/10], Step [18/750], Loss: 0.1515\n",
      "Epoch [5/10], Step [19/750], Loss: 0.0721\n",
      "Epoch [5/10], Step [20/750], Loss: 0.0741\n",
      "Epoch [5/10], Step [21/750], Loss: 0.0455\n",
      "Epoch [5/10], Step [22/750], Loss: 0.0404\n",
      "Epoch [5/10], Step [23/750], Loss: 0.1166\n",
      "Epoch [5/10], Step [24/750], Loss: 0.0738\n",
      "Epoch [5/10], Step [25/750], Loss: 0.0792\n",
      "Epoch [5/10], Step [26/750], Loss: 0.0474\n",
      "Epoch [5/10], Step [27/750], Loss: 0.1600\n",
      "Epoch [5/10], Step [28/750], Loss: 0.1034\n",
      "Epoch [5/10], Step [29/750], Loss: 0.0680\n",
      "Epoch [5/10], Step [30/750], Loss: 0.0879\n",
      "Epoch [5/10], Step [31/750], Loss: 0.0370\n",
      "Epoch [5/10], Step [32/750], Loss: 0.1184\n",
      "Epoch [5/10], Step [33/750], Loss: 0.0410\n",
      "Epoch [5/10], Step [34/750], Loss: 0.0339\n",
      "Epoch [5/10], Step [35/750], Loss: 0.0308\n",
      "Epoch [5/10], Step [36/750], Loss: 0.1165\n",
      "Epoch [5/10], Step [37/750], Loss: 0.0403\n",
      "Epoch [5/10], Step [38/750], Loss: 0.0850\n",
      "Epoch [5/10], Step [39/750], Loss: 0.1439\n",
      "Epoch [5/10], Step [40/750], Loss: 0.0493\n",
      "Epoch [5/10], Step [41/750], Loss: 0.0216\n",
      "Epoch [5/10], Step [42/750], Loss: 0.1038\n",
      "Epoch [5/10], Step [43/750], Loss: 0.0729\n",
      "Epoch [5/10], Step [44/750], Loss: 0.1512\n",
      "Epoch [5/10], Step [45/750], Loss: 0.0841\n",
      "Epoch [5/10], Step [46/750], Loss: 0.0153\n",
      "Epoch [5/10], Step [47/750], Loss: 0.0876\n",
      "Epoch [5/10], Step [48/750], Loss: 0.0941\n",
      "Epoch [5/10], Step [49/750], Loss: 0.1101\n",
      "Epoch [5/10], Step [50/750], Loss: 0.0943\n",
      "Epoch [5/10], Step [51/750], Loss: 0.0333\n",
      "Epoch [5/10], Step [52/750], Loss: 0.0144\n",
      "Epoch [5/10], Step [53/750], Loss: 0.0363\n",
      "Epoch [5/10], Step [54/750], Loss: 0.0296\n",
      "Epoch [5/10], Step [55/750], Loss: 0.0060\n",
      "Epoch [5/10], Step [56/750], Loss: 0.0865\n",
      "Epoch [5/10], Step [57/750], Loss: 0.0785\n",
      "Epoch [5/10], Step [58/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [59/750], Loss: 0.0591\n",
      "Epoch [5/10], Step [60/750], Loss: 0.0470\n",
      "Epoch [5/10], Step [61/750], Loss: 0.1521\n",
      "Epoch [5/10], Step [62/750], Loss: 0.0893\n",
      "Epoch [5/10], Step [63/750], Loss: 0.1279\n",
      "Epoch [5/10], Step [64/750], Loss: 0.0175\n",
      "Epoch [5/10], Step [65/750], Loss: 0.1892\n",
      "Epoch [5/10], Step [66/750], Loss: 0.1204\n",
      "Epoch [5/10], Step [67/750], Loss: 0.0231\n",
      "Epoch [5/10], Step [68/750], Loss: 0.1345\n",
      "Epoch [5/10], Step [69/750], Loss: 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [70/750], Loss: 0.0830\n",
      "Epoch [5/10], Step [71/750], Loss: 0.0405\n",
      "Epoch [5/10], Step [72/750], Loss: 0.0302\n",
      "Epoch [5/10], Step [73/750], Loss: 0.0274\n",
      "Epoch [5/10], Step [74/750], Loss: 0.0599\n",
      "Epoch [5/10], Step [75/750], Loss: 0.0053\n",
      "Epoch [5/10], Step [76/750], Loss: 0.0743\n",
      "Epoch [5/10], Step [77/750], Loss: 0.0639\n",
      "Epoch [5/10], Step [78/750], Loss: 0.0627\n",
      "Epoch [5/10], Step [79/750], Loss: 0.0430\n",
      "Epoch [5/10], Step [80/750], Loss: 0.0613\n",
      "Epoch [5/10], Step [81/750], Loss: 0.0754\n",
      "Epoch [5/10], Step [82/750], Loss: 0.0142\n",
      "Epoch [5/10], Step [83/750], Loss: 0.0212\n",
      "Epoch [5/10], Step [84/750], Loss: 0.0220\n",
      "Epoch [5/10], Step [85/750], Loss: 0.0998\n",
      "Epoch [5/10], Step [86/750], Loss: 0.1002\n",
      "Epoch [5/10], Step [87/750], Loss: 0.0348\n",
      "Epoch [5/10], Step [88/750], Loss: 0.1492\n",
      "Epoch [5/10], Step [89/750], Loss: 0.1094\n",
      "Epoch [5/10], Step [90/750], Loss: 0.1156\n",
      "Epoch [5/10], Step [91/750], Loss: 0.0538\n",
      "Epoch [5/10], Step [92/750], Loss: 0.1503\n",
      "Epoch [5/10], Step [93/750], Loss: 0.0915\n",
      "Epoch [5/10], Step [94/750], Loss: 0.0381\n",
      "Epoch [5/10], Step [95/750], Loss: 0.0533\n",
      "Epoch [5/10], Step [96/750], Loss: 0.0270\n",
      "Epoch [5/10], Step [97/750], Loss: 0.2747\n",
      "Epoch [5/10], Step [98/750], Loss: 0.0281\n",
      "Epoch [5/10], Step [99/750], Loss: 0.2742\n",
      "Epoch [5/10], Step [100/750], Loss: 0.0701\n",
      "Epoch [5/10], Step [101/750], Loss: 0.0643\n",
      "Epoch [5/10], Step [102/750], Loss: 0.0448\n",
      "Epoch [5/10], Step [103/750], Loss: 0.0416\n",
      "Epoch [5/10], Step [104/750], Loss: 0.0428\n",
      "Epoch [5/10], Step [105/750], Loss: 0.1268\n",
      "Epoch [5/10], Step [106/750], Loss: 0.1867\n",
      "Epoch [5/10], Step [107/750], Loss: 0.0552\n",
      "Epoch [5/10], Step [108/750], Loss: 0.0676\n",
      "Epoch [5/10], Step [109/750], Loss: 0.0691\n",
      "Epoch [5/10], Step [110/750], Loss: 0.1282\n",
      "Epoch [5/10], Step [111/750], Loss: 0.0946\n",
      "Epoch [5/10], Step [112/750], Loss: 0.0286\n",
      "Epoch [5/10], Step [113/750], Loss: 0.0397\n",
      "Epoch [5/10], Step [114/750], Loss: 0.0419\n",
      "Epoch [5/10], Step [115/750], Loss: 0.0131\n",
      "Epoch [5/10], Step [116/750], Loss: 0.0365\n",
      "Epoch [5/10], Step [117/750], Loss: 0.0490\n",
      "Epoch [5/10], Step [118/750], Loss: 0.0097\n",
      "Epoch [5/10], Step [119/750], Loss: 0.0671\n",
      "Epoch [5/10], Step [120/750], Loss: 0.0945\n",
      "Epoch [5/10], Step [121/750], Loss: 0.0216\n",
      "Epoch [5/10], Step [122/750], Loss: 0.1473\n",
      "Epoch [5/10], Step [123/750], Loss: 0.1295\n",
      "Epoch [5/10], Step [124/750], Loss: 0.1385\n",
      "Epoch [5/10], Step [125/750], Loss: 0.0211\n",
      "Epoch [5/10], Step [126/750], Loss: 0.0491\n",
      "Epoch [5/10], Step [127/750], Loss: 0.0642\n",
      "Epoch [5/10], Step [128/750], Loss: 0.0769\n",
      "Epoch [5/10], Step [129/750], Loss: 0.0488\n",
      "Epoch [5/10], Step [130/750], Loss: 0.0725\n",
      "Epoch [5/10], Step [131/750], Loss: 0.0240\n",
      "Epoch [5/10], Step [132/750], Loss: 0.1283\n",
      "Epoch [5/10], Step [133/750], Loss: 0.0287\n",
      "Epoch [5/10], Step [134/750], Loss: 0.1710\n",
      "Epoch [5/10], Step [135/750], Loss: 0.1345\n",
      "Epoch [5/10], Step [136/750], Loss: 0.0200\n",
      "Epoch [5/10], Step [137/750], Loss: 0.0602\n",
      "Epoch [5/10], Step [138/750], Loss: 0.1088\n",
      "Epoch [5/10], Step [139/750], Loss: 0.0527\n",
      "Epoch [5/10], Step [140/750], Loss: 0.0126\n",
      "Epoch [5/10], Step [141/750], Loss: 0.1422\n",
      "Epoch [5/10], Step [142/750], Loss: 0.1368\n",
      "Epoch [5/10], Step [143/750], Loss: 0.1076\n",
      "Epoch [5/10], Step [144/750], Loss: 0.0579\n",
      "Epoch [5/10], Step [145/750], Loss: 0.0284\n",
      "Epoch [5/10], Step [146/750], Loss: 0.1096\n",
      "Epoch [5/10], Step [147/750], Loss: 0.0458\n",
      "Epoch [5/10], Step [148/750], Loss: 0.0744\n",
      "Epoch [5/10], Step [149/750], Loss: 0.0600\n",
      "Epoch [5/10], Step [150/750], Loss: 0.1992\n",
      "Epoch [5/10], Step [151/750], Loss: 0.1368\n",
      "Epoch [5/10], Step [152/750], Loss: 0.0393\n",
      "Epoch [5/10], Step [153/750], Loss: 0.0247\n",
      "Epoch [5/10], Step [154/750], Loss: 0.0239\n",
      "Epoch [5/10], Step [155/750], Loss: 0.2558\n",
      "Epoch [5/10], Step [156/750], Loss: 0.0389\n",
      "Epoch [5/10], Step [157/750], Loss: 0.0793\n",
      "Epoch [5/10], Step [158/750], Loss: 0.0517\n",
      "Epoch [5/10], Step [159/750], Loss: 0.0375\n",
      "Epoch [5/10], Step [160/750], Loss: 0.2019\n",
      "Epoch [5/10], Step [161/750], Loss: 0.1381\n",
      "Epoch [5/10], Step [162/750], Loss: 0.0650\n",
      "Epoch [5/10], Step [163/750], Loss: 0.0858\n",
      "Epoch [5/10], Step [164/750], Loss: 0.0387\n",
      "Epoch [5/10], Step [165/750], Loss: 0.1253\n",
      "Epoch [5/10], Step [166/750], Loss: 0.0370\n",
      "Epoch [5/10], Step [167/750], Loss: 0.0971\n",
      "Epoch [5/10], Step [168/750], Loss: 0.0660\n",
      "Epoch [5/10], Step [169/750], Loss: 0.0829\n",
      "Epoch [5/10], Step [170/750], Loss: 0.0746\n",
      "Epoch [5/10], Step [171/750], Loss: 0.0728\n",
      "Epoch [5/10], Step [172/750], Loss: 0.0250\n",
      "Epoch [5/10], Step [173/750], Loss: 0.1067\n",
      "Epoch [5/10], Step [174/750], Loss: 0.0646\n",
      "Epoch [5/10], Step [175/750], Loss: 0.1441\n",
      "Epoch [5/10], Step [176/750], Loss: 0.0356\n",
      "Epoch [5/10], Step [177/750], Loss: 0.0594\n",
      "Epoch [5/10], Step [178/750], Loss: 0.1432\n",
      "Epoch [5/10], Step [179/750], Loss: 0.1216\n",
      "Epoch [5/10], Step [180/750], Loss: 0.0989\n",
      "Epoch [5/10], Step [181/750], Loss: 0.0978\n",
      "Epoch [5/10], Step [182/750], Loss: 0.1182\n",
      "Epoch [5/10], Step [183/750], Loss: 0.1497\n",
      "Epoch [5/10], Step [184/750], Loss: 0.1546\n",
      "Epoch [5/10], Step [185/750], Loss: 0.0815\n",
      "Epoch [5/10], Step [186/750], Loss: 0.0380\n",
      "Epoch [5/10], Step [187/750], Loss: 0.0755\n",
      "Epoch [5/10], Step [188/750], Loss: 0.0245\n",
      "Epoch [5/10], Step [189/750], Loss: 0.1478\n",
      "Epoch [5/10], Step [190/750], Loss: 0.0670\n",
      "Epoch [5/10], Step [191/750], Loss: 0.0470\n",
      "Epoch [5/10], Step [192/750], Loss: 0.1837\n",
      "Epoch [5/10], Step [193/750], Loss: 0.0379\n",
      "Epoch [5/10], Step [194/750], Loss: 0.0773\n",
      "Epoch [5/10], Step [195/750], Loss: 0.0246\n",
      "Epoch [5/10], Step [196/750], Loss: 0.0161\n",
      "Epoch [5/10], Step [197/750], Loss: 0.0430\n",
      "Epoch [5/10], Step [198/750], Loss: 0.0377\n",
      "Epoch [5/10], Step [199/750], Loss: 0.0467\n",
      "Epoch [5/10], Step [200/750], Loss: 0.0246\n",
      "Epoch [5/10], Step [201/750], Loss: 0.0770\n",
      "Epoch [5/10], Step [202/750], Loss: 0.1227\n",
      "Epoch [5/10], Step [203/750], Loss: 0.0195\n",
      "Epoch [5/10], Step [204/750], Loss: 0.0844\n",
      "Epoch [5/10], Step [205/750], Loss: 0.0290\n",
      "Epoch [5/10], Step [206/750], Loss: 0.0116\n",
      "Epoch [5/10], Step [207/750], Loss: 0.0845\n",
      "Epoch [5/10], Step [208/750], Loss: 0.0708\n",
      "Epoch [5/10], Step [209/750], Loss: 0.0338\n",
      "Epoch [5/10], Step [210/750], Loss: 0.0913\n",
      "Epoch [5/10], Step [211/750], Loss: 0.0286\n",
      "Epoch [5/10], Step [212/750], Loss: 0.0420\n",
      "Epoch [5/10], Step [213/750], Loss: 0.0207\n",
      "Epoch [5/10], Step [214/750], Loss: 0.0120\n",
      "Epoch [5/10], Step [215/750], Loss: 0.1215\n",
      "Epoch [5/10], Step [216/750], Loss: 0.1236\n",
      "Epoch [5/10], Step [217/750], Loss: 0.0620\n",
      "Epoch [5/10], Step [218/750], Loss: 0.0683\n",
      "Epoch [5/10], Step [219/750], Loss: 0.0597\n",
      "Epoch [5/10], Step [220/750], Loss: 0.0480\n",
      "Epoch [5/10], Step [221/750], Loss: 0.0953\n",
      "Epoch [5/10], Step [222/750], Loss: 0.0901\n",
      "Epoch [5/10], Step [223/750], Loss: 0.1424\n",
      "Epoch [5/10], Step [224/750], Loss: 0.0758\n",
      "Epoch [5/10], Step [225/750], Loss: 0.0508\n",
      "Epoch [5/10], Step [226/750], Loss: 0.0779\n",
      "Epoch [5/10], Step [227/750], Loss: 0.0961\n",
      "Epoch [5/10], Step [228/750], Loss: 0.0409\n",
      "Epoch [5/10], Step [229/750], Loss: 0.0471\n",
      "Epoch [5/10], Step [230/750], Loss: 0.0759\n",
      "Epoch [5/10], Step [231/750], Loss: 0.2087\n",
      "Epoch [5/10], Step [232/750], Loss: 0.0570\n",
      "Epoch [5/10], Step [233/750], Loss: 0.0679\n",
      "Epoch [5/10], Step [234/750], Loss: 0.1157\n",
      "Epoch [5/10], Step [235/750], Loss: 0.0648\n",
      "Epoch [5/10], Step [236/750], Loss: 0.1179\n",
      "Epoch [5/10], Step [237/750], Loss: 0.0430\n",
      "Epoch [5/10], Step [238/750], Loss: 0.0360\n",
      "Epoch [5/10], Step [239/750], Loss: 0.0916\n",
      "Epoch [5/10], Step [240/750], Loss: 0.0830\n",
      "Epoch [5/10], Step [241/750], Loss: 0.0290\n",
      "Epoch [5/10], Step [242/750], Loss: 0.0273\n",
      "Epoch [5/10], Step [243/750], Loss: 0.0189\n",
      "Epoch [5/10], Step [244/750], Loss: 0.0979\n",
      "Epoch [5/10], Step [245/750], Loss: 0.0751\n",
      "Epoch [5/10], Step [246/750], Loss: 0.0749\n",
      "Epoch [5/10], Step [247/750], Loss: 0.0675\n",
      "Epoch [5/10], Step [248/750], Loss: 0.1671\n",
      "Epoch [5/10], Step [249/750], Loss: 0.0456\n",
      "Epoch [5/10], Step [250/750], Loss: 0.2091\n",
      "Epoch [5/10], Step [251/750], Loss: 0.1027\n",
      "Epoch [5/10], Step [252/750], Loss: 0.0568\n",
      "Epoch [5/10], Step [253/750], Loss: 0.1726\n",
      "Epoch [5/10], Step [254/750], Loss: 0.0718\n",
      "Epoch [5/10], Step [255/750], Loss: 0.0222\n",
      "Epoch [5/10], Step [256/750], Loss: 0.0865\n",
      "Epoch [5/10], Step [257/750], Loss: 0.1496\n",
      "Epoch [5/10], Step [258/750], Loss: 0.0779\n",
      "Epoch [5/10], Step [259/750], Loss: 0.0270\n",
      "Epoch [5/10], Step [260/750], Loss: 0.1756\n",
      "Epoch [5/10], Step [261/750], Loss: 0.0946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [262/750], Loss: 0.0479\n",
      "Epoch [5/10], Step [263/750], Loss: 0.0681\n",
      "Epoch [5/10], Step [264/750], Loss: 0.0591\n",
      "Epoch [5/10], Step [265/750], Loss: 0.0165\n",
      "Epoch [5/10], Step [266/750], Loss: 0.0250\n",
      "Epoch [5/10], Step [267/750], Loss: 0.1383\n",
      "Epoch [5/10], Step [268/750], Loss: 0.0797\n",
      "Epoch [5/10], Step [269/750], Loss: 0.0459\n",
      "Epoch [5/10], Step [270/750], Loss: 0.1310\n",
      "Epoch [5/10], Step [271/750], Loss: 0.0753\n",
      "Epoch [5/10], Step [272/750], Loss: 0.0196\n",
      "Epoch [5/10], Step [273/750], Loss: 0.0279\n",
      "Epoch [5/10], Step [274/750], Loss: 0.0708\n",
      "Epoch [5/10], Step [275/750], Loss: 0.0093\n",
      "Epoch [5/10], Step [276/750], Loss: 0.0248\n",
      "Epoch [5/10], Step [277/750], Loss: 0.0520\n",
      "Epoch [5/10], Step [278/750], Loss: 0.0194\n",
      "Epoch [5/10], Step [279/750], Loss: 0.0540\n",
      "Epoch [5/10], Step [280/750], Loss: 0.1428\n",
      "Epoch [5/10], Step [281/750], Loss: 0.1105\n",
      "Epoch [5/10], Step [282/750], Loss: 0.0585\n",
      "Epoch [5/10], Step [283/750], Loss: 0.0346\n",
      "Epoch [5/10], Step [284/750], Loss: 0.0565\n",
      "Epoch [5/10], Step [285/750], Loss: 0.1418\n",
      "Epoch [5/10], Step [286/750], Loss: 0.0368\n",
      "Epoch [5/10], Step [287/750], Loss: 0.0665\n",
      "Epoch [5/10], Step [288/750], Loss: 0.0766\n",
      "Epoch [5/10], Step [289/750], Loss: 0.0215\n",
      "Epoch [5/10], Step [290/750], Loss: 0.2081\n",
      "Epoch [5/10], Step [291/750], Loss: 0.0894\n",
      "Epoch [5/10], Step [292/750], Loss: 0.0810\n",
      "Epoch [5/10], Step [293/750], Loss: 0.0115\n",
      "Epoch [5/10], Step [294/750], Loss: 0.0410\n",
      "Epoch [5/10], Step [295/750], Loss: 0.0753\n",
      "Epoch [5/10], Step [296/750], Loss: 0.0605\n",
      "Epoch [5/10], Step [297/750], Loss: 0.0571\n",
      "Epoch [5/10], Step [298/750], Loss: 0.0342\n",
      "Epoch [5/10], Step [299/750], Loss: 0.0916\n",
      "Epoch [5/10], Step [300/750], Loss: 0.0595\n",
      "Epoch [5/10], Step [301/750], Loss: 0.0121\n",
      "Epoch [5/10], Step [302/750], Loss: 0.0720\n",
      "Epoch [5/10], Step [303/750], Loss: 0.1054\n",
      "Epoch [5/10], Step [304/750], Loss: 0.0685\n",
      "Epoch [5/10], Step [305/750], Loss: 0.0201\n",
      "Epoch [5/10], Step [306/750], Loss: 0.0838\n",
      "Epoch [5/10], Step [307/750], Loss: 0.0858\n",
      "Epoch [5/10], Step [308/750], Loss: 0.1376\n",
      "Epoch [5/10], Step [309/750], Loss: 0.1362\n",
      "Epoch [5/10], Step [310/750], Loss: 0.0089\n",
      "Epoch [5/10], Step [311/750], Loss: 0.0760\n",
      "Epoch [5/10], Step [312/750], Loss: 0.0437\n",
      "Epoch [5/10], Step [313/750], Loss: 0.0106\n",
      "Epoch [5/10], Step [314/750], Loss: 0.1318\n",
      "Epoch [5/10], Step [315/750], Loss: 0.0036\n",
      "Epoch [5/10], Step [316/750], Loss: 0.0669\n",
      "Epoch [5/10], Step [317/750], Loss: 0.0487\n",
      "Epoch [5/10], Step [318/750], Loss: 0.0231\n",
      "Epoch [5/10], Step [319/750], Loss: 0.1335\n",
      "Epoch [5/10], Step [320/750], Loss: 0.1329\n",
      "Epoch [5/10], Step [321/750], Loss: 0.1439\n",
      "Epoch [5/10], Step [322/750], Loss: 0.1052\n",
      "Epoch [5/10], Step [323/750], Loss: 0.0184\n",
      "Epoch [5/10], Step [324/750], Loss: 0.0921\n",
      "Epoch [5/10], Step [325/750], Loss: 0.0863\n",
      "Epoch [5/10], Step [326/750], Loss: 0.1509\n",
      "Epoch [5/10], Step [327/750], Loss: 0.0636\n",
      "Epoch [5/10], Step [328/750], Loss: 0.0502\n",
      "Epoch [5/10], Step [329/750], Loss: 0.1009\n",
      "Epoch [5/10], Step [330/750], Loss: 0.1004\n",
      "Epoch [5/10], Step [331/750], Loss: 0.0919\n",
      "Epoch [5/10], Step [332/750], Loss: 0.0975\n",
      "Epoch [5/10], Step [333/750], Loss: 0.0276\n",
      "Epoch [5/10], Step [334/750], Loss: 0.0785\n",
      "Epoch [5/10], Step [335/750], Loss: 0.1800\n",
      "Epoch [5/10], Step [336/750], Loss: 0.0587\n",
      "Epoch [5/10], Step [337/750], Loss: 0.0540\n",
      "Epoch [5/10], Step [338/750], Loss: 0.1382\n",
      "Epoch [5/10], Step [339/750], Loss: 0.1680\n",
      "Epoch [5/10], Step [340/750], Loss: 0.0194\n",
      "Epoch [5/10], Step [341/750], Loss: 0.1553\n",
      "Epoch [5/10], Step [342/750], Loss: 0.0833\n",
      "Epoch [5/10], Step [343/750], Loss: 0.0292\n",
      "Epoch [5/10], Step [344/750], Loss: 0.0945\n",
      "Epoch [5/10], Step [345/750], Loss: 0.0440\n",
      "Epoch [5/10], Step [346/750], Loss: 0.0604\n",
      "Epoch [5/10], Step [347/750], Loss: 0.0156\n",
      "Epoch [5/10], Step [348/750], Loss: 0.0926\n",
      "Epoch [5/10], Step [349/750], Loss: 0.1145\n",
      "Epoch [5/10], Step [350/750], Loss: 0.0415\n",
      "Epoch [5/10], Step [351/750], Loss: 0.0264\n",
      "Epoch [5/10], Step [352/750], Loss: 0.0681\n",
      "Epoch [5/10], Step [353/750], Loss: 0.0314\n",
      "Epoch [5/10], Step [354/750], Loss: 0.0335\n",
      "Epoch [5/10], Step [355/750], Loss: 0.0423\n",
      "Epoch [5/10], Step [356/750], Loss: 0.0538\n",
      "Epoch [5/10], Step [357/750], Loss: 0.0841\n",
      "Epoch [5/10], Step [358/750], Loss: 0.0503\n",
      "Epoch [5/10], Step [359/750], Loss: 0.0480\n",
      "Epoch [5/10], Step [360/750], Loss: 0.0131\n",
      "Epoch [5/10], Step [361/750], Loss: 0.1828\n",
      "Epoch [5/10], Step [362/750], Loss: 0.0136\n",
      "Epoch [5/10], Step [363/750], Loss: 0.0749\n",
      "Epoch [5/10], Step [364/750], Loss: 0.1315\n",
      "Epoch [5/10], Step [365/750], Loss: 0.2656\n",
      "Epoch [5/10], Step [366/750], Loss: 0.0269\n",
      "Epoch [5/10], Step [367/750], Loss: 0.0201\n",
      "Epoch [5/10], Step [368/750], Loss: 0.1239\n",
      "Epoch [5/10], Step [369/750], Loss: 0.0500\n",
      "Epoch [5/10], Step [370/750], Loss: 0.1175\n",
      "Epoch [5/10], Step [371/750], Loss: 0.1646\n",
      "Epoch [5/10], Step [372/750], Loss: 0.1705\n",
      "Epoch [5/10], Step [373/750], Loss: 0.0586\n",
      "Epoch [5/10], Step [374/750], Loss: 0.0383\n",
      "Epoch [5/10], Step [375/750], Loss: 0.0416\n",
      "Epoch [5/10], Step [376/750], Loss: 0.0743\n",
      "Epoch [5/10], Step [377/750], Loss: 0.1202\n",
      "Epoch [5/10], Step [378/750], Loss: 0.2103\n",
      "Epoch [5/10], Step [379/750], Loss: 0.1182\n",
      "Epoch [5/10], Step [380/750], Loss: 0.1448\n",
      "Epoch [5/10], Step [381/750], Loss: 0.0366\n",
      "Epoch [5/10], Step [382/750], Loss: 0.0971\n",
      "Epoch [5/10], Step [383/750], Loss: 0.0933\n",
      "Epoch [5/10], Step [384/750], Loss: 0.0412\n",
      "Epoch [5/10], Step [385/750], Loss: 0.0606\n",
      "Epoch [5/10], Step [386/750], Loss: 0.1010\n",
      "Epoch [5/10], Step [387/750], Loss: 0.1313\n",
      "Epoch [5/10], Step [388/750], Loss: 0.2226\n",
      "Epoch [5/10], Step [389/750], Loss: 0.0208\n",
      "Epoch [5/10], Step [390/750], Loss: 0.0742\n",
      "Epoch [5/10], Step [391/750], Loss: 0.0190\n",
      "Epoch [5/10], Step [392/750], Loss: 0.0956\n",
      "Epoch [5/10], Step [393/750], Loss: 0.1023\n",
      "Epoch [5/10], Step [394/750], Loss: 0.0456\n",
      "Epoch [5/10], Step [395/750], Loss: 0.0251\n",
      "Epoch [5/10], Step [396/750], Loss: 0.1227\n",
      "Epoch [5/10], Step [397/750], Loss: 0.0641\n",
      "Epoch [5/10], Step [398/750], Loss: 0.1176\n",
      "Epoch [5/10], Step [399/750], Loss: 0.1637\n",
      "Epoch [5/10], Step [400/750], Loss: 0.1375\n",
      "Epoch [5/10], Step [401/750], Loss: 0.0714\n",
      "Epoch [5/10], Step [402/750], Loss: 0.1615\n",
      "Epoch [5/10], Step [403/750], Loss: 0.0201\n",
      "Epoch [5/10], Step [404/750], Loss: 0.1063\n",
      "Epoch [5/10], Step [405/750], Loss: 0.0526\n",
      "Epoch [5/10], Step [406/750], Loss: 0.0716\n",
      "Epoch [5/10], Step [407/750], Loss: 0.0504\n",
      "Epoch [5/10], Step [408/750], Loss: 0.0301\n",
      "Epoch [5/10], Step [409/750], Loss: 0.1086\n",
      "Epoch [5/10], Step [410/750], Loss: 0.0563\n",
      "Epoch [5/10], Step [411/750], Loss: 0.0093\n",
      "Epoch [5/10], Step [412/750], Loss: 0.0923\n",
      "Epoch [5/10], Step [413/750], Loss: 0.1162\n",
      "Epoch [5/10], Step [414/750], Loss: 0.1039\n",
      "Epoch [5/10], Step [415/750], Loss: 0.1341\n",
      "Epoch [5/10], Step [416/750], Loss: 0.0527\n",
      "Epoch [5/10], Step [417/750], Loss: 0.0334\n",
      "Epoch [5/10], Step [418/750], Loss: 0.0571\n",
      "Epoch [5/10], Step [419/750], Loss: 0.0666\n",
      "Epoch [5/10], Step [420/750], Loss: 0.0510\n",
      "Epoch [5/10], Step [421/750], Loss: 0.0987\n",
      "Epoch [5/10], Step [422/750], Loss: 0.0556\n",
      "Epoch [5/10], Step [423/750], Loss: 0.1656\n",
      "Epoch [5/10], Step [424/750], Loss: 0.0862\n",
      "Epoch [5/10], Step [425/750], Loss: 0.0472\n",
      "Epoch [5/10], Step [426/750], Loss: 0.0901\n",
      "Epoch [5/10], Step [427/750], Loss: 0.1580\n",
      "Epoch [5/10], Step [428/750], Loss: 0.3392\n",
      "Epoch [5/10], Step [429/750], Loss: 0.0352\n",
      "Epoch [5/10], Step [430/750], Loss: 0.0993\n",
      "Epoch [5/10], Step [431/750], Loss: 0.0463\n",
      "Epoch [5/10], Step [432/750], Loss: 0.0453\n",
      "Epoch [5/10], Step [433/750], Loss: 0.1297\n",
      "Epoch [5/10], Step [434/750], Loss: 0.0469\n",
      "Epoch [5/10], Step [435/750], Loss: 0.0474\n",
      "Epoch [5/10], Step [436/750], Loss: 0.2274\n",
      "Epoch [5/10], Step [437/750], Loss: 0.0404\n",
      "Epoch [5/10], Step [438/750], Loss: 0.1936\n",
      "Epoch [5/10], Step [439/750], Loss: 0.0496\n",
      "Epoch [5/10], Step [440/750], Loss: 0.1107\n",
      "Epoch [5/10], Step [441/750], Loss: 0.0294\n",
      "Epoch [5/10], Step [442/750], Loss: 0.0859\n",
      "Epoch [5/10], Step [443/750], Loss: 0.0320\n",
      "Epoch [5/10], Step [444/750], Loss: 0.1010\n",
      "Epoch [5/10], Step [445/750], Loss: 0.1249\n",
      "Epoch [5/10], Step [446/750], Loss: 0.0580\n",
      "Epoch [5/10], Step [447/750], Loss: 0.0167\n",
      "Epoch [5/10], Step [448/750], Loss: 0.0076\n",
      "Epoch [5/10], Step [449/750], Loss: 0.0840\n",
      "Epoch [5/10], Step [450/750], Loss: 0.1075\n",
      "Epoch [5/10], Step [451/750], Loss: 0.1408\n",
      "Epoch [5/10], Step [452/750], Loss: 0.0933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [453/750], Loss: 0.0349\n",
      "Epoch [5/10], Step [454/750], Loss: 0.0263\n",
      "Epoch [5/10], Step [455/750], Loss: 0.0116\n",
      "Epoch [5/10], Step [456/750], Loss: 0.0183\n",
      "Epoch [5/10], Step [457/750], Loss: 0.0746\n",
      "Epoch [5/10], Step [458/750], Loss: 0.1054\n",
      "Epoch [5/10], Step [459/750], Loss: 0.0074\n",
      "Epoch [5/10], Step [460/750], Loss: 0.0642\n",
      "Epoch [5/10], Step [461/750], Loss: 0.0640\n",
      "Epoch [5/10], Step [462/750], Loss: 0.0666\n",
      "Epoch [5/10], Step [463/750], Loss: 0.1834\n",
      "Epoch [5/10], Step [464/750], Loss: 0.1375\n",
      "Epoch [5/10], Step [465/750], Loss: 0.0319\n",
      "Epoch [5/10], Step [466/750], Loss: 0.0418\n",
      "Epoch [5/10], Step [467/750], Loss: 0.0193\n",
      "Epoch [5/10], Step [468/750], Loss: 0.0537\n",
      "Epoch [5/10], Step [469/750], Loss: 0.0677\n",
      "Epoch [5/10], Step [470/750], Loss: 0.1509\n",
      "Epoch [5/10], Step [471/750], Loss: 0.0473\n",
      "Epoch [5/10], Step [472/750], Loss: 0.0403\n",
      "Epoch [5/10], Step [473/750], Loss: 0.0932\n",
      "Epoch [5/10], Step [474/750], Loss: 0.0686\n",
      "Epoch [5/10], Step [475/750], Loss: 0.1142\n",
      "Epoch [5/10], Step [476/750], Loss: 0.1199\n",
      "Epoch [5/10], Step [477/750], Loss: 0.0163\n",
      "Epoch [5/10], Step [478/750], Loss: 0.1685\n",
      "Epoch [5/10], Step [479/750], Loss: 0.1309\n",
      "Epoch [5/10], Step [480/750], Loss: 0.0558\n",
      "Epoch [5/10], Step [481/750], Loss: 0.0327\n",
      "Epoch [5/10], Step [482/750], Loss: 0.0114\n",
      "Epoch [5/10], Step [483/750], Loss: 0.0375\n",
      "Epoch [5/10], Step [484/750], Loss: 0.0957\n",
      "Epoch [5/10], Step [485/750], Loss: 0.0797\n",
      "Epoch [5/10], Step [486/750], Loss: 0.0176\n",
      "Epoch [5/10], Step [487/750], Loss: 0.0686\n",
      "Epoch [5/10], Step [488/750], Loss: 0.0434\n",
      "Epoch [5/10], Step [489/750], Loss: 0.0483\n",
      "Epoch [5/10], Step [490/750], Loss: 0.0130\n",
      "Epoch [5/10], Step [491/750], Loss: 0.0390\n",
      "Epoch [5/10], Step [492/750], Loss: 0.0347\n",
      "Epoch [5/10], Step [493/750], Loss: 0.0085\n",
      "Epoch [5/10], Step [494/750], Loss: 0.0649\n",
      "Epoch [5/10], Step [495/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [496/750], Loss: 0.0101\n",
      "Epoch [5/10], Step [497/750], Loss: 0.0345\n",
      "Epoch [5/10], Step [498/750], Loss: 0.0168\n",
      "Epoch [5/10], Step [499/750], Loss: 0.0501\n",
      "Epoch [5/10], Step [500/750], Loss: 0.3072\n",
      "Epoch [5/10], Step [501/750], Loss: 0.1630\n",
      "Epoch [5/10], Step [502/750], Loss: 0.1703\n",
      "Epoch [5/10], Step [503/750], Loss: 0.0823\n",
      "Epoch [5/10], Step [504/750], Loss: 0.0858\n",
      "Epoch [5/10], Step [505/750], Loss: 0.1279\n",
      "Epoch [5/10], Step [506/750], Loss: 0.0628\n",
      "Epoch [5/10], Step [507/750], Loss: 0.0551\n",
      "Epoch [5/10], Step [508/750], Loss: 0.0205\n",
      "Epoch [5/10], Step [509/750], Loss: 0.0770\n",
      "Epoch [5/10], Step [510/750], Loss: 0.0619\n",
      "Epoch [5/10], Step [511/750], Loss: 0.0664\n",
      "Epoch [5/10], Step [512/750], Loss: 0.0964\n",
      "Epoch [5/10], Step [513/750], Loss: 0.1141\n",
      "Epoch [5/10], Step [514/750], Loss: 0.1280\n",
      "Epoch [5/10], Step [515/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [516/750], Loss: 0.0547\n",
      "Epoch [5/10], Step [517/750], Loss: 0.0397\n",
      "Epoch [5/10], Step [518/750], Loss: 0.1740\n",
      "Epoch [5/10], Step [519/750], Loss: 0.0681\n",
      "Epoch [5/10], Step [520/750], Loss: 0.1375\n",
      "Epoch [5/10], Step [521/750], Loss: 0.0070\n",
      "Epoch [5/10], Step [522/750], Loss: 0.0619\n",
      "Epoch [5/10], Step [523/750], Loss: 0.0869\n",
      "Epoch [5/10], Step [524/750], Loss: 0.0375\n",
      "Epoch [5/10], Step [525/750], Loss: 0.0936\n",
      "Epoch [5/10], Step [526/750], Loss: 0.0548\n",
      "Epoch [5/10], Step [527/750], Loss: 0.0505\n",
      "Epoch [5/10], Step [528/750], Loss: 0.0332\n",
      "Epoch [5/10], Step [529/750], Loss: 0.0313\n",
      "Epoch [5/10], Step [530/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [531/750], Loss: 0.2173\n",
      "Epoch [5/10], Step [532/750], Loss: 0.1077\n",
      "Epoch [5/10], Step [533/750], Loss: 0.0406\n",
      "Epoch [5/10], Step [534/750], Loss: 0.0756\n",
      "Epoch [5/10], Step [535/750], Loss: 0.0759\n",
      "Epoch [5/10], Step [536/750], Loss: 0.0582\n",
      "Epoch [5/10], Step [537/750], Loss: 0.0977\n",
      "Epoch [5/10], Step [538/750], Loss: 0.0387\n",
      "Epoch [5/10], Step [539/750], Loss: 0.0772\n",
      "Epoch [5/10], Step [540/750], Loss: 0.0596\n",
      "Epoch [5/10], Step [541/750], Loss: 0.1396\n",
      "Epoch [5/10], Step [542/750], Loss: 0.0208\n",
      "Epoch [5/10], Step [543/750], Loss: 0.1190\n",
      "Epoch [5/10], Step [544/750], Loss: 0.0882\n",
      "Epoch [5/10], Step [545/750], Loss: 0.1255\n",
      "Epoch [5/10], Step [546/750], Loss: 0.0723\n",
      "Epoch [5/10], Step [547/750], Loss: 0.1147\n",
      "Epoch [5/10], Step [548/750], Loss: 0.1198\n",
      "Epoch [5/10], Step [549/750], Loss: 0.1482\n",
      "Epoch [5/10], Step [550/750], Loss: 0.1533\n",
      "Epoch [5/10], Step [551/750], Loss: 0.0235\n",
      "Epoch [5/10], Step [552/750], Loss: 0.0660\n",
      "Epoch [5/10], Step [553/750], Loss: 0.1029\n",
      "Epoch [5/10], Step [554/750], Loss: 0.1055\n",
      "Epoch [5/10], Step [555/750], Loss: 0.0875\n",
      "Epoch [5/10], Step [556/750], Loss: 0.0635\n",
      "Epoch [5/10], Step [557/750], Loss: 0.1382\n",
      "Epoch [5/10], Step [558/750], Loss: 0.1093\n",
      "Epoch [5/10], Step [559/750], Loss: 0.0509\n",
      "Epoch [5/10], Step [560/750], Loss: 0.0460\n",
      "Epoch [5/10], Step [561/750], Loss: 0.0276\n",
      "Epoch [5/10], Step [562/750], Loss: 0.0809\n",
      "Epoch [5/10], Step [563/750], Loss: 0.1097\n",
      "Epoch [5/10], Step [564/750], Loss: 0.0973\n",
      "Epoch [5/10], Step [565/750], Loss: 0.0247\n",
      "Epoch [5/10], Step [566/750], Loss: 0.0443\n",
      "Epoch [5/10], Step [567/750], Loss: 0.1349\n",
      "Epoch [5/10], Step [568/750], Loss: 0.1011\n",
      "Epoch [5/10], Step [569/750], Loss: 0.1027\n",
      "Epoch [5/10], Step [570/750], Loss: 0.0555\n",
      "Epoch [5/10], Step [571/750], Loss: 0.0620\n",
      "Epoch [5/10], Step [572/750], Loss: 0.0633\n",
      "Epoch [5/10], Step [573/750], Loss: 0.0397\n",
      "Epoch [5/10], Step [574/750], Loss: 0.0508\n",
      "Epoch [5/10], Step [575/750], Loss: 0.1723\n",
      "Epoch [5/10], Step [576/750], Loss: 0.0415\n",
      "Epoch [5/10], Step [577/750], Loss: 0.0769\n",
      "Epoch [5/10], Step [578/750], Loss: 0.0684\n",
      "Epoch [5/10], Step [579/750], Loss: 0.0394\n",
      "Epoch [5/10], Step [580/750], Loss: 0.0584\n",
      "Epoch [5/10], Step [581/750], Loss: 0.0756\n",
      "Epoch [5/10], Step [582/750], Loss: 0.0526\n",
      "Epoch [5/10], Step [583/750], Loss: 0.0644\n",
      "Epoch [5/10], Step [584/750], Loss: 0.0650\n",
      "Epoch [5/10], Step [585/750], Loss: 0.1426\n",
      "Epoch [5/10], Step [586/750], Loss: 0.0405\n",
      "Epoch [5/10], Step [587/750], Loss: 0.1441\n",
      "Epoch [5/10], Step [588/750], Loss: 0.0886\n",
      "Epoch [5/10], Step [589/750], Loss: 0.0473\n",
      "Epoch [5/10], Step [590/750], Loss: 0.1082\n",
      "Epoch [5/10], Step [591/750], Loss: 0.0728\n",
      "Epoch [5/10], Step [592/750], Loss: 0.0962\n",
      "Epoch [5/10], Step [593/750], Loss: 0.0344\n",
      "Epoch [5/10], Step [594/750], Loss: 0.0727\n",
      "Epoch [5/10], Step [595/750], Loss: 0.0632\n",
      "Epoch [5/10], Step [596/750], Loss: 0.0820\n",
      "Epoch [5/10], Step [597/750], Loss: 0.1917\n",
      "Epoch [5/10], Step [598/750], Loss: 0.0250\n",
      "Epoch [5/10], Step [599/750], Loss: 0.0853\n",
      "Epoch [5/10], Step [600/750], Loss: 0.0523\n",
      "Epoch [5/10], Step [601/750], Loss: 0.0849\n",
      "Epoch [5/10], Step [602/750], Loss: 0.0384\n",
      "Epoch [5/10], Step [603/750], Loss: 0.0550\n",
      "Epoch [5/10], Step [604/750], Loss: 0.2012\n",
      "Epoch [5/10], Step [605/750], Loss: 0.0198\n",
      "Epoch [5/10], Step [606/750], Loss: 0.0438\n",
      "Epoch [5/10], Step [607/750], Loss: 0.0284\n",
      "Epoch [5/10], Step [608/750], Loss: 0.0687\n",
      "Epoch [5/10], Step [609/750], Loss: 0.0685\n",
      "Epoch [5/10], Step [610/750], Loss: 0.0931\n",
      "Epoch [5/10], Step [611/750], Loss: 0.0536\n",
      "Epoch [5/10], Step [612/750], Loss: 0.0482\n",
      "Epoch [5/10], Step [613/750], Loss: 0.0596\n",
      "Epoch [5/10], Step [614/750], Loss: 0.0491\n",
      "Epoch [5/10], Step [615/750], Loss: 0.1426\n",
      "Epoch [5/10], Step [616/750], Loss: 0.0768\n",
      "Epoch [5/10], Step [617/750], Loss: 0.0288\n",
      "Epoch [5/10], Step [618/750], Loss: 0.1514\n",
      "Epoch [5/10], Step [619/750], Loss: 0.0411\n",
      "Epoch [5/10], Step [620/750], Loss: 0.0443\n",
      "Epoch [5/10], Step [621/750], Loss: 0.0224\n",
      "Epoch [5/10], Step [622/750], Loss: 0.1057\n",
      "Epoch [5/10], Step [623/750], Loss: 0.0657\n",
      "Epoch [5/10], Step [624/750], Loss: 0.0839\n",
      "Epoch [5/10], Step [625/750], Loss: 0.0518\n",
      "Epoch [5/10], Step [626/750], Loss: 0.0519\n",
      "Epoch [5/10], Step [627/750], Loss: 0.0915\n",
      "Epoch [5/10], Step [628/750], Loss: 0.0477\n",
      "Epoch [5/10], Step [629/750], Loss: 0.0838\n",
      "Epoch [5/10], Step [630/750], Loss: 0.0343\n",
      "Epoch [5/10], Step [631/750], Loss: 0.0478\n",
      "Epoch [5/10], Step [632/750], Loss: 0.0433\n",
      "Epoch [5/10], Step [633/750], Loss: 0.0135\n",
      "Epoch [5/10], Step [634/750], Loss: 0.1102\n",
      "Epoch [5/10], Step [635/750], Loss: 0.0357\n",
      "Epoch [5/10], Step [636/750], Loss: 0.1684\n",
      "Epoch [5/10], Step [637/750], Loss: 0.0572\n",
      "Epoch [5/10], Step [638/750], Loss: 0.0392\n",
      "Epoch [5/10], Step [639/750], Loss: 0.1384\n",
      "Epoch [5/10], Step [640/750], Loss: 0.0301\n",
      "Epoch [5/10], Step [641/750], Loss: 0.0134\n",
      "Epoch [5/10], Step [642/750], Loss: 0.0634\n",
      "Epoch [5/10], Step [643/750], Loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [644/750], Loss: 0.0475\n",
      "Epoch [5/10], Step [645/750], Loss: 0.1652\n",
      "Epoch [5/10], Step [646/750], Loss: 0.0809\n",
      "Epoch [5/10], Step [647/750], Loss: 0.0372\n",
      "Epoch [5/10], Step [648/750], Loss: 0.0250\n",
      "Epoch [5/10], Step [649/750], Loss: 0.1380\n",
      "Epoch [5/10], Step [650/750], Loss: 0.1147\n",
      "Epoch [5/10], Step [651/750], Loss: 0.1279\n",
      "Epoch [5/10], Step [652/750], Loss: 0.0314\n",
      "Epoch [5/10], Step [653/750], Loss: 0.0845\n",
      "Epoch [5/10], Step [654/750], Loss: 0.0137\n",
      "Epoch [5/10], Step [655/750], Loss: 0.0513\n",
      "Epoch [5/10], Step [656/750], Loss: 0.1325\n",
      "Epoch [5/10], Step [657/750], Loss: 0.0711\n",
      "Epoch [5/10], Step [658/750], Loss: 0.0213\n",
      "Epoch [5/10], Step [659/750], Loss: 0.0441\n",
      "Epoch [5/10], Step [660/750], Loss: 0.1109\n",
      "Epoch [5/10], Step [661/750], Loss: 0.0310\n",
      "Epoch [5/10], Step [662/750], Loss: 0.2770\n",
      "Epoch [5/10], Step [663/750], Loss: 0.1026\n",
      "Epoch [5/10], Step [664/750], Loss: 0.0368\n",
      "Epoch [5/10], Step [665/750], Loss: 0.0974\n",
      "Epoch [5/10], Step [666/750], Loss: 0.1023\n",
      "Epoch [5/10], Step [667/750], Loss: 0.0222\n",
      "Epoch [5/10], Step [668/750], Loss: 0.0398\n",
      "Epoch [5/10], Step [669/750], Loss: 0.0605\n",
      "Epoch [5/10], Step [670/750], Loss: 0.0314\n",
      "Epoch [5/10], Step [671/750], Loss: 0.1748\n",
      "Epoch [5/10], Step [672/750], Loss: 0.1273\n",
      "Epoch [5/10], Step [673/750], Loss: 0.0183\n",
      "Epoch [5/10], Step [674/750], Loss: 0.0871\n",
      "Epoch [5/10], Step [675/750], Loss: 0.1015\n",
      "Epoch [5/10], Step [676/750], Loss: 0.0956\n",
      "Epoch [5/10], Step [677/750], Loss: 0.0337\n",
      "Epoch [5/10], Step [678/750], Loss: 0.1040\n",
      "Epoch [5/10], Step [679/750], Loss: 0.0512\n",
      "Epoch [5/10], Step [680/750], Loss: 0.1609\n",
      "Epoch [5/10], Step [681/750], Loss: 0.0432\n",
      "Epoch [5/10], Step [682/750], Loss: 0.0271\n",
      "Epoch [5/10], Step [683/750], Loss: 0.0353\n",
      "Epoch [5/10], Step [684/750], Loss: 0.0655\n",
      "Epoch [5/10], Step [685/750], Loss: 0.1538\n",
      "Epoch [5/10], Step [686/750], Loss: 0.1801\n",
      "Epoch [5/10], Step [687/750], Loss: 0.1616\n",
      "Epoch [5/10], Step [688/750], Loss: 0.1445\n",
      "Epoch [5/10], Step [689/750], Loss: 0.0287\n",
      "Epoch [5/10], Step [690/750], Loss: 0.1484\n",
      "Epoch [5/10], Step [691/750], Loss: 0.1155\n",
      "Epoch [5/10], Step [692/750], Loss: 0.0779\n",
      "Epoch [5/10], Step [693/750], Loss: 0.1402\n",
      "Epoch [5/10], Step [694/750], Loss: 0.0249\n",
      "Epoch [5/10], Step [695/750], Loss: 0.1062\n",
      "Epoch [5/10], Step [696/750], Loss: 0.0186\n",
      "Epoch [5/10], Step [697/750], Loss: 0.0704\n",
      "Epoch [5/10], Step [698/750], Loss: 0.0455\n",
      "Epoch [5/10], Step [699/750], Loss: 0.0508\n",
      "Epoch [5/10], Step [700/750], Loss: 0.0190\n",
      "Epoch [5/10], Step [701/750], Loss: 0.0597\n",
      "Epoch [5/10], Step [702/750], Loss: 0.1096\n",
      "Epoch [5/10], Step [703/750], Loss: 0.1809\n",
      "Epoch [5/10], Step [704/750], Loss: 0.0889\n",
      "Epoch [5/10], Step [705/750], Loss: 0.0805\n",
      "Epoch [5/10], Step [706/750], Loss: 0.1232\n",
      "Epoch [5/10], Step [707/750], Loss: 0.1054\n",
      "Epoch [5/10], Step [708/750], Loss: 0.0336\n",
      "Epoch [5/10], Step [709/750], Loss: 0.1720\n",
      "Epoch [5/10], Step [710/750], Loss: 0.0606\n",
      "Epoch [5/10], Step [711/750], Loss: 0.0723\n",
      "Epoch [5/10], Step [712/750], Loss: 0.1939\n",
      "Epoch [5/10], Step [713/750], Loss: 0.0423\n",
      "Epoch [5/10], Step [714/750], Loss: 0.1349\n",
      "Epoch [5/10], Step [715/750], Loss: 0.0696\n",
      "Epoch [5/10], Step [716/750], Loss: 0.0206\n",
      "Epoch [5/10], Step [717/750], Loss: 0.0525\n",
      "Epoch [5/10], Step [718/750], Loss: 0.1490\n",
      "Epoch [5/10], Step [719/750], Loss: 0.2269\n",
      "Epoch [5/10], Step [720/750], Loss: 0.1068\n",
      "Epoch [5/10], Step [721/750], Loss: 0.2844\n",
      "Epoch [5/10], Step [722/750], Loss: 0.0485\n",
      "Epoch [5/10], Step [723/750], Loss: 0.1944\n",
      "Epoch [5/10], Step [724/750], Loss: 0.0249\n",
      "Epoch [5/10], Step [725/750], Loss: 0.1227\n",
      "Epoch [5/10], Step [726/750], Loss: 0.1516\n",
      "Epoch [5/10], Step [727/750], Loss: 0.0908\n",
      "Epoch [5/10], Step [728/750], Loss: 0.1095\n",
      "Epoch [5/10], Step [729/750], Loss: 0.1616\n",
      "Epoch [5/10], Step [730/750], Loss: 0.1159\n",
      "Epoch [5/10], Step [731/750], Loss: 0.2061\n",
      "Epoch [5/10], Step [732/750], Loss: 0.0898\n",
      "Epoch [5/10], Step [733/750], Loss: 0.1085\n",
      "Epoch [5/10], Step [734/750], Loss: 0.1111\n",
      "Epoch [5/10], Step [735/750], Loss: 0.2872\n",
      "Epoch [5/10], Step [736/750], Loss: 0.1746\n",
      "Epoch [5/10], Step [737/750], Loss: 0.0512\n",
      "Epoch [5/10], Step [738/750], Loss: 0.1354\n",
      "Epoch [5/10], Step [739/750], Loss: 0.1225\n",
      "Epoch [5/10], Step [740/750], Loss: 0.1488\n",
      "Epoch [5/10], Step [741/750], Loss: 0.0674\n",
      "Epoch [5/10], Step [742/750], Loss: 0.0755\n",
      "Epoch [5/10], Step [743/750], Loss: 0.1210\n",
      "Epoch [5/10], Step [744/750], Loss: 0.1364\n",
      "Epoch [5/10], Step [745/750], Loss: 0.1505\n",
      "Epoch [5/10], Step [746/750], Loss: 0.0976\n",
      "Epoch [5/10], Step [747/750], Loss: 0.0286\n",
      "Epoch [5/10], Step [748/750], Loss: 0.0320\n",
      "Epoch [5/10], Step [749/750], Loss: 0.0283\n",
      "Epoch [5/10], Step [750/750], Loss: 0.0509\n",
      "\n",
      "\n",
      "Epoch [6/10], Step [1/750], Loss: 0.1100\n",
      "Epoch [6/10], Step [2/750], Loss: 0.0656\n",
      "Epoch [6/10], Step [3/750], Loss: 0.1670\n",
      "Epoch [6/10], Step [4/750], Loss: 0.0898\n",
      "Epoch [6/10], Step [5/750], Loss: 0.1246\n",
      "Epoch [6/10], Step [6/750], Loss: 0.0184\n",
      "Epoch [6/10], Step [7/750], Loss: 0.0355\n",
      "Epoch [6/10], Step [8/750], Loss: 0.0211\n",
      "Epoch [6/10], Step [9/750], Loss: 0.0352\n",
      "Epoch [6/10], Step [10/750], Loss: 0.1759\n",
      "Epoch [6/10], Step [11/750], Loss: 0.0975\n",
      "Epoch [6/10], Step [12/750], Loss: 0.1248\n",
      "Epoch [6/10], Step [13/750], Loss: 0.1298\n",
      "Epoch [6/10], Step [14/750], Loss: 0.1094\n",
      "Epoch [6/10], Step [15/750], Loss: 0.0739\n",
      "Epoch [6/10], Step [16/750], Loss: 0.1306\n",
      "Epoch [6/10], Step [17/750], Loss: 0.1570\n",
      "Epoch [6/10], Step [18/750], Loss: 0.1081\n",
      "Epoch [6/10], Step [19/750], Loss: 0.0392\n",
      "Epoch [6/10], Step [20/750], Loss: 0.1788\n",
      "Epoch [6/10], Step [21/750], Loss: 0.0453\n",
      "Epoch [6/10], Step [22/750], Loss: 0.0273\n",
      "Epoch [6/10], Step [23/750], Loss: 0.1015\n",
      "Epoch [6/10], Step [24/750], Loss: 0.0482\n",
      "Epoch [6/10], Step [25/750], Loss: 0.0900\n",
      "Epoch [6/10], Step [26/750], Loss: 0.1412\n",
      "Epoch [6/10], Step [27/750], Loss: 0.0943\n",
      "Epoch [6/10], Step [28/750], Loss: 0.0210\n",
      "Epoch [6/10], Step [29/750], Loss: 0.0964\n",
      "Epoch [6/10], Step [30/750], Loss: 0.0698\n",
      "Epoch [6/10], Step [31/750], Loss: 0.1875\n",
      "Epoch [6/10], Step [32/750], Loss: 0.1004\n",
      "Epoch [6/10], Step [33/750], Loss: 0.1301\n",
      "Epoch [6/10], Step [34/750], Loss: 0.0282\n",
      "Epoch [6/10], Step [35/750], Loss: 0.0623\n",
      "Epoch [6/10], Step [36/750], Loss: 0.0407\n",
      "Epoch [6/10], Step [37/750], Loss: 0.0415\n",
      "Epoch [6/10], Step [38/750], Loss: 0.2512\n",
      "Epoch [6/10], Step [39/750], Loss: 0.1433\n",
      "Epoch [6/10], Step [40/750], Loss: 0.1076\n",
      "Epoch [6/10], Step [41/750], Loss: 0.1196\n",
      "Epoch [6/10], Step [42/750], Loss: 0.0348\n",
      "Epoch [6/10], Step [43/750], Loss: 0.0303\n",
      "Epoch [6/10], Step [44/750], Loss: 0.0981\n",
      "Epoch [6/10], Step [45/750], Loss: 0.1483\n",
      "Epoch [6/10], Step [46/750], Loss: 0.0609\n",
      "Epoch [6/10], Step [47/750], Loss: 0.1437\n",
      "Epoch [6/10], Step [48/750], Loss: 0.0867\n",
      "Epoch [6/10], Step [49/750], Loss: 0.1528\n",
      "Epoch [6/10], Step [50/750], Loss: 0.1225\n",
      "Epoch [6/10], Step [51/750], Loss: 0.1124\n",
      "Epoch [6/10], Step [52/750], Loss: 0.0766\n",
      "Epoch [6/10], Step [53/750], Loss: 0.0668\n",
      "Epoch [6/10], Step [54/750], Loss: 0.0187\n",
      "Epoch [6/10], Step [55/750], Loss: 0.0866\n",
      "Epoch [6/10], Step [56/750], Loss: 0.0285\n",
      "Epoch [6/10], Step [57/750], Loss: 0.0749\n",
      "Epoch [6/10], Step [58/750], Loss: 0.0606\n",
      "Epoch [6/10], Step [59/750], Loss: 0.0577\n",
      "Epoch [6/10], Step [60/750], Loss: 0.1493\n",
      "Epoch [6/10], Step [61/750], Loss: 0.0942\n",
      "Epoch [6/10], Step [62/750], Loss: 0.0874\n",
      "Epoch [6/10], Step [63/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [64/750], Loss: 0.0291\n",
      "Epoch [6/10], Step [65/750], Loss: 0.0281\n",
      "Epoch [6/10], Step [66/750], Loss: 0.0452\n",
      "Epoch [6/10], Step [67/750], Loss: 0.0457\n",
      "Epoch [6/10], Step [68/750], Loss: 0.1216\n",
      "Epoch [6/10], Step [69/750], Loss: 0.1009\n",
      "Epoch [6/10], Step [70/750], Loss: 0.0945\n",
      "Epoch [6/10], Step [71/750], Loss: 0.0859\n",
      "Epoch [6/10], Step [72/750], Loss: 0.0428\n",
      "Epoch [6/10], Step [73/750], Loss: 0.0146\n",
      "Epoch [6/10], Step [74/750], Loss: 0.0751\n",
      "Epoch [6/10], Step [75/750], Loss: 0.0258\n",
      "Epoch [6/10], Step [76/750], Loss: 0.0486\n",
      "Epoch [6/10], Step [77/750], Loss: 0.1599\n",
      "Epoch [6/10], Step [78/750], Loss: 0.0526\n",
      "Epoch [6/10], Step [79/750], Loss: 0.1966\n",
      "Epoch [6/10], Step [80/750], Loss: 0.0552\n",
      "Epoch [6/10], Step [81/750], Loss: 0.1185\n",
      "Epoch [6/10], Step [82/750], Loss: 0.0540\n",
      "Epoch [6/10], Step [83/750], Loss: 0.0116\n",
      "Epoch [6/10], Step [84/750], Loss: 0.0681\n",
      "Epoch [6/10], Step [85/750], Loss: 0.1555\n",
      "Epoch [6/10], Step [86/750], Loss: 0.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [87/750], Loss: 0.0984\n",
      "Epoch [6/10], Step [88/750], Loss: 0.0745\n",
      "Epoch [6/10], Step [89/750], Loss: 0.0444\n",
      "Epoch [6/10], Step [90/750], Loss: 0.1814\n",
      "Epoch [6/10], Step [91/750], Loss: 0.1217\n",
      "Epoch [6/10], Step [92/750], Loss: 0.1048\n",
      "Epoch [6/10], Step [93/750], Loss: 0.1389\n",
      "Epoch [6/10], Step [94/750], Loss: 0.0933\n",
      "Epoch [6/10], Step [95/750], Loss: 0.0342\n",
      "Epoch [6/10], Step [96/750], Loss: 0.2622\n",
      "Epoch [6/10], Step [97/750], Loss: 0.0985\n",
      "Epoch [6/10], Step [98/750], Loss: 0.0654\n",
      "Epoch [6/10], Step [99/750], Loss: 0.0350\n",
      "Epoch [6/10], Step [100/750], Loss: 0.0259\n",
      "Epoch [6/10], Step [101/750], Loss: 0.0519\n",
      "Epoch [6/10], Step [102/750], Loss: 0.0526\n",
      "Epoch [6/10], Step [103/750], Loss: 0.0229\n",
      "Epoch [6/10], Step [104/750], Loss: 0.0875\n",
      "Epoch [6/10], Step [105/750], Loss: 0.0414\n",
      "Epoch [6/10], Step [106/750], Loss: 0.0355\n",
      "Epoch [6/10], Step [107/750], Loss: 0.0186\n",
      "Epoch [6/10], Step [108/750], Loss: 0.0470\n",
      "Epoch [6/10], Step [109/750], Loss: 0.0881\n",
      "Epoch [6/10], Step [110/750], Loss: 0.0505\n",
      "Epoch [6/10], Step [111/750], Loss: 0.0199\n",
      "Epoch [6/10], Step [112/750], Loss: 0.1491\n",
      "Epoch [6/10], Step [113/750], Loss: 0.0172\n",
      "Epoch [6/10], Step [114/750], Loss: 0.0283\n",
      "Epoch [6/10], Step [115/750], Loss: 0.0533\n",
      "Epoch [6/10], Step [116/750], Loss: 0.0240\n",
      "Epoch [6/10], Step [117/750], Loss: 0.0600\n",
      "Epoch [6/10], Step [118/750], Loss: 0.0965\n",
      "Epoch [6/10], Step [119/750], Loss: 0.2268\n",
      "Epoch [6/10], Step [120/750], Loss: 0.0779\n",
      "Epoch [6/10], Step [121/750], Loss: 0.0687\n",
      "Epoch [6/10], Step [122/750], Loss: 0.0559\n",
      "Epoch [6/10], Step [123/750], Loss: 0.1140\n",
      "Epoch [6/10], Step [124/750], Loss: 0.1170\n",
      "Epoch [6/10], Step [125/750], Loss: 0.1420\n",
      "Epoch [6/10], Step [126/750], Loss: 0.0670\n",
      "Epoch [6/10], Step [127/750], Loss: 0.0867\n",
      "Epoch [6/10], Step [128/750], Loss: 0.1909\n",
      "Epoch [6/10], Step [129/750], Loss: 0.0884\n",
      "Epoch [6/10], Step [130/750], Loss: 0.0717\n",
      "Epoch [6/10], Step [131/750], Loss: 0.0186\n",
      "Epoch [6/10], Step [132/750], Loss: 0.2599\n",
      "Epoch [6/10], Step [133/750], Loss: 0.0881\n",
      "Epoch [6/10], Step [134/750], Loss: 0.1184\n",
      "Epoch [6/10], Step [135/750], Loss: 0.0563\n",
      "Epoch [6/10], Step [136/750], Loss: 0.0420\n",
      "Epoch [6/10], Step [137/750], Loss: 0.0745\n",
      "Epoch [6/10], Step [138/750], Loss: 0.0251\n",
      "Epoch [6/10], Step [139/750], Loss: 0.1349\n",
      "Epoch [6/10], Step [140/750], Loss: 0.0246\n",
      "Epoch [6/10], Step [141/750], Loss: 0.1425\n",
      "Epoch [6/10], Step [142/750], Loss: 0.0610\n",
      "Epoch [6/10], Step [143/750], Loss: 0.0197\n",
      "Epoch [6/10], Step [144/750], Loss: 0.0903\n",
      "Epoch [6/10], Step [145/750], Loss: 0.1005\n",
      "Epoch [6/10], Step [146/750], Loss: 0.0569\n",
      "Epoch [6/10], Step [147/750], Loss: 0.0729\n",
      "Epoch [6/10], Step [148/750], Loss: 0.0292\n",
      "Epoch [6/10], Step [149/750], Loss: 0.0350\n",
      "Epoch [6/10], Step [150/750], Loss: 0.0208\n",
      "Epoch [6/10], Step [151/750], Loss: 0.0468\n",
      "Epoch [6/10], Step [152/750], Loss: 0.0562\n",
      "Epoch [6/10], Step [153/750], Loss: 0.0291\n",
      "Epoch [6/10], Step [154/750], Loss: 0.1374\n",
      "Epoch [6/10], Step [155/750], Loss: 0.0478\n",
      "Epoch [6/10], Step [156/750], Loss: 0.1187\n",
      "Epoch [6/10], Step [157/750], Loss: 0.0119\n",
      "Epoch [6/10], Step [158/750], Loss: 0.0081\n",
      "Epoch [6/10], Step [159/750], Loss: 0.0184\n",
      "Epoch [6/10], Step [160/750], Loss: 0.1831\n",
      "Epoch [6/10], Step [161/750], Loss: 0.1090\n",
      "Epoch [6/10], Step [162/750], Loss: 0.0618\n",
      "Epoch [6/10], Step [163/750], Loss: 0.0189\n",
      "Epoch [6/10], Step [164/750], Loss: 0.0708\n",
      "Epoch [6/10], Step [165/750], Loss: 0.0655\n",
      "Epoch [6/10], Step [166/750], Loss: 0.0094\n",
      "Epoch [6/10], Step [167/750], Loss: 0.1471\n",
      "Epoch [6/10], Step [168/750], Loss: 0.2082\n",
      "Epoch [6/10], Step [169/750], Loss: 0.0195\n",
      "Epoch [6/10], Step [170/750], Loss: 0.1890\n",
      "Epoch [6/10], Step [171/750], Loss: 0.0306\n",
      "Epoch [6/10], Step [172/750], Loss: 0.0428\n",
      "Epoch [6/10], Step [173/750], Loss: 0.0170\n",
      "Epoch [6/10], Step [174/750], Loss: 0.0221\n",
      "Epoch [6/10], Step [175/750], Loss: 0.1551\n",
      "Epoch [6/10], Step [176/750], Loss: 0.0654\n",
      "Epoch [6/10], Step [177/750], Loss: 0.1371\n",
      "Epoch [6/10], Step [178/750], Loss: 0.0882\n",
      "Epoch [6/10], Step [179/750], Loss: 0.0268\n",
      "Epoch [6/10], Step [180/750], Loss: 0.1371\n",
      "Epoch [6/10], Step [181/750], Loss: 0.0363\n",
      "Epoch [6/10], Step [182/750], Loss: 0.0257\n",
      "Epoch [6/10], Step [183/750], Loss: 0.0465\n",
      "Epoch [6/10], Step [184/750], Loss: 0.1085\n",
      "Epoch [6/10], Step [185/750], Loss: 0.0446\n",
      "Epoch [6/10], Step [186/750], Loss: 0.0664\n",
      "Epoch [6/10], Step [187/750], Loss: 0.0536\n",
      "Epoch [6/10], Step [188/750], Loss: 0.2987\n",
      "Epoch [6/10], Step [189/750], Loss: 0.0551\n",
      "Epoch [6/10], Step [190/750], Loss: 0.0564\n",
      "Epoch [6/10], Step [191/750], Loss: 0.0435\n",
      "Epoch [6/10], Step [192/750], Loss: 0.1857\n",
      "Epoch [6/10], Step [193/750], Loss: 0.1177\n",
      "Epoch [6/10], Step [194/750], Loss: 0.0833\n",
      "Epoch [6/10], Step [195/750], Loss: 0.1582\n",
      "Epoch [6/10], Step [196/750], Loss: 0.0107\n",
      "Epoch [6/10], Step [197/750], Loss: 0.0597\n",
      "Epoch [6/10], Step [198/750], Loss: 0.0554\n",
      "Epoch [6/10], Step [199/750], Loss: 0.0420\n",
      "Epoch [6/10], Step [200/750], Loss: 0.0622\n",
      "Epoch [6/10], Step [201/750], Loss: 0.0615\n",
      "Epoch [6/10], Step [202/750], Loss: 0.0499\n",
      "Epoch [6/10], Step [203/750], Loss: 0.1049\n",
      "Epoch [6/10], Step [204/750], Loss: 0.0308\n",
      "Epoch [6/10], Step [205/750], Loss: 0.0584\n",
      "Epoch [6/10], Step [206/750], Loss: 0.0863\n",
      "Epoch [6/10], Step [207/750], Loss: 0.0435\n",
      "Epoch [6/10], Step [208/750], Loss: 0.0753\n",
      "Epoch [6/10], Step [209/750], Loss: 0.0629\n",
      "Epoch [6/10], Step [210/750], Loss: 0.1240\n",
      "Epoch [6/10], Step [211/750], Loss: 0.0668\n",
      "Epoch [6/10], Step [212/750], Loss: 0.0272\n",
      "Epoch [6/10], Step [213/750], Loss: 0.0633\n",
      "Epoch [6/10], Step [214/750], Loss: 0.1324\n",
      "Epoch [6/10], Step [215/750], Loss: 0.0225\n",
      "Epoch [6/10], Step [216/750], Loss: 0.0755\n",
      "Epoch [6/10], Step [217/750], Loss: 0.0228\n",
      "Epoch [6/10], Step [218/750], Loss: 0.1135\n",
      "Epoch [6/10], Step [219/750], Loss: 0.0862\n",
      "Epoch [6/10], Step [220/750], Loss: 0.0362\n",
      "Epoch [6/10], Step [221/750], Loss: 0.0349\n",
      "Epoch [6/10], Step [222/750], Loss: 0.0972\n",
      "Epoch [6/10], Step [223/750], Loss: 0.1761\n",
      "Epoch [6/10], Step [224/750], Loss: 0.1437\n",
      "Epoch [6/10], Step [225/750], Loss: 0.0553\n",
      "Epoch [6/10], Step [226/750], Loss: 0.0639\n",
      "Epoch [6/10], Step [227/750], Loss: 0.0873\n",
      "Epoch [6/10], Step [228/750], Loss: 0.0240\n",
      "Epoch [6/10], Step [229/750], Loss: 0.0406\n",
      "Epoch [6/10], Step [230/750], Loss: 0.0545\n",
      "Epoch [6/10], Step [231/750], Loss: 0.0503\n",
      "Epoch [6/10], Step [232/750], Loss: 0.0103\n",
      "Epoch [6/10], Step [233/750], Loss: 0.0664\n",
      "Epoch [6/10], Step [234/750], Loss: 0.0340\n",
      "Epoch [6/10], Step [235/750], Loss: 0.0745\n",
      "Epoch [6/10], Step [236/750], Loss: 0.0963\n",
      "Epoch [6/10], Step [237/750], Loss: 0.0267\n",
      "Epoch [6/10], Step [238/750], Loss: 0.1552\n",
      "Epoch [6/10], Step [239/750], Loss: 0.0563\n",
      "Epoch [6/10], Step [240/750], Loss: 0.0909\n",
      "Epoch [6/10], Step [241/750], Loss: 0.1926\n",
      "Epoch [6/10], Step [242/750], Loss: 0.0764\n",
      "Epoch [6/10], Step [243/750], Loss: 0.0425\n",
      "Epoch [6/10], Step [244/750], Loss: 0.0789\n",
      "Epoch [6/10], Step [245/750], Loss: 0.0907\n",
      "Epoch [6/10], Step [246/750], Loss: 0.1482\n",
      "Epoch [6/10], Step [247/750], Loss: 0.0607\n",
      "Epoch [6/10], Step [248/750], Loss: 0.0680\n",
      "Epoch [6/10], Step [249/750], Loss: 0.1160\n",
      "Epoch [6/10], Step [250/750], Loss: 0.2015\n",
      "Epoch [6/10], Step [251/750], Loss: 0.0270\n",
      "Epoch [6/10], Step [252/750], Loss: 0.0775\n",
      "Epoch [6/10], Step [253/750], Loss: 0.1591\n",
      "Epoch [6/10], Step [254/750], Loss: 0.0800\n",
      "Epoch [6/10], Step [255/750], Loss: 0.2176\n",
      "Epoch [6/10], Step [256/750], Loss: 0.0167\n",
      "Epoch [6/10], Step [257/750], Loss: 0.1144\n",
      "Epoch [6/10], Step [258/750], Loss: 0.0229\n",
      "Epoch [6/10], Step [259/750], Loss: 0.1004\n",
      "Epoch [6/10], Step [260/750], Loss: 0.0290\n",
      "Epoch [6/10], Step [261/750], Loss: 0.1503\n",
      "Epoch [6/10], Step [262/750], Loss: 0.0766\n",
      "Epoch [6/10], Step [263/750], Loss: 0.1147\n",
      "Epoch [6/10], Step [264/750], Loss: 0.0915\n",
      "Epoch [6/10], Step [265/750], Loss: 0.0400\n",
      "Epoch [6/10], Step [266/750], Loss: 0.0694\n",
      "Epoch [6/10], Step [267/750], Loss: 0.0788\n",
      "Epoch [6/10], Step [268/750], Loss: 0.0989\n",
      "Epoch [6/10], Step [269/750], Loss: 0.0286\n",
      "Epoch [6/10], Step [270/750], Loss: 0.0534\n",
      "Epoch [6/10], Step [271/750], Loss: 0.0438\n",
      "Epoch [6/10], Step [272/750], Loss: 0.0979\n",
      "Epoch [6/10], Step [273/750], Loss: 0.0311\n",
      "Epoch [6/10], Step [274/750], Loss: 0.0160\n",
      "Epoch [6/10], Step [275/750], Loss: 0.0540\n",
      "Epoch [6/10], Step [276/750], Loss: 0.0409\n",
      "Epoch [6/10], Step [277/750], Loss: 0.0478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [278/750], Loss: 0.0258\n",
      "Epoch [6/10], Step [279/750], Loss: 0.1326\n",
      "Epoch [6/10], Step [280/750], Loss: 0.0384\n",
      "Epoch [6/10], Step [281/750], Loss: 0.0598\n",
      "Epoch [6/10], Step [282/750], Loss: 0.0940\n",
      "Epoch [6/10], Step [283/750], Loss: 0.0279\n",
      "Epoch [6/10], Step [284/750], Loss: 0.0326\n",
      "Epoch [6/10], Step [285/750], Loss: 0.1020\n",
      "Epoch [6/10], Step [286/750], Loss: 0.1097\n",
      "Epoch [6/10], Step [287/750], Loss: 0.0740\n",
      "Epoch [6/10], Step [288/750], Loss: 0.0155\n",
      "Epoch [6/10], Step [289/750], Loss: 0.0188\n",
      "Epoch [6/10], Step [290/750], Loss: 0.0922\n",
      "Epoch [6/10], Step [291/750], Loss: 0.1727\n",
      "Epoch [6/10], Step [292/750], Loss: 0.0165\n",
      "Epoch [6/10], Step [293/750], Loss: 0.0145\n",
      "Epoch [6/10], Step [294/750], Loss: 0.1172\n",
      "Epoch [6/10], Step [295/750], Loss: 0.0383\n",
      "Epoch [6/10], Step [296/750], Loss: 0.2102\n",
      "Epoch [6/10], Step [297/750], Loss: 0.0867\n",
      "Epoch [6/10], Step [298/750], Loss: 0.0522\n",
      "Epoch [6/10], Step [299/750], Loss: 0.0163\n",
      "Epoch [6/10], Step [300/750], Loss: 0.0658\n",
      "Epoch [6/10], Step [301/750], Loss: 0.0238\n",
      "Epoch [6/10], Step [302/750], Loss: 0.1062\n",
      "Epoch [6/10], Step [303/750], Loss: 0.1003\n",
      "Epoch [6/10], Step [304/750], Loss: 0.0459\n",
      "Epoch [6/10], Step [305/750], Loss: 0.0822\n",
      "Epoch [6/10], Step [306/750], Loss: 0.0925\n",
      "Epoch [6/10], Step [307/750], Loss: 0.0683\n",
      "Epoch [6/10], Step [308/750], Loss: 0.0765\n",
      "Epoch [6/10], Step [309/750], Loss: 0.0909\n",
      "Epoch [6/10], Step [310/750], Loss: 0.1907\n",
      "Epoch [6/10], Step [311/750], Loss: 0.0667\n",
      "Epoch [6/10], Step [312/750], Loss: 0.0409\n",
      "Epoch [6/10], Step [313/750], Loss: 0.0538\n",
      "Epoch [6/10], Step [314/750], Loss: 0.0182\n",
      "Epoch [6/10], Step [315/750], Loss: 0.0329\n",
      "Epoch [6/10], Step [316/750], Loss: 0.0208\n",
      "Epoch [6/10], Step [317/750], Loss: 0.0604\n",
      "Epoch [6/10], Step [318/750], Loss: 0.0145\n",
      "Epoch [6/10], Step [319/750], Loss: 0.0147\n",
      "Epoch [6/10], Step [320/750], Loss: 0.0777\n",
      "Epoch [6/10], Step [321/750], Loss: 0.1205\n",
      "Epoch [6/10], Step [322/750], Loss: 0.0346\n",
      "Epoch [6/10], Step [323/750], Loss: 0.0365\n",
      "Epoch [6/10], Step [324/750], Loss: 0.0466\n",
      "Epoch [6/10], Step [325/750], Loss: 0.1724\n",
      "Epoch [6/10], Step [326/750], Loss: 0.0300\n",
      "Epoch [6/10], Step [327/750], Loss: 0.0566\n",
      "Epoch [6/10], Step [328/750], Loss: 0.1306\n",
      "Epoch [6/10], Step [329/750], Loss: 0.0569\n",
      "Epoch [6/10], Step [330/750], Loss: 0.1326\n",
      "Epoch [6/10], Step [331/750], Loss: 0.1258\n",
      "Epoch [6/10], Step [332/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [333/750], Loss: 0.0515\n",
      "Epoch [6/10], Step [334/750], Loss: 0.0684\n",
      "Epoch [6/10], Step [335/750], Loss: 0.1045\n",
      "Epoch [6/10], Step [336/750], Loss: 0.1706\n",
      "Epoch [6/10], Step [337/750], Loss: 0.0599\n",
      "Epoch [6/10], Step [338/750], Loss: 0.0578\n",
      "Epoch [6/10], Step [339/750], Loss: 0.0719\n",
      "Epoch [6/10], Step [340/750], Loss: 0.0975\n",
      "Epoch [6/10], Step [341/750], Loss: 0.0226\n",
      "Epoch [6/10], Step [342/750], Loss: 0.1647\n",
      "Epoch [6/10], Step [343/750], Loss: 0.0978\n",
      "Epoch [6/10], Step [344/750], Loss: 0.0539\n",
      "Epoch [6/10], Step [345/750], Loss: 0.0519\n",
      "Epoch [6/10], Step [346/750], Loss: 0.0827\n",
      "Epoch [6/10], Step [347/750], Loss: 0.0416\n",
      "Epoch [6/10], Step [348/750], Loss: 0.0381\n",
      "Epoch [6/10], Step [349/750], Loss: 0.0536\n",
      "Epoch [6/10], Step [350/750], Loss: 0.0690\n",
      "Epoch [6/10], Step [351/750], Loss: 0.1648\n",
      "Epoch [6/10], Step [352/750], Loss: 0.1916\n",
      "Epoch [6/10], Step [353/750], Loss: 0.1373\n",
      "Epoch [6/10], Step [354/750], Loss: 0.0452\n",
      "Epoch [6/10], Step [355/750], Loss: 0.0639\n",
      "Epoch [6/10], Step [356/750], Loss: 0.0259\n",
      "Epoch [6/10], Step [357/750], Loss: 0.1013\n",
      "Epoch [6/10], Step [358/750], Loss: 0.1087\n",
      "Epoch [6/10], Step [359/750], Loss: 0.1242\n",
      "Epoch [6/10], Step [360/750], Loss: 0.1365\n",
      "Epoch [6/10], Step [361/750], Loss: 0.0578\n",
      "Epoch [6/10], Step [362/750], Loss: 0.0416\n",
      "Epoch [6/10], Step [363/750], Loss: 0.1438\n",
      "Epoch [6/10], Step [364/750], Loss: 0.0824\n",
      "Epoch [6/10], Step [365/750], Loss: 0.1867\n",
      "Epoch [6/10], Step [366/750], Loss: 0.1367\n",
      "Epoch [6/10], Step [367/750], Loss: 0.0761\n",
      "Epoch [6/10], Step [368/750], Loss: 0.2084\n",
      "Epoch [6/10], Step [369/750], Loss: 0.1483\n",
      "Epoch [6/10], Step [370/750], Loss: 0.0451\n",
      "Epoch [6/10], Step [371/750], Loss: 0.0278\n",
      "Epoch [6/10], Step [372/750], Loss: 0.0497\n",
      "Epoch [6/10], Step [373/750], Loss: 0.3530\n",
      "Epoch [6/10], Step [374/750], Loss: 0.1022\n",
      "Epoch [6/10], Step [375/750], Loss: 0.0985\n",
      "Epoch [6/10], Step [376/750], Loss: 0.0517\n",
      "Epoch [6/10], Step [377/750], Loss: 0.0372\n",
      "Epoch [6/10], Step [378/750], Loss: 0.0751\n",
      "Epoch [6/10], Step [379/750], Loss: 0.0426\n",
      "Epoch [6/10], Step [380/750], Loss: 0.0788\n",
      "Epoch [6/10], Step [381/750], Loss: 0.1956\n",
      "Epoch [6/10], Step [382/750], Loss: 0.0241\n",
      "Epoch [6/10], Step [383/750], Loss: 0.0644\n",
      "Epoch [6/10], Step [384/750], Loss: 0.0344\n",
      "Epoch [6/10], Step [385/750], Loss: 0.0096\n",
      "Epoch [6/10], Step [386/750], Loss: 0.1590\n",
      "Epoch [6/10], Step [387/750], Loss: 0.0827\n",
      "Epoch [6/10], Step [388/750], Loss: 0.0370\n",
      "Epoch [6/10], Step [389/750], Loss: 0.1243\n",
      "Epoch [6/10], Step [390/750], Loss: 0.0527\n",
      "Epoch [6/10], Step [391/750], Loss: 0.0279\n",
      "Epoch [6/10], Step [392/750], Loss: 0.0935\n",
      "Epoch [6/10], Step [393/750], Loss: 0.0704\n",
      "Epoch [6/10], Step [394/750], Loss: 0.0708\n",
      "Epoch [6/10], Step [395/750], Loss: 0.0752\n",
      "Epoch [6/10], Step [396/750], Loss: 0.0503\n",
      "Epoch [6/10], Step [397/750], Loss: 0.0529\n",
      "Epoch [6/10], Step [398/750], Loss: 0.0944\n",
      "Epoch [6/10], Step [399/750], Loss: 0.0542\n",
      "Epoch [6/10], Step [400/750], Loss: 0.0778\n",
      "Epoch [6/10], Step [401/750], Loss: 0.0174\n",
      "Epoch [6/10], Step [402/750], Loss: 0.0740\n",
      "Epoch [6/10], Step [403/750], Loss: 0.0324\n",
      "Epoch [6/10], Step [404/750], Loss: 0.0769\n",
      "Epoch [6/10], Step [405/750], Loss: 0.0382\n",
      "Epoch [6/10], Step [406/750], Loss: 0.0587\n",
      "Epoch [6/10], Step [407/750], Loss: 0.0364\n",
      "Epoch [6/10], Step [408/750], Loss: 0.0218\n",
      "Epoch [6/10], Step [409/750], Loss: 0.0650\n",
      "Epoch [6/10], Step [410/750], Loss: 0.1416\n",
      "Epoch [6/10], Step [411/750], Loss: 0.1311\n",
      "Epoch [6/10], Step [412/750], Loss: 0.0347\n",
      "Epoch [6/10], Step [413/750], Loss: 0.0147\n",
      "Epoch [6/10], Step [414/750], Loss: 0.0334\n",
      "Epoch [6/10], Step [415/750], Loss: 0.0809\n",
      "Epoch [6/10], Step [416/750], Loss: 0.0169\n",
      "Epoch [6/10], Step [417/750], Loss: 0.0944\n",
      "Epoch [6/10], Step [418/750], Loss: 0.0610\n",
      "Epoch [6/10], Step [419/750], Loss: 0.1075\n",
      "Epoch [6/10], Step [420/750], Loss: 0.1358\n",
      "Epoch [6/10], Step [421/750], Loss: 0.0111\n",
      "Epoch [6/10], Step [422/750], Loss: 0.0834\n",
      "Epoch [6/10], Step [423/750], Loss: 0.1634\n",
      "Epoch [6/10], Step [424/750], Loss: 0.0399\n",
      "Epoch [6/10], Step [425/750], Loss: 0.1396\n",
      "Epoch [6/10], Step [426/750], Loss: 0.0508\n",
      "Epoch [6/10], Step [427/750], Loss: 0.0732\n",
      "Epoch [6/10], Step [428/750], Loss: 0.0106\n",
      "Epoch [6/10], Step [429/750], Loss: 0.0345\n",
      "Epoch [6/10], Step [430/750], Loss: 0.1568\n",
      "Epoch [6/10], Step [431/750], Loss: 0.2159\n",
      "Epoch [6/10], Step [432/750], Loss: 0.0080\n",
      "Epoch [6/10], Step [433/750], Loss: 0.0945\n",
      "Epoch [6/10], Step [434/750], Loss: 0.1202\n",
      "Epoch [6/10], Step [435/750], Loss: 0.0614\n",
      "Epoch [6/10], Step [436/750], Loss: 0.0483\n",
      "Epoch [6/10], Step [437/750], Loss: 0.1150\n",
      "Epoch [6/10], Step [438/750], Loss: 0.0633\n",
      "Epoch [6/10], Step [439/750], Loss: 0.0284\n",
      "Epoch [6/10], Step [440/750], Loss: 0.0321\n",
      "Epoch [6/10], Step [441/750], Loss: 0.0928\n",
      "Epoch [6/10], Step [442/750], Loss: 0.0635\n",
      "Epoch [6/10], Step [443/750], Loss: 0.1577\n",
      "Epoch [6/10], Step [444/750], Loss: 0.0081\n",
      "Epoch [6/10], Step [445/750], Loss: 0.0220\n",
      "Epoch [6/10], Step [446/750], Loss: 0.1403\n",
      "Epoch [6/10], Step [447/750], Loss: 0.0304\n",
      "Epoch [6/10], Step [448/750], Loss: 0.0621\n",
      "Epoch [6/10], Step [449/750], Loss: 0.0707\n",
      "Epoch [6/10], Step [450/750], Loss: 0.0440\n",
      "Epoch [6/10], Step [451/750], Loss: 0.0157\n",
      "Epoch [6/10], Step [452/750], Loss: 0.0590\n",
      "Epoch [6/10], Step [453/750], Loss: 0.0559\n",
      "Epoch [6/10], Step [454/750], Loss: 0.1077\n",
      "Epoch [6/10], Step [455/750], Loss: 0.0583\n",
      "Epoch [6/10], Step [456/750], Loss: 0.1273\n",
      "Epoch [6/10], Step [457/750], Loss: 0.1047\n",
      "Epoch [6/10], Step [458/750], Loss: 0.0675\n",
      "Epoch [6/10], Step [459/750], Loss: 0.0631\n",
      "Epoch [6/10], Step [460/750], Loss: 0.2103\n",
      "Epoch [6/10], Step [461/750], Loss: 0.0330\n",
      "Epoch [6/10], Step [462/750], Loss: 0.0810\n",
      "Epoch [6/10], Step [463/750], Loss: 0.0790\n",
      "Epoch [6/10], Step [464/750], Loss: 0.0621\n",
      "Epoch [6/10], Step [465/750], Loss: 0.1266\n",
      "Epoch [6/10], Step [466/750], Loss: 0.0549\n",
      "Epoch [6/10], Step [467/750], Loss: 0.0526\n",
      "Epoch [6/10], Step [468/750], Loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [469/750], Loss: 0.0987\n",
      "Epoch [6/10], Step [470/750], Loss: 0.1138\n",
      "Epoch [6/10], Step [471/750], Loss: 0.1162\n",
      "Epoch [6/10], Step [472/750], Loss: 0.0268\n",
      "Epoch [6/10], Step [473/750], Loss: 0.0473\n",
      "Epoch [6/10], Step [474/750], Loss: 0.1611\n",
      "Epoch [6/10], Step [475/750], Loss: 0.1006\n",
      "Epoch [6/10], Step [476/750], Loss: 0.0381\n",
      "Epoch [6/10], Step [477/750], Loss: 0.0937\n",
      "Epoch [6/10], Step [478/750], Loss: 0.0296\n",
      "Epoch [6/10], Step [479/750], Loss: 0.1200\n",
      "Epoch [6/10], Step [480/750], Loss: 0.1079\n",
      "Epoch [6/10], Step [481/750], Loss: 0.0620\n",
      "Epoch [6/10], Step [482/750], Loss: 0.0444\n",
      "Epoch [6/10], Step [483/750], Loss: 0.0633\n",
      "Epoch [6/10], Step [484/750], Loss: 0.0910\n",
      "Epoch [6/10], Step [485/750], Loss: 0.1598\n",
      "Epoch [6/10], Step [486/750], Loss: 0.0493\n",
      "Epoch [6/10], Step [487/750], Loss: 0.1296\n",
      "Epoch [6/10], Step [488/750], Loss: 0.1472\n",
      "Epoch [6/10], Step [489/750], Loss: 0.0524\n",
      "Epoch [6/10], Step [490/750], Loss: 0.0107\n",
      "Epoch [6/10], Step [491/750], Loss: 0.0806\n",
      "Epoch [6/10], Step [492/750], Loss: 0.0688\n",
      "Epoch [6/10], Step [493/750], Loss: 0.0684\n",
      "Epoch [6/10], Step [494/750], Loss: 0.0542\n",
      "Epoch [6/10], Step [495/750], Loss: 0.0299\n",
      "Epoch [6/10], Step [496/750], Loss: 0.1369\n",
      "Epoch [6/10], Step [497/750], Loss: 0.0414\n",
      "Epoch [6/10], Step [498/750], Loss: 0.0840\n",
      "Epoch [6/10], Step [499/750], Loss: 0.0900\n",
      "Epoch [6/10], Step [500/750], Loss: 0.1128\n",
      "Epoch [6/10], Step [501/750], Loss: 0.1088\n",
      "Epoch [6/10], Step [502/750], Loss: 0.1060\n",
      "Epoch [6/10], Step [503/750], Loss: 0.1519\n",
      "Epoch [6/10], Step [504/750], Loss: 0.1098\n",
      "Epoch [6/10], Step [505/750], Loss: 0.0905\n",
      "Epoch [6/10], Step [506/750], Loss: 0.0656\n",
      "Epoch [6/10], Step [507/750], Loss: 0.0476\n",
      "Epoch [6/10], Step [508/750], Loss: 0.1255\n",
      "Epoch [6/10], Step [509/750], Loss: 0.1322\n",
      "Epoch [6/10], Step [510/750], Loss: 0.0781\n",
      "Epoch [6/10], Step [511/750], Loss: 0.1348\n",
      "Epoch [6/10], Step [512/750], Loss: 0.1102\n",
      "Epoch [6/10], Step [513/750], Loss: 0.0937\n",
      "Epoch [6/10], Step [514/750], Loss: 0.0402\n",
      "Epoch [6/10], Step [515/750], Loss: 0.0312\n",
      "Epoch [6/10], Step [516/750], Loss: 0.1117\n",
      "Epoch [6/10], Step [517/750], Loss: 0.0844\n",
      "Epoch [6/10], Step [518/750], Loss: 0.0904\n",
      "Epoch [6/10], Step [519/750], Loss: 0.0557\n",
      "Epoch [6/10], Step [520/750], Loss: 0.0754\n",
      "Epoch [6/10], Step [521/750], Loss: 0.0975\n",
      "Epoch [6/10], Step [522/750], Loss: 0.0109\n",
      "Epoch [6/10], Step [523/750], Loss: 0.0900\n",
      "Epoch [6/10], Step [524/750], Loss: 0.0120\n",
      "Epoch [6/10], Step [525/750], Loss: 0.0298\n",
      "Epoch [6/10], Step [526/750], Loss: 0.0405\n",
      "Epoch [6/10], Step [527/750], Loss: 0.0546\n",
      "Epoch [6/10], Step [528/750], Loss: 0.0702\n",
      "Epoch [6/10], Step [529/750], Loss: 0.2405\n",
      "Epoch [6/10], Step [530/750], Loss: 0.0401\n",
      "Epoch [6/10], Step [531/750], Loss: 0.0603\n",
      "Epoch [6/10], Step [532/750], Loss: 0.1293\n",
      "Epoch [6/10], Step [533/750], Loss: 0.1445\n",
      "Epoch [6/10], Step [534/750], Loss: 0.1075\n",
      "Epoch [6/10], Step [535/750], Loss: 0.0426\n",
      "Epoch [6/10], Step [536/750], Loss: 0.2309\n",
      "Epoch [6/10], Step [537/750], Loss: 0.0357\n",
      "Epoch [6/10], Step [538/750], Loss: 0.0206\n",
      "Epoch [6/10], Step [539/750], Loss: 0.0091\n",
      "Epoch [6/10], Step [540/750], Loss: 0.0259\n",
      "Epoch [6/10], Step [541/750], Loss: 0.0060\n",
      "Epoch [6/10], Step [542/750], Loss: 0.0525\n",
      "Epoch [6/10], Step [543/750], Loss: 0.2130\n",
      "Epoch [6/10], Step [544/750], Loss: 0.1068\n",
      "Epoch [6/10], Step [545/750], Loss: 0.0364\n",
      "Epoch [6/10], Step [546/750], Loss: 0.1086\n",
      "Epoch [6/10], Step [547/750], Loss: 0.0189\n",
      "Epoch [6/10], Step [548/750], Loss: 0.0690\n",
      "Epoch [6/10], Step [549/750], Loss: 0.0275\n",
      "Epoch [6/10], Step [550/750], Loss: 0.1752\n",
      "Epoch [6/10], Step [551/750], Loss: 0.1464\n",
      "Epoch [6/10], Step [552/750], Loss: 0.0904\n",
      "Epoch [6/10], Step [553/750], Loss: 0.1545\n",
      "Epoch [6/10], Step [554/750], Loss: 0.1636\n",
      "Epoch [6/10], Step [555/750], Loss: 0.0463\n",
      "Epoch [6/10], Step [556/750], Loss: 0.0404\n",
      "Epoch [6/10], Step [557/750], Loss: 0.0152\n",
      "Epoch [6/10], Step [558/750], Loss: 0.0315\n",
      "Epoch [6/10], Step [559/750], Loss: 0.1885\n",
      "Epoch [6/10], Step [560/750], Loss: 0.0471\n",
      "Epoch [6/10], Step [561/750], Loss: 0.0852\n",
      "Epoch [6/10], Step [562/750], Loss: 0.0271\n",
      "Epoch [6/10], Step [563/750], Loss: 0.0926\n",
      "Epoch [6/10], Step [564/750], Loss: 0.0590\n",
      "Epoch [6/10], Step [565/750], Loss: 0.1071\n",
      "Epoch [6/10], Step [566/750], Loss: 0.0604\n",
      "Epoch [6/10], Step [567/750], Loss: 0.0229\n",
      "Epoch [6/10], Step [568/750], Loss: 0.0915\n",
      "Epoch [6/10], Step [569/750], Loss: 0.0384\n",
      "Epoch [6/10], Step [570/750], Loss: 0.0542\n",
      "Epoch [6/10], Step [571/750], Loss: 0.1061\n",
      "Epoch [6/10], Step [572/750], Loss: 0.0330\n",
      "Epoch [6/10], Step [573/750], Loss: 0.0477\n",
      "Epoch [6/10], Step [574/750], Loss: 0.0867\n",
      "Epoch [6/10], Step [575/750], Loss: 0.0923\n",
      "Epoch [6/10], Step [576/750], Loss: 0.0595\n",
      "Epoch [6/10], Step [577/750], Loss: 0.0088\n",
      "Epoch [6/10], Step [578/750], Loss: 0.0688\n",
      "Epoch [6/10], Step [579/750], Loss: 0.1079\n",
      "Epoch [6/10], Step [580/750], Loss: 0.0515\n",
      "Epoch [6/10], Step [581/750], Loss: 0.0930\n",
      "Epoch [6/10], Step [582/750], Loss: 0.0818\n",
      "Epoch [6/10], Step [583/750], Loss: 0.0300\n",
      "Epoch [6/10], Step [584/750], Loss: 0.0671\n",
      "Epoch [6/10], Step [585/750], Loss: 0.1096\n",
      "Epoch [6/10], Step [586/750], Loss: 0.0825\n",
      "Epoch [6/10], Step [587/750], Loss: 0.0341\n",
      "Epoch [6/10], Step [588/750], Loss: 0.0844\n",
      "Epoch [6/10], Step [589/750], Loss: 0.1831\n",
      "Epoch [6/10], Step [590/750], Loss: 0.0207\n",
      "Epoch [6/10], Step [591/750], Loss: 0.0835\n",
      "Epoch [6/10], Step [592/750], Loss: 0.0884\n",
      "Epoch [6/10], Step [593/750], Loss: 0.1031\n",
      "Epoch [6/10], Step [594/750], Loss: 0.1359\n",
      "Epoch [6/10], Step [595/750], Loss: 0.0190\n",
      "Epoch [6/10], Step [596/750], Loss: 0.0558\n",
      "Epoch [6/10], Step [597/750], Loss: 0.0546\n",
      "Epoch [6/10], Step [598/750], Loss: 0.0325\n",
      "Epoch [6/10], Step [599/750], Loss: 0.0361\n",
      "Epoch [6/10], Step [600/750], Loss: 0.0451\n",
      "Epoch [6/10], Step [601/750], Loss: 0.1900\n",
      "Epoch [6/10], Step [602/750], Loss: 0.1074\n",
      "Epoch [6/10], Step [603/750], Loss: 0.0323\n",
      "Epoch [6/10], Step [604/750], Loss: 0.0157\n",
      "Epoch [6/10], Step [605/750], Loss: 0.1429\n",
      "Epoch [6/10], Step [606/750], Loss: 0.1207\n",
      "Epoch [6/10], Step [607/750], Loss: 0.0551\n",
      "Epoch [6/10], Step [608/750], Loss: 0.1197\n",
      "Epoch [6/10], Step [609/750], Loss: 0.0912\n",
      "Epoch [6/10], Step [610/750], Loss: 0.3436\n",
      "Epoch [6/10], Step [611/750], Loss: 0.0243\n",
      "Epoch [6/10], Step [612/750], Loss: 0.0555\n",
      "Epoch [6/10], Step [613/750], Loss: 0.0724\n",
      "Epoch [6/10], Step [614/750], Loss: 0.0227\n",
      "Epoch [6/10], Step [615/750], Loss: 0.1605\n",
      "Epoch [6/10], Step [616/750], Loss: 0.0411\n",
      "Epoch [6/10], Step [617/750], Loss: 0.0623\n",
      "Epoch [6/10], Step [618/750], Loss: 0.0541\n",
      "Epoch [6/10], Step [619/750], Loss: 0.0254\n",
      "Epoch [6/10], Step [620/750], Loss: 0.2381\n",
      "Epoch [6/10], Step [621/750], Loss: 0.0224\n",
      "Epoch [6/10], Step [622/750], Loss: 0.0306\n",
      "Epoch [6/10], Step [623/750], Loss: 0.1720\n",
      "Epoch [6/10], Step [624/750], Loss: 0.0306\n",
      "Epoch [6/10], Step [625/750], Loss: 0.0720\n",
      "Epoch [6/10], Step [626/750], Loss: 0.0288\n",
      "Epoch [6/10], Step [627/750], Loss: 0.0702\n",
      "Epoch [6/10], Step [628/750], Loss: 0.1539\n",
      "Epoch [6/10], Step [629/750], Loss: 0.1200\n",
      "Epoch [6/10], Step [630/750], Loss: 0.1057\n",
      "Epoch [6/10], Step [631/750], Loss: 0.0871\n",
      "Epoch [6/10], Step [632/750], Loss: 0.0459\n",
      "Epoch [6/10], Step [633/750], Loss: 0.0918\n",
      "Epoch [6/10], Step [634/750], Loss: 0.0376\n",
      "Epoch [6/10], Step [635/750], Loss: 0.1167\n",
      "Epoch [6/10], Step [636/750], Loss: 0.1225\n",
      "Epoch [6/10], Step [637/750], Loss: 0.0192\n",
      "Epoch [6/10], Step [638/750], Loss: 0.0302\n",
      "Epoch [6/10], Step [639/750], Loss: 0.0202\n",
      "Epoch [6/10], Step [640/750], Loss: 0.0323\n",
      "Epoch [6/10], Step [641/750], Loss: 0.0521\n",
      "Epoch [6/10], Step [642/750], Loss: 0.0420\n",
      "Epoch [6/10], Step [643/750], Loss: 0.0684\n",
      "Epoch [6/10], Step [644/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [645/750], Loss: 0.0252\n",
      "Epoch [6/10], Step [646/750], Loss: 0.0500\n",
      "Epoch [6/10], Step [647/750], Loss: 0.0477\n",
      "Epoch [6/10], Step [648/750], Loss: 0.0864\n",
      "Epoch [6/10], Step [649/750], Loss: 0.1599\n",
      "Epoch [6/10], Step [650/750], Loss: 0.0468\n",
      "Epoch [6/10], Step [651/750], Loss: 0.1799\n",
      "Epoch [6/10], Step [652/750], Loss: 0.0437\n",
      "Epoch [6/10], Step [653/750], Loss: 0.0849\n",
      "Epoch [6/10], Step [654/750], Loss: 0.0959\n",
      "Epoch [6/10], Step [655/750], Loss: 0.0645\n",
      "Epoch [6/10], Step [656/750], Loss: 0.3637\n",
      "Epoch [6/10], Step [657/750], Loss: 0.1763\n",
      "Epoch [6/10], Step [658/750], Loss: 0.0823\n",
      "Epoch [6/10], Step [659/750], Loss: 0.1207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [660/750], Loss: 0.0292\n",
      "Epoch [6/10], Step [661/750], Loss: 0.1198\n",
      "Epoch [6/10], Step [662/750], Loss: 0.1501\n",
      "Epoch [6/10], Step [663/750], Loss: 0.0983\n",
      "Epoch [6/10], Step [664/750], Loss: 0.2468\n",
      "Epoch [6/10], Step [665/750], Loss: 0.0206\n",
      "Epoch [6/10], Step [666/750], Loss: 0.0481\n",
      "Epoch [6/10], Step [667/750], Loss: 0.0643\n",
      "Epoch [6/10], Step [668/750], Loss: 0.0490\n",
      "Epoch [6/10], Step [669/750], Loss: 0.0696\n",
      "Epoch [6/10], Step [670/750], Loss: 0.0439\n",
      "Epoch [6/10], Step [671/750], Loss: 0.1298\n",
      "Epoch [6/10], Step [672/750], Loss: 0.1504\n",
      "Epoch [6/10], Step [673/750], Loss: 0.1183\n",
      "Epoch [6/10], Step [674/750], Loss: 0.1097\n",
      "Epoch [6/10], Step [675/750], Loss: 0.0061\n",
      "Epoch [6/10], Step [676/750], Loss: 0.1431\n",
      "Epoch [6/10], Step [677/750], Loss: 0.0104\n",
      "Epoch [6/10], Step [678/750], Loss: 0.0049\n",
      "Epoch [6/10], Step [679/750], Loss: 0.0939\n",
      "Epoch [6/10], Step [680/750], Loss: 0.1143\n",
      "Epoch [6/10], Step [681/750], Loss: 0.0873\n",
      "Epoch [6/10], Step [682/750], Loss: 0.1333\n",
      "Epoch [6/10], Step [683/750], Loss: 0.0641\n",
      "Epoch [6/10], Step [684/750], Loss: 0.2398\n",
      "Epoch [6/10], Step [685/750], Loss: 0.0451\n",
      "Epoch [6/10], Step [686/750], Loss: 0.0451\n",
      "Epoch [6/10], Step [687/750], Loss: 0.0983\n",
      "Epoch [6/10], Step [688/750], Loss: 0.0981\n",
      "Epoch [6/10], Step [689/750], Loss: 0.0661\n",
      "Epoch [6/10], Step [690/750], Loss: 0.0238\n",
      "Epoch [6/10], Step [691/750], Loss: 0.0739\n",
      "Epoch [6/10], Step [692/750], Loss: 0.0577\n",
      "Epoch [6/10], Step [693/750], Loss: 0.1454\n",
      "Epoch [6/10], Step [694/750], Loss: 0.0931\n",
      "Epoch [6/10], Step [695/750], Loss: 0.1349\n",
      "Epoch [6/10], Step [696/750], Loss: 0.0775\n",
      "Epoch [6/10], Step [697/750], Loss: 0.0472\n",
      "Epoch [6/10], Step [698/750], Loss: 0.0988\n",
      "Epoch [6/10], Step [699/750], Loss: 0.0406\n",
      "Epoch [6/10], Step [700/750], Loss: 0.0739\n",
      "Epoch [6/10], Step [701/750], Loss: 0.0233\n",
      "Epoch [6/10], Step [702/750], Loss: 0.0551\n",
      "Epoch [6/10], Step [703/750], Loss: 0.0820\n",
      "Epoch [6/10], Step [704/750], Loss: 0.1123\n",
      "Epoch [6/10], Step [705/750], Loss: 0.0557\n",
      "Epoch [6/10], Step [706/750], Loss: 0.1237\n",
      "Epoch [6/10], Step [707/750], Loss: 0.0877\n",
      "Epoch [6/10], Step [708/750], Loss: 0.0595\n",
      "Epoch [6/10], Step [709/750], Loss: 0.1146\n",
      "Epoch [6/10], Step [710/750], Loss: 0.0482\n",
      "Epoch [6/10], Step [711/750], Loss: 0.0775\n",
      "Epoch [6/10], Step [712/750], Loss: 0.0607\n",
      "Epoch [6/10], Step [713/750], Loss: 0.0594\n",
      "Epoch [6/10], Step [714/750], Loss: 0.0489\n",
      "Epoch [6/10], Step [715/750], Loss: 0.1131\n",
      "Epoch [6/10], Step [716/750], Loss: 0.1689\n",
      "Epoch [6/10], Step [717/750], Loss: 0.0584\n",
      "Epoch [6/10], Step [718/750], Loss: 0.0762\n",
      "Epoch [6/10], Step [719/750], Loss: 0.0274\n",
      "Epoch [6/10], Step [720/750], Loss: 0.1086\n",
      "Epoch [6/10], Step [721/750], Loss: 0.0465\n",
      "Epoch [6/10], Step [722/750], Loss: 0.0507\n",
      "Epoch [6/10], Step [723/750], Loss: 0.0646\n",
      "Epoch [6/10], Step [724/750], Loss: 0.0886\n",
      "Epoch [6/10], Step [725/750], Loss: 0.2149\n",
      "Epoch [6/10], Step [726/750], Loss: 0.0594\n",
      "Epoch [6/10], Step [727/750], Loss: 0.0751\n",
      "Epoch [6/10], Step [728/750], Loss: 0.1120\n",
      "Epoch [6/10], Step [729/750], Loss: 0.1616\n",
      "Epoch [6/10], Step [730/750], Loss: 0.1273\n",
      "Epoch [6/10], Step [731/750], Loss: 0.0616\n",
      "Epoch [6/10], Step [732/750], Loss: 0.1041\n",
      "Epoch [6/10], Step [733/750], Loss: 0.0741\n",
      "Epoch [6/10], Step [734/750], Loss: 0.0810\n",
      "Epoch [6/10], Step [735/750], Loss: 0.2119\n",
      "Epoch [6/10], Step [736/750], Loss: 0.0966\n",
      "Epoch [6/10], Step [737/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [738/750], Loss: 0.1252\n",
      "Epoch [6/10], Step [739/750], Loss: 0.0484\n",
      "Epoch [6/10], Step [740/750], Loss: 0.0466\n",
      "Epoch [6/10], Step [741/750], Loss: 0.0463\n",
      "Epoch [6/10], Step [742/750], Loss: 0.0749\n",
      "Epoch [6/10], Step [743/750], Loss: 0.0702\n",
      "Epoch [6/10], Step [744/750], Loss: 0.0870\n",
      "Epoch [6/10], Step [745/750], Loss: 0.0922\n",
      "Epoch [6/10], Step [746/750], Loss: 0.0697\n",
      "Epoch [6/10], Step [747/750], Loss: 0.0442\n",
      "Epoch [6/10], Step [748/750], Loss: 0.0992\n",
      "Epoch [6/10], Step [749/750], Loss: 0.0794\n",
      "Epoch [6/10], Step [750/750], Loss: 0.1128\n",
      "\n",
      "\n",
      "Epoch [7/10], Step [1/750], Loss: 0.1189\n",
      "Epoch [7/10], Step [2/750], Loss: 0.0801\n",
      "Epoch [7/10], Step [3/750], Loss: 0.1666\n",
      "Epoch [7/10], Step [4/750], Loss: 0.1025\n",
      "Epoch [7/10], Step [5/750], Loss: 0.0309\n",
      "Epoch [7/10], Step [6/750], Loss: 0.2239\n",
      "Epoch [7/10], Step [7/750], Loss: 0.0695\n",
      "Epoch [7/10], Step [8/750], Loss: 0.1675\n",
      "Epoch [7/10], Step [9/750], Loss: 0.1559\n",
      "Epoch [7/10], Step [10/750], Loss: 0.0467\n",
      "Epoch [7/10], Step [11/750], Loss: 0.0846\n",
      "Epoch [7/10], Step [12/750], Loss: 0.0396\n",
      "Epoch [7/10], Step [13/750], Loss: 0.0393\n",
      "Epoch [7/10], Step [14/750], Loss: 0.1346\n",
      "Epoch [7/10], Step [15/750], Loss: 0.0648\n",
      "Epoch [7/10], Step [16/750], Loss: 0.1788\n",
      "Epoch [7/10], Step [17/750], Loss: 0.1265\n",
      "Epoch [7/10], Step [18/750], Loss: 0.0573\n",
      "Epoch [7/10], Step [19/750], Loss: 0.1715\n",
      "Epoch [7/10], Step [20/750], Loss: 0.0858\n",
      "Epoch [7/10], Step [21/750], Loss: 0.1788\n",
      "Epoch [7/10], Step [22/750], Loss: 0.0114\n",
      "Epoch [7/10], Step [23/750], Loss: 0.1161\n",
      "Epoch [7/10], Step [24/750], Loss: 0.0758\n",
      "Epoch [7/10], Step [25/750], Loss: 0.0142\n",
      "Epoch [7/10], Step [26/750], Loss: 0.1014\n",
      "Epoch [7/10], Step [27/750], Loss: 0.0122\n",
      "Epoch [7/10], Step [28/750], Loss: 0.0663\n",
      "Epoch [7/10], Step [29/750], Loss: 0.0442\n",
      "Epoch [7/10], Step [30/750], Loss: 0.0752\n",
      "Epoch [7/10], Step [31/750], Loss: 0.0803\n",
      "Epoch [7/10], Step [32/750], Loss: 0.0709\n",
      "Epoch [7/10], Step [33/750], Loss: 0.0337\n",
      "Epoch [7/10], Step [34/750], Loss: 0.0151\n",
      "Epoch [7/10], Step [35/750], Loss: 0.1211\n",
      "Epoch [7/10], Step [36/750], Loss: 0.0461\n",
      "Epoch [7/10], Step [37/750], Loss: 0.0746\n",
      "Epoch [7/10], Step [38/750], Loss: 0.0372\n",
      "Epoch [7/10], Step [39/750], Loss: 0.0331\n",
      "Epoch [7/10], Step [40/750], Loss: 0.0495\n",
      "Epoch [7/10], Step [41/750], Loss: 0.0657\n",
      "Epoch [7/10], Step [42/750], Loss: 0.0477\n",
      "Epoch [7/10], Step [43/750], Loss: 0.0614\n",
      "Epoch [7/10], Step [44/750], Loss: 0.0452\n",
      "Epoch [7/10], Step [45/750], Loss: 0.0927\n",
      "Epoch [7/10], Step [46/750], Loss: 0.0502\n",
      "Epoch [7/10], Step [47/750], Loss: 0.0589\n",
      "Epoch [7/10], Step [48/750], Loss: 0.0264\n",
      "Epoch [7/10], Step [49/750], Loss: 0.0301\n",
      "Epoch [7/10], Step [50/750], Loss: 0.0588\n",
      "Epoch [7/10], Step [51/750], Loss: 0.0461\n",
      "Epoch [7/10], Step [52/750], Loss: 0.1597\n",
      "Epoch [7/10], Step [53/750], Loss: 0.0165\n",
      "Epoch [7/10], Step [54/750], Loss: 0.0970\n",
      "Epoch [7/10], Step [55/750], Loss: 0.0652\n",
      "Epoch [7/10], Step [56/750], Loss: 0.0645\n",
      "Epoch [7/10], Step [57/750], Loss: 0.0201\n",
      "Epoch [7/10], Step [58/750], Loss: 0.0261\n",
      "Epoch [7/10], Step [59/750], Loss: 0.0835\n",
      "Epoch [7/10], Step [60/750], Loss: 0.0202\n",
      "Epoch [7/10], Step [61/750], Loss: 0.0614\n",
      "Epoch [7/10], Step [62/750], Loss: 0.0369\n",
      "Epoch [7/10], Step [63/750], Loss: 0.0153\n",
      "Epoch [7/10], Step [64/750], Loss: 0.0432\n",
      "Epoch [7/10], Step [65/750], Loss: 0.0161\n",
      "Epoch [7/10], Step [66/750], Loss: 0.1634\n",
      "Epoch [7/10], Step [67/750], Loss: 0.0456\n",
      "Epoch [7/10], Step [68/750], Loss: 0.0823\n",
      "Epoch [7/10], Step [69/750], Loss: 0.0639\n",
      "Epoch [7/10], Step [70/750], Loss: 0.1345\n",
      "Epoch [7/10], Step [71/750], Loss: 0.0222\n",
      "Epoch [7/10], Step [72/750], Loss: 0.0394\n",
      "Epoch [7/10], Step [73/750], Loss: 0.0665\n",
      "Epoch [7/10], Step [74/750], Loss: 0.0109\n",
      "Epoch [7/10], Step [75/750], Loss: 0.0359\n",
      "Epoch [7/10], Step [76/750], Loss: 0.0238\n",
      "Epoch [7/10], Step [77/750], Loss: 0.0658\n",
      "Epoch [7/10], Step [78/750], Loss: 0.1203\n",
      "Epoch [7/10], Step [79/750], Loss: 0.0938\n",
      "Epoch [7/10], Step [80/750], Loss: 0.0245\n",
      "Epoch [7/10], Step [81/750], Loss: 0.0139\n",
      "Epoch [7/10], Step [82/750], Loss: 0.0556\n",
      "Epoch [7/10], Step [83/750], Loss: 0.1609\n",
      "Epoch [7/10], Step [84/750], Loss: 0.1322\n",
      "Epoch [7/10], Step [85/750], Loss: 0.0417\n",
      "Epoch [7/10], Step [86/750], Loss: 0.0471\n",
      "Epoch [7/10], Step [87/750], Loss: 0.0152\n",
      "Epoch [7/10], Step [88/750], Loss: 0.1790\n",
      "Epoch [7/10], Step [89/750], Loss: 0.0150\n",
      "Epoch [7/10], Step [90/750], Loss: 0.0477\n",
      "Epoch [7/10], Step [91/750], Loss: 0.0322\n",
      "Epoch [7/10], Step [92/750], Loss: 0.0361\n",
      "Epoch [7/10], Step [93/750], Loss: 0.0216\n",
      "Epoch [7/10], Step [94/750], Loss: 0.0911\n",
      "Epoch [7/10], Step [95/750], Loss: 0.0390\n",
      "Epoch [7/10], Step [96/750], Loss: 0.0402\n",
      "Epoch [7/10], Step [97/750], Loss: 0.0444\n",
      "Epoch [7/10], Step [98/750], Loss: 0.0602\n",
      "Epoch [7/10], Step [99/750], Loss: 0.0283\n",
      "Epoch [7/10], Step [100/750], Loss: 0.1021\n",
      "Epoch [7/10], Step [101/750], Loss: 0.0191\n",
      "Epoch [7/10], Step [102/750], Loss: 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [103/750], Loss: 0.0386\n",
      "Epoch [7/10], Step [104/750], Loss: 0.0441\n",
      "Epoch [7/10], Step [105/750], Loss: 0.0157\n",
      "Epoch [7/10], Step [106/750], Loss: 0.1158\n",
      "Epoch [7/10], Step [107/750], Loss: 0.0078\n",
      "Epoch [7/10], Step [108/750], Loss: 0.0191\n",
      "Epoch [7/10], Step [109/750], Loss: 0.0107\n",
      "Epoch [7/10], Step [110/750], Loss: 0.0690\n",
      "Epoch [7/10], Step [111/750], Loss: 0.1122\n",
      "Epoch [7/10], Step [112/750], Loss: 0.0566\n",
      "Epoch [7/10], Step [113/750], Loss: 0.0408\n",
      "Epoch [7/10], Step [114/750], Loss: 0.0360\n",
      "Epoch [7/10], Step [115/750], Loss: 0.0191\n",
      "Epoch [7/10], Step [116/750], Loss: 0.0489\n",
      "Epoch [7/10], Step [117/750], Loss: 0.1250\n",
      "Epoch [7/10], Step [118/750], Loss: 0.0781\n",
      "Epoch [7/10], Step [119/750], Loss: 0.0371\n",
      "Epoch [7/10], Step [120/750], Loss: 0.0255\n",
      "Epoch [7/10], Step [121/750], Loss: 0.1545\n",
      "Epoch [7/10], Step [122/750], Loss: 0.0151\n",
      "Epoch [7/10], Step [123/750], Loss: 0.1340\n",
      "Epoch [7/10], Step [124/750], Loss: 0.0141\n",
      "Epoch [7/10], Step [125/750], Loss: 0.1242\n",
      "Epoch [7/10], Step [126/750], Loss: 0.0434\n",
      "Epoch [7/10], Step [127/750], Loss: 0.0581\n",
      "Epoch [7/10], Step [128/750], Loss: 0.1414\n",
      "Epoch [7/10], Step [129/750], Loss: 0.0319\n",
      "Epoch [7/10], Step [130/750], Loss: 0.0586\n",
      "Epoch [7/10], Step [131/750], Loss: 0.0847\n",
      "Epoch [7/10], Step [132/750], Loss: 0.1383\n",
      "Epoch [7/10], Step [133/750], Loss: 0.0045\n",
      "Epoch [7/10], Step [134/750], Loss: 0.0256\n",
      "Epoch [7/10], Step [135/750], Loss: 0.0278\n",
      "Epoch [7/10], Step [136/750], Loss: 0.0389\n",
      "Epoch [7/10], Step [137/750], Loss: 0.0551\n",
      "Epoch [7/10], Step [138/750], Loss: 0.0474\n",
      "Epoch [7/10], Step [139/750], Loss: 0.1035\n",
      "Epoch [7/10], Step [140/750], Loss: 0.0153\n",
      "Epoch [7/10], Step [141/750], Loss: 0.0313\n",
      "Epoch [7/10], Step [142/750], Loss: 0.0294\n",
      "Epoch [7/10], Step [143/750], Loss: 0.1647\n",
      "Epoch [7/10], Step [144/750], Loss: 0.0482\n",
      "Epoch [7/10], Step [145/750], Loss: 0.1644\n",
      "Epoch [7/10], Step [146/750], Loss: 0.1045\n",
      "Epoch [7/10], Step [147/750], Loss: 0.0244\n",
      "Epoch [7/10], Step [148/750], Loss: 0.0310\n",
      "Epoch [7/10], Step [149/750], Loss: 0.1250\n",
      "Epoch [7/10], Step [150/750], Loss: 0.1052\n",
      "Epoch [7/10], Step [151/750], Loss: 0.0806\n",
      "Epoch [7/10], Step [152/750], Loss: 0.1157\n",
      "Epoch [7/10], Step [153/750], Loss: 0.2012\n",
      "Epoch [7/10], Step [154/750], Loss: 0.1304\n",
      "Epoch [7/10], Step [155/750], Loss: 0.0876\n",
      "Epoch [7/10], Step [156/750], Loss: 0.0575\n",
      "Epoch [7/10], Step [157/750], Loss: 0.0927\n",
      "Epoch [7/10], Step [158/750], Loss: 0.1743\n",
      "Epoch [7/10], Step [159/750], Loss: 0.1259\n",
      "Epoch [7/10], Step [160/750], Loss: 0.0596\n",
      "Epoch [7/10], Step [161/750], Loss: 0.0258\n",
      "Epoch [7/10], Step [162/750], Loss: 0.0838\n",
      "Epoch [7/10], Step [163/750], Loss: 0.1477\n",
      "Epoch [7/10], Step [164/750], Loss: 0.1366\n",
      "Epoch [7/10], Step [165/750], Loss: 0.0991\n",
      "Epoch [7/10], Step [166/750], Loss: 0.0307\n",
      "Epoch [7/10], Step [167/750], Loss: 0.1468\n",
      "Epoch [7/10], Step [168/750], Loss: 0.1223\n",
      "Epoch [7/10], Step [169/750], Loss: 0.0502\n",
      "Epoch [7/10], Step [170/750], Loss: 0.1732\n",
      "Epoch [7/10], Step [171/750], Loss: 0.1632\n",
      "Epoch [7/10], Step [172/750], Loss: 0.0296\n",
      "Epoch [7/10], Step [173/750], Loss: 0.0777\n",
      "Epoch [7/10], Step [174/750], Loss: 0.0417\n",
      "Epoch [7/10], Step [175/750], Loss: 0.0400\n",
      "Epoch [7/10], Step [176/750], Loss: 0.1110\n",
      "Epoch [7/10], Step [177/750], Loss: 0.1155\n",
      "Epoch [7/10], Step [178/750], Loss: 0.1736\n",
      "Epoch [7/10], Step [179/750], Loss: 0.0323\n",
      "Epoch [7/10], Step [180/750], Loss: 0.0106\n",
      "Epoch [7/10], Step [181/750], Loss: 0.1171\n",
      "Epoch [7/10], Step [182/750], Loss: 0.1778\n",
      "Epoch [7/10], Step [183/750], Loss: 0.0767\n",
      "Epoch [7/10], Step [184/750], Loss: 0.2383\n",
      "Epoch [7/10], Step [185/750], Loss: 0.0298\n",
      "Epoch [7/10], Step [186/750], Loss: 0.1321\n",
      "Epoch [7/10], Step [187/750], Loss: 0.1064\n",
      "Epoch [7/10], Step [188/750], Loss: 0.0535\n",
      "Epoch [7/10], Step [189/750], Loss: 0.0755\n",
      "Epoch [7/10], Step [190/750], Loss: 0.0594\n",
      "Epoch [7/10], Step [191/750], Loss: 0.0506\n",
      "Epoch [7/10], Step [192/750], Loss: 0.1370\n",
      "Epoch [7/10], Step [193/750], Loss: 0.2891\n",
      "Epoch [7/10], Step [194/750], Loss: 0.1050\n",
      "Epoch [7/10], Step [195/750], Loss: 0.0183\n",
      "Epoch [7/10], Step [196/750], Loss: 0.0780\n",
      "Epoch [7/10], Step [197/750], Loss: 0.1615\n",
      "Epoch [7/10], Step [198/750], Loss: 0.1945\n",
      "Epoch [7/10], Step [199/750], Loss: 0.0333\n",
      "Epoch [7/10], Step [200/750], Loss: 0.0150\n",
      "Epoch [7/10], Step [201/750], Loss: 0.0086\n",
      "Epoch [7/10], Step [202/750], Loss: 0.0949\n",
      "Epoch [7/10], Step [203/750], Loss: 0.0781\n",
      "Epoch [7/10], Step [204/750], Loss: 0.0617\n",
      "Epoch [7/10], Step [205/750], Loss: 0.0101\n",
      "Epoch [7/10], Step [206/750], Loss: 0.0760\n",
      "Epoch [7/10], Step [207/750], Loss: 0.0221\n",
      "Epoch [7/10], Step [208/750], Loss: 0.1379\n",
      "Epoch [7/10], Step [209/750], Loss: 0.1036\n",
      "Epoch [7/10], Step [210/750], Loss: 0.0716\n",
      "Epoch [7/10], Step [211/750], Loss: 0.1078\n",
      "Epoch [7/10], Step [212/750], Loss: 0.0592\n",
      "Epoch [7/10], Step [213/750], Loss: 0.0345\n",
      "Epoch [7/10], Step [214/750], Loss: 0.1043\n",
      "Epoch [7/10], Step [215/750], Loss: 0.1337\n",
      "Epoch [7/10], Step [216/750], Loss: 0.2351\n",
      "Epoch [7/10], Step [217/750], Loss: 0.0809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-dac347325ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-c46aa2f17cf8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_epochs, model, loaders)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train(num_epochs, hnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ed953a",
   "metadata": {
    "id": "f1ed953a"
   },
   "outputs": [],
   "source": [
    "torch.save(hnn.state_dict(), 'trained_model_16qubits_4_layers_with_strong_entagling.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "20:08 -- 30 steps"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fully_connected_with_qnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00cd50cc19624ebf946c288dcf96ca77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a0c3aa1494d454b85ce6083f2c98234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ca85bfb648a4586ab15f601f45bd7c2",
      "placeholder": "​",
      "style": "IPY_MODEL_979724284c094071b6c3143666a2a8d5",
      "value": " 0/10 [00:22&lt;?, ?it/s]"
     }
    },
    "0aa6d7245fc747b58457668a840cd66b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0de84b8c5dde45b68b6fe495e3978524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1784bfcf80e54eb1a3b7873cd36494b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fb4ea8439054fbeaab29cbbdd8d8c62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2454c06e04cc44a59af6a54edf771dcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d31e57f44fef4cd99cbda543609a5363",
      "placeholder": "​",
      "style": "IPY_MODEL_f1cb6810b0f0425c925092fd2c564460",
      "value": " 29696/? [00:00&lt;00:00, 779622.51it/s]"
     }
    },
    "2bae88a771624fce8a7195ab2d3790e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3629620f44dc4eec928e8285f4e292c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c55b6cc69fe4e71bfefdfafe172e1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42c3a0dfb96d4d0a9cbcfbefdb88634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7381bd873134277869b9bf86f7f6cde",
       "IPY_MODEL_92a84a7a4c1a49fca9c649540174de1a",
       "IPY_MODEL_973a9057772b4a33bebe1c71b2548322"
      ],
      "layout": "IPY_MODEL_fb3c5d28cc434035936450f03eaab7d4"
     }
    },
    "4472460dcaf349e282e8505097ac56db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b9f9045a6a64724b75bed3bdf4825e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d29ed3d913f4c3dadd8aa28ffdf60ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fb4ea8439054fbeaab29cbbdd8d8c62",
      "placeholder": "​",
      "style": "IPY_MODEL_7598f22b00ca4188abd0e988d87c8717",
      "value": ""
     }
    },
    "4ee572a2f86844b38f1475756d831d7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53264b907c324fd2903f6a33df4024eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3629620f44dc4eec928e8285f4e292c7",
      "placeholder": "​",
      "style": "IPY_MODEL_ca79710ed42844eda53edd54ad1cce9e",
      "value": ""
     }
    },
    "585d33ea2f6c4c6f866ab5eaf500a486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4472460dcaf349e282e8505097ac56db",
      "placeholder": "​",
      "style": "IPY_MODEL_00cd50cc19624ebf946c288dcf96ca77",
      "value": " 5120/? [00:00&lt;00:00, 149206.45it/s]"
     }
    },
    "5f557bc2ab954fcdbb3145c5ae1cd1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_831588c036b84ba5919552e1c0ffaf95",
      "placeholder": "​",
      "style": "IPY_MODEL_4b9f9045a6a64724b75bed3bdf4825e5",
      "value": " 9913344/? [00:00&lt;00:00, 18038716.63it/s]"
     }
    },
    "611e4230f7284f56a36e03b6cab128bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "656d789dd50d4d7c95121ee911a0315e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "664e26cb5e91441d8360e652dc6f3f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbeac195f2cf4776b6c95dedda39513c",
      "placeholder": "​",
      "style": "IPY_MODEL_611e4230f7284f56a36e03b6cab128bb",
      "value": ""
     }
    },
    "70629c93466c490cb4d10c7ba2e41d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7081d0216eb6473fae87f7331becfb53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7192858941cb47649969779dc0e63c91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_664e26cb5e91441d8360e652dc6f3f13",
       "IPY_MODEL_ba90ae57f0bf4101b5306b32401f5ca6",
       "IPY_MODEL_585d33ea2f6c4c6f866ab5eaf500a486"
      ],
      "layout": "IPY_MODEL_0de84b8c5dde45b68b6fe495e3978524"
     }
    },
    "739c6da6cd64446686e87fd499fc4e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1784bfcf80e54eb1a3b7873cd36494b1",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae7d8308ff8541d082c143732f92bce6",
      "value": 28881
     }
    },
    "7598f22b00ca4188abd0e988d87c8717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ca85bfb648a4586ab15f601f45bd7c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "831588c036b84ba5919552e1c0ffaf95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b99aefdd9a247678de2cefd312207bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7081d0216eb6473fae87f7331becfb53",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70629c93466c490cb4d10c7ba2e41d62",
      "value": 0
     }
    },
    "9002f4b1af6d4c03b8f53fecdffaa3b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a84a7a4c1a49fca9c649540174de1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bae88a771624fce8a7195ab2d3790e1",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5767d4185754f1f82e22dc55b9b659e",
      "value": 1648877
     }
    },
    "973a9057772b4a33bebe1c71b2548322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcaf3aab2df24777bb896394049144d2",
      "placeholder": "​",
      "style": "IPY_MODEL_656d789dd50d4d7c95121ee911a0315e",
      "value": " 1649664/? [00:00&lt;00:00, 5358482.30it/s]"
     }
    },
    "979724284c094071b6c3143666a2a8d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a0d229daebc428d8d0bea6db980845f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2b522fb50d54cecaead8906ecc2c88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2db74a18ce8412399aba11b3bab930b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa56b1689edb4a75aa4af965407467e6",
       "IPY_MODEL_8b99aefdd9a247678de2cefd312207bb",
       "IPY_MODEL_0a0c3aa1494d454b85ce6083f2c98234"
      ],
      "layout": "IPY_MODEL_9002f4b1af6d4c03b8f53fecdffaa3b0"
     }
    },
    "a5767d4185754f1f82e22dc55b9b659e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa56b1689edb4a75aa4af965407467e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df312d8125694913844f2856ee295e67",
      "placeholder": "​",
      "style": "IPY_MODEL_0aa6d7245fc747b58457668a840cd66b",
      "value": "  0%"
     }
    },
    "ae7d8308ff8541d082c143732f92bce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7381bd873134277869b9bf86f7f6cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee572a2f86844b38f1475756d831d7e",
      "placeholder": "​",
      "style": "IPY_MODEL_a2b522fb50d54cecaead8906ecc2c88f",
      "value": ""
     }
    },
    "ba90ae57f0bf4101b5306b32401f5ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a0d229daebc428d8d0bea6db980845f",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc04c3799392479f84746241eac0c9bc",
      "value": 4542
     }
    },
    "bcaf3aab2df24777bb896394049144d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7dfb28ce1ec490bbbc71bbf8f8bc7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d29ed3d913f4c3dadd8aa28ffdf60ab",
       "IPY_MODEL_739c6da6cd64446686e87fd499fc4e8c",
       "IPY_MODEL_2454c06e04cc44a59af6a54edf771dcf"
      ],
      "layout": "IPY_MODEL_fc29fb7181a64867aa764553a94327cf"
     }
    },
    "ca79710ed42844eda53edd54ad1cce9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d31e57f44fef4cd99cbda543609a5363": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8d21603da7146628c7025db753adeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbeac195f2cf4776b6c95dedda39513c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc04c3799392479f84746241eac0c9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df312d8125694913844f2856ee295e67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df69f8986a7b46df869d78996f9a92bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53264b907c324fd2903f6a33df4024eb",
       "IPY_MODEL_fe3e249b5f1947ec9fc496ab71992860",
       "IPY_MODEL_5f557bc2ab954fcdbb3145c5ae1cd1fe"
      ],
      "layout": "IPY_MODEL_3c55b6cc69fe4e71bfefdfafe172e1f4"
     }
    },
    "f1cb6810b0f0425c925092fd2c564460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4bb69ed5dcf45cabca0294b04062d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb3c5d28cc434035936450f03eaab7d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc29fb7181a64867aa764553a94327cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe3e249b5f1947ec9fc496ab71992860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4bb69ed5dcf45cabca0294b04062d68",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8d21603da7146628c7025db753adeb3",
      "value": 9912422
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
