{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd6e9a6",
   "metadata": {
    "id": "4fd6e9a6"
   },
   "source": [
    "# Satifsying requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1b8b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55d1b8b4",
    "outputId": "d6f2cb29-3894-412c-8cbc-e846998c6962"
   },
   "outputs": [],
   "source": [
    "!pip install pennylane --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11760f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce11760f",
    "outputId": "5da30c23-33c4-4c0a-fe9c-58bb05319786"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25b8a9e",
   "metadata": {
    "id": "a25b8a9e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc1b4e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dc1b4e5",
    "outputId": "4ba9778d-35b6-457e-d8b4-e9c59969fc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653bc14",
   "metadata": {
    "id": "e653bc14"
   },
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a22a6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467,
     "referenced_widgets": [
      "df69f8986a7b46df869d78996f9a92bf",
      "3c55b6cc69fe4e71bfefdfafe172e1f4",
      "53264b907c324fd2903f6a33df4024eb",
      "fe3e249b5f1947ec9fc496ab71992860",
      "5f557bc2ab954fcdbb3145c5ae1cd1fe",
      "ca79710ed42844eda53edd54ad1cce9e",
      "3629620f44dc4eec928e8285f4e292c7",
      "d8d21603da7146628c7025db753adeb3",
      "f4bb69ed5dcf45cabca0294b04062d68",
      "4b9f9045a6a64724b75bed3bdf4825e5",
      "831588c036b84ba5919552e1c0ffaf95",
      "c7dfb28ce1ec490bbbc71bbf8f8bc7bb",
      "fc29fb7181a64867aa764553a94327cf",
      "4d29ed3d913f4c3dadd8aa28ffdf60ab",
      "739c6da6cd64446686e87fd499fc4e8c",
      "2454c06e04cc44a59af6a54edf771dcf",
      "7598f22b00ca4188abd0e988d87c8717",
      "1fb4ea8439054fbeaab29cbbdd8d8c62",
      "ae7d8308ff8541d082c143732f92bce6",
      "1784bfcf80e54eb1a3b7873cd36494b1",
      "f1cb6810b0f0425c925092fd2c564460",
      "d31e57f44fef4cd99cbda543609a5363",
      "42c3a0dfb96d4d0a9cbcfbefdb88634a",
      "fb3c5d28cc434035936450f03eaab7d4",
      "b7381bd873134277869b9bf86f7f6cde",
      "92a84a7a4c1a49fca9c649540174de1a",
      "973a9057772b4a33bebe1c71b2548322",
      "a2b522fb50d54cecaead8906ecc2c88f",
      "4ee572a2f86844b38f1475756d831d7e",
      "a5767d4185754f1f82e22dc55b9b659e",
      "2bae88a771624fce8a7195ab2d3790e1",
      "656d789dd50d4d7c95121ee911a0315e",
      "bcaf3aab2df24777bb896394049144d2",
      "7192858941cb47649969779dc0e63c91",
      "0de84b8c5dde45b68b6fe495e3978524",
      "664e26cb5e91441d8360e652dc6f3f13",
      "ba90ae57f0bf4101b5306b32401f5ca6",
      "585d33ea2f6c4c6f866ab5eaf500a486",
      "611e4230f7284f56a36e03b6cab128bb",
      "dbeac195f2cf4776b6c95dedda39513c",
      "dc04c3799392479f84746241eac0c9bc",
      "9a0d229daebc428d8d0bea6db980845f",
      "00cd50cc19624ebf946c288dcf96ca77",
      "4472460dcaf349e282e8505097ac56db"
     ]
    },
    "id": "33a22a6f",
    "outputId": "d99650b6-68ff-4c1e-bf7c-3ac0dc41c7c3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OLEG\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ce5a95",
   "metadata": {
    "id": "09ce5a95"
   },
   "source": [
    "# Preparing data with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd1531f",
   "metadata": {
    "id": "0cd1531f"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=80, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1,\n",
    "                                          pin_memory=True),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1,\n",
    "                                          pin_memory=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dada402",
   "metadata": {
    "id": "3dada402"
   },
   "source": [
    "# Defining a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121f2af3",
   "metadata": {
    "id": "121f2af3"
   },
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(features=inputs, wires=range(n_qubits))\n",
    "    \n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    \n",
    "    return [qml.expval(qml.PauliY(wires=i)) for i in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e8604a",
   "metadata": {
    "id": "f8e8604a"
   },
   "outputs": [],
   "source": [
    "n_layers = 4\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a67b30b7",
   "metadata": {
    "id": "a67b30b7"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class HybridNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,    \n",
    "            ),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),                \n",
    "        )\n",
    "        self.fc_1 = nn.Linear(32 * 7 * 7, 16)\n",
    "        \n",
    "        # LIST USAGE?\n",
    "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer_4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        \n",
    "        self.qlayer_1.to(device)\n",
    "        self.qlayer_2.to(device)\n",
    "        self.qlayer_3.to(device)\n",
    "        self.qlayer_4.to(device)\n",
    "        \n",
    "        self.fc_2 = nn.Linear(16, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        x = self.fc_1(x)\n",
    "        #print('Before split')\n",
    "        x_1, x_2, x_3, x_4 = torch.split(x, 4, dim=1) # second argument is number of elements in one new tensor\n",
    "        #print('After split')\n",
    "        #x = torch.Tensor(0)\n",
    "        \n",
    "        x_1 = self.qlayer_1(x_1)\n",
    "        x_2 = self.qlayer_2(x_2)\n",
    "        x_3 = self.qlayer_3(x_3)\n",
    "        x_4 = self.qlayer_4(x_4)\n",
    "        \n",
    "        #print(x.device)\n",
    "        \n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        logits = self.fc_2(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3df4eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db3df4eb",
    "outputId": "9eddce9b-8bf3-4fb1-8d8f-12fbb55c6b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_1): Linear(in_features=1568, out_features=24, bias=True)\n",
      "  (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_3): <Quantum Torch Layer: func=qnode>\n",
      "  (qlayer_4): <Quantum Torch Layer: func=qnode>\n",
      "  (fc_2): Linear(in_features=24, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hnn = HybridNN()\n",
    "hnn = hnn.to(device)\n",
    "print(hnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cbe6",
   "metadata": {
    "id": "6809cbe6"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a415a96",
   "metadata": {
    "id": "1a415a96"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9aafa9",
   "metadata": {
    "id": "df9aafa9"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(hnn.parameters(), lr = 0.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc5c6d9",
   "metadata": {
    "id": "7cc5c6d9"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train(num_epochs, model, loaders):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in trange(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            b_x, b_y = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(b_x)             \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            loss.backward()               \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 10 >= 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "        print('\\n')\n",
    "        \n",
    "def train(model, opt, loss_fn, epochs, data_tr, data_val):\n",
    "    X_val, Y_val = next(iter(data_val))\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        val_loss = 0.0\n",
    "        model.train()  # train mode\n",
    "\n",
    "        for X_batch, Y_batch in data_tr:\n",
    "            \n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(Y_batch, outputs)\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "            avg_loss += loss.item() / len(data_tr)\n",
    "            \n",
    "            X_batch = X_batch.to(cpu_dev)\n",
    "            Y_batch = Y_batch.to(cpu_dev)\n",
    "            del X_batch, Y_batch, outputs, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "       \n",
    "        toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        \n",
    "        for X_batch, Y_batch in data_val:\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            Y_batch = Y_batch.to(DEVICE)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(X_batch)\n",
    "                loss = loss_fn(Y_batch, outputs)\n",
    "            X_batch = X_batch.to(cpu_dev)\n",
    "            Y_batch = Y_batch.to(cpu_dev)\n",
    "            val_loss += loss.item() / len(data_val)\n",
    "            del X_batch, Y_batch, outputs, loss\n",
    "            \n",
    "\n",
    "        history.append((avg_loss, val_loss))\n",
    "        Y_hat = model(X_val.to(DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "        # Visualize tools\n",
    "        clear_output(wait=True)\n",
    "        for k in range(6):\n",
    "            plt.subplot(2, 6, k+1)\n",
    "            plt.imshow(np.rollaxis(X_val[k].numpy(), 0, 3), cmap='gray')\n",
    "            plt.title('Real')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(2, 6, k+7)\n",
    "            plt.imshow(Y_hat[k, 0], cmap='gray')\n",
    "            plt.title('Output')\n",
    "            plt.axis('off')\n",
    "        plt.suptitle('%d / %d - loss: %f, val_loss: %f' % (epoch+1, epochs, avg_loss, val_loss))\n",
    "        plt.show()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f9ed6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "a2db74a18ce8412399aba11b3bab930b",
      "9002f4b1af6d4c03b8f53fecdffaa3b0",
      "aa56b1689edb4a75aa4af965407467e6",
      "8b99aefdd9a247678de2cefd312207bb",
      "0a0c3aa1494d454b85ce6083f2c98234",
      "0aa6d7245fc747b58457668a840cd66b",
      "df312d8125694913844f2856ee295e67",
      "70629c93466c490cb4d10c7ba2e41d62",
      "7081d0216eb6473fae87f7331becfb53",
      "979724284c094071b6c3143666a2a8d5",
      "7ca85bfb648a4586ab15f601f45bd7c2"
     ]
    },
    "id": "20f9ed6c",
    "outputId": "3b1078fe-8904-4227-b481-0d9b43a61f33",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58479a8860714f849aff0e6ce6c858e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OLEG\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:147: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:240.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/750], Loss: 2.3181\n",
      "Epoch [1/10], Step [2/750], Loss: 2.3290\n",
      "Epoch [1/10], Step [3/750], Loss: 2.3232\n",
      "Epoch [1/10], Step [4/750], Loss: 2.3185\n",
      "Epoch [1/10], Step [5/750], Loss: 2.3440\n",
      "Epoch [1/10], Step [6/750], Loss: 2.3065\n",
      "Epoch [1/10], Step [7/750], Loss: 2.3022\n",
      "Epoch [1/10], Step [8/750], Loss: 2.2835\n",
      "Epoch [1/10], Step [9/750], Loss: 2.3066\n",
      "Epoch [1/10], Step [10/750], Loss: 2.3325\n",
      "Epoch [1/10], Step [11/750], Loss: 2.3298\n",
      "Epoch [1/10], Step [12/750], Loss: 2.2889\n",
      "Epoch [1/10], Step [13/750], Loss: 2.2821\n",
      "Epoch [1/10], Step [14/750], Loss: 2.2964\n",
      "Epoch [1/10], Step [15/750], Loss: 2.3244\n",
      "Epoch [1/10], Step [16/750], Loss: 2.2900\n",
      "Epoch [1/10], Step [17/750], Loss: 2.3071\n",
      "Epoch [1/10], Step [18/750], Loss: 2.2964\n",
      "Epoch [1/10], Step [19/750], Loss: 2.3056\n",
      "Epoch [1/10], Step [20/750], Loss: 2.2988\n",
      "Epoch [1/10], Step [21/750], Loss: 2.3047\n",
      "Epoch [1/10], Step [22/750], Loss: 2.2976\n",
      "Epoch [1/10], Step [23/750], Loss: 2.2890\n",
      "Epoch [1/10], Step [24/750], Loss: 2.2714\n",
      "Epoch [1/10], Step [25/750], Loss: 2.2775\n",
      "Epoch [1/10], Step [26/750], Loss: 2.2701\n",
      "Epoch [1/10], Step [27/750], Loss: 2.2314\n",
      "Epoch [1/10], Step [28/750], Loss: 2.3179\n",
      "Epoch [1/10], Step [29/750], Loss: 2.2520\n",
      "Epoch [1/10], Step [30/750], Loss: 2.1972\n",
      "Epoch [1/10], Step [31/750], Loss: 2.1567\n",
      "Epoch [1/10], Step [32/750], Loss: 2.1809\n",
      "Epoch [1/10], Step [33/750], Loss: 2.2086\n",
      "Epoch [1/10], Step [34/750], Loss: 2.1330\n",
      "Epoch [1/10], Step [35/750], Loss: 2.1301\n",
      "Epoch [1/10], Step [36/750], Loss: 2.1556\n",
      "Epoch [1/10], Step [37/750], Loss: 2.1428\n",
      "Epoch [1/10], Step [38/750], Loss: 2.0485\n",
      "Epoch [1/10], Step [39/750], Loss: 2.0431\n",
      "Epoch [1/10], Step [40/750], Loss: 2.1703\n",
      "Epoch [1/10], Step [41/750], Loss: 1.9676\n",
      "Epoch [1/10], Step [42/750], Loss: 2.1289\n",
      "Epoch [1/10], Step [43/750], Loss: 2.0270\n",
      "Epoch [1/10], Step [44/750], Loss: 2.1466\n",
      "Epoch [1/10], Step [45/750], Loss: 1.9407\n",
      "Epoch [1/10], Step [46/750], Loss: 2.0482\n",
      "Epoch [1/10], Step [47/750], Loss: 1.8343\n",
      "Epoch [1/10], Step [48/750], Loss: 2.0657\n",
      "Epoch [1/10], Step [49/750], Loss: 1.7725\n",
      "Epoch [1/10], Step [50/750], Loss: 1.8754\n",
      "Epoch [1/10], Step [51/750], Loss: 2.1040\n",
      "Epoch [1/10], Step [52/750], Loss: 1.7111\n",
      "Epoch [1/10], Step [53/750], Loss: 1.8031\n",
      "Epoch [1/10], Step [54/750], Loss: 1.6370\n",
      "Epoch [1/10], Step [55/750], Loss: 1.6734\n",
      "Epoch [1/10], Step [56/750], Loss: 1.6117\n",
      "Epoch [1/10], Step [57/750], Loss: 1.5213\n",
      "Epoch [1/10], Step [58/750], Loss: 1.5774\n",
      "Epoch [1/10], Step [59/750], Loss: 1.4546\n",
      "Epoch [1/10], Step [60/750], Loss: 1.5097\n",
      "Epoch [1/10], Step [61/750], Loss: 1.4814\n",
      "Epoch [1/10], Step [62/750], Loss: 1.4696\n",
      "Epoch [1/10], Step [63/750], Loss: 1.4148\n",
      "Epoch [1/10], Step [64/750], Loss: 1.2543\n",
      "Epoch [1/10], Step [65/750], Loss: 1.3166\n",
      "Epoch [1/10], Step [66/750], Loss: 1.4149\n",
      "Epoch [1/10], Step [67/750], Loss: 1.1137\n",
      "Epoch [1/10], Step [68/750], Loss: 1.2880\n",
      "Epoch [1/10], Step [69/750], Loss: 0.8947\n",
      "Epoch [1/10], Step [70/750], Loss: 1.0783\n",
      "Epoch [1/10], Step [71/750], Loss: 1.1407\n",
      "Epoch [1/10], Step [72/750], Loss: 1.0672\n",
      "Epoch [1/10], Step [73/750], Loss: 1.1338\n",
      "Epoch [1/10], Step [74/750], Loss: 1.0981\n",
      "Epoch [1/10], Step [75/750], Loss: 0.9414\n",
      "Epoch [1/10], Step [76/750], Loss: 0.8466\n",
      "Epoch [1/10], Step [77/750], Loss: 0.8756\n",
      "Epoch [1/10], Step [78/750], Loss: 0.7468\n",
      "Epoch [1/10], Step [79/750], Loss: 0.7752\n",
      "Epoch [1/10], Step [80/750], Loss: 0.7875\n",
      "Epoch [1/10], Step [81/750], Loss: 0.6991\n",
      "Epoch [1/10], Step [82/750], Loss: 0.7874\n",
      "Epoch [1/10], Step [83/750], Loss: 0.8289\n",
      "Epoch [1/10], Step [84/750], Loss: 0.7394\n",
      "Epoch [1/10], Step [85/750], Loss: 0.6043\n",
      "Epoch [1/10], Step [86/750], Loss: 0.6325\n",
      "Epoch [1/10], Step [87/750], Loss: 0.6000\n",
      "Epoch [1/10], Step [88/750], Loss: 0.6827\n",
      "Epoch [1/10], Step [89/750], Loss: 0.5774\n",
      "Epoch [1/10], Step [90/750], Loss: 0.5304\n",
      "Epoch [1/10], Step [91/750], Loss: 0.6674\n",
      "Epoch [1/10], Step [92/750], Loss: 0.4895\n",
      "Epoch [1/10], Step [93/750], Loss: 0.4541\n",
      "Epoch [1/10], Step [94/750], Loss: 0.4557\n",
      "Epoch [1/10], Step [95/750], Loss: 0.6332\n",
      "Epoch [1/10], Step [96/750], Loss: 0.3828\n",
      "Epoch [1/10], Step [97/750], Loss: 0.4018\n",
      "Epoch [1/10], Step [98/750], Loss: 0.5306\n",
      "Epoch [1/10], Step [99/750], Loss: 0.3626\n",
      "Epoch [1/10], Step [100/750], Loss: 0.4097\n",
      "Epoch [1/10], Step [101/750], Loss: 0.3369\n",
      "Epoch [1/10], Step [102/750], Loss: 0.4999\n",
      "Epoch [1/10], Step [103/750], Loss: 0.3964\n",
      "Epoch [1/10], Step [104/750], Loss: 0.3180\n",
      "Epoch [1/10], Step [105/750], Loss: 0.3095\n",
      "Epoch [1/10], Step [106/750], Loss: 0.4762\n",
      "Epoch [1/10], Step [107/750], Loss: 0.3269\n",
      "Epoch [1/10], Step [108/750], Loss: 0.2927\n",
      "Epoch [1/10], Step [109/750], Loss: 0.4798\n",
      "Epoch [1/10], Step [110/750], Loss: 0.2745\n",
      "Epoch [1/10], Step [111/750], Loss: 0.2270\n",
      "Epoch [1/10], Step [112/750], Loss: 0.3230\n",
      "Epoch [1/10], Step [113/750], Loss: 0.2806\n",
      "Epoch [1/10], Step [114/750], Loss: 0.3229\n",
      "Epoch [1/10], Step [115/750], Loss: 0.3244\n",
      "Epoch [1/10], Step [116/750], Loss: 0.2249\n",
      "Epoch [1/10], Step [117/750], Loss: 0.1783\n",
      "Epoch [1/10], Step [118/750], Loss: 0.2658\n",
      "Epoch [1/10], Step [119/750], Loss: 0.4074\n",
      "Epoch [1/10], Step [120/750], Loss: 0.2457\n",
      "Epoch [1/10], Step [121/750], Loss: 0.2897\n",
      "Epoch [1/10], Step [122/750], Loss: 0.2634\n",
      "Epoch [1/10], Step [123/750], Loss: 0.4400\n",
      "Epoch [1/10], Step [124/750], Loss: 0.2150\n",
      "Epoch [1/10], Step [125/750], Loss: 0.1838\n",
      "Epoch [1/10], Step [126/750], Loss: 0.4460\n",
      "Epoch [1/10], Step [127/750], Loss: 0.2540\n",
      "Epoch [1/10], Step [128/750], Loss: 0.2181\n",
      "Epoch [1/10], Step [129/750], Loss: 0.2467\n",
      "Epoch [1/10], Step [130/750], Loss: 0.2453\n",
      "Epoch [1/10], Step [131/750], Loss: 0.3273\n",
      "Epoch [1/10], Step [132/750], Loss: 0.1976\n",
      "Epoch [1/10], Step [133/750], Loss: 0.3135\n",
      "Epoch [1/10], Step [134/750], Loss: 0.3018\n",
      "Epoch [1/10], Step [135/750], Loss: 0.2933\n",
      "Epoch [1/10], Step [136/750], Loss: 0.1788\n",
      "Epoch [1/10], Step [137/750], Loss: 0.2362\n",
      "Epoch [1/10], Step [138/750], Loss: 0.4962\n",
      "Epoch [1/10], Step [139/750], Loss: 0.2687\n",
      "Epoch [1/10], Step [140/750], Loss: 0.2877\n",
      "Epoch [1/10], Step [141/750], Loss: 0.2090\n",
      "Epoch [1/10], Step [142/750], Loss: 0.2218\n",
      "Epoch [1/10], Step [143/750], Loss: 0.2843\n",
      "Epoch [1/10], Step [144/750], Loss: 0.3533\n",
      "Epoch [1/10], Step [145/750], Loss: 0.3783\n",
      "Epoch [1/10], Step [146/750], Loss: 0.1612\n",
      "Epoch [1/10], Step [147/750], Loss: 0.3356\n",
      "Epoch [1/10], Step [148/750], Loss: 0.2151\n",
      "Epoch [1/10], Step [149/750], Loss: 0.3014\n",
      "Epoch [1/10], Step [150/750], Loss: 0.1677\n",
      "Epoch [1/10], Step [151/750], Loss: 0.2027\n",
      "Epoch [1/10], Step [152/750], Loss: 0.2292\n",
      "Epoch [1/10], Step [153/750], Loss: 0.0944\n",
      "Epoch [1/10], Step [154/750], Loss: 0.1643\n",
      "Epoch [1/10], Step [155/750], Loss: 0.1970\n",
      "Epoch [1/10], Step [156/750], Loss: 0.1526\n",
      "Epoch [1/10], Step [157/750], Loss: 0.2122\n",
      "Epoch [1/10], Step [158/750], Loss: 0.1613\n",
      "Epoch [1/10], Step [159/750], Loss: 0.1952\n",
      "Epoch [1/10], Step [160/750], Loss: 0.1570\n",
      "Epoch [1/10], Step [161/750], Loss: 0.1384\n",
      "Epoch [1/10], Step [162/750], Loss: 0.1021\n",
      "Epoch [1/10], Step [163/750], Loss: 0.1999\n",
      "Epoch [1/10], Step [164/750], Loss: 0.2023\n",
      "Epoch [1/10], Step [165/750], Loss: 0.3824\n",
      "Epoch [1/10], Step [166/750], Loss: 0.1569\n",
      "Epoch [1/10], Step [167/750], Loss: 0.2211\n",
      "Epoch [1/10], Step [168/750], Loss: 0.2186\n",
      "Epoch [1/10], Step [169/750], Loss: 0.1350\n",
      "Epoch [1/10], Step [170/750], Loss: 0.1511\n",
      "Epoch [1/10], Step [171/750], Loss: 0.2240\n",
      "Epoch [1/10], Step [172/750], Loss: 0.1172\n",
      "Epoch [1/10], Step [173/750], Loss: 0.2852\n",
      "Epoch [1/10], Step [174/750], Loss: 0.2477\n",
      "Epoch [1/10], Step [175/750], Loss: 0.1597\n",
      "Epoch [1/10], Step [176/750], Loss: 0.1688\n",
      "Epoch [1/10], Step [177/750], Loss: 0.1931\n",
      "Epoch [1/10], Step [178/750], Loss: 0.1804\n",
      "Epoch [1/10], Step [179/750], Loss: 0.1580\n",
      "Epoch [1/10], Step [180/750], Loss: 0.1288\n",
      "Epoch [1/10], Step [181/750], Loss: 0.1019\n",
      "Epoch [1/10], Step [182/750], Loss: 0.1301\n",
      "Epoch [1/10], Step [183/750], Loss: 0.0975\n",
      "Epoch [1/10], Step [184/750], Loss: 0.2178\n",
      "Epoch [1/10], Step [185/750], Loss: 0.1006\n",
      "Epoch [1/10], Step [186/750], Loss: 0.1064\n",
      "Epoch [1/10], Step [187/750], Loss: 0.1794\n",
      "Epoch [1/10], Step [188/750], Loss: 0.1994\n",
      "Epoch [1/10], Step [189/750], Loss: 0.1968\n",
      "Epoch [1/10], Step [190/750], Loss: 0.1820\n",
      "Epoch [1/10], Step [191/750], Loss: 0.2368\n",
      "Epoch [1/10], Step [192/750], Loss: 0.1235\n",
      "Epoch [1/10], Step [193/750], Loss: 0.1137\n",
      "Epoch [1/10], Step [194/750], Loss: 0.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [195/750], Loss: 0.1785\n",
      "Epoch [1/10], Step [196/750], Loss: 0.1872\n",
      "Epoch [1/10], Step [197/750], Loss: 0.1622\n",
      "Epoch [1/10], Step [198/750], Loss: 0.1468\n",
      "Epoch [1/10], Step [199/750], Loss: 0.0663\n",
      "Epoch [1/10], Step [200/750], Loss: 0.0795\n",
      "Epoch [1/10], Step [201/750], Loss: 0.1131\n",
      "Epoch [1/10], Step [202/750], Loss: 0.1341\n",
      "Epoch [1/10], Step [203/750], Loss: 0.1091\n",
      "Epoch [1/10], Step [204/750], Loss: 0.0753\n",
      "Epoch [1/10], Step [205/750], Loss: 0.1019\n",
      "Epoch [1/10], Step [206/750], Loss: 0.1355\n",
      "Epoch [1/10], Step [207/750], Loss: 0.1628\n",
      "Epoch [1/10], Step [208/750], Loss: 0.1723\n",
      "Epoch [1/10], Step [209/750], Loss: 0.3023\n",
      "Epoch [1/10], Step [210/750], Loss: 0.3015\n",
      "Epoch [1/10], Step [211/750], Loss: 0.1145\n",
      "Epoch [1/10], Step [212/750], Loss: 0.1506\n",
      "Epoch [1/10], Step [213/750], Loss: 0.0939\n",
      "Epoch [1/10], Step [214/750], Loss: 0.0568\n",
      "Epoch [1/10], Step [215/750], Loss: 0.1776\n",
      "Epoch [1/10], Step [216/750], Loss: 0.0564\n",
      "Epoch [1/10], Step [217/750], Loss: 0.0885\n",
      "Epoch [1/10], Step [218/750], Loss: 0.1448\n",
      "Epoch [1/10], Step [219/750], Loss: 0.1599\n",
      "Epoch [1/10], Step [220/750], Loss: 0.0869\n",
      "Epoch [1/10], Step [221/750], Loss: 0.0742\n",
      "Epoch [1/10], Step [222/750], Loss: 0.2563\n",
      "Epoch [1/10], Step [223/750], Loss: 0.1240\n",
      "Epoch [1/10], Step [224/750], Loss: 0.0910\n",
      "Epoch [1/10], Step [225/750], Loss: 0.0704\n",
      "Epoch [1/10], Step [226/750], Loss: 0.1059\n",
      "Epoch [1/10], Step [227/750], Loss: 0.1521\n",
      "Epoch [1/10], Step [228/750], Loss: 0.1345\n",
      "Epoch [1/10], Step [229/750], Loss: 0.1492\n",
      "Epoch [1/10], Step [230/750], Loss: 0.0764\n",
      "Epoch [1/10], Step [231/750], Loss: 0.1850\n",
      "Epoch [1/10], Step [232/750], Loss: 0.0914\n",
      "Epoch [1/10], Step [233/750], Loss: 0.0994\n",
      "Epoch [1/10], Step [234/750], Loss: 0.0964\n",
      "Epoch [1/10], Step [235/750], Loss: 0.0990\n",
      "Epoch [1/10], Step [236/750], Loss: 0.1885\n",
      "Epoch [1/10], Step [237/750], Loss: 0.1693\n",
      "Epoch [1/10], Step [238/750], Loss: 0.1975\n",
      "Epoch [1/10], Step [239/750], Loss: 0.2099\n",
      "Epoch [1/10], Step [240/750], Loss: 0.1232\n",
      "Epoch [1/10], Step [241/750], Loss: 0.1214\n",
      "Epoch [1/10], Step [242/750], Loss: 0.0778\n",
      "Epoch [1/10], Step [243/750], Loss: 0.1146\n",
      "Epoch [1/10], Step [244/750], Loss: 0.1359\n",
      "Epoch [1/10], Step [245/750], Loss: 0.1063\n",
      "Epoch [1/10], Step [246/750], Loss: 0.1856\n",
      "Epoch [1/10], Step [247/750], Loss: 0.1395\n",
      "Epoch [1/10], Step [248/750], Loss: 0.1378\n",
      "Epoch [1/10], Step [249/750], Loss: 0.1393\n",
      "Epoch [1/10], Step [250/750], Loss: 0.1440\n",
      "Epoch [1/10], Step [251/750], Loss: 0.1425\n",
      "Epoch [1/10], Step [252/750], Loss: 0.0809\n",
      "Epoch [1/10], Step [253/750], Loss: 0.0925\n",
      "Epoch [1/10], Step [254/750], Loss: 0.3001\n",
      "Epoch [1/10], Step [255/750], Loss: 0.1191\n",
      "Epoch [1/10], Step [256/750], Loss: 0.1288\n",
      "Epoch [1/10], Step [257/750], Loss: 0.0615\n",
      "Epoch [1/10], Step [258/750], Loss: 0.0546\n",
      "Epoch [1/10], Step [259/750], Loss: 0.0946\n",
      "Epoch [1/10], Step [260/750], Loss: 0.2064\n",
      "Epoch [1/10], Step [261/750], Loss: 0.1029\n",
      "Epoch [1/10], Step [262/750], Loss: 0.1128\n",
      "Epoch [1/10], Step [263/750], Loss: 0.1666\n",
      "Epoch [1/10], Step [264/750], Loss: 0.1129\n",
      "Epoch [1/10], Step [265/750], Loss: 0.0686\n",
      "Epoch [1/10], Step [266/750], Loss: 0.1351\n",
      "Epoch [1/10], Step [267/750], Loss: 0.0213\n",
      "Epoch [1/10], Step [268/750], Loss: 0.1987\n",
      "Epoch [1/10], Step [269/750], Loss: 0.1617\n",
      "Epoch [1/10], Step [270/750], Loss: 0.1445\n",
      "Epoch [1/10], Step [271/750], Loss: 0.1784\n",
      "Epoch [1/10], Step [272/750], Loss: 0.1260\n",
      "Epoch [1/10], Step [273/750], Loss: 0.1009\n",
      "Epoch [1/10], Step [274/750], Loss: 0.0867\n",
      "Epoch [1/10], Step [275/750], Loss: 0.0760\n",
      "Epoch [1/10], Step [276/750], Loss: 0.0773\n",
      "Epoch [1/10], Step [277/750], Loss: 0.0893\n",
      "Epoch [1/10], Step [278/750], Loss: 0.1507\n",
      "Epoch [1/10], Step [279/750], Loss: 0.0512\n",
      "Epoch [1/10], Step [280/750], Loss: 0.1088\n",
      "Epoch [1/10], Step [281/750], Loss: 0.1028\n",
      "Epoch [1/10], Step [282/750], Loss: 0.0895\n",
      "Epoch [1/10], Step [283/750], Loss: 0.1846\n",
      "Epoch [1/10], Step [284/750], Loss: 0.0732\n",
      "Epoch [1/10], Step [285/750], Loss: 0.0575\n",
      "Epoch [1/10], Step [286/750], Loss: 0.1116\n",
      "Epoch [1/10], Step [287/750], Loss: 0.1140\n",
      "Epoch [1/10], Step [288/750], Loss: 0.0374\n",
      "Epoch [1/10], Step [289/750], Loss: 0.0913\n",
      "Epoch [1/10], Step [290/750], Loss: 0.1942\n",
      "Epoch [1/10], Step [291/750], Loss: 0.1400\n",
      "Epoch [1/10], Step [292/750], Loss: 0.0926\n",
      "Epoch [1/10], Step [293/750], Loss: 0.1432\n",
      "Epoch [1/10], Step [294/750], Loss: 0.0699\n",
      "Epoch [1/10], Step [295/750], Loss: 0.0720\n",
      "Epoch [1/10], Step [296/750], Loss: 0.1166\n",
      "Epoch [1/10], Step [297/750], Loss: 0.1065\n",
      "Epoch [1/10], Step [298/750], Loss: 0.0873\n",
      "Epoch [1/10], Step [299/750], Loss: 0.2342\n",
      "Epoch [1/10], Step [300/750], Loss: 0.1036\n",
      "Epoch [1/10], Step [301/750], Loss: 0.0939\n",
      "Epoch [1/10], Step [302/750], Loss: 0.1214\n",
      "Epoch [1/10], Step [303/750], Loss: 0.0806\n",
      "Epoch [1/10], Step [304/750], Loss: 0.1013\n",
      "Epoch [1/10], Step [305/750], Loss: 0.0257\n",
      "Epoch [1/10], Step [306/750], Loss: 0.1654\n",
      "Epoch [1/10], Step [307/750], Loss: 0.0650\n",
      "Epoch [1/10], Step [308/750], Loss: 0.1309\n",
      "Epoch [1/10], Step [309/750], Loss: 0.1231\n",
      "Epoch [1/10], Step [310/750], Loss: 0.1514\n",
      "Epoch [1/10], Step [311/750], Loss: 0.0427\n",
      "Epoch [1/10], Step [312/750], Loss: 0.1876\n",
      "Epoch [1/10], Step [313/750], Loss: 0.0308\n",
      "Epoch [1/10], Step [314/750], Loss: 0.1407\n",
      "Epoch [1/10], Step [315/750], Loss: 0.1013\n",
      "Epoch [1/10], Step [316/750], Loss: 0.0396\n",
      "Epoch [1/10], Step [317/750], Loss: 0.0677\n",
      "Epoch [1/10], Step [318/750], Loss: 0.1820\n",
      "Epoch [1/10], Step [319/750], Loss: 0.0984\n",
      "Epoch [1/10], Step [320/750], Loss: 0.1397\n",
      "Epoch [1/10], Step [321/750], Loss: 0.0501\n",
      "Epoch [1/10], Step [322/750], Loss: 0.0402\n",
      "Epoch [1/10], Step [323/750], Loss: 0.2702\n",
      "Epoch [1/10], Step [324/750], Loss: 0.0763\n",
      "Epoch [1/10], Step [325/750], Loss: 0.0764\n",
      "Epoch [1/10], Step [326/750], Loss: 0.1593\n",
      "Epoch [1/10], Step [327/750], Loss: 0.0623\n",
      "Epoch [1/10], Step [328/750], Loss: 0.0645\n",
      "Epoch [1/10], Step [329/750], Loss: 0.0798\n",
      "Epoch [1/10], Step [330/750], Loss: 0.1004\n",
      "Epoch [1/10], Step [331/750], Loss: 0.1505\n",
      "Epoch [1/10], Step [332/750], Loss: 0.0976\n",
      "Epoch [1/10], Step [333/750], Loss: 0.0933\n",
      "Epoch [1/10], Step [334/750], Loss: 0.1042\n",
      "Epoch [1/10], Step [335/750], Loss: 0.1360\n",
      "Epoch [1/10], Step [336/750], Loss: 0.0707\n",
      "Epoch [1/10], Step [337/750], Loss: 0.1797\n",
      "Epoch [1/10], Step [338/750], Loss: 0.2169\n",
      "Epoch [1/10], Step [339/750], Loss: 0.0689\n",
      "Epoch [1/10], Step [340/750], Loss: 0.0839\n",
      "Epoch [1/10], Step [341/750], Loss: 0.0607\n",
      "Epoch [1/10], Step [342/750], Loss: 0.1730\n",
      "Epoch [1/10], Step [343/750], Loss: 0.0475\n",
      "Epoch [1/10], Step [344/750], Loss: 0.1024\n",
      "Epoch [1/10], Step [345/750], Loss: 0.0577\n",
      "Epoch [1/10], Step [346/750], Loss: 0.0572\n",
      "Epoch [1/10], Step [347/750], Loss: 0.0677\n",
      "Epoch [1/10], Step [348/750], Loss: 0.0815\n",
      "Epoch [1/10], Step [349/750], Loss: 0.0535\n",
      "Epoch [1/10], Step [350/750], Loss: 0.0790\n",
      "Epoch [1/10], Step [351/750], Loss: 0.1036\n",
      "Epoch [1/10], Step [352/750], Loss: 0.0333\n",
      "Epoch [1/10], Step [353/750], Loss: 0.0257\n",
      "Epoch [1/10], Step [354/750], Loss: 0.1110\n",
      "Epoch [1/10], Step [355/750], Loss: 0.1320\n",
      "Epoch [1/10], Step [356/750], Loss: 0.1049\n",
      "Epoch [1/10], Step [357/750], Loss: 0.0801\n",
      "Epoch [1/10], Step [358/750], Loss: 0.1945\n",
      "Epoch [1/10], Step [359/750], Loss: 0.1567\n",
      "Epoch [1/10], Step [360/750], Loss: 0.0768\n",
      "Epoch [1/10], Step [361/750], Loss: 0.0686\n",
      "Epoch [1/10], Step [362/750], Loss: 0.0766\n",
      "Epoch [1/10], Step [363/750], Loss: 0.1205\n",
      "Epoch [1/10], Step [364/750], Loss: 0.0347\n",
      "Epoch [1/10], Step [365/750], Loss: 0.1579\n",
      "Epoch [1/10], Step [366/750], Loss: 0.0531\n",
      "Epoch [1/10], Step [367/750], Loss: 0.1129\n",
      "Epoch [1/10], Step [368/750], Loss: 0.0663\n",
      "Epoch [1/10], Step [369/750], Loss: 0.0620\n",
      "Epoch [1/10], Step [370/750], Loss: 0.1815\n",
      "Epoch [1/10], Step [371/750], Loss: 0.1861\n",
      "Epoch [1/10], Step [372/750], Loss: 0.0894\n",
      "Epoch [1/10], Step [373/750], Loss: 0.0746\n",
      "Epoch [1/10], Step [374/750], Loss: 0.1738\n",
      "Epoch [1/10], Step [375/750], Loss: 0.0834\n",
      "Epoch [1/10], Step [376/750], Loss: 0.0709\n",
      "Epoch [1/10], Step [377/750], Loss: 0.0708\n",
      "Epoch [1/10], Step [378/750], Loss: 0.1147\n",
      "Epoch [1/10], Step [379/750], Loss: 0.0532\n",
      "Epoch [1/10], Step [380/750], Loss: 0.0777\n",
      "Epoch [1/10], Step [381/750], Loss: 0.0383\n",
      "Epoch [1/10], Step [382/750], Loss: 0.1354\n",
      "Epoch [1/10], Step [383/750], Loss: 0.0644\n",
      "Epoch [1/10], Step [384/750], Loss: 0.0657\n",
      "Epoch [1/10], Step [385/750], Loss: 0.0829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [386/750], Loss: 0.1757\n",
      "Epoch [1/10], Step [387/750], Loss: 0.0694\n",
      "Epoch [1/10], Step [388/750], Loss: 0.0764\n",
      "Epoch [1/10], Step [389/750], Loss: 0.0583\n",
      "Epoch [1/10], Step [390/750], Loss: 0.0786\n",
      "Epoch [1/10], Step [391/750], Loss: 0.1184\n",
      "Epoch [1/10], Step [392/750], Loss: 0.1061\n",
      "Epoch [1/10], Step [393/750], Loss: 0.0722\n",
      "Epoch [1/10], Step [394/750], Loss: 0.1016\n",
      "Epoch [1/10], Step [395/750], Loss: 0.0676\n",
      "Epoch [1/10], Step [396/750], Loss: 0.0234\n",
      "Epoch [1/10], Step [397/750], Loss: 0.1200\n",
      "Epoch [1/10], Step [398/750], Loss: 0.0912\n",
      "Epoch [1/10], Step [399/750], Loss: 0.0924\n",
      "Epoch [1/10], Step [400/750], Loss: 0.0822\n",
      "Epoch [1/10], Step [401/750], Loss: 0.1078\n",
      "Epoch [1/10], Step [402/750], Loss: 0.0761\n",
      "Epoch [1/10], Step [403/750], Loss: 0.0967\n",
      "Epoch [1/10], Step [404/750], Loss: 0.0724\n",
      "Epoch [1/10], Step [405/750], Loss: 0.1089\n",
      "Epoch [1/10], Step [406/750], Loss: 0.1199\n",
      "Epoch [1/10], Step [407/750], Loss: 0.0666\n",
      "Epoch [1/10], Step [408/750], Loss: 0.1042\n",
      "Epoch [1/10], Step [409/750], Loss: 0.1352\n",
      "Epoch [1/10], Step [410/750], Loss: 0.0589\n",
      "Epoch [1/10], Step [411/750], Loss: 0.1659\n",
      "Epoch [1/10], Step [412/750], Loss: 0.1145\n",
      "Epoch [1/10], Step [413/750], Loss: 0.1422\n",
      "Epoch [1/10], Step [414/750], Loss: 0.1127\n",
      "Epoch [1/10], Step [415/750], Loss: 0.0689\n",
      "Epoch [1/10], Step [416/750], Loss: 0.1141\n",
      "Epoch [1/10], Step [417/750], Loss: 0.1633\n",
      "Epoch [1/10], Step [418/750], Loss: 0.0739\n",
      "Epoch [1/10], Step [419/750], Loss: 0.0668\n",
      "Epoch [1/10], Step [420/750], Loss: 0.0606\n",
      "Epoch [1/10], Step [421/750], Loss: 0.1601\n",
      "Epoch [1/10], Step [422/750], Loss: 0.2140\n",
      "Epoch [1/10], Step [423/750], Loss: 0.0869\n",
      "Epoch [1/10], Step [424/750], Loss: 0.1585\n",
      "Epoch [1/10], Step [425/750], Loss: 0.1453\n",
      "Epoch [1/10], Step [426/750], Loss: 0.2391\n",
      "Epoch [1/10], Step [427/750], Loss: 0.0616\n",
      "Epoch [1/10], Step [428/750], Loss: 0.0678\n",
      "Epoch [1/10], Step [429/750], Loss: 0.0414\n",
      "Epoch [1/10], Step [430/750], Loss: 0.1501\n",
      "Epoch [1/10], Step [431/750], Loss: 0.0496\n",
      "Epoch [1/10], Step [432/750], Loss: 0.0162\n",
      "Epoch [1/10], Step [433/750], Loss: 0.0909\n",
      "Epoch [1/10], Step [434/750], Loss: 0.0260\n",
      "Epoch [1/10], Step [435/750], Loss: 0.0418\n",
      "Epoch [1/10], Step [436/750], Loss: 0.0739\n",
      "Epoch [1/10], Step [437/750], Loss: 0.0781\n",
      "Epoch [1/10], Step [438/750], Loss: 0.1264\n",
      "Epoch [1/10], Step [439/750], Loss: 0.0624\n",
      "Epoch [1/10], Step [440/750], Loss: 0.0833\n",
      "Epoch [1/10], Step [441/750], Loss: 0.1332\n",
      "Epoch [1/10], Step [442/750], Loss: 0.0761\n",
      "Epoch [1/10], Step [443/750], Loss: 0.2382\n",
      "Epoch [1/10], Step [444/750], Loss: 0.1516\n",
      "Epoch [1/10], Step [445/750], Loss: 0.0376\n",
      "Epoch [1/10], Step [446/750], Loss: 0.0627\n",
      "Epoch [1/10], Step [447/750], Loss: 0.2248\n",
      "Epoch [1/10], Step [448/750], Loss: 0.1212\n",
      "Epoch [1/10], Step [449/750], Loss: 0.0785\n",
      "Epoch [1/10], Step [450/750], Loss: 0.0372\n",
      "Epoch [1/10], Step [451/750], Loss: 0.0615\n",
      "Epoch [1/10], Step [452/750], Loss: 0.0624\n",
      "Epoch [1/10], Step [453/750], Loss: 0.1062\n",
      "Epoch [1/10], Step [454/750], Loss: 0.0383\n",
      "Epoch [1/10], Step [455/750], Loss: 0.0594\n",
      "Epoch [1/10], Step [456/750], Loss: 0.0715\n",
      "Epoch [1/10], Step [457/750], Loss: 0.0664\n",
      "Epoch [1/10], Step [458/750], Loss: 0.0877\n",
      "Epoch [1/10], Step [459/750], Loss: 0.1668\n",
      "Epoch [1/10], Step [460/750], Loss: 0.0603\n",
      "Epoch [1/10], Step [461/750], Loss: 0.0462\n",
      "Epoch [1/10], Step [462/750], Loss: 0.0343\n",
      "Epoch [1/10], Step [463/750], Loss: 0.1044\n",
      "Epoch [1/10], Step [464/750], Loss: 0.0719\n",
      "Epoch [1/10], Step [465/750], Loss: 0.1232\n",
      "Epoch [1/10], Step [466/750], Loss: 0.1149\n",
      "Epoch [1/10], Step [467/750], Loss: 0.0771\n",
      "Epoch [1/10], Step [468/750], Loss: 0.0627\n",
      "Epoch [1/10], Step [469/750], Loss: 0.0383\n",
      "Epoch [1/10], Step [470/750], Loss: 0.0286\n",
      "Epoch [1/10], Step [471/750], Loss: 0.1058\n",
      "Epoch [1/10], Step [472/750], Loss: 0.0798\n",
      "Epoch [1/10], Step [473/750], Loss: 0.0534\n",
      "Epoch [1/10], Step [474/750], Loss: 0.1352\n",
      "Epoch [1/10], Step [475/750], Loss: 0.3080\n",
      "Epoch [1/10], Step [476/750], Loss: 0.1200\n",
      "Epoch [1/10], Step [477/750], Loss: 0.2801\n",
      "Epoch [1/10], Step [478/750], Loss: 0.1257\n",
      "Epoch [1/10], Step [479/750], Loss: 0.0456\n",
      "Epoch [1/10], Step [480/750], Loss: 0.2110\n",
      "Epoch [1/10], Step [481/750], Loss: 0.0430\n",
      "Epoch [1/10], Step [482/750], Loss: 0.1228\n",
      "Epoch [1/10], Step [483/750], Loss: 0.1506\n",
      "Epoch [1/10], Step [484/750], Loss: 0.1044\n",
      "Epoch [1/10], Step [485/750], Loss: 0.0845\n",
      "Epoch [1/10], Step [486/750], Loss: 0.0514\n",
      "Epoch [1/10], Step [487/750], Loss: 0.0766\n",
      "Epoch [1/10], Step [488/750], Loss: 0.0821\n",
      "Epoch [1/10], Step [489/750], Loss: 0.0555\n",
      "Epoch [1/10], Step [490/750], Loss: 0.0550\n",
      "Epoch [1/10], Step [491/750], Loss: 0.0270\n",
      "Epoch [1/10], Step [492/750], Loss: 0.0588\n",
      "Epoch [1/10], Step [493/750], Loss: 0.2855\n",
      "Epoch [1/10], Step [494/750], Loss: 0.0413\n",
      "Epoch [1/10], Step [495/750], Loss: 0.0122\n",
      "Epoch [1/10], Step [496/750], Loss: 0.0618\n",
      "Epoch [1/10], Step [497/750], Loss: 0.2171\n",
      "Epoch [1/10], Step [498/750], Loss: 0.1020\n",
      "Epoch [1/10], Step [499/750], Loss: 0.0591\n",
      "Epoch [1/10], Step [500/750], Loss: 0.2492\n",
      "Epoch [1/10], Step [501/750], Loss: 0.0683\n",
      "Epoch [1/10], Step [502/750], Loss: 0.1838\n",
      "Epoch [1/10], Step [503/750], Loss: 0.0604\n",
      "Epoch [1/10], Step [504/750], Loss: 0.0324\n",
      "Epoch [1/10], Step [505/750], Loss: 0.0321\n",
      "Epoch [1/10], Step [506/750], Loss: 0.1144\n",
      "Epoch [1/10], Step [507/750], Loss: 0.1976\n",
      "Epoch [1/10], Step [508/750], Loss: 0.1578\n",
      "Epoch [1/10], Step [509/750], Loss: 0.0396\n",
      "Epoch [1/10], Step [510/750], Loss: 0.0549\n",
      "Epoch [1/10], Step [511/750], Loss: 0.0964\n",
      "Epoch [1/10], Step [512/750], Loss: 0.1095\n",
      "Epoch [1/10], Step [513/750], Loss: 0.0666\n",
      "Epoch [1/10], Step [514/750], Loss: 0.1987\n",
      "Epoch [1/10], Step [515/750], Loss: 0.1268\n",
      "Epoch [1/10], Step [516/750], Loss: 0.0460\n",
      "Epoch [1/10], Step [517/750], Loss: 0.0919\n",
      "Epoch [1/10], Step [518/750], Loss: 0.1076\n",
      "Epoch [1/10], Step [519/750], Loss: 0.0337\n",
      "Epoch [1/10], Step [520/750], Loss: 0.1204\n",
      "Epoch [1/10], Step [521/750], Loss: 0.1211\n",
      "Epoch [1/10], Step [522/750], Loss: 0.1061\n",
      "Epoch [1/10], Step [523/750], Loss: 0.1364\n",
      "Epoch [1/10], Step [524/750], Loss: 0.0253\n",
      "Epoch [1/10], Step [525/750], Loss: 0.0981\n",
      "Epoch [1/10], Step [526/750], Loss: 0.0332\n",
      "Epoch [1/10], Step [527/750], Loss: 0.1190\n",
      "Epoch [1/10], Step [528/750], Loss: 0.1204\n",
      "Epoch [1/10], Step [529/750], Loss: 0.1039\n",
      "Epoch [1/10], Step [530/750], Loss: 0.0548\n",
      "Epoch [1/10], Step [531/750], Loss: 0.0648\n",
      "Epoch [1/10], Step [532/750], Loss: 0.1310\n",
      "Epoch [1/10], Step [533/750], Loss: 0.0483\n",
      "Epoch [1/10], Step [534/750], Loss: 0.0314\n",
      "Epoch [1/10], Step [535/750], Loss: 0.0811\n",
      "Epoch [1/10], Step [536/750], Loss: 0.1766\n",
      "Epoch [1/10], Step [537/750], Loss: 0.0486\n",
      "Epoch [1/10], Step [538/750], Loss: 0.0411\n",
      "Epoch [1/10], Step [539/750], Loss: 0.1872\n",
      "Epoch [1/10], Step [540/750], Loss: 0.1263\n",
      "Epoch [1/10], Step [541/750], Loss: 0.0301\n",
      "Epoch [1/10], Step [542/750], Loss: 0.0615\n",
      "Epoch [1/10], Step [543/750], Loss: 0.0623\n",
      "Epoch [1/10], Step [544/750], Loss: 0.0757\n",
      "Epoch [1/10], Step [545/750], Loss: 0.1071\n",
      "Epoch [1/10], Step [546/750], Loss: 0.1470\n",
      "Epoch [1/10], Step [547/750], Loss: 0.0442\n",
      "Epoch [1/10], Step [548/750], Loss: 0.1656\n",
      "Epoch [1/10], Step [549/750], Loss: 0.0475\n",
      "Epoch [1/10], Step [550/750], Loss: 0.0348\n",
      "Epoch [1/10], Step [551/750], Loss: 0.0173\n",
      "Epoch [1/10], Step [552/750], Loss: 0.0598\n",
      "Epoch [1/10], Step [553/750], Loss: 0.0755\n",
      "Epoch [1/10], Step [554/750], Loss: 0.1818\n",
      "Epoch [1/10], Step [555/750], Loss: 0.0413\n",
      "Epoch [1/10], Step [556/750], Loss: 0.0908\n",
      "Epoch [1/10], Step [557/750], Loss: 0.0527\n",
      "Epoch [1/10], Step [558/750], Loss: 0.0346\n",
      "Epoch [1/10], Step [559/750], Loss: 0.0500\n",
      "Epoch [1/10], Step [560/750], Loss: 0.0615\n",
      "Epoch [1/10], Step [561/750], Loss: 0.2125\n",
      "Epoch [1/10], Step [562/750], Loss: 0.0983\n",
      "Epoch [1/10], Step [563/750], Loss: 0.0278\n",
      "Epoch [1/10], Step [564/750], Loss: 0.1659\n",
      "Epoch [1/10], Step [565/750], Loss: 0.0597\n",
      "Epoch [1/10], Step [566/750], Loss: 0.0687\n",
      "Epoch [1/10], Step [567/750], Loss: 0.0465\n",
      "Epoch [1/10], Step [568/750], Loss: 0.2165\n",
      "Epoch [1/10], Step [569/750], Loss: 0.0533\n",
      "Epoch [1/10], Step [570/750], Loss: 0.1073\n",
      "Epoch [1/10], Step [571/750], Loss: 0.0497\n",
      "Epoch [1/10], Step [572/750], Loss: 0.0382\n",
      "Epoch [1/10], Step [573/750], Loss: 0.1175\n",
      "Epoch [1/10], Step [574/750], Loss: 0.0353\n",
      "Epoch [1/10], Step [575/750], Loss: 0.0584\n",
      "Epoch [1/10], Step [576/750], Loss: 0.0621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [577/750], Loss: 0.1574\n",
      "Epoch [1/10], Step [578/750], Loss: 0.1119\n",
      "Epoch [1/10], Step [579/750], Loss: 0.1512\n",
      "Epoch [1/10], Step [580/750], Loss: 0.0580\n",
      "Epoch [1/10], Step [581/750], Loss: 0.1360\n",
      "Epoch [1/10], Step [582/750], Loss: 0.1305\n",
      "Epoch [1/10], Step [583/750], Loss: 0.0314\n",
      "Epoch [1/10], Step [584/750], Loss: 0.0624\n",
      "Epoch [1/10], Step [585/750], Loss: 0.1389\n",
      "Epoch [1/10], Step [586/750], Loss: 0.0356\n",
      "Epoch [1/10], Step [587/750], Loss: 0.0643\n",
      "Epoch [1/10], Step [588/750], Loss: 0.0331\n",
      "Epoch [1/10], Step [589/750], Loss: 0.0273\n",
      "Epoch [1/10], Step [590/750], Loss: 0.1479\n",
      "Epoch [1/10], Step [591/750], Loss: 0.0763\n",
      "Epoch [1/10], Step [592/750], Loss: 0.1529\n",
      "Epoch [1/10], Step [593/750], Loss: 0.0651\n",
      "Epoch [1/10], Step [594/750], Loss: 0.1108\n",
      "Epoch [1/10], Step [595/750], Loss: 0.0313\n",
      "Epoch [1/10], Step [596/750], Loss: 0.0906\n",
      "Epoch [1/10], Step [597/750], Loss: 0.0953\n",
      "Epoch [1/10], Step [598/750], Loss: 0.1456\n",
      "Epoch [1/10], Step [599/750], Loss: 0.0803\n",
      "Epoch [1/10], Step [600/750], Loss: 0.1624\n",
      "Epoch [1/10], Step [601/750], Loss: 0.0887\n",
      "Epoch [1/10], Step [602/750], Loss: 0.0250\n",
      "Epoch [1/10], Step [603/750], Loss: 0.0360\n",
      "Epoch [1/10], Step [604/750], Loss: 0.0157\n",
      "Epoch [1/10], Step [605/750], Loss: 0.1149\n",
      "Epoch [1/10], Step [606/750], Loss: 0.1300\n",
      "Epoch [1/10], Step [607/750], Loss: 0.0557\n",
      "Epoch [1/10], Step [608/750], Loss: 0.0681\n",
      "Epoch [1/10], Step [609/750], Loss: 0.0518\n",
      "Epoch [1/10], Step [610/750], Loss: 0.0395\n",
      "Epoch [1/10], Step [611/750], Loss: 0.1329\n",
      "Epoch [1/10], Step [612/750], Loss: 0.0989\n",
      "Epoch [1/10], Step [613/750], Loss: 0.0442\n",
      "Epoch [1/10], Step [614/750], Loss: 0.2114\n",
      "Epoch [1/10], Step [615/750], Loss: 0.0682\n",
      "Epoch [1/10], Step [616/750], Loss: 0.1275\n",
      "Epoch [1/10], Step [617/750], Loss: 0.0592\n",
      "Epoch [1/10], Step [618/750], Loss: 0.1204\n",
      "Epoch [1/10], Step [619/750], Loss: 0.0949\n",
      "Epoch [1/10], Step [620/750], Loss: 0.0220\n",
      "Epoch [1/10], Step [621/750], Loss: 0.0829\n",
      "Epoch [1/10], Step [622/750], Loss: 0.1841\n",
      "Epoch [1/10], Step [623/750], Loss: 0.1313\n",
      "Epoch [1/10], Step [624/750], Loss: 0.0568\n",
      "Epoch [1/10], Step [625/750], Loss: 0.0997\n",
      "Epoch [1/10], Step [626/750], Loss: 0.0775\n",
      "Epoch [1/10], Step [627/750], Loss: 0.0280\n",
      "Epoch [1/10], Step [628/750], Loss: 0.0749\n",
      "Epoch [1/10], Step [629/750], Loss: 0.0265\n",
      "Epoch [1/10], Step [630/750], Loss: 0.2106\n",
      "Epoch [1/10], Step [631/750], Loss: 0.0371\n",
      "Epoch [1/10], Step [632/750], Loss: 0.0676\n",
      "Epoch [1/10], Step [633/750], Loss: 0.1280\n",
      "Epoch [1/10], Step [634/750], Loss: 0.1106\n",
      "Epoch [1/10], Step [635/750], Loss: 0.1969\n",
      "Epoch [1/10], Step [636/750], Loss: 0.1275\n",
      "Epoch [1/10], Step [637/750], Loss: 0.1404\n",
      "Epoch [1/10], Step [638/750], Loss: 0.1349\n",
      "Epoch [1/10], Step [639/750], Loss: 0.0609\n",
      "Epoch [1/10], Step [640/750], Loss: 0.0410\n",
      "Epoch [1/10], Step [641/750], Loss: 0.1204\n",
      "Epoch [1/10], Step [642/750], Loss: 0.1117\n",
      "Epoch [1/10], Step [643/750], Loss: 0.1820\n",
      "Epoch [1/10], Step [644/750], Loss: 0.1881\n",
      "Epoch [1/10], Step [645/750], Loss: 0.0183\n",
      "Epoch [1/10], Step [646/750], Loss: 0.0701\n",
      "Epoch [1/10], Step [647/750], Loss: 0.0331\n",
      "Epoch [1/10], Step [648/750], Loss: 0.2360\n",
      "Epoch [1/10], Step [649/750], Loss: 0.0264\n",
      "Epoch [1/10], Step [650/750], Loss: 0.1504\n",
      "Epoch [1/10], Step [651/750], Loss: 0.0569\n",
      "Epoch [1/10], Step [652/750], Loss: 0.0600\n",
      "Epoch [1/10], Step [653/750], Loss: 0.1010\n",
      "Epoch [1/10], Step [654/750], Loss: 0.0708\n",
      "Epoch [1/10], Step [655/750], Loss: 0.1811\n",
      "Epoch [1/10], Step [656/750], Loss: 0.0677\n",
      "Epoch [1/10], Step [657/750], Loss: 0.1619\n",
      "Epoch [1/10], Step [658/750], Loss: 0.0681\n",
      "Epoch [1/10], Step [659/750], Loss: 0.2161\n",
      "Epoch [1/10], Step [660/750], Loss: 0.1097\n",
      "Epoch [1/10], Step [661/750], Loss: 0.2054\n",
      "Epoch [1/10], Step [662/750], Loss: 0.0941\n",
      "Epoch [1/10], Step [663/750], Loss: 0.1302\n",
      "Epoch [1/10], Step [664/750], Loss: 0.2336\n",
      "Epoch [1/10], Step [665/750], Loss: 0.0692\n",
      "Epoch [1/10], Step [666/750], Loss: 0.0755\n",
      "Epoch [1/10], Step [667/750], Loss: 0.1750\n",
      "Epoch [1/10], Step [668/750], Loss: 0.0800\n",
      "Epoch [1/10], Step [669/750], Loss: 0.1579\n",
      "Epoch [1/10], Step [670/750], Loss: 0.1553\n",
      "Epoch [1/10], Step [671/750], Loss: 0.1159\n",
      "Epoch [1/10], Step [672/750], Loss: 0.0862\n",
      "Epoch [1/10], Step [673/750], Loss: 0.1595\n",
      "Epoch [1/10], Step [674/750], Loss: 0.2187\n",
      "Epoch [1/10], Step [675/750], Loss: 0.0628\n",
      "Epoch [1/10], Step [676/750], Loss: 0.0853\n",
      "Epoch [1/10], Step [677/750], Loss: 0.0995\n",
      "Epoch [1/10], Step [678/750], Loss: 0.1075\n",
      "Epoch [1/10], Step [679/750], Loss: 0.1443\n",
      "Epoch [1/10], Step [680/750], Loss: 0.0433\n",
      "Epoch [1/10], Step [681/750], Loss: 0.2901\n",
      "Epoch [1/10], Step [682/750], Loss: 0.2167\n",
      "Epoch [1/10], Step [683/750], Loss: 0.1372\n",
      "Epoch [1/10], Step [684/750], Loss: 0.0917\n",
      "Epoch [1/10], Step [685/750], Loss: 0.0917\n",
      "Epoch [1/10], Step [686/750], Loss: 0.2154\n",
      "Epoch [1/10], Step [687/750], Loss: 0.2473\n",
      "Epoch [1/10], Step [688/750], Loss: 0.1402\n",
      "Epoch [1/10], Step [689/750], Loss: 0.0805\n",
      "Epoch [1/10], Step [690/750], Loss: 0.0845\n",
      "Epoch [1/10], Step [691/750], Loss: 0.0746\n",
      "Epoch [1/10], Step [692/750], Loss: 0.0459\n",
      "Epoch [1/10], Step [693/750], Loss: 0.0722\n",
      "Epoch [1/10], Step [694/750], Loss: 0.0607\n",
      "Epoch [1/10], Step [695/750], Loss: 0.3108\n",
      "Epoch [1/10], Step [696/750], Loss: 0.0444\n",
      "Epoch [1/10], Step [697/750], Loss: 0.0772\n",
      "Epoch [1/10], Step [698/750], Loss: 0.0381\n",
      "Epoch [1/10], Step [699/750], Loss: 0.0496\n",
      "Epoch [1/10], Step [700/750], Loss: 0.1012\n",
      "Epoch [1/10], Step [701/750], Loss: 0.1909\n",
      "Epoch [1/10], Step [702/750], Loss: 0.1339\n",
      "Epoch [1/10], Step [703/750], Loss: 0.0483\n",
      "Epoch [1/10], Step [704/750], Loss: 0.0723\n",
      "Epoch [1/10], Step [705/750], Loss: 0.0158\n",
      "Epoch [1/10], Step [706/750], Loss: 0.1615\n",
      "Epoch [1/10], Step [707/750], Loss: 0.0473\n",
      "Epoch [1/10], Step [708/750], Loss: 0.1752\n",
      "Epoch [1/10], Step [709/750], Loss: 0.0719\n",
      "Epoch [1/10], Step [710/750], Loss: 0.0631\n",
      "Epoch [1/10], Step [711/750], Loss: 0.0271\n",
      "Epoch [1/10], Step [712/750], Loss: 0.0830\n",
      "Epoch [1/10], Step [713/750], Loss: 0.0408\n",
      "Epoch [1/10], Step [714/750], Loss: 0.0641\n",
      "Epoch [1/10], Step [715/750], Loss: 0.0309\n",
      "Epoch [1/10], Step [716/750], Loss: 0.0757\n",
      "Epoch [1/10], Step [717/750], Loss: 0.1238\n",
      "Epoch [1/10], Step [718/750], Loss: 0.1165\n",
      "Epoch [1/10], Step [719/750], Loss: 0.1756\n",
      "Epoch [1/10], Step [720/750], Loss: 0.1380\n",
      "Epoch [1/10], Step [721/750], Loss: 0.0387\n",
      "Epoch [1/10], Step [722/750], Loss: 0.0666\n",
      "Epoch [1/10], Step [723/750], Loss: 0.0664\n",
      "Epoch [1/10], Step [724/750], Loss: 0.1693\n",
      "Epoch [1/10], Step [725/750], Loss: 0.1219\n",
      "Epoch [1/10], Step [726/750], Loss: 0.0334\n",
      "Epoch [1/10], Step [727/750], Loss: 0.1005\n",
      "Epoch [1/10], Step [728/750], Loss: 0.1009\n",
      "Epoch [1/10], Step [729/750], Loss: 0.1238\n",
      "Epoch [1/10], Step [730/750], Loss: 0.0592\n",
      "Epoch [1/10], Step [731/750], Loss: 0.0637\n",
      "Epoch [1/10], Step [732/750], Loss: 0.2350\n",
      "Epoch [1/10], Step [733/750], Loss: 0.1326\n",
      "Epoch [1/10], Step [734/750], Loss: 0.1216\n",
      "Epoch [1/10], Step [735/750], Loss: 0.1030\n",
      "Epoch [1/10], Step [736/750], Loss: 0.1417\n",
      "Epoch [1/10], Step [737/750], Loss: 0.1374\n",
      "Epoch [1/10], Step [738/750], Loss: 0.1851\n",
      "Epoch [1/10], Step [739/750], Loss: 0.1242\n",
      "Epoch [1/10], Step [740/750], Loss: 0.0688\n",
      "Epoch [1/10], Step [741/750], Loss: 0.0821\n",
      "Epoch [1/10], Step [742/750], Loss: 0.0439\n",
      "Epoch [1/10], Step [743/750], Loss: 0.0567\n",
      "Epoch [1/10], Step [744/750], Loss: 0.1092\n",
      "Epoch [1/10], Step [745/750], Loss: 0.0197\n",
      "Epoch [1/10], Step [746/750], Loss: 0.1464\n",
      "Epoch [1/10], Step [747/750], Loss: 0.1042\n",
      "Epoch [1/10], Step [748/750], Loss: 0.0454\n",
      "Epoch [1/10], Step [749/750], Loss: 0.1110\n",
      "Epoch [1/10], Step [750/750], Loss: 0.0968\n",
      "\n",
      "\n",
      "Epoch [2/10], Step [1/750], Loss: 0.0462\n",
      "Epoch [2/10], Step [2/750], Loss: 0.0857\n",
      "Epoch [2/10], Step [3/750], Loss: 0.0384\n",
      "Epoch [2/10], Step [4/750], Loss: 0.0446\n",
      "Epoch [2/10], Step [5/750], Loss: 0.0797\n",
      "Epoch [2/10], Step [6/750], Loss: 0.1373\n",
      "Epoch [2/10], Step [7/750], Loss: 0.0521\n",
      "Epoch [2/10], Step [8/750], Loss: 0.0552\n",
      "Epoch [2/10], Step [9/750], Loss: 0.1066\n",
      "Epoch [2/10], Step [10/750], Loss: 0.0766\n",
      "Epoch [2/10], Step [11/750], Loss: 0.1022\n",
      "Epoch [2/10], Step [12/750], Loss: 0.0381\n",
      "Epoch [2/10], Step [13/750], Loss: 0.0382\n",
      "Epoch [2/10], Step [14/750], Loss: 0.0569\n",
      "Epoch [2/10], Step [15/750], Loss: 0.1006\n",
      "Epoch [2/10], Step [16/750], Loss: 0.0284\n",
      "Epoch [2/10], Step [17/750], Loss: 0.0395\n",
      "Epoch [2/10], Step [18/750], Loss: 0.0976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [19/750], Loss: 0.0284\n",
      "Epoch [2/10], Step [20/750], Loss: 0.0707\n",
      "Epoch [2/10], Step [21/750], Loss: 0.0113\n",
      "Epoch [2/10], Step [22/750], Loss: 0.0348\n",
      "Epoch [2/10], Step [23/750], Loss: 0.0131\n",
      "Epoch [2/10], Step [24/750], Loss: 0.0340\n",
      "Epoch [2/10], Step [25/750], Loss: 0.0459\n",
      "Epoch [2/10], Step [26/750], Loss: 0.0124\n",
      "Epoch [2/10], Step [27/750], Loss: 0.0545\n",
      "Epoch [2/10], Step [28/750], Loss: 0.1441\n",
      "Epoch [2/10], Step [29/750], Loss: 0.0164\n",
      "Epoch [2/10], Step [30/750], Loss: 0.0260\n",
      "Epoch [2/10], Step [31/750], Loss: 0.0171\n",
      "Epoch [2/10], Step [32/750], Loss: 0.0743\n",
      "Epoch [2/10], Step [33/750], Loss: 0.0646\n",
      "Epoch [2/10], Step [34/750], Loss: 0.0881\n",
      "Epoch [2/10], Step [35/750], Loss: 0.0914\n",
      "Epoch [2/10], Step [36/750], Loss: 0.0236\n",
      "Epoch [2/10], Step [37/750], Loss: 0.0819\n",
      "Epoch [2/10], Step [38/750], Loss: 0.1095\n",
      "Epoch [2/10], Step [39/750], Loss: 0.1014\n",
      "Epoch [2/10], Step [40/750], Loss: 0.1380\n",
      "Epoch [2/10], Step [41/750], Loss: 0.1032\n",
      "Epoch [2/10], Step [42/750], Loss: 0.0734\n",
      "Epoch [2/10], Step [43/750], Loss: 0.0268\n",
      "Epoch [2/10], Step [44/750], Loss: 0.0741\n",
      "Epoch [2/10], Step [45/750], Loss: 0.0979\n",
      "Epoch [2/10], Step [46/750], Loss: 0.0823\n",
      "Epoch [2/10], Step [47/750], Loss: 0.0199\n",
      "Epoch [2/10], Step [48/750], Loss: 0.0182\n",
      "Epoch [2/10], Step [49/750], Loss: 0.0526\n",
      "Epoch [2/10], Step [50/750], Loss: 0.0868\n",
      "Epoch [2/10], Step [51/750], Loss: 0.0409\n",
      "Epoch [2/10], Step [52/750], Loss: 0.0692\n",
      "Epoch [2/10], Step [53/750], Loss: 0.0227\n",
      "Epoch [2/10], Step [54/750], Loss: 0.1167\n",
      "Epoch [2/10], Step [55/750], Loss: 0.0545\n",
      "Epoch [2/10], Step [56/750], Loss: 0.0111\n",
      "Epoch [2/10], Step [57/750], Loss: 0.0253\n",
      "Epoch [2/10], Step [58/750], Loss: 0.0921\n",
      "Epoch [2/10], Step [59/750], Loss: 0.0239\n",
      "Epoch [2/10], Step [60/750], Loss: 0.0295\n",
      "Epoch [2/10], Step [61/750], Loss: 0.1340\n",
      "Epoch [2/10], Step [62/750], Loss: 0.0649\n",
      "Epoch [2/10], Step [63/750], Loss: 0.0255\n",
      "Epoch [2/10], Step [64/750], Loss: 0.0492\n",
      "Epoch [2/10], Step [65/750], Loss: 0.0546\n",
      "Epoch [2/10], Step [66/750], Loss: 0.0490\n",
      "Epoch [2/10], Step [67/750], Loss: 0.0762\n",
      "Epoch [2/10], Step [68/750], Loss: 0.1029\n",
      "Epoch [2/10], Step [69/750], Loss: 0.0379\n",
      "Epoch [2/10], Step [70/750], Loss: 0.0237\n",
      "Epoch [2/10], Step [71/750], Loss: 0.0812\n",
      "Epoch [2/10], Step [72/750], Loss: 0.0896\n",
      "Epoch [2/10], Step [73/750], Loss: 0.0445\n",
      "Epoch [2/10], Step [74/750], Loss: 0.0334\n",
      "Epoch [2/10], Step [75/750], Loss: 0.0410\n",
      "Epoch [2/10], Step [76/750], Loss: 0.0808\n",
      "Epoch [2/10], Step [77/750], Loss: 0.1184\n",
      "Epoch [2/10], Step [78/750], Loss: 0.1109\n",
      "Epoch [2/10], Step [79/750], Loss: 0.0414\n",
      "Epoch [2/10], Step [80/750], Loss: 0.0317\n",
      "Epoch [2/10], Step [81/750], Loss: 0.0954\n",
      "Epoch [2/10], Step [82/750], Loss: 0.1631\n",
      "Epoch [2/10], Step [83/750], Loss: 0.1516\n",
      "Epoch [2/10], Step [84/750], Loss: 0.0281\n",
      "Epoch [2/10], Step [85/750], Loss: 0.0784\n",
      "Epoch [2/10], Step [86/750], Loss: 0.0888\n",
      "Epoch [2/10], Step [87/750], Loss: 0.0565\n",
      "Epoch [2/10], Step [88/750], Loss: 0.1417\n",
      "Epoch [2/10], Step [89/750], Loss: 0.0687\n",
      "Epoch [2/10], Step [90/750], Loss: 0.0314\n",
      "Epoch [2/10], Step [91/750], Loss: 0.0898\n",
      "Epoch [2/10], Step [92/750], Loss: 0.0801\n",
      "Epoch [2/10], Step [93/750], Loss: 0.0828\n",
      "Epoch [2/10], Step [94/750], Loss: 0.0555\n",
      "Epoch [2/10], Step [95/750], Loss: 0.0320\n",
      "Epoch [2/10], Step [96/750], Loss: 0.0446\n",
      "Epoch [2/10], Step [97/750], Loss: 0.0830\n",
      "Epoch [2/10], Step [98/750], Loss: 0.1109\n",
      "Epoch [2/10], Step [99/750], Loss: 0.1103\n",
      "Epoch [2/10], Step [100/750], Loss: 0.0078\n",
      "Epoch [2/10], Step [101/750], Loss: 0.0769\n",
      "Epoch [2/10], Step [102/750], Loss: 0.1521\n",
      "Epoch [2/10], Step [103/750], Loss: 0.0883\n",
      "Epoch [2/10], Step [104/750], Loss: 0.0866\n",
      "Epoch [2/10], Step [105/750], Loss: 0.0778\n",
      "Epoch [2/10], Step [106/750], Loss: 0.0634\n",
      "Epoch [2/10], Step [107/750], Loss: 0.1001\n",
      "Epoch [2/10], Step [108/750], Loss: 0.0999\n",
      "Epoch [2/10], Step [109/750], Loss: 0.0968\n",
      "Epoch [2/10], Step [110/750], Loss: 0.1223\n",
      "Epoch [2/10], Step [111/750], Loss: 0.0739\n",
      "Epoch [2/10], Step [112/750], Loss: 0.0736\n",
      "Epoch [2/10], Step [113/750], Loss: 0.0489\n",
      "Epoch [2/10], Step [114/750], Loss: 0.0217\n",
      "Epoch [2/10], Step [115/750], Loss: 0.1024\n",
      "Epoch [2/10], Step [116/750], Loss: 0.0520\n",
      "Epoch [2/10], Step [117/750], Loss: 0.1129\n",
      "Epoch [2/10], Step [118/750], Loss: 0.0744\n",
      "Epoch [2/10], Step [119/750], Loss: 0.0799\n",
      "Epoch [2/10], Step [120/750], Loss: 0.1847\n",
      "Epoch [2/10], Step [121/750], Loss: 0.1533\n",
      "Epoch [2/10], Step [122/750], Loss: 0.0826\n",
      "Epoch [2/10], Step [123/750], Loss: 0.0226\n",
      "Epoch [2/10], Step [124/750], Loss: 0.0776\n",
      "Epoch [2/10], Step [125/750], Loss: 0.0224\n",
      "Epoch [2/10], Step [126/750], Loss: 0.0860\n",
      "Epoch [2/10], Step [127/750], Loss: 0.0339\n",
      "Epoch [2/10], Step [128/750], Loss: 0.0466\n",
      "Epoch [2/10], Step [129/750], Loss: 0.0366\n",
      "Epoch [2/10], Step [130/750], Loss: 0.0204\n",
      "Epoch [2/10], Step [131/750], Loss: 0.0440\n",
      "Epoch [2/10], Step [132/750], Loss: 0.0282\n",
      "Epoch [2/10], Step [133/750], Loss: 0.0364\n",
      "Epoch [2/10], Step [134/750], Loss: 0.0333\n",
      "Epoch [2/10], Step [135/750], Loss: 0.0803\n",
      "Epoch [2/10], Step [136/750], Loss: 0.0441\n",
      "Epoch [2/10], Step [137/750], Loss: 0.0115\n",
      "Epoch [2/10], Step [138/750], Loss: 0.0257\n",
      "Epoch [2/10], Step [139/750], Loss: 0.1014\n",
      "Epoch [2/10], Step [140/750], Loss: 0.0930\n",
      "Epoch [2/10], Step [141/750], Loss: 0.0780\n",
      "Epoch [2/10], Step [142/750], Loss: 0.0608\n",
      "Epoch [2/10], Step [143/750], Loss: 0.0655\n",
      "Epoch [2/10], Step [144/750], Loss: 0.0386\n",
      "Epoch [2/10], Step [145/750], Loss: 0.0196\n",
      "Epoch [2/10], Step [146/750], Loss: 0.0397\n",
      "Epoch [2/10], Step [147/750], Loss: 0.0623\n",
      "Epoch [2/10], Step [148/750], Loss: 0.0506\n",
      "Epoch [2/10], Step [149/750], Loss: 0.0418\n",
      "Epoch [2/10], Step [150/750], Loss: 0.1885\n",
      "Epoch [2/10], Step [151/750], Loss: 0.0170\n",
      "Epoch [2/10], Step [152/750], Loss: 0.0250\n",
      "Epoch [2/10], Step [153/750], Loss: 0.1285\n",
      "Epoch [2/10], Step [154/750], Loss: 0.0215\n",
      "Epoch [2/10], Step [155/750], Loss: 0.0158\n",
      "Epoch [2/10], Step [156/750], Loss: 0.0410\n",
      "Epoch [2/10], Step [157/750], Loss: 0.1122\n",
      "Epoch [2/10], Step [158/750], Loss: 0.0233\n",
      "Epoch [2/10], Step [159/750], Loss: 0.0844\n",
      "Epoch [2/10], Step [160/750], Loss: 0.0763\n",
      "Epoch [2/10], Step [161/750], Loss: 0.0639\n",
      "Epoch [2/10], Step [162/750], Loss: 0.0825\n",
      "Epoch [2/10], Step [163/750], Loss: 0.0656\n",
      "Epoch [2/10], Step [164/750], Loss: 0.0931\n",
      "Epoch [2/10], Step [165/750], Loss: 0.0360\n",
      "Epoch [2/10], Step [166/750], Loss: 0.1206\n",
      "Epoch [2/10], Step [167/750], Loss: 0.0646\n",
      "Epoch [2/10], Step [168/750], Loss: 0.1292\n",
      "Epoch [2/10], Step [169/750], Loss: 0.0831\n",
      "Epoch [2/10], Step [170/750], Loss: 0.0531\n",
      "Epoch [2/10], Step [171/750], Loss: 0.1784\n",
      "Epoch [2/10], Step [172/750], Loss: 0.0761\n",
      "Epoch [2/10], Step [173/750], Loss: 0.0734\n",
      "Epoch [2/10], Step [174/750], Loss: 0.0309\n",
      "Epoch [2/10], Step [175/750], Loss: 0.2177\n",
      "Epoch [2/10], Step [176/750], Loss: 0.0323\n",
      "Epoch [2/10], Step [177/750], Loss: 0.1084\n",
      "Epoch [2/10], Step [178/750], Loss: 0.1648\n",
      "Epoch [2/10], Step [179/750], Loss: 0.1193\n",
      "Epoch [2/10], Step [180/750], Loss: 0.0541\n",
      "Epoch [2/10], Step [181/750], Loss: 0.0370\n",
      "Epoch [2/10], Step [182/750], Loss: 0.0994\n",
      "Epoch [2/10], Step [183/750], Loss: 0.0418\n",
      "Epoch [2/10], Step [184/750], Loss: 0.0343\n",
      "Epoch [2/10], Step [185/750], Loss: 0.0851\n",
      "Epoch [2/10], Step [186/750], Loss: 0.0984\n",
      "Epoch [2/10], Step [187/750], Loss: 0.0795\n",
      "Epoch [2/10], Step [188/750], Loss: 0.0637\n",
      "Epoch [2/10], Step [189/750], Loss: 0.0600\n",
      "Epoch [2/10], Step [190/750], Loss: 0.0568\n",
      "Epoch [2/10], Step [191/750], Loss: 0.1254\n",
      "Epoch [2/10], Step [192/750], Loss: 0.0857\n",
      "Epoch [2/10], Step [193/750], Loss: 0.0658\n",
      "Epoch [2/10], Step [194/750], Loss: 0.0201\n",
      "Epoch [2/10], Step [195/750], Loss: 0.0483\n",
      "Epoch [2/10], Step [196/750], Loss: 0.0360\n",
      "Epoch [2/10], Step [197/750], Loss: 0.0849\n",
      "Epoch [2/10], Step [198/750], Loss: 0.2102\n",
      "Epoch [2/10], Step [199/750], Loss: 0.0764\n",
      "Epoch [2/10], Step [200/750], Loss: 0.0782\n",
      "Epoch [2/10], Step [201/750], Loss: 0.0279\n",
      "Epoch [2/10], Step [202/750], Loss: 0.0567\n",
      "Epoch [2/10], Step [203/750], Loss: 0.0256\n",
      "Epoch [2/10], Step [204/750], Loss: 0.0534\n",
      "Epoch [2/10], Step [205/750], Loss: 0.0542\n",
      "Epoch [2/10], Step [206/750], Loss: 0.0684\n",
      "Epoch [2/10], Step [207/750], Loss: 0.0492\n",
      "Epoch [2/10], Step [208/750], Loss: 0.0810\n",
      "Epoch [2/10], Step [209/750], Loss: 0.0809\n",
      "Epoch [2/10], Step [210/750], Loss: 0.1182\n",
      "Epoch [2/10], Step [211/750], Loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [212/750], Loss: 0.0371\n",
      "Epoch [2/10], Step [213/750], Loss: 0.0839\n",
      "Epoch [2/10], Step [214/750], Loss: 0.0346\n",
      "Epoch [2/10], Step [215/750], Loss: 0.0601\n",
      "Epoch [2/10], Step [216/750], Loss: 0.1781\n",
      "Epoch [2/10], Step [217/750], Loss: 0.1713\n",
      "Epoch [2/10], Step [218/750], Loss: 0.0855\n",
      "Epoch [2/10], Step [219/750], Loss: 0.2684\n",
      "Epoch [2/10], Step [220/750], Loss: 0.1751\n",
      "Epoch [2/10], Step [221/750], Loss: 0.1590\n",
      "Epoch [2/10], Step [222/750], Loss: 0.0778\n",
      "Epoch [2/10], Step [223/750], Loss: 0.1092\n",
      "Epoch [2/10], Step [224/750], Loss: 0.0626\n",
      "Epoch [2/10], Step [225/750], Loss: 0.1735\n",
      "Epoch [2/10], Step [226/750], Loss: 0.0817\n",
      "Epoch [2/10], Step [227/750], Loss: 0.1032\n",
      "Epoch [2/10], Step [228/750], Loss: 0.0970\n",
      "Epoch [2/10], Step [229/750], Loss: 0.1011\n",
      "Epoch [2/10], Step [230/750], Loss: 0.1151\n",
      "Epoch [2/10], Step [231/750], Loss: 0.0606\n",
      "Epoch [2/10], Step [232/750], Loss: 0.0735\n",
      "Epoch [2/10], Step [233/750], Loss: 0.1021\n",
      "Epoch [2/10], Step [234/750], Loss: 0.0422\n",
      "Epoch [2/10], Step [235/750], Loss: 0.0297\n",
      "Epoch [2/10], Step [236/750], Loss: 0.0596\n",
      "Epoch [2/10], Step [237/750], Loss: 0.0412\n",
      "Epoch [2/10], Step [238/750], Loss: 0.0932\n",
      "Epoch [2/10], Step [239/750], Loss: 0.2288\n",
      "Epoch [2/10], Step [240/750], Loss: 0.0934\n",
      "Epoch [2/10], Step [241/750], Loss: 0.0238\n",
      "Epoch [2/10], Step [242/750], Loss: 0.0470\n",
      "Epoch [2/10], Step [243/750], Loss: 0.0599\n",
      "Epoch [2/10], Step [244/750], Loss: 0.0862\n",
      "Epoch [2/10], Step [245/750], Loss: 0.0084\n",
      "Epoch [2/10], Step [246/750], Loss: 0.0471\n",
      "Epoch [2/10], Step [247/750], Loss: 0.1466\n",
      "Epoch [2/10], Step [248/750], Loss: 0.0423\n",
      "Epoch [2/10], Step [249/750], Loss: 0.0618\n",
      "Epoch [2/10], Step [250/750], Loss: 0.0522\n",
      "Epoch [2/10], Step [251/750], Loss: 0.0441\n",
      "Epoch [2/10], Step [252/750], Loss: 0.0449\n",
      "Epoch [2/10], Step [253/750], Loss: 0.0991\n",
      "Epoch [2/10], Step [254/750], Loss: 0.0871\n",
      "Epoch [2/10], Step [255/750], Loss: 0.0813\n",
      "Epoch [2/10], Step [256/750], Loss: 0.0369\n",
      "Epoch [2/10], Step [257/750], Loss: 0.0441\n",
      "Epoch [2/10], Step [258/750], Loss: 0.0091\n",
      "Epoch [2/10], Step [259/750], Loss: 0.1023\n",
      "Epoch [2/10], Step [260/750], Loss: 0.0108\n",
      "Epoch [2/10], Step [261/750], Loss: 0.0865\n",
      "Epoch [2/10], Step [262/750], Loss: 0.0676\n",
      "Epoch [2/10], Step [263/750], Loss: 0.0716\n",
      "Epoch [2/10], Step [264/750], Loss: 0.0340\n",
      "Epoch [2/10], Step [265/750], Loss: 0.3018\n",
      "Epoch [2/10], Step [266/750], Loss: 0.0344\n",
      "Epoch [2/10], Step [267/750], Loss: 0.0755\n",
      "Epoch [2/10], Step [268/750], Loss: 0.1290\n",
      "Epoch [2/10], Step [269/750], Loss: 0.0554\n",
      "Epoch [2/10], Step [270/750], Loss: 0.0729\n",
      "Epoch [2/10], Step [271/750], Loss: 0.1019\n",
      "Epoch [2/10], Step [272/750], Loss: 0.1146\n",
      "Epoch [2/10], Step [273/750], Loss: 0.1059\n",
      "Epoch [2/10], Step [274/750], Loss: 0.0625\n",
      "Epoch [2/10], Step [275/750], Loss: 0.0279\n",
      "Epoch [2/10], Step [276/750], Loss: 0.0262\n",
      "Epoch [2/10], Step [277/750], Loss: 0.0531\n",
      "Epoch [2/10], Step [278/750], Loss: 0.0692\n",
      "Epoch [2/10], Step [279/750], Loss: 0.0617\n",
      "Epoch [2/10], Step [280/750], Loss: 0.0523\n",
      "Epoch [2/10], Step [281/750], Loss: 0.1588\n",
      "Epoch [2/10], Step [282/750], Loss: 0.0216\n",
      "Epoch [2/10], Step [283/750], Loss: 0.0906\n",
      "Epoch [2/10], Step [284/750], Loss: 0.0137\n",
      "Epoch [2/10], Step [285/750], Loss: 0.0618\n",
      "Epoch [2/10], Step [286/750], Loss: 0.0204\n",
      "Epoch [2/10], Step [287/750], Loss: 0.0121\n",
      "Epoch [2/10], Step [288/750], Loss: 0.0353\n",
      "Epoch [2/10], Step [289/750], Loss: 0.0229\n",
      "Epoch [2/10], Step [290/750], Loss: 0.1737\n",
      "Epoch [2/10], Step [291/750], Loss: 0.0750\n",
      "Epoch [2/10], Step [292/750], Loss: 0.0473\n",
      "Epoch [2/10], Step [293/750], Loss: 0.0873\n",
      "Epoch [2/10], Step [294/750], Loss: 0.0532\n",
      "Epoch [2/10], Step [295/750], Loss: 0.0425\n",
      "Epoch [2/10], Step [296/750], Loss: 0.0271\n",
      "Epoch [2/10], Step [297/750], Loss: 0.0447\n",
      "Epoch [2/10], Step [298/750], Loss: 0.1209\n",
      "Epoch [2/10], Step [299/750], Loss: 0.1416\n",
      "Epoch [2/10], Step [300/750], Loss: 0.1052\n",
      "Epoch [2/10], Step [301/750], Loss: 0.0340\n",
      "Epoch [2/10], Step [302/750], Loss: 0.0469\n",
      "Epoch [2/10], Step [303/750], Loss: 0.0550\n",
      "Epoch [2/10], Step [304/750], Loss: 0.0634\n",
      "Epoch [2/10], Step [305/750], Loss: 0.0938\n",
      "Epoch [2/10], Step [306/750], Loss: 0.0197\n",
      "Epoch [2/10], Step [307/750], Loss: 0.1696\n",
      "Epoch [2/10], Step [308/750], Loss: 0.1690\n",
      "Epoch [2/10], Step [309/750], Loss: 0.1292\n",
      "Epoch [2/10], Step [310/750], Loss: 0.0756\n",
      "Epoch [2/10], Step [311/750], Loss: 0.0454\n",
      "Epoch [2/10], Step [312/750], Loss: 0.1498\n",
      "Epoch [2/10], Step [313/750], Loss: 0.0273\n",
      "Epoch [2/10], Step [314/750], Loss: 0.1015\n",
      "Epoch [2/10], Step [315/750], Loss: 0.0479\n",
      "Epoch [2/10], Step [316/750], Loss: 0.0614\n",
      "Epoch [2/10], Step [317/750], Loss: 0.1332\n",
      "Epoch [2/10], Step [318/750], Loss: 0.0260\n",
      "Epoch [2/10], Step [319/750], Loss: 0.0723\n",
      "Epoch [2/10], Step [320/750], Loss: 0.1197\n",
      "Epoch [2/10], Step [321/750], Loss: 0.0105\n",
      "Epoch [2/10], Step [322/750], Loss: 0.0209\n",
      "Epoch [2/10], Step [323/750], Loss: 0.0655\n",
      "Epoch [2/10], Step [324/750], Loss: 0.0265\n",
      "Epoch [2/10], Step [325/750], Loss: 0.0245\n",
      "Epoch [2/10], Step [326/750], Loss: 0.0440\n",
      "Epoch [2/10], Step [327/750], Loss: 0.0416\n",
      "Epoch [2/10], Step [328/750], Loss: 0.0262\n",
      "Epoch [2/10], Step [329/750], Loss: 0.0524\n",
      "Epoch [2/10], Step [330/750], Loss: 0.0908\n",
      "Epoch [2/10], Step [331/750], Loss: 0.1176\n",
      "Epoch [2/10], Step [332/750], Loss: 0.0518\n",
      "Epoch [2/10], Step [333/750], Loss: 0.0634\n",
      "Epoch [2/10], Step [334/750], Loss: 0.0619\n",
      "Epoch [2/10], Step [335/750], Loss: 0.0726\n",
      "Epoch [2/10], Step [336/750], Loss: 0.0547\n",
      "Epoch [2/10], Step [337/750], Loss: 0.0060\n",
      "Epoch [2/10], Step [338/750], Loss: 0.0658\n",
      "Epoch [2/10], Step [339/750], Loss: 0.0827\n",
      "Epoch [2/10], Step [340/750], Loss: 0.0581\n",
      "Epoch [2/10], Step [341/750], Loss: 0.0581\n",
      "Epoch [2/10], Step [342/750], Loss: 0.0076\n",
      "Epoch [2/10], Step [343/750], Loss: 0.0116\n",
      "Epoch [2/10], Step [344/750], Loss: 0.1166\n",
      "Epoch [2/10], Step [345/750], Loss: 0.0946\n",
      "Epoch [2/10], Step [346/750], Loss: 0.0677\n",
      "Epoch [2/10], Step [347/750], Loss: 0.1219\n",
      "Epoch [2/10], Step [348/750], Loss: 0.0195\n",
      "Epoch [2/10], Step [349/750], Loss: 0.2153\n",
      "Epoch [2/10], Step [350/750], Loss: 0.0916\n",
      "Epoch [2/10], Step [351/750], Loss: 0.1058\n",
      "Epoch [2/10], Step [352/750], Loss: 0.0534\n",
      "Epoch [2/10], Step [353/750], Loss: 0.0341\n",
      "Epoch [2/10], Step [354/750], Loss: 0.0706\n",
      "Epoch [2/10], Step [355/750], Loss: 0.2488\n",
      "Epoch [2/10], Step [356/750], Loss: 0.0733\n",
      "Epoch [2/10], Step [357/750], Loss: 0.1680\n",
      "Epoch [2/10], Step [358/750], Loss: 0.2393\n",
      "Epoch [2/10], Step [359/750], Loss: 0.0471\n",
      "Epoch [2/10], Step [360/750], Loss: 0.0450\n",
      "Epoch [2/10], Step [361/750], Loss: 0.0770\n",
      "Epoch [2/10], Step [362/750], Loss: 0.0753\n",
      "Epoch [2/10], Step [363/750], Loss: 0.0571\n",
      "Epoch [2/10], Step [364/750], Loss: 0.1031\n",
      "Epoch [2/10], Step [365/750], Loss: 0.1312\n",
      "Epoch [2/10], Step [366/750], Loss: 0.0215\n",
      "Epoch [2/10], Step [367/750], Loss: 0.0702\n",
      "Epoch [2/10], Step [368/750], Loss: 0.1786\n",
      "Epoch [2/10], Step [369/750], Loss: 0.0868\n",
      "Epoch [2/10], Step [370/750], Loss: 0.0879\n",
      "Epoch [2/10], Step [371/750], Loss: 0.1233\n",
      "Epoch [2/10], Step [372/750], Loss: 0.0274\n",
      "Epoch [2/10], Step [373/750], Loss: 0.1033\n",
      "Epoch [2/10], Step [374/750], Loss: 0.1445\n",
      "Epoch [2/10], Step [375/750], Loss: 0.0381\n",
      "Epoch [2/10], Step [376/750], Loss: 0.1370\n",
      "Epoch [2/10], Step [377/750], Loss: 0.0146\n",
      "Epoch [2/10], Step [378/750], Loss: 0.0358\n",
      "Epoch [2/10], Step [379/750], Loss: 0.0666\n",
      "Epoch [2/10], Step [380/750], Loss: 0.0239\n",
      "Epoch [2/10], Step [381/750], Loss: 0.0319\n",
      "Epoch [2/10], Step [382/750], Loss: 0.0245\n",
      "Epoch [2/10], Step [383/750], Loss: 0.1077\n",
      "Epoch [2/10], Step [384/750], Loss: 0.1440\n",
      "Epoch [2/10], Step [385/750], Loss: 0.0273\n",
      "Epoch [2/10], Step [386/750], Loss: 0.1796\n",
      "Epoch [2/10], Step [387/750], Loss: 0.0130\n",
      "Epoch [2/10], Step [388/750], Loss: 0.2581\n",
      "Epoch [2/10], Step [389/750], Loss: 0.0491\n",
      "Epoch [2/10], Step [390/750], Loss: 0.0576\n",
      "Epoch [2/10], Step [391/750], Loss: 0.0137\n",
      "Epoch [2/10], Step [392/750], Loss: 0.0406\n",
      "Epoch [2/10], Step [393/750], Loss: 0.1173\n",
      "Epoch [2/10], Step [394/750], Loss: 0.1121\n",
      "Epoch [2/10], Step [395/750], Loss: 0.1161\n",
      "Epoch [2/10], Step [396/750], Loss: 0.0807\n",
      "Epoch [2/10], Step [397/750], Loss: 0.0283\n",
      "Epoch [2/10], Step [398/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [399/750], Loss: 0.0560\n",
      "Epoch [2/10], Step [400/750], Loss: 0.1024\n",
      "Epoch [2/10], Step [401/750], Loss: 0.1171\n",
      "Epoch [2/10], Step [402/750], Loss: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [403/750], Loss: 0.1167\n",
      "Epoch [2/10], Step [404/750], Loss: 0.0840\n",
      "Epoch [2/10], Step [405/750], Loss: 0.1230\n",
      "Epoch [2/10], Step [406/750], Loss: 0.0850\n",
      "Epoch [2/10], Step [407/750], Loss: 0.1157\n",
      "Epoch [2/10], Step [408/750], Loss: 0.0274\n",
      "Epoch [2/10], Step [409/750], Loss: 0.0793\n",
      "Epoch [2/10], Step [410/750], Loss: 0.0908\n",
      "Epoch [2/10], Step [411/750], Loss: 0.0640\n",
      "Epoch [2/10], Step [412/750], Loss: 0.0553\n",
      "Epoch [2/10], Step [413/750], Loss: 0.0303\n",
      "Epoch [2/10], Step [414/750], Loss: 0.0172\n",
      "Epoch [2/10], Step [415/750], Loss: 0.0507\n",
      "Epoch [2/10], Step [416/750], Loss: 0.0135\n",
      "Epoch [2/10], Step [417/750], Loss: 0.0928\n",
      "Epoch [2/10], Step [418/750], Loss: 0.0468\n",
      "Epoch [2/10], Step [419/750], Loss: 0.1086\n",
      "Epoch [2/10], Step [420/750], Loss: 0.0960\n",
      "Epoch [2/10], Step [421/750], Loss: 0.0397\n",
      "Epoch [2/10], Step [422/750], Loss: 0.0519\n",
      "Epoch [2/10], Step [423/750], Loss: 0.1006\n",
      "Epoch [2/10], Step [424/750], Loss: 0.0320\n",
      "Epoch [2/10], Step [425/750], Loss: 0.0756\n",
      "Epoch [2/10], Step [426/750], Loss: 0.0493\n",
      "Epoch [2/10], Step [427/750], Loss: 0.0454\n",
      "Epoch [2/10], Step [428/750], Loss: 0.1227\n",
      "Epoch [2/10], Step [429/750], Loss: 0.0384\n",
      "Epoch [2/10], Step [430/750], Loss: 0.2040\n",
      "Epoch [2/10], Step [431/750], Loss: 0.1571\n",
      "Epoch [2/10], Step [432/750], Loss: 0.0841\n",
      "Epoch [2/10], Step [433/750], Loss: 0.0858\n",
      "Epoch [2/10], Step [434/750], Loss: 0.0082\n",
      "Epoch [2/10], Step [435/750], Loss: 0.0409\n",
      "Epoch [2/10], Step [436/750], Loss: 0.1782\n",
      "Epoch [2/10], Step [437/750], Loss: 0.1373\n",
      "Epoch [2/10], Step [438/750], Loss: 0.0269\n",
      "Epoch [2/10], Step [439/750], Loss: 0.0314\n",
      "Epoch [2/10], Step [440/750], Loss: 0.0734\n",
      "Epoch [2/10], Step [441/750], Loss: 0.0186\n",
      "Epoch [2/10], Step [442/750], Loss: 0.1022\n",
      "Epoch [2/10], Step [443/750], Loss: 0.0652\n",
      "Epoch [2/10], Step [444/750], Loss: 0.1856\n",
      "Epoch [2/10], Step [445/750], Loss: 0.0624\n",
      "Epoch [2/10], Step [446/750], Loss: 0.0564\n",
      "Epoch [2/10], Step [447/750], Loss: 0.0885\n",
      "Epoch [2/10], Step [448/750], Loss: 0.1288\n",
      "Epoch [2/10], Step [449/750], Loss: 0.0762\n",
      "Epoch [2/10], Step [450/750], Loss: 0.1332\n",
      "Epoch [2/10], Step [451/750], Loss: 0.0965\n",
      "Epoch [2/10], Step [452/750], Loss: 0.1360\n",
      "Epoch [2/10], Step [453/750], Loss: 0.1424\n",
      "Epoch [2/10], Step [454/750], Loss: 0.2022\n",
      "Epoch [2/10], Step [455/750], Loss: 0.0764\n",
      "Epoch [2/10], Step [456/750], Loss: 0.0983\n",
      "Epoch [2/10], Step [457/750], Loss: 0.0998\n",
      "Epoch [2/10], Step [458/750], Loss: 0.0636\n",
      "Epoch [2/10], Step [459/750], Loss: 0.0615\n",
      "Epoch [2/10], Step [460/750], Loss: 0.0349\n",
      "Epoch [2/10], Step [461/750], Loss: 0.0691\n",
      "Epoch [2/10], Step [462/750], Loss: 0.0189\n",
      "Epoch [2/10], Step [463/750], Loss: 0.1034\n",
      "Epoch [2/10], Step [464/750], Loss: 0.0316\n",
      "Epoch [2/10], Step [465/750], Loss: 0.1335\n",
      "Epoch [2/10], Step [466/750], Loss: 0.0209\n",
      "Epoch [2/10], Step [467/750], Loss: 0.0355\n",
      "Epoch [2/10], Step [468/750], Loss: 0.1002\n",
      "Epoch [2/10], Step [469/750], Loss: 0.1219\n",
      "Epoch [2/10], Step [470/750], Loss: 0.0852\n",
      "Epoch [2/10], Step [471/750], Loss: 0.2119\n",
      "Epoch [2/10], Step [472/750], Loss: 0.0148\n",
      "Epoch [2/10], Step [473/750], Loss: 0.2528\n",
      "Epoch [2/10], Step [474/750], Loss: 0.0406\n",
      "Epoch [2/10], Step [475/750], Loss: 0.0441\n",
      "Epoch [2/10], Step [476/750], Loss: 0.0700\n",
      "Epoch [2/10], Step [477/750], Loss: 0.0101\n",
      "Epoch [2/10], Step [478/750], Loss: 0.0570\n",
      "Epoch [2/10], Step [479/750], Loss: 0.0461\n",
      "Epoch [2/10], Step [480/750], Loss: 0.0710\n",
      "Epoch [2/10], Step [481/750], Loss: 0.1375\n",
      "Epoch [2/10], Step [482/750], Loss: 0.0281\n",
      "Epoch [2/10], Step [483/750], Loss: 0.0432\n",
      "Epoch [2/10], Step [484/750], Loss: 0.0527\n",
      "Epoch [2/10], Step [485/750], Loss: 0.0383\n",
      "Epoch [2/10], Step [486/750], Loss: 0.0529\n",
      "Epoch [2/10], Step [487/750], Loss: 0.1295\n",
      "Epoch [2/10], Step [488/750], Loss: 0.2083\n",
      "Epoch [2/10], Step [489/750], Loss: 0.0497\n",
      "Epoch [2/10], Step [490/750], Loss: 0.0266\n",
      "Epoch [2/10], Step [491/750], Loss: 0.0862\n",
      "Epoch [2/10], Step [492/750], Loss: 0.0782\n",
      "Epoch [2/10], Step [493/750], Loss: 0.0433\n",
      "Epoch [2/10], Step [494/750], Loss: 0.0522\n",
      "Epoch [2/10], Step [495/750], Loss: 0.0709\n",
      "Epoch [2/10], Step [496/750], Loss: 0.0914\n",
      "Epoch [2/10], Step [497/750], Loss: 0.0399\n",
      "Epoch [2/10], Step [498/750], Loss: 0.1095\n",
      "Epoch [2/10], Step [499/750], Loss: 0.0826\n",
      "Epoch [2/10], Step [500/750], Loss: 0.1186\n",
      "Epoch [2/10], Step [501/750], Loss: 0.1226\n",
      "Epoch [2/10], Step [502/750], Loss: 0.0475\n",
      "Epoch [2/10], Step [503/750], Loss: 0.0613\n",
      "Epoch [2/10], Step [504/750], Loss: 0.0067\n",
      "Epoch [2/10], Step [505/750], Loss: 0.0274\n",
      "Epoch [2/10], Step [506/750], Loss: 0.0744\n",
      "Epoch [2/10], Step [507/750], Loss: 0.0359\n",
      "Epoch [2/10], Step [508/750], Loss: 0.0154\n",
      "Epoch [2/10], Step [509/750], Loss: 0.1036\n",
      "Epoch [2/10], Step [510/750], Loss: 0.1341\n",
      "Epoch [2/10], Step [511/750], Loss: 0.0641\n",
      "Epoch [2/10], Step [512/750], Loss: 0.0715\n",
      "Epoch [2/10], Step [513/750], Loss: 0.1550\n",
      "Epoch [2/10], Step [514/750], Loss: 0.0283\n",
      "Epoch [2/10], Step [515/750], Loss: 0.0572\n",
      "Epoch [2/10], Step [516/750], Loss: 0.0278\n",
      "Epoch [2/10], Step [517/750], Loss: 0.0541\n",
      "Epoch [2/10], Step [518/750], Loss: 0.2135\n",
      "Epoch [2/10], Step [519/750], Loss: 0.0483\n",
      "Epoch [2/10], Step [520/750], Loss: 0.2078\n",
      "Epoch [2/10], Step [521/750], Loss: 0.0101\n",
      "Epoch [2/10], Step [522/750], Loss: 0.1553\n",
      "Epoch [2/10], Step [523/750], Loss: 0.0875\n",
      "Epoch [2/10], Step [524/750], Loss: 0.1187\n",
      "Epoch [2/10], Step [525/750], Loss: 0.1361\n",
      "Epoch [2/10], Step [526/750], Loss: 0.1310\n",
      "Epoch [2/10], Step [527/750], Loss: 0.0815\n",
      "Epoch [2/10], Step [528/750], Loss: 0.0591\n",
      "Epoch [2/10], Step [529/750], Loss: 0.0543\n",
      "Epoch [2/10], Step [530/750], Loss: 0.1561\n",
      "Epoch [2/10], Step [531/750], Loss: 0.0989\n",
      "Epoch [2/10], Step [532/750], Loss: 0.0275\n",
      "Epoch [2/10], Step [533/750], Loss: 0.0223\n",
      "Epoch [2/10], Step [534/750], Loss: 0.0239\n",
      "Epoch [2/10], Step [535/750], Loss: 0.0289\n",
      "Epoch [2/10], Step [536/750], Loss: 0.0642\n",
      "Epoch [2/10], Step [537/750], Loss: 0.0352\n",
      "Epoch [2/10], Step [538/750], Loss: 0.0536\n",
      "Epoch [2/10], Step [539/750], Loss: 0.0388\n",
      "Epoch [2/10], Step [540/750], Loss: 0.2296\n",
      "Epoch [2/10], Step [541/750], Loss: 0.0857\n",
      "Epoch [2/10], Step [542/750], Loss: 0.1115\n",
      "Epoch [2/10], Step [543/750], Loss: 0.0175\n",
      "Epoch [2/10], Step [544/750], Loss: 0.1472\n",
      "Epoch [2/10], Step [545/750], Loss: 0.2214\n",
      "Epoch [2/10], Step [546/750], Loss: 0.3037\n",
      "Epoch [2/10], Step [547/750], Loss: 0.0935\n",
      "Epoch [2/10], Step [548/750], Loss: 0.0101\n",
      "Epoch [2/10], Step [549/750], Loss: 0.0773\n",
      "Epoch [2/10], Step [550/750], Loss: 0.0911\n",
      "Epoch [2/10], Step [551/750], Loss: 0.1005\n",
      "Epoch [2/10], Step [552/750], Loss: 0.1041\n",
      "Epoch [2/10], Step [553/750], Loss: 0.1183\n",
      "Epoch [2/10], Step [554/750], Loss: 0.0526\n",
      "Epoch [2/10], Step [555/750], Loss: 0.1846\n",
      "Epoch [2/10], Step [556/750], Loss: 0.0530\n",
      "Epoch [2/10], Step [557/750], Loss: 0.1063\n",
      "Epoch [2/10], Step [558/750], Loss: 0.0701\n",
      "Epoch [2/10], Step [559/750], Loss: 0.0824\n",
      "Epoch [2/10], Step [560/750], Loss: 0.2225\n",
      "Epoch [2/10], Step [561/750], Loss: 0.1543\n",
      "Epoch [2/10], Step [562/750], Loss: 0.0150\n",
      "Epoch [2/10], Step [563/750], Loss: 0.0579\n",
      "Epoch [2/10], Step [564/750], Loss: 0.0707\n",
      "Epoch [2/10], Step [565/750], Loss: 0.1162\n",
      "Epoch [2/10], Step [566/750], Loss: 0.0284\n",
      "Epoch [2/10], Step [567/750], Loss: 0.0287\n",
      "Epoch [2/10], Step [568/750], Loss: 0.0366\n",
      "Epoch [2/10], Step [569/750], Loss: 0.0630\n",
      "Epoch [2/10], Step [570/750], Loss: 0.0882\n",
      "Epoch [2/10], Step [571/750], Loss: 0.0438\n",
      "Epoch [2/10], Step [572/750], Loss: 0.0871\n",
      "Epoch [2/10], Step [573/750], Loss: 0.2228\n",
      "Epoch [2/10], Step [574/750], Loss: 0.1398\n",
      "Epoch [2/10], Step [575/750], Loss: 0.2598\n",
      "Epoch [2/10], Step [576/750], Loss: 0.1737\n",
      "Epoch [2/10], Step [577/750], Loss: 0.0279\n",
      "Epoch [2/10], Step [578/750], Loss: 0.1224\n",
      "Epoch [2/10], Step [579/750], Loss: 0.0262\n",
      "Epoch [2/10], Step [580/750], Loss: 0.2033\n",
      "Epoch [2/10], Step [581/750], Loss: 0.1329\n",
      "Epoch [2/10], Step [582/750], Loss: 0.0376\n",
      "Epoch [2/10], Step [583/750], Loss: 0.1008\n",
      "Epoch [2/10], Step [584/750], Loss: 0.0813\n",
      "Epoch [2/10], Step [585/750], Loss: 0.0350\n",
      "Epoch [2/10], Step [586/750], Loss: 0.0625\n",
      "Epoch [2/10], Step [587/750], Loss: 0.0276\n",
      "Epoch [2/10], Step [588/750], Loss: 0.0882\n",
      "Epoch [2/10], Step [589/750], Loss: 0.2062\n",
      "Epoch [2/10], Step [590/750], Loss: 0.0383\n",
      "Epoch [2/10], Step [591/750], Loss: 0.1068\n",
      "Epoch [2/10], Step [592/750], Loss: 0.0502\n",
      "Epoch [2/10], Step [593/750], Loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [594/750], Loss: 0.0366\n",
      "Epoch [2/10], Step [595/750], Loss: 0.0081\n",
      "Epoch [2/10], Step [596/750], Loss: 0.0562\n",
      "Epoch [2/10], Step [597/750], Loss: 0.1816\n",
      "Epoch [2/10], Step [598/750], Loss: 0.0183\n",
      "Epoch [2/10], Step [599/750], Loss: 0.0256\n",
      "Epoch [2/10], Step [600/750], Loss: 0.0911\n",
      "Epoch [2/10], Step [601/750], Loss: 0.0105\n",
      "Epoch [2/10], Step [602/750], Loss: 0.0369\n",
      "Epoch [2/10], Step [603/750], Loss: 0.0132\n",
      "Epoch [2/10], Step [604/750], Loss: 0.0493\n",
      "Epoch [2/10], Step [605/750], Loss: 0.0499\n",
      "Epoch [2/10], Step [606/750], Loss: 0.0722\n",
      "Epoch [2/10], Step [607/750], Loss: 0.0052\n",
      "Epoch [2/10], Step [608/750], Loss: 0.0658\n",
      "Epoch [2/10], Step [609/750], Loss: 0.0422\n",
      "Epoch [2/10], Step [610/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [611/750], Loss: 0.1889\n",
      "Epoch [2/10], Step [612/750], Loss: 0.0497\n",
      "Epoch [2/10], Step [613/750], Loss: 0.1112\n",
      "Epoch [2/10], Step [614/750], Loss: 0.0298\n",
      "Epoch [2/10], Step [615/750], Loss: 0.0418\n",
      "Epoch [2/10], Step [616/750], Loss: 0.0526\n",
      "Epoch [2/10], Step [617/750], Loss: 0.1134\n",
      "Epoch [2/10], Step [618/750], Loss: 0.0798\n",
      "Epoch [2/10], Step [619/750], Loss: 0.1365\n",
      "Epoch [2/10], Step [620/750], Loss: 0.0111\n",
      "Epoch [2/10], Step [621/750], Loss: 0.0125\n",
      "Epoch [2/10], Step [622/750], Loss: 0.0124\n",
      "Epoch [2/10], Step [623/750], Loss: 0.0917\n",
      "Epoch [2/10], Step [624/750], Loss: 0.1849\n",
      "Epoch [2/10], Step [625/750], Loss: 0.1480\n",
      "Epoch [2/10], Step [626/750], Loss: 0.0585\n",
      "Epoch [2/10], Step [627/750], Loss: 0.0478\n",
      "Epoch [2/10], Step [628/750], Loss: 0.0055\n",
      "Epoch [2/10], Step [629/750], Loss: 0.0428\n",
      "Epoch [2/10], Step [630/750], Loss: 0.0333\n",
      "Epoch [2/10], Step [631/750], Loss: 0.0904\n",
      "Epoch [2/10], Step [632/750], Loss: 0.0650\n",
      "Epoch [2/10], Step [633/750], Loss: 0.0648\n",
      "Epoch [2/10], Step [634/750], Loss: 0.0762\n",
      "Epoch [2/10], Step [635/750], Loss: 0.0545\n",
      "Epoch [2/10], Step [636/750], Loss: 0.0433\n",
      "Epoch [2/10], Step [637/750], Loss: 0.0287\n",
      "Epoch [2/10], Step [638/750], Loss: 0.0630\n",
      "Epoch [2/10], Step [639/750], Loss: 0.0090\n",
      "Epoch [2/10], Step [640/750], Loss: 0.1178\n",
      "Epoch [2/10], Step [641/750], Loss: 0.0319\n",
      "Epoch [2/10], Step [642/750], Loss: 0.0709\n",
      "Epoch [2/10], Step [643/750], Loss: 0.1036\n",
      "Epoch [2/10], Step [644/750], Loss: 0.1794\n",
      "Epoch [2/10], Step [645/750], Loss: 0.0581\n",
      "Epoch [2/10], Step [646/750], Loss: 0.0101\n",
      "Epoch [2/10], Step [647/750], Loss: 0.0462\n",
      "Epoch [2/10], Step [648/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [649/750], Loss: 0.0800\n",
      "Epoch [2/10], Step [650/750], Loss: 0.0427\n",
      "Epoch [2/10], Step [651/750], Loss: 0.0600\n",
      "Epoch [2/10], Step [652/750], Loss: 0.1842\n",
      "Epoch [2/10], Step [653/750], Loss: 0.1004\n",
      "Epoch [2/10], Step [654/750], Loss: 0.1338\n",
      "Epoch [2/10], Step [655/750], Loss: 0.1329\n",
      "Epoch [2/10], Step [656/750], Loss: 0.1040\n",
      "Epoch [2/10], Step [657/750], Loss: 0.0478\n",
      "Epoch [2/10], Step [658/750], Loss: 0.0873\n",
      "Epoch [2/10], Step [659/750], Loss: 0.0704\n",
      "Epoch [2/10], Step [660/750], Loss: 0.0900\n",
      "Epoch [2/10], Step [661/750], Loss: 0.1100\n",
      "Epoch [2/10], Step [662/750], Loss: 0.0629\n",
      "Epoch [2/10], Step [663/750], Loss: 0.1029\n",
      "Epoch [2/10], Step [664/750], Loss: 0.0367\n",
      "Epoch [2/10], Step [665/750], Loss: 0.0566\n",
      "Epoch [2/10], Step [666/750], Loss: 0.0376\n",
      "Epoch [2/10], Step [667/750], Loss: 0.0612\n",
      "Epoch [2/10], Step [668/750], Loss: 0.0688\n",
      "Epoch [2/10], Step [669/750], Loss: 0.0446\n",
      "Epoch [2/10], Step [670/750], Loss: 0.0284\n",
      "Epoch [2/10], Step [671/750], Loss: 0.0879\n",
      "Epoch [2/10], Step [672/750], Loss: 0.0200\n",
      "Epoch [2/10], Step [673/750], Loss: 0.0282\n",
      "Epoch [2/10], Step [674/750], Loss: 0.1273\n",
      "Epoch [2/10], Step [675/750], Loss: 0.0152\n",
      "Epoch [2/10], Step [676/750], Loss: 0.1302\n",
      "Epoch [2/10], Step [677/750], Loss: 0.0481\n",
      "Epoch [2/10], Step [678/750], Loss: 0.0174\n",
      "Epoch [2/10], Step [679/750], Loss: 0.0104\n",
      "Epoch [2/10], Step [680/750], Loss: 0.0160\n",
      "Epoch [2/10], Step [681/750], Loss: 0.0606\n",
      "Epoch [2/10], Step [682/750], Loss: 0.0576\n",
      "Epoch [2/10], Step [683/750], Loss: 0.1742\n",
      "Epoch [2/10], Step [684/750], Loss: 0.0165\n",
      "Epoch [2/10], Step [685/750], Loss: 0.0218\n",
      "Epoch [2/10], Step [686/750], Loss: 0.1190\n",
      "Epoch [2/10], Step [687/750], Loss: 0.0322\n",
      "Epoch [2/10], Step [688/750], Loss: 0.0159\n",
      "Epoch [2/10], Step [689/750], Loss: 0.0106\n",
      "Epoch [2/10], Step [690/750], Loss: 0.1219\n",
      "Epoch [2/10], Step [691/750], Loss: 0.0698\n",
      "Epoch [2/10], Step [692/750], Loss: 0.0181\n",
      "Epoch [2/10], Step [693/750], Loss: 0.0266\n",
      "Epoch [2/10], Step [694/750], Loss: 0.1815\n",
      "Epoch [2/10], Step [695/750], Loss: 0.0257\n",
      "Epoch [2/10], Step [696/750], Loss: 0.1936\n",
      "Epoch [2/10], Step [697/750], Loss: 0.0609\n",
      "Epoch [2/10], Step [698/750], Loss: 0.1049\n",
      "Epoch [2/10], Step [699/750], Loss: 0.0198\n",
      "Epoch [2/10], Step [700/750], Loss: 0.1349\n",
      "Epoch [2/10], Step [701/750], Loss: 0.0206\n",
      "Epoch [2/10], Step [702/750], Loss: 0.0259\n",
      "Epoch [2/10], Step [703/750], Loss: 0.0150\n",
      "Epoch [2/10], Step [704/750], Loss: 0.0255\n",
      "Epoch [2/10], Step [705/750], Loss: 0.0417\n",
      "Epoch [2/10], Step [706/750], Loss: 0.0172\n",
      "Epoch [2/10], Step [707/750], Loss: 0.0645\n",
      "Epoch [2/10], Step [708/750], Loss: 0.1779\n",
      "Epoch [2/10], Step [709/750], Loss: 0.0164\n",
      "Epoch [2/10], Step [710/750], Loss: 0.0935\n",
      "Epoch [2/10], Step [711/750], Loss: 0.0818\n",
      "Epoch [2/10], Step [712/750], Loss: 0.0157\n",
      "Epoch [2/10], Step [713/750], Loss: 0.1324\n",
      "Epoch [2/10], Step [714/750], Loss: 0.0804\n",
      "Epoch [2/10], Step [715/750], Loss: 0.0719\n",
      "Epoch [2/10], Step [716/750], Loss: 0.1059\n",
      "Epoch [2/10], Step [717/750], Loss: 0.0175\n",
      "Epoch [2/10], Step [718/750], Loss: 0.1012\n",
      "Epoch [2/10], Step [719/750], Loss: 0.0702\n",
      "Epoch [2/10], Step [720/750], Loss: 0.0225\n",
      "Epoch [2/10], Step [721/750], Loss: 0.0115\n",
      "Epoch [2/10], Step [722/750], Loss: 0.0387\n",
      "Epoch [2/10], Step [723/750], Loss: 0.0526\n",
      "Epoch [2/10], Step [724/750], Loss: 0.0890\n",
      "Epoch [2/10], Step [725/750], Loss: 0.1090\n",
      "Epoch [2/10], Step [726/750], Loss: 0.0746\n",
      "Epoch [2/10], Step [727/750], Loss: 0.0773\n",
      "Epoch [2/10], Step [728/750], Loss: 0.0317\n",
      "Epoch [2/10], Step [729/750], Loss: 0.0205\n",
      "Epoch [2/10], Step [730/750], Loss: 0.0874\n",
      "Epoch [2/10], Step [731/750], Loss: 0.0384\n",
      "Epoch [2/10], Step [732/750], Loss: 0.0403\n",
      "Epoch [2/10], Step [733/750], Loss: 0.0449\n",
      "Epoch [2/10], Step [734/750], Loss: 0.1002\n",
      "Epoch [2/10], Step [735/750], Loss: 0.0808\n",
      "Epoch [2/10], Step [736/750], Loss: 0.0924\n",
      "Epoch [2/10], Step [737/750], Loss: 0.0339\n",
      "Epoch [2/10], Step [738/750], Loss: 0.0136\n",
      "Epoch [2/10], Step [739/750], Loss: 0.0662\n",
      "Epoch [2/10], Step [740/750], Loss: 0.0600\n",
      "Epoch [2/10], Step [741/750], Loss: 0.0998\n",
      "Epoch [2/10], Step [742/750], Loss: 0.1047\n",
      "Epoch [2/10], Step [743/750], Loss: 0.0472\n",
      "Epoch [2/10], Step [744/750], Loss: 0.1581\n",
      "Epoch [2/10], Step [745/750], Loss: 0.0205\n",
      "Epoch [2/10], Step [746/750], Loss: 0.0324\n",
      "Epoch [2/10], Step [747/750], Loss: 0.1789\n",
      "Epoch [2/10], Step [748/750], Loss: 0.0571\n",
      "Epoch [2/10], Step [749/750], Loss: 0.0663\n",
      "Epoch [2/10], Step [750/750], Loss: 0.0104\n",
      "\n",
      "\n",
      "Epoch [3/10], Step [1/750], Loss: 0.0196\n",
      "Epoch [3/10], Step [2/750], Loss: 0.0924\n",
      "Epoch [3/10], Step [3/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [4/750], Loss: 0.0210\n",
      "Epoch [3/10], Step [5/750], Loss: 0.0230\n",
      "Epoch [3/10], Step [6/750], Loss: 0.0844\n",
      "Epoch [3/10], Step [7/750], Loss: 0.0133\n",
      "Epoch [3/10], Step [8/750], Loss: 0.0895\n",
      "Epoch [3/10], Step [9/750], Loss: 0.0680\n",
      "Epoch [3/10], Step [10/750], Loss: 0.0983\n",
      "Epoch [3/10], Step [11/750], Loss: 0.0530\n",
      "Epoch [3/10], Step [12/750], Loss: 0.0464\n",
      "Epoch [3/10], Step [13/750], Loss: 0.0498\n",
      "Epoch [3/10], Step [14/750], Loss: 0.0141\n",
      "Epoch [3/10], Step [15/750], Loss: 0.0198\n",
      "Epoch [3/10], Step [16/750], Loss: 0.0137\n",
      "Epoch [3/10], Step [17/750], Loss: 0.0092\n",
      "Epoch [3/10], Step [18/750], Loss: 0.0227\n",
      "Epoch [3/10], Step [19/750], Loss: 0.1091\n",
      "Epoch [3/10], Step [20/750], Loss: 0.1405\n",
      "Epoch [3/10], Step [21/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [22/750], Loss: 0.0614\n",
      "Epoch [3/10], Step [23/750], Loss: 0.1037\n",
      "Epoch [3/10], Step [24/750], Loss: 0.0113\n",
      "Epoch [3/10], Step [25/750], Loss: 0.0158\n",
      "Epoch [3/10], Step [26/750], Loss: 0.0726\n",
      "Epoch [3/10], Step [27/750], Loss: 0.0511\n",
      "Epoch [3/10], Step [28/750], Loss: 0.0839\n",
      "Epoch [3/10], Step [29/750], Loss: 0.1278\n",
      "Epoch [3/10], Step [30/750], Loss: 0.0630\n",
      "Epoch [3/10], Step [31/750], Loss: 0.0535\n",
      "Epoch [3/10], Step [32/750], Loss: 0.0617\n",
      "Epoch [3/10], Step [33/750], Loss: 0.0480\n",
      "Epoch [3/10], Step [34/750], Loss: 0.0315\n",
      "Epoch [3/10], Step [35/750], Loss: 0.0779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [36/750], Loss: 0.0306\n",
      "Epoch [3/10], Step [37/750], Loss: 0.1057\n",
      "Epoch [3/10], Step [38/750], Loss: 0.1494\n",
      "Epoch [3/10], Step [39/750], Loss: 0.0445\n",
      "Epoch [3/10], Step [40/750], Loss: 0.0578\n",
      "Epoch [3/10], Step [41/750], Loss: 0.0386\n",
      "Epoch [3/10], Step [42/750], Loss: 0.0104\n",
      "Epoch [3/10], Step [43/750], Loss: 0.0630\n",
      "Epoch [3/10], Step [44/750], Loss: 0.0406\n",
      "Epoch [3/10], Step [45/750], Loss: 0.0434\n",
      "Epoch [3/10], Step [46/750], Loss: 0.1862\n",
      "Epoch [3/10], Step [47/750], Loss: 0.0364\n",
      "Epoch [3/10], Step [48/750], Loss: 0.0252\n",
      "Epoch [3/10], Step [49/750], Loss: 0.0348\n",
      "Epoch [3/10], Step [50/750], Loss: 0.1088\n",
      "Epoch [3/10], Step [51/750], Loss: 0.0289\n",
      "Epoch [3/10], Step [52/750], Loss: 0.0824\n",
      "Epoch [3/10], Step [53/750], Loss: 0.0109\n",
      "Epoch [3/10], Step [54/750], Loss: 0.1648\n",
      "Epoch [3/10], Step [55/750], Loss: 0.0369\n",
      "Epoch [3/10], Step [56/750], Loss: 0.0059\n",
      "Epoch [3/10], Step [57/750], Loss: 0.0438\n",
      "Epoch [3/10], Step [58/750], Loss: 0.0182\n",
      "Epoch [3/10], Step [59/750], Loss: 0.0492\n",
      "Epoch [3/10], Step [60/750], Loss: 0.0954\n",
      "Epoch [3/10], Step [61/750], Loss: 0.0185\n",
      "Epoch [3/10], Step [62/750], Loss: 0.0535\n",
      "Epoch [3/10], Step [63/750], Loss: 0.0719\n",
      "Epoch [3/10], Step [64/750], Loss: 0.0299\n",
      "Epoch [3/10], Step [65/750], Loss: 0.1825\n",
      "Epoch [3/10], Step [66/750], Loss: 0.0495\n",
      "Epoch [3/10], Step [67/750], Loss: 0.0947\n",
      "Epoch [3/10], Step [68/750], Loss: 0.0611\n",
      "Epoch [3/10], Step [69/750], Loss: 0.0581\n",
      "Epoch [3/10], Step [70/750], Loss: 0.0585\n",
      "Epoch [3/10], Step [71/750], Loss: 0.0855\n",
      "Epoch [3/10], Step [72/750], Loss: 0.1282\n",
      "Epoch [3/10], Step [73/750], Loss: 0.0507\n",
      "Epoch [3/10], Step [74/750], Loss: 0.0602\n",
      "Epoch [3/10], Step [75/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [76/750], Loss: 0.0595\n",
      "Epoch [3/10], Step [77/750], Loss: 0.0334\n",
      "Epoch [3/10], Step [78/750], Loss: 0.1922\n",
      "Epoch [3/10], Step [79/750], Loss: 0.0653\n",
      "Epoch [3/10], Step [80/750], Loss: 0.0248\n",
      "Epoch [3/10], Step [81/750], Loss: 0.1071\n",
      "Epoch [3/10], Step [82/750], Loss: 0.0369\n",
      "Epoch [3/10], Step [83/750], Loss: 0.1295\n",
      "Epoch [3/10], Step [84/750], Loss: 0.1163\n",
      "Epoch [3/10], Step [85/750], Loss: 0.0354\n",
      "Epoch [3/10], Step [86/750], Loss: 0.1974\n",
      "Epoch [3/10], Step [87/750], Loss: 0.0730\n",
      "Epoch [3/10], Step [88/750], Loss: 0.0242\n",
      "Epoch [3/10], Step [89/750], Loss: 0.0896\n",
      "Epoch [3/10], Step [90/750], Loss: 0.1217\n",
      "Epoch [3/10], Step [91/750], Loss: 0.0452\n",
      "Epoch [3/10], Step [92/750], Loss: 0.0124\n",
      "Epoch [3/10], Step [93/750], Loss: 0.1241\n",
      "Epoch [3/10], Step [94/750], Loss: 0.0298\n",
      "Epoch [3/10], Step [95/750], Loss: 0.0598\n",
      "Epoch [3/10], Step [96/750], Loss: 0.0632\n",
      "Epoch [3/10], Step [97/750], Loss: 0.0306\n",
      "Epoch [3/10], Step [98/750], Loss: 0.0126\n",
      "Epoch [3/10], Step [99/750], Loss: 0.0174\n",
      "Epoch [3/10], Step [100/750], Loss: 0.0489\n",
      "Epoch [3/10], Step [101/750], Loss: 0.0126\n",
      "Epoch [3/10], Step [102/750], Loss: 0.0522\n",
      "Epoch [3/10], Step [103/750], Loss: 0.0929\n",
      "Epoch [3/10], Step [104/750], Loss: 0.0384\n",
      "Epoch [3/10], Step [105/750], Loss: 0.0733\n",
      "Epoch [3/10], Step [106/750], Loss: 0.1278\n",
      "Epoch [3/10], Step [107/750], Loss: 0.0607\n",
      "Epoch [3/10], Step [108/750], Loss: 0.0224\n",
      "Epoch [3/10], Step [109/750], Loss: 0.0440\n",
      "Epoch [3/10], Step [110/750], Loss: 0.0533\n",
      "Epoch [3/10], Step [111/750], Loss: 0.0931\n",
      "Epoch [3/10], Step [112/750], Loss: 0.0567\n",
      "Epoch [3/10], Step [113/750], Loss: 0.0424\n",
      "Epoch [3/10], Step [114/750], Loss: 0.0736\n",
      "Epoch [3/10], Step [115/750], Loss: 0.1029\n",
      "Epoch [3/10], Step [116/750], Loss: 0.0400\n",
      "Epoch [3/10], Step [117/750], Loss: 0.0417\n",
      "Epoch [3/10], Step [118/750], Loss: 0.1051\n",
      "Epoch [3/10], Step [119/750], Loss: 0.0528\n",
      "Epoch [3/10], Step [120/750], Loss: 0.0687\n",
      "Epoch [3/10], Step [121/750], Loss: 0.0844\n",
      "Epoch [3/10], Step [122/750], Loss: 0.0522\n",
      "Epoch [3/10], Step [123/750], Loss: 0.0885\n",
      "Epoch [3/10], Step [124/750], Loss: 0.1106\n",
      "Epoch [3/10], Step [125/750], Loss: 0.0588\n",
      "Epoch [3/10], Step [126/750], Loss: 0.0736\n",
      "Epoch [3/10], Step [127/750], Loss: 0.0150\n",
      "Epoch [3/10], Step [128/750], Loss: 0.0102\n",
      "Epoch [3/10], Step [129/750], Loss: 0.1307\n",
      "Epoch [3/10], Step [130/750], Loss: 0.1099\n",
      "Epoch [3/10], Step [131/750], Loss: 0.1178\n",
      "Epoch [3/10], Step [132/750], Loss: 0.1546\n",
      "Epoch [3/10], Step [133/750], Loss: 0.0167\n",
      "Epoch [3/10], Step [134/750], Loss: 0.1168\n",
      "Epoch [3/10], Step [135/750], Loss: 0.0143\n",
      "Epoch [3/10], Step [136/750], Loss: 0.0139\n",
      "Epoch [3/10], Step [137/750], Loss: 0.0212\n",
      "Epoch [3/10], Step [138/750], Loss: 0.0101\n",
      "Epoch [3/10], Step [139/750], Loss: 0.0859\n",
      "Epoch [3/10], Step [140/750], Loss: 0.0643\n",
      "Epoch [3/10], Step [141/750], Loss: 0.0507\n",
      "Epoch [3/10], Step [142/750], Loss: 0.0688\n",
      "Epoch [3/10], Step [143/750], Loss: 0.0126\n",
      "Epoch [3/10], Step [144/750], Loss: 0.0085\n",
      "Epoch [3/10], Step [145/750], Loss: 0.0766\n",
      "Epoch [3/10], Step [146/750], Loss: 0.0783\n",
      "Epoch [3/10], Step [147/750], Loss: 0.0781\n",
      "Epoch [3/10], Step [148/750], Loss: 0.0161\n",
      "Epoch [3/10], Step [149/750], Loss: 0.0373\n",
      "Epoch [3/10], Step [150/750], Loss: 0.0074\n",
      "Epoch [3/10], Step [151/750], Loss: 0.0917\n",
      "Epoch [3/10], Step [152/750], Loss: 0.0965\n",
      "Epoch [3/10], Step [153/750], Loss: 0.0416\n",
      "Epoch [3/10], Step [154/750], Loss: 0.0209\n",
      "Epoch [3/10], Step [155/750], Loss: 0.0816\n",
      "Epoch [3/10], Step [156/750], Loss: 0.0274\n",
      "Epoch [3/10], Step [157/750], Loss: 0.1222\n",
      "Epoch [3/10], Step [158/750], Loss: 0.1597\n",
      "Epoch [3/10], Step [159/750], Loss: 0.0692\n",
      "Epoch [3/10], Step [160/750], Loss: 0.0792\n",
      "Epoch [3/10], Step [161/750], Loss: 0.1271\n",
      "Epoch [3/10], Step [162/750], Loss: 0.0954\n",
      "Epoch [3/10], Step [163/750], Loss: 0.0310\n",
      "Epoch [3/10], Step [164/750], Loss: 0.0216\n",
      "Epoch [3/10], Step [165/750], Loss: 0.0193\n",
      "Epoch [3/10], Step [166/750], Loss: 0.0477\n",
      "Epoch [3/10], Step [167/750], Loss: 0.0442\n",
      "Epoch [3/10], Step [168/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [169/750], Loss: 0.0804\n",
      "Epoch [3/10], Step [170/750], Loss: 0.0804\n",
      "Epoch [3/10], Step [171/750], Loss: 0.0789\n",
      "Epoch [3/10], Step [172/750], Loss: 0.0085\n",
      "Epoch [3/10], Step [173/750], Loss: 0.1056\n",
      "Epoch [3/10], Step [174/750], Loss: 0.0145\n",
      "Epoch [3/10], Step [175/750], Loss: 0.0587\n",
      "Epoch [3/10], Step [176/750], Loss: 0.0179\n",
      "Epoch [3/10], Step [177/750], Loss: 0.0076\n",
      "Epoch [3/10], Step [178/750], Loss: 0.0959\n",
      "Epoch [3/10], Step [179/750], Loss: 0.0154\n",
      "Epoch [3/10], Step [180/750], Loss: 0.0720\n",
      "Epoch [3/10], Step [181/750], Loss: 0.0301\n",
      "Epoch [3/10], Step [182/750], Loss: 0.1047\n",
      "Epoch [3/10], Step [183/750], Loss: 0.0417\n",
      "Epoch [3/10], Step [184/750], Loss: 0.0376\n",
      "Epoch [3/10], Step [185/750], Loss: 0.0185\n",
      "Epoch [3/10], Step [186/750], Loss: 0.0971\n",
      "Epoch [3/10], Step [187/750], Loss: 0.0536\n",
      "Epoch [3/10], Step [188/750], Loss: 0.0362\n",
      "Epoch [3/10], Step [189/750], Loss: 0.0554\n",
      "Epoch [3/10], Step [190/750], Loss: 0.0174\n",
      "Epoch [3/10], Step [191/750], Loss: 0.0688\n",
      "Epoch [3/10], Step [192/750], Loss: 0.1395\n",
      "Epoch [3/10], Step [193/750], Loss: 0.0183\n",
      "Epoch [3/10], Step [194/750], Loss: 0.0731\n",
      "Epoch [3/10], Step [195/750], Loss: 0.0254\n",
      "Epoch [3/10], Step [196/750], Loss: 0.1714\n",
      "Epoch [3/10], Step [197/750], Loss: 0.0611\n",
      "Epoch [3/10], Step [198/750], Loss: 0.0788\n",
      "Epoch [3/10], Step [199/750], Loss: 0.0092\n",
      "Epoch [3/10], Step [200/750], Loss: 0.0479\n",
      "Epoch [3/10], Step [201/750], Loss: 0.1360\n",
      "Epoch [3/10], Step [202/750], Loss: 0.0713\n",
      "Epoch [3/10], Step [203/750], Loss: 0.0481\n",
      "Epoch [3/10], Step [204/750], Loss: 0.0601\n",
      "Epoch [3/10], Step [205/750], Loss: 0.0380\n",
      "Epoch [3/10], Step [206/750], Loss: 0.0030\n",
      "Epoch [3/10], Step [207/750], Loss: 0.0263\n",
      "Epoch [3/10], Step [208/750], Loss: 0.0119\n",
      "Epoch [3/10], Step [209/750], Loss: 0.0121\n",
      "Epoch [3/10], Step [210/750], Loss: 0.0612\n",
      "Epoch [3/10], Step [211/750], Loss: 0.1248\n",
      "Epoch [3/10], Step [212/750], Loss: 0.0422\n",
      "Epoch [3/10], Step [213/750], Loss: 0.1229\n",
      "Epoch [3/10], Step [214/750], Loss: 0.0429\n",
      "Epoch [3/10], Step [215/750], Loss: 0.1092\n",
      "Epoch [3/10], Step [216/750], Loss: 0.0418\n",
      "Epoch [3/10], Step [217/750], Loss: 0.0160\n",
      "Epoch [3/10], Step [218/750], Loss: 0.0873\n",
      "Epoch [3/10], Step [219/750], Loss: 0.0601\n",
      "Epoch [3/10], Step [220/750], Loss: 0.0331\n",
      "Epoch [3/10], Step [221/750], Loss: 0.0293\n",
      "Epoch [3/10], Step [222/750], Loss: 0.0593\n",
      "Epoch [3/10], Step [223/750], Loss: 0.0438\n",
      "Epoch [3/10], Step [224/750], Loss: 0.0239\n",
      "Epoch [3/10], Step [225/750], Loss: 0.0219\n",
      "Epoch [3/10], Step [226/750], Loss: 0.0314\n",
      "Epoch [3/10], Step [227/750], Loss: 0.0241\n",
      "Epoch [3/10], Step [228/750], Loss: 0.0562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [229/750], Loss: 0.1387\n",
      "Epoch [3/10], Step [230/750], Loss: 0.0828\n",
      "Epoch [3/10], Step [231/750], Loss: 0.0567\n",
      "Epoch [3/10], Step [232/750], Loss: 0.1244\n",
      "Epoch [3/10], Step [233/750], Loss: 0.0903\n",
      "Epoch [3/10], Step [234/750], Loss: 0.0542\n",
      "Epoch [3/10], Step [235/750], Loss: 0.0277\n",
      "Epoch [3/10], Step [236/750], Loss: 0.0304\n",
      "Epoch [3/10], Step [237/750], Loss: 0.0366\n",
      "Epoch [3/10], Step [238/750], Loss: 0.0422\n",
      "Epoch [3/10], Step [239/750], Loss: 0.0520\n",
      "Epoch [3/10], Step [240/750], Loss: 0.0538\n",
      "Epoch [3/10], Step [241/750], Loss: 0.1571\n",
      "Epoch [3/10], Step [242/750], Loss: 0.0249\n",
      "Epoch [3/10], Step [243/750], Loss: 0.1288\n",
      "Epoch [3/10], Step [244/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [245/750], Loss: 0.0161\n",
      "Epoch [3/10], Step [246/750], Loss: 0.0165\n",
      "Epoch [3/10], Step [247/750], Loss: 0.0303\n",
      "Epoch [3/10], Step [248/750], Loss: 0.0348\n",
      "Epoch [3/10], Step [249/750], Loss: 0.0645\n",
      "Epoch [3/10], Step [250/750], Loss: 0.0159\n",
      "Epoch [3/10], Step [251/750], Loss: 0.0313\n",
      "Epoch [3/10], Step [252/750], Loss: 0.0197\n",
      "Epoch [3/10], Step [253/750], Loss: 0.0371\n",
      "Epoch [3/10], Step [254/750], Loss: 0.0709\n",
      "Epoch [3/10], Step [255/750], Loss: 0.1047\n",
      "Epoch [3/10], Step [256/750], Loss: 0.0718\n",
      "Epoch [3/10], Step [257/750], Loss: 0.0708\n",
      "Epoch [3/10], Step [258/750], Loss: 0.0787\n",
      "Epoch [3/10], Step [259/750], Loss: 0.0529\n",
      "Epoch [3/10], Step [260/750], Loss: 0.0947\n",
      "Epoch [3/10], Step [261/750], Loss: 0.0495\n",
      "Epoch [3/10], Step [262/750], Loss: 0.0550\n",
      "Epoch [3/10], Step [263/750], Loss: 0.0421\n",
      "Epoch [3/10], Step [264/750], Loss: 0.0570\n",
      "Epoch [3/10], Step [265/750], Loss: 0.1650\n",
      "Epoch [3/10], Step [266/750], Loss: 0.0228\n",
      "Epoch [3/10], Step [267/750], Loss: 0.0069\n",
      "Epoch [3/10], Step [268/750], Loss: 0.0475\n",
      "Epoch [3/10], Step [269/750], Loss: 0.1280\n",
      "Epoch [3/10], Step [270/750], Loss: 0.0683\n",
      "Epoch [3/10], Step [271/750], Loss: 0.0451\n",
      "Epoch [3/10], Step [272/750], Loss: 0.0317\n",
      "Epoch [3/10], Step [273/750], Loss: 0.2368\n",
      "Epoch [3/10], Step [274/750], Loss: 0.1146\n",
      "Epoch [3/10], Step [275/750], Loss: 0.0155\n",
      "Epoch [3/10], Step [276/750], Loss: 0.0477\n",
      "Epoch [3/10], Step [277/750], Loss: 0.0392\n",
      "Epoch [3/10], Step [278/750], Loss: 0.1610\n",
      "Epoch [3/10], Step [279/750], Loss: 0.0855\n",
      "Epoch [3/10], Step [280/750], Loss: 0.0886\n",
      "Epoch [3/10], Step [281/750], Loss: 0.1465\n",
      "Epoch [3/10], Step [282/750], Loss: 0.0586\n",
      "Epoch [3/10], Step [283/750], Loss: 0.1952\n",
      "Epoch [3/10], Step [284/750], Loss: 0.1322\n",
      "Epoch [3/10], Step [285/750], Loss: 0.1525\n",
      "Epoch [3/10], Step [286/750], Loss: 0.0785\n",
      "Epoch [3/10], Step [287/750], Loss: 0.0904\n",
      "Epoch [3/10], Step [288/750], Loss: 0.0823\n",
      "Epoch [3/10], Step [289/750], Loss: 0.1045\n",
      "Epoch [3/10], Step [290/750], Loss: 0.1727\n",
      "Epoch [3/10], Step [291/750], Loss: 0.1962\n",
      "Epoch [3/10], Step [292/750], Loss: 0.0167\n",
      "Epoch [3/10], Step [293/750], Loss: 0.1451\n",
      "Epoch [3/10], Step [294/750], Loss: 0.0377\n",
      "Epoch [3/10], Step [295/750], Loss: 0.0312\n",
      "Epoch [3/10], Step [296/750], Loss: 0.0858\n",
      "Epoch [3/10], Step [297/750], Loss: 0.0475\n",
      "Epoch [3/10], Step [298/750], Loss: 0.1772\n",
      "Epoch [3/10], Step [299/750], Loss: 0.0990\n",
      "Epoch [3/10], Step [300/750], Loss: 0.0691\n",
      "Epoch [3/10], Step [301/750], Loss: 0.0821\n",
      "Epoch [3/10], Step [302/750], Loss: 0.0391\n",
      "Epoch [3/10], Step [303/750], Loss: 0.0962\n",
      "Epoch [3/10], Step [304/750], Loss: 0.1103\n",
      "Epoch [3/10], Step [305/750], Loss: 0.0340\n",
      "Epoch [3/10], Step [306/750], Loss: 0.0725\n",
      "Epoch [3/10], Step [307/750], Loss: 0.1308\n",
      "Epoch [3/10], Step [308/750], Loss: 0.0675\n",
      "Epoch [3/10], Step [309/750], Loss: 0.0812\n",
      "Epoch [3/10], Step [310/750], Loss: 0.0655\n",
      "Epoch [3/10], Step [311/750], Loss: 0.1003\n",
      "Epoch [3/10], Step [312/750], Loss: 0.0166\n",
      "Epoch [3/10], Step [313/750], Loss: 0.1902\n",
      "Epoch [3/10], Step [314/750], Loss: 0.1516\n",
      "Epoch [3/10], Step [315/750], Loss: 0.0995\n",
      "Epoch [3/10], Step [316/750], Loss: 0.0874\n",
      "Epoch [3/10], Step [317/750], Loss: 0.0730\n",
      "Epoch [3/10], Step [318/750], Loss: 0.0544\n",
      "Epoch [3/10], Step [319/750], Loss: 0.0868\n",
      "Epoch [3/10], Step [320/750], Loss: 0.0258\n",
      "Epoch [3/10], Step [321/750], Loss: 0.0855\n",
      "Epoch [3/10], Step [322/750], Loss: 0.0791\n",
      "Epoch [3/10], Step [323/750], Loss: 0.0986\n",
      "Epoch [3/10], Step [324/750], Loss: 0.0723\n",
      "Epoch [3/10], Step [325/750], Loss: 0.0485\n",
      "Epoch [3/10], Step [326/750], Loss: 0.0067\n",
      "Epoch [3/10], Step [327/750], Loss: 0.1734\n",
      "Epoch [3/10], Step [328/750], Loss: 0.1851\n",
      "Epoch [3/10], Step [329/750], Loss: 0.0323\n",
      "Epoch [3/10], Step [330/750], Loss: 0.0858\n",
      "Epoch [3/10], Step [331/750], Loss: 0.0430\n",
      "Epoch [3/10], Step [332/750], Loss: 0.0728\n",
      "Epoch [3/10], Step [333/750], Loss: 0.1234\n",
      "Epoch [3/10], Step [334/750], Loss: 0.1122\n",
      "Epoch [3/10], Step [335/750], Loss: 0.0804\n",
      "Epoch [3/10], Step [336/750], Loss: 0.0374\n",
      "Epoch [3/10], Step [337/750], Loss: 0.0285\n",
      "Epoch [3/10], Step [338/750], Loss: 0.0296\n",
      "Epoch [3/10], Step [339/750], Loss: 0.0773\n",
      "Epoch [3/10], Step [340/750], Loss: 0.0991\n",
      "Epoch [3/10], Step [341/750], Loss: 0.0184\n",
      "Epoch [3/10], Step [342/750], Loss: 0.0149\n",
      "Epoch [3/10], Step [343/750], Loss: 0.0252\n",
      "Epoch [3/10], Step [344/750], Loss: 0.1178\n",
      "Epoch [3/10], Step [345/750], Loss: 0.2009\n",
      "Epoch [3/10], Step [346/750], Loss: 0.0113\n",
      "Epoch [3/10], Step [347/750], Loss: 0.1428\n",
      "Epoch [3/10], Step [348/750], Loss: 0.0179\n",
      "Epoch [3/10], Step [349/750], Loss: 0.0255\n",
      "Epoch [3/10], Step [350/750], Loss: 0.0775\n",
      "Epoch [3/10], Step [351/750], Loss: 0.0677\n",
      "Epoch [3/10], Step [352/750], Loss: 0.0922\n",
      "Epoch [3/10], Step [353/750], Loss: 0.0541\n",
      "Epoch [3/10], Step [354/750], Loss: 0.0512\n",
      "Epoch [3/10], Step [355/750], Loss: 0.0765\n",
      "Epoch [3/10], Step [356/750], Loss: 0.1447\n",
      "Epoch [3/10], Step [357/750], Loss: 0.0949\n",
      "Epoch [3/10], Step [358/750], Loss: 0.0921\n",
      "Epoch [3/10], Step [359/750], Loss: 0.0388\n",
      "Epoch [3/10], Step [360/750], Loss: 0.0449\n",
      "Epoch [3/10], Step [361/750], Loss: 0.0734\n",
      "Epoch [3/10], Step [362/750], Loss: 0.0751\n",
      "Epoch [3/10], Step [363/750], Loss: 0.0504\n",
      "Epoch [3/10], Step [364/750], Loss: 0.0501\n",
      "Epoch [3/10], Step [365/750], Loss: 0.0393\n",
      "Epoch [3/10], Step [366/750], Loss: 0.0803\n",
      "Epoch [3/10], Step [367/750], Loss: 0.0425\n",
      "Epoch [3/10], Step [368/750], Loss: 0.0931\n",
      "Epoch [3/10], Step [369/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [370/750], Loss: 0.0668\n",
      "Epoch [3/10], Step [371/750], Loss: 0.0231\n",
      "Epoch [3/10], Step [372/750], Loss: 0.0190\n",
      "Epoch [3/10], Step [373/750], Loss: 0.0483\n",
      "Epoch [3/10], Step [374/750], Loss: 0.1164\n",
      "Epoch [3/10], Step [375/750], Loss: 0.0773\n",
      "Epoch [3/10], Step [376/750], Loss: 0.0312\n",
      "Epoch [3/10], Step [377/750], Loss: 0.0567\n",
      "Epoch [3/10], Step [378/750], Loss: 0.1064\n",
      "Epoch [3/10], Step [379/750], Loss: 0.1975\n",
      "Epoch [3/10], Step [380/750], Loss: 0.0157\n",
      "Epoch [3/10], Step [381/750], Loss: 0.0695\n",
      "Epoch [3/10], Step [382/750], Loss: 0.0852\n",
      "Epoch [3/10], Step [383/750], Loss: 0.0977\n",
      "Epoch [3/10], Step [384/750], Loss: 0.0791\n",
      "Epoch [3/10], Step [385/750], Loss: 0.0527\n",
      "Epoch [3/10], Step [386/750], Loss: 0.0854\n",
      "Epoch [3/10], Step [387/750], Loss: 0.0709\n",
      "Epoch [3/10], Step [388/750], Loss: 0.0794\n",
      "Epoch [3/10], Step [389/750], Loss: 0.0283\n",
      "Epoch [3/10], Step [390/750], Loss: 0.0435\n",
      "Epoch [3/10], Step [391/750], Loss: 0.0778\n",
      "Epoch [3/10], Step [392/750], Loss: 0.0101\n",
      "Epoch [3/10], Step [393/750], Loss: 0.0476\n",
      "Epoch [3/10], Step [394/750], Loss: 0.0179\n",
      "Epoch [3/10], Step [395/750], Loss: 0.0687\n",
      "Epoch [3/10], Step [396/750], Loss: 0.0300\n",
      "Epoch [3/10], Step [397/750], Loss: 0.0294\n",
      "Epoch [3/10], Step [398/750], Loss: 0.1548\n",
      "Epoch [3/10], Step [399/750], Loss: 0.0184\n",
      "Epoch [3/10], Step [400/750], Loss: 0.1242\n",
      "Epoch [3/10], Step [401/750], Loss: 0.0724\n",
      "Epoch [3/10], Step [402/750], Loss: 0.0905\n",
      "Epoch [3/10], Step [403/750], Loss: 0.0428\n",
      "Epoch [3/10], Step [404/750], Loss: 0.0810\n",
      "Epoch [3/10], Step [405/750], Loss: 0.1426\n",
      "Epoch [3/10], Step [406/750], Loss: 0.0180\n",
      "Epoch [3/10], Step [407/750], Loss: 0.0017\n",
      "Epoch [3/10], Step [408/750], Loss: 0.1563\n",
      "Epoch [3/10], Step [409/750], Loss: 0.1336\n",
      "Epoch [3/10], Step [410/750], Loss: 0.0183\n",
      "Epoch [3/10], Step [411/750], Loss: 0.1824\n",
      "Epoch [3/10], Step [412/750], Loss: 0.0299\n",
      "Epoch [3/10], Step [413/750], Loss: 0.0479\n",
      "Epoch [3/10], Step [414/750], Loss: 0.0400\n",
      "Epoch [3/10], Step [415/750], Loss: 0.0804\n",
      "Epoch [3/10], Step [416/750], Loss: 0.0507\n",
      "Epoch [3/10], Step [417/750], Loss: 0.0962\n",
      "Epoch [3/10], Step [418/750], Loss: 0.1157\n",
      "Epoch [3/10], Step [419/750], Loss: 0.1219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [420/750], Loss: 0.0629\n",
      "Epoch [3/10], Step [421/750], Loss: 0.0539\n",
      "Epoch [3/10], Step [422/750], Loss: 0.3365\n",
      "Epoch [3/10], Step [423/750], Loss: 0.1030\n",
      "Epoch [3/10], Step [424/750], Loss: 0.0398\n",
      "Epoch [3/10], Step [425/750], Loss: 0.0785\n",
      "Epoch [3/10], Step [426/750], Loss: 0.1093\n",
      "Epoch [3/10], Step [427/750], Loss: 0.0399\n",
      "Epoch [3/10], Step [428/750], Loss: 0.0639\n",
      "Epoch [3/10], Step [429/750], Loss: 0.0240\n",
      "Epoch [3/10], Step [430/750], Loss: 0.0891\n",
      "Epoch [3/10], Step [431/750], Loss: 0.0303\n",
      "Epoch [3/10], Step [432/750], Loss: 0.1881\n",
      "Epoch [3/10], Step [433/750], Loss: 0.0271\n",
      "Epoch [3/10], Step [434/750], Loss: 0.0391\n",
      "Epoch [3/10], Step [435/750], Loss: 0.0912\n",
      "Epoch [3/10], Step [436/750], Loss: 0.0277\n",
      "Epoch [3/10], Step [437/750], Loss: 0.1561\n",
      "Epoch [3/10], Step [438/750], Loss: 0.0784\n",
      "Epoch [3/10], Step [439/750], Loss: 0.0145\n",
      "Epoch [3/10], Step [440/750], Loss: 0.0979\n",
      "Epoch [3/10], Step [441/750], Loss: 0.0195\n",
      "Epoch [3/10], Step [442/750], Loss: 0.0602\n",
      "Epoch [3/10], Step [443/750], Loss: 0.1711\n",
      "Epoch [3/10], Step [444/750], Loss: 0.1079\n",
      "Epoch [3/10], Step [445/750], Loss: 0.0450\n",
      "Epoch [3/10], Step [446/750], Loss: 0.0251\n",
      "Epoch [3/10], Step [447/750], Loss: 0.0229\n",
      "Epoch [3/10], Step [448/750], Loss: 0.0987\n",
      "Epoch [3/10], Step [449/750], Loss: 0.0598\n",
      "Epoch [3/10], Step [450/750], Loss: 0.0277\n",
      "Epoch [3/10], Step [451/750], Loss: 0.1904\n",
      "Epoch [3/10], Step [452/750], Loss: 0.0740\n",
      "Epoch [3/10], Step [453/750], Loss: 0.0935\n",
      "Epoch [3/10], Step [454/750], Loss: 0.0661\n",
      "Epoch [3/10], Step [455/750], Loss: 0.0254\n",
      "Epoch [3/10], Step [456/750], Loss: 0.1358\n",
      "Epoch [3/10], Step [457/750], Loss: 0.1403\n",
      "Epoch [3/10], Step [458/750], Loss: 0.1677\n",
      "Epoch [3/10], Step [459/750], Loss: 0.0261\n",
      "Epoch [3/10], Step [460/750], Loss: 0.0794\n",
      "Epoch [3/10], Step [461/750], Loss: 0.0267\n",
      "Epoch [3/10], Step [462/750], Loss: 0.1399\n",
      "Epoch [3/10], Step [463/750], Loss: 0.0472\n",
      "Epoch [3/10], Step [464/750], Loss: 0.1320\n",
      "Epoch [3/10], Step [465/750], Loss: 0.0813\n",
      "Epoch [3/10], Step [466/750], Loss: 0.0450\n",
      "Epoch [3/10], Step [467/750], Loss: 0.0448\n",
      "Epoch [3/10], Step [468/750], Loss: 0.0532\n",
      "Epoch [3/10], Step [469/750], Loss: 0.0560\n",
      "Epoch [3/10], Step [470/750], Loss: 0.1127\n",
      "Epoch [3/10], Step [471/750], Loss: 0.1174\n",
      "Epoch [3/10], Step [472/750], Loss: 0.1612\n",
      "Epoch [3/10], Step [473/750], Loss: 0.0732\n",
      "Epoch [3/10], Step [474/750], Loss: 0.0542\n",
      "Epoch [3/10], Step [475/750], Loss: 0.0168\n",
      "Epoch [3/10], Step [476/750], Loss: 0.1243\n",
      "Epoch [3/10], Step [477/750], Loss: 0.0398\n",
      "Epoch [3/10], Step [478/750], Loss: 0.0213\n",
      "Epoch [3/10], Step [479/750], Loss: 0.0792\n",
      "Epoch [3/10], Step [480/750], Loss: 0.2180\n",
      "Epoch [3/10], Step [481/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [482/750], Loss: 0.0733\n",
      "Epoch [3/10], Step [483/750], Loss: 0.0455\n",
      "Epoch [3/10], Step [484/750], Loss: 0.0757\n",
      "Epoch [3/10], Step [485/750], Loss: 0.0966\n",
      "Epoch [3/10], Step [486/750], Loss: 0.0911\n",
      "Epoch [3/10], Step [487/750], Loss: 0.0975\n",
      "Epoch [3/10], Step [488/750], Loss: 0.1123\n",
      "Epoch [3/10], Step [489/750], Loss: 0.1507\n",
      "Epoch [3/10], Step [490/750], Loss: 0.0423\n",
      "Epoch [3/10], Step [491/750], Loss: 0.0273\n",
      "Epoch [3/10], Step [492/750], Loss: 0.0512\n",
      "Epoch [3/10], Step [493/750], Loss: 0.0525\n",
      "Epoch [3/10], Step [494/750], Loss: 0.0433\n",
      "Epoch [3/10], Step [495/750], Loss: 0.1312\n",
      "Epoch [3/10], Step [496/750], Loss: 0.0739\n",
      "Epoch [3/10], Step [497/750], Loss: 0.0297\n",
      "Epoch [3/10], Step [498/750], Loss: 0.1368\n",
      "Epoch [3/10], Step [499/750], Loss: 0.1422\n",
      "Epoch [3/10], Step [500/750], Loss: 0.1236\n",
      "Epoch [3/10], Step [501/750], Loss: 0.0460\n",
      "Epoch [3/10], Step [502/750], Loss: 0.0515\n",
      "Epoch [3/10], Step [503/750], Loss: 0.0268\n",
      "Epoch [3/10], Step [504/750], Loss: 0.0252\n",
      "Epoch [3/10], Step [505/750], Loss: 0.2366\n",
      "Epoch [3/10], Step [506/750], Loss: 0.1001\n",
      "Epoch [3/10], Step [507/750], Loss: 0.0561\n",
      "Epoch [3/10], Step [508/750], Loss: 0.0209\n",
      "Epoch [3/10], Step [509/750], Loss: 0.0161\n",
      "Epoch [3/10], Step [510/750], Loss: 0.1212\n",
      "Epoch [3/10], Step [511/750], Loss: 0.0976\n",
      "Epoch [3/10], Step [512/750], Loss: 0.0844\n",
      "Epoch [3/10], Step [513/750], Loss: 0.0370\n",
      "Epoch [3/10], Step [514/750], Loss: 0.0364\n",
      "Epoch [3/10], Step [515/750], Loss: 0.0669\n",
      "Epoch [3/10], Step [516/750], Loss: 0.0248\n",
      "Epoch [3/10], Step [517/750], Loss: 0.0291\n",
      "Epoch [3/10], Step [518/750], Loss: 0.0154\n",
      "Epoch [3/10], Step [519/750], Loss: 0.0335\n",
      "Epoch [3/10], Step [520/750], Loss: 0.2407\n",
      "Epoch [3/10], Step [521/750], Loss: 0.0447\n",
      "Epoch [3/10], Step [522/750], Loss: 0.0793\n",
      "Epoch [3/10], Step [523/750], Loss: 0.0644\n",
      "Epoch [3/10], Step [524/750], Loss: 0.0351\n",
      "Epoch [3/10], Step [525/750], Loss: 0.0216\n",
      "Epoch [3/10], Step [526/750], Loss: 0.0879\n",
      "Epoch [3/10], Step [527/750], Loss: 0.1708\n",
      "Epoch [3/10], Step [528/750], Loss: 0.1016\n",
      "Epoch [3/10], Step [529/750], Loss: 0.1171\n",
      "Epoch [3/10], Step [530/750], Loss: 0.0505\n",
      "Epoch [3/10], Step [531/750], Loss: 0.1182\n",
      "Epoch [3/10], Step [532/750], Loss: 0.0554\n",
      "Epoch [3/10], Step [533/750], Loss: 0.0787\n",
      "Epoch [3/10], Step [534/750], Loss: 0.0496\n",
      "Epoch [3/10], Step [535/750], Loss: 0.0304\n",
      "Epoch [3/10], Step [536/750], Loss: 0.0488\n",
      "Epoch [3/10], Step [537/750], Loss: 0.0286\n",
      "Epoch [3/10], Step [538/750], Loss: 0.0092\n",
      "Epoch [3/10], Step [539/750], Loss: 0.0103\n",
      "Epoch [3/10], Step [540/750], Loss: 0.1004\n",
      "Epoch [3/10], Step [541/750], Loss: 0.0150\n",
      "Epoch [3/10], Step [542/750], Loss: 0.0222\n",
      "Epoch [3/10], Step [543/750], Loss: 0.0286\n",
      "Epoch [3/10], Step [544/750], Loss: 0.0510\n",
      "Epoch [3/10], Step [545/750], Loss: 0.1465\n",
      "Epoch [3/10], Step [546/750], Loss: 0.0289\n",
      "Epoch [3/10], Step [547/750], Loss: 0.0982\n",
      "Epoch [3/10], Step [548/750], Loss: 0.0676\n",
      "Epoch [3/10], Step [549/750], Loss: 0.1675\n",
      "Epoch [3/10], Step [550/750], Loss: 0.0244\n",
      "Epoch [3/10], Step [551/750], Loss: 0.0878\n",
      "Epoch [3/10], Step [552/750], Loss: 0.1489\n",
      "Epoch [3/10], Step [553/750], Loss: 0.1148\n",
      "Epoch [3/10], Step [554/750], Loss: 0.1471\n",
      "Epoch [3/10], Step [555/750], Loss: 0.0308\n",
      "Epoch [3/10], Step [556/750], Loss: 0.0175\n",
      "Epoch [3/10], Step [557/750], Loss: 0.0695\n",
      "Epoch [3/10], Step [558/750], Loss: 0.0938\n",
      "Epoch [3/10], Step [559/750], Loss: 0.0565\n",
      "Epoch [3/10], Step [560/750], Loss: 0.1026\n",
      "Epoch [3/10], Step [561/750], Loss: 0.1024\n",
      "Epoch [3/10], Step [562/750], Loss: 0.0480\n",
      "Epoch [3/10], Step [563/750], Loss: 0.1596\n",
      "Epoch [3/10], Step [564/750], Loss: 0.0199\n",
      "Epoch [3/10], Step [565/750], Loss: 0.1366\n",
      "Epoch [3/10], Step [566/750], Loss: 0.1253\n",
      "Epoch [3/10], Step [567/750], Loss: 0.1640\n",
      "Epoch [3/10], Step [568/750], Loss: 0.1286\n",
      "Epoch [3/10], Step [569/750], Loss: 0.0334\n",
      "Epoch [3/10], Step [570/750], Loss: 0.1628\n",
      "Epoch [3/10], Step [571/750], Loss: 0.0677\n",
      "Epoch [3/10], Step [572/750], Loss: 0.3481\n",
      "Epoch [3/10], Step [573/750], Loss: 0.1329\n",
      "Epoch [3/10], Step [574/750], Loss: 0.0535\n",
      "Epoch [3/10], Step [575/750], Loss: 0.1439\n",
      "Epoch [3/10], Step [576/750], Loss: 0.1049\n",
      "Epoch [3/10], Step [577/750], Loss: 0.0401\n",
      "Epoch [3/10], Step [578/750], Loss: 0.1576\n",
      "Epoch [3/10], Step [579/750], Loss: 0.2112\n",
      "Epoch [3/10], Step [580/750], Loss: 0.1106\n",
      "Epoch [3/10], Step [581/750], Loss: 0.1947\n",
      "Epoch [3/10], Step [582/750], Loss: 0.0283\n",
      "Epoch [3/10], Step [583/750], Loss: 0.0420\n",
      "Epoch [3/10], Step [584/750], Loss: 0.0177\n",
      "Epoch [3/10], Step [585/750], Loss: 0.0382\n",
      "Epoch [3/10], Step [586/750], Loss: 0.0296\n",
      "Epoch [3/10], Step [587/750], Loss: 0.0230\n",
      "Epoch [3/10], Step [588/750], Loss: 0.0988\n",
      "Epoch [3/10], Step [589/750], Loss: 0.0316\n",
      "Epoch [3/10], Step [590/750], Loss: 0.0891\n",
      "Epoch [3/10], Step [591/750], Loss: 0.1198\n",
      "Epoch [3/10], Step [592/750], Loss: 0.0919\n",
      "Epoch [3/10], Step [593/750], Loss: 0.0361\n",
      "Epoch [3/10], Step [594/750], Loss: 0.0509\n",
      "Epoch [3/10], Step [595/750], Loss: 0.0167\n",
      "Epoch [3/10], Step [596/750], Loss: 0.1165\n",
      "Epoch [3/10], Step [597/750], Loss: 0.1171\n",
      "Epoch [3/10], Step [598/750], Loss: 0.0251\n",
      "Epoch [3/10], Step [599/750], Loss: 0.0630\n",
      "Epoch [3/10], Step [600/750], Loss: 0.0435\n",
      "Epoch [3/10], Step [601/750], Loss: 0.0553\n",
      "Epoch [3/10], Step [602/750], Loss: 0.0735\n",
      "Epoch [3/10], Step [603/750], Loss: 0.0794\n",
      "Epoch [3/10], Step [604/750], Loss: 0.0537\n",
      "Epoch [3/10], Step [605/750], Loss: 0.0373\n",
      "Epoch [3/10], Step [606/750], Loss: 0.0260\n",
      "Epoch [3/10], Step [607/750], Loss: 0.0788\n",
      "Epoch [3/10], Step [608/750], Loss: 0.1349\n",
      "Epoch [3/10], Step [609/750], Loss: 0.0294\n",
      "Epoch [3/10], Step [610/750], Loss: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [611/750], Loss: 0.0824\n",
      "Epoch [3/10], Step [612/750], Loss: 0.1214\n",
      "Epoch [3/10], Step [613/750], Loss: 0.0266\n",
      "Epoch [3/10], Step [614/750], Loss: 0.1298\n",
      "Epoch [3/10], Step [615/750], Loss: 0.1637\n",
      "Epoch [3/10], Step [616/750], Loss: 0.1900\n",
      "Epoch [3/10], Step [617/750], Loss: 0.0816\n",
      "Epoch [3/10], Step [618/750], Loss: 0.1103\n",
      "Epoch [3/10], Step [619/750], Loss: 0.0965\n",
      "Epoch [3/10], Step [620/750], Loss: 0.0175\n",
      "Epoch [3/10], Step [621/750], Loss: 0.0513\n",
      "Epoch [3/10], Step [622/750], Loss: 0.0616\n",
      "Epoch [3/10], Step [623/750], Loss: 0.1313\n",
      "Epoch [3/10], Step [624/750], Loss: 0.0744\n",
      "Epoch [3/10], Step [625/750], Loss: 0.0159\n",
      "Epoch [3/10], Step [626/750], Loss: 0.0357\n",
      "Epoch [3/10], Step [627/750], Loss: 0.0874\n",
      "Epoch [3/10], Step [628/750], Loss: 0.0476\n",
      "Epoch [3/10], Step [629/750], Loss: 0.1439\n",
      "Epoch [3/10], Step [630/750], Loss: 0.0264\n",
      "Epoch [3/10], Step [631/750], Loss: 0.0103\n",
      "Epoch [3/10], Step [632/750], Loss: 0.0575\n",
      "Epoch [3/10], Step [633/750], Loss: 0.0231\n",
      "Epoch [3/10], Step [634/750], Loss: 0.1529\n",
      "Epoch [3/10], Step [635/750], Loss: 0.1946\n",
      "Epoch [3/10], Step [636/750], Loss: 0.0087\n",
      "Epoch [3/10], Step [637/750], Loss: 0.0507\n",
      "Epoch [3/10], Step [638/750], Loss: 0.0529\n",
      "Epoch [3/10], Step [639/750], Loss: 0.0316\n",
      "Epoch [3/10], Step [640/750], Loss: 0.0694\n",
      "Epoch [3/10], Step [641/750], Loss: 0.1552\n",
      "Epoch [3/10], Step [642/750], Loss: 0.0243\n",
      "Epoch [3/10], Step [643/750], Loss: 0.0759\n",
      "Epoch [3/10], Step [644/750], Loss: 0.0747\n",
      "Epoch [3/10], Step [645/750], Loss: 0.0942\n",
      "Epoch [3/10], Step [646/750], Loss: 0.1572\n",
      "Epoch [3/10], Step [647/750], Loss: 0.0846\n",
      "Epoch [3/10], Step [648/750], Loss: 0.0351\n",
      "Epoch [3/10], Step [649/750], Loss: 0.0406\n",
      "Epoch [3/10], Step [650/750], Loss: 0.0415\n",
      "Epoch [3/10], Step [651/750], Loss: 0.0579\n",
      "Epoch [3/10], Step [652/750], Loss: 0.1757\n",
      "Epoch [3/10], Step [653/750], Loss: 0.0247\n",
      "Epoch [3/10], Step [654/750], Loss: 0.2456\n",
      "Epoch [3/10], Step [655/750], Loss: 0.0751\n",
      "Epoch [3/10], Step [656/750], Loss: 0.1013\n",
      "Epoch [3/10], Step [657/750], Loss: 0.0365\n",
      "Epoch [3/10], Step [658/750], Loss: 0.0240\n",
      "Epoch [3/10], Step [659/750], Loss: 0.0996\n",
      "Epoch [3/10], Step [660/750], Loss: 0.0488\n",
      "Epoch [3/10], Step [661/750], Loss: 0.1875\n",
      "Epoch [3/10], Step [662/750], Loss: 0.0086\n",
      "Epoch [3/10], Step [663/750], Loss: 0.2551\n",
      "Epoch [3/10], Step [664/750], Loss: 0.0091\n",
      "Epoch [3/10], Step [665/750], Loss: 0.0876\n",
      "Epoch [3/10], Step [666/750], Loss: 0.0788\n",
      "Epoch [3/10], Step [667/750], Loss: 0.0508\n",
      "Epoch [3/10], Step [668/750], Loss: 0.0497\n",
      "Epoch [3/10], Step [669/750], Loss: 0.0738\n",
      "Epoch [3/10], Step [670/750], Loss: 0.0156\n",
      "Epoch [3/10], Step [671/750], Loss: 0.1144\n",
      "Epoch [3/10], Step [672/750], Loss: 0.0321\n",
      "Epoch [3/10], Step [673/750], Loss: 0.0600\n",
      "Epoch [3/10], Step [674/750], Loss: 0.0566\n",
      "Epoch [3/10], Step [675/750], Loss: 0.0276\n",
      "Epoch [3/10], Step [676/750], Loss: 0.0782\n",
      "Epoch [3/10], Step [677/750], Loss: 0.0261\n",
      "Epoch [3/10], Step [678/750], Loss: 0.0692\n",
      "Epoch [3/10], Step [679/750], Loss: 0.0284\n",
      "Epoch [3/10], Step [680/750], Loss: 0.0725\n",
      "Epoch [3/10], Step [681/750], Loss: 0.0216\n",
      "Epoch [3/10], Step [682/750], Loss: 0.1355\n",
      "Epoch [3/10], Step [683/750], Loss: 0.0741\n",
      "Epoch [3/10], Step [684/750], Loss: 0.0680\n",
      "Epoch [3/10], Step [685/750], Loss: 0.0593\n",
      "Epoch [3/10], Step [686/750], Loss: 0.1316\n",
      "Epoch [3/10], Step [687/750], Loss: 0.0444\n",
      "Epoch [3/10], Step [688/750], Loss: 0.1068\n",
      "Epoch [3/10], Step [689/750], Loss: 0.0083\n",
      "Epoch [3/10], Step [690/750], Loss: 0.1154\n",
      "Epoch [3/10], Step [691/750], Loss: 0.0373\n",
      "Epoch [3/10], Step [692/750], Loss: 0.0701\n",
      "Epoch [3/10], Step [693/750], Loss: 0.0754\n",
      "Epoch [3/10], Step [694/750], Loss: 0.0451\n",
      "Epoch [3/10], Step [695/750], Loss: 0.0096\n",
      "Epoch [3/10], Step [696/750], Loss: 0.0589\n",
      "Epoch [3/10], Step [697/750], Loss: 0.0373\n",
      "Epoch [3/10], Step [698/750], Loss: 0.0344\n",
      "Epoch [3/10], Step [699/750], Loss: 0.0379\n",
      "Epoch [3/10], Step [700/750], Loss: 0.0273\n",
      "Epoch [3/10], Step [701/750], Loss: 0.1026\n",
      "Epoch [3/10], Step [702/750], Loss: 0.0734\n",
      "Epoch [3/10], Step [703/750], Loss: 0.0478\n",
      "Epoch [3/10], Step [704/750], Loss: 0.0346\n",
      "Epoch [3/10], Step [705/750], Loss: 0.0216\n",
      "Epoch [3/10], Step [706/750], Loss: 0.0492\n",
      "Epoch [3/10], Step [707/750], Loss: 0.0451\n",
      "Epoch [3/10], Step [708/750], Loss: 0.1408\n",
      "Epoch [3/10], Step [709/750], Loss: 0.0216\n",
      "Epoch [3/10], Step [710/750], Loss: 0.1399\n",
      "Epoch [3/10], Step [711/750], Loss: 0.0919\n",
      "Epoch [3/10], Step [712/750], Loss: 0.1788\n",
      "Epoch [3/10], Step [713/750], Loss: 0.1076\n",
      "Epoch [3/10], Step [714/750], Loss: 0.0187\n",
      "Epoch [3/10], Step [715/750], Loss: 0.1524\n",
      "Epoch [3/10], Step [716/750], Loss: 0.0265\n",
      "Epoch [3/10], Step [717/750], Loss: 0.0661\n",
      "Epoch [3/10], Step [718/750], Loss: 0.0741\n",
      "Epoch [3/10], Step [719/750], Loss: 0.0055\n",
      "Epoch [3/10], Step [720/750], Loss: 0.0691\n",
      "Epoch [3/10], Step [721/750], Loss: 0.0841\n",
      "Epoch [3/10], Step [722/750], Loss: 0.0347\n",
      "Epoch [3/10], Step [723/750], Loss: 0.0653\n",
      "Epoch [3/10], Step [724/750], Loss: 0.1217\n",
      "Epoch [3/10], Step [725/750], Loss: 0.0848\n",
      "Epoch [3/10], Step [726/750], Loss: 0.0194\n",
      "Epoch [3/10], Step [727/750], Loss: 0.0084\n",
      "Epoch [3/10], Step [728/750], Loss: 0.0360\n",
      "Epoch [3/10], Step [729/750], Loss: 0.0868\n",
      "Epoch [3/10], Step [730/750], Loss: 0.1079\n",
      "Epoch [3/10], Step [731/750], Loss: 0.0961\n",
      "Epoch [3/10], Step [732/750], Loss: 0.2185\n",
      "Epoch [3/10], Step [733/750], Loss: 0.0615\n",
      "Epoch [3/10], Step [734/750], Loss: 0.0266\n",
      "Epoch [3/10], Step [735/750], Loss: 0.0707\n",
      "Epoch [3/10], Step [736/750], Loss: 0.0925\n",
      "Epoch [3/10], Step [737/750], Loss: 0.0160\n",
      "Epoch [3/10], Step [738/750], Loss: 0.0950\n",
      "Epoch [3/10], Step [739/750], Loss: 0.0210\n",
      "Epoch [3/10], Step [740/750], Loss: 0.1222\n",
      "Epoch [3/10], Step [741/750], Loss: 0.1164\n",
      "Epoch [3/10], Step [742/750], Loss: 0.0267\n",
      "Epoch [3/10], Step [743/750], Loss: 0.0791\n",
      "Epoch [3/10], Step [744/750], Loss: 0.0324\n",
      "Epoch [3/10], Step [745/750], Loss: 0.0543\n",
      "Epoch [3/10], Step [746/750], Loss: 0.0495\n",
      "Epoch [3/10], Step [747/750], Loss: 0.1225\n",
      "Epoch [3/10], Step [748/750], Loss: 0.1657\n",
      "Epoch [3/10], Step [749/750], Loss: 0.0593\n",
      "Epoch [3/10], Step [750/750], Loss: 0.0142\n",
      "\n",
      "\n",
      "Epoch [4/10], Step [1/750], Loss: 0.0061\n",
      "Epoch [4/10], Step [2/750], Loss: 0.0640\n",
      "Epoch [4/10], Step [3/750], Loss: 0.0312\n",
      "Epoch [4/10], Step [4/750], Loss: 0.0705\n",
      "Epoch [4/10], Step [5/750], Loss: 0.1400\n",
      "Epoch [4/10], Step [6/750], Loss: 0.0423\n",
      "Epoch [4/10], Step [7/750], Loss: 0.0627\n",
      "Epoch [4/10], Step [8/750], Loss: 0.0253\n",
      "Epoch [4/10], Step [9/750], Loss: 0.0287\n",
      "Epoch [4/10], Step [10/750], Loss: 0.0448\n",
      "Epoch [4/10], Step [11/750], Loss: 0.1862\n",
      "Epoch [4/10], Step [12/750], Loss: 0.0556\n",
      "Epoch [4/10], Step [13/750], Loss: 0.0153\n",
      "Epoch [4/10], Step [14/750], Loss: 0.0188\n",
      "Epoch [4/10], Step [15/750], Loss: 0.0365\n",
      "Epoch [4/10], Step [16/750], Loss: 0.0143\n",
      "Epoch [4/10], Step [17/750], Loss: 0.1283\n",
      "Epoch [4/10], Step [18/750], Loss: 0.0113\n",
      "Epoch [4/10], Step [19/750], Loss: 0.0098\n",
      "Epoch [4/10], Step [20/750], Loss: 0.0383\n",
      "Epoch [4/10], Step [21/750], Loss: 0.0307\n",
      "Epoch [4/10], Step [22/750], Loss: 0.0357\n",
      "Epoch [4/10], Step [23/750], Loss: 0.0435\n",
      "Epoch [4/10], Step [24/750], Loss: 0.0060\n",
      "Epoch [4/10], Step [25/750], Loss: 0.0584\n",
      "Epoch [4/10], Step [26/750], Loss: 0.0287\n",
      "Epoch [4/10], Step [27/750], Loss: 0.0704\n",
      "Epoch [4/10], Step [28/750], Loss: 0.0079\n",
      "Epoch [4/10], Step [29/750], Loss: 0.0723\n",
      "Epoch [4/10], Step [30/750], Loss: 0.0775\n",
      "Epoch [4/10], Step [31/750], Loss: 0.0292\n",
      "Epoch [4/10], Step [32/750], Loss: 0.0616\n",
      "Epoch [4/10], Step [33/750], Loss: 0.0411\n",
      "Epoch [4/10], Step [34/750], Loss: 0.0431\n",
      "Epoch [4/10], Step [35/750], Loss: 0.1338\n",
      "Epoch [4/10], Step [36/750], Loss: 0.1085\n",
      "Epoch [4/10], Step [37/750], Loss: 0.0158\n",
      "Epoch [4/10], Step [38/750], Loss: 0.0488\n",
      "Epoch [4/10], Step [39/750], Loss: 0.1019\n",
      "Epoch [4/10], Step [40/750], Loss: 0.0806\n",
      "Epoch [4/10], Step [41/750], Loss: 0.0970\n",
      "Epoch [4/10], Step [42/750], Loss: 0.0840\n",
      "Epoch [4/10], Step [43/750], Loss: 0.0171\n",
      "Epoch [4/10], Step [44/750], Loss: 0.0224\n",
      "Epoch [4/10], Step [45/750], Loss: 0.0927\n",
      "Epoch [4/10], Step [46/750], Loss: 0.0495\n",
      "Epoch [4/10], Step [47/750], Loss: 0.1124\n",
      "Epoch [4/10], Step [48/750], Loss: 0.0639\n",
      "Epoch [4/10], Step [49/750], Loss: 0.0979\n",
      "Epoch [4/10], Step [50/750], Loss: 0.1036\n",
      "Epoch [4/10], Step [51/750], Loss: 0.0202\n",
      "Epoch [4/10], Step [52/750], Loss: 0.0614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [53/750], Loss: 0.0857\n",
      "Epoch [4/10], Step [54/750], Loss: 0.2045\n",
      "Epoch [4/10], Step [55/750], Loss: 0.0563\n",
      "Epoch [4/10], Step [56/750], Loss: 0.0482\n",
      "Epoch [4/10], Step [57/750], Loss: 0.0809\n",
      "Epoch [4/10], Step [58/750], Loss: 0.0479\n",
      "Epoch [4/10], Step [59/750], Loss: 0.0776\n",
      "Epoch [4/10], Step [60/750], Loss: 0.0304\n",
      "Epoch [4/10], Step [61/750], Loss: 0.0451\n",
      "Epoch [4/10], Step [62/750], Loss: 0.0548\n",
      "Epoch [4/10], Step [63/750], Loss: 0.0960\n",
      "Epoch [4/10], Step [64/750], Loss: 0.0636\n",
      "Epoch [4/10], Step [65/750], Loss: 0.0092\n",
      "Epoch [4/10], Step [66/750], Loss: 0.0415\n",
      "Epoch [4/10], Step [67/750], Loss: 0.0823\n",
      "Epoch [4/10], Step [68/750], Loss: 0.1563\n",
      "Epoch [4/10], Step [69/750], Loss: 0.0246\n",
      "Epoch [4/10], Step [70/750], Loss: 0.1184\n",
      "Epoch [4/10], Step [71/750], Loss: 0.0478\n",
      "Epoch [4/10], Step [72/750], Loss: 0.0424\n",
      "Epoch [4/10], Step [73/750], Loss: 0.0901\n",
      "Epoch [4/10], Step [74/750], Loss: 0.0599\n",
      "Epoch [4/10], Step [75/750], Loss: 0.0391\n",
      "Epoch [4/10], Step [76/750], Loss: 0.1124\n",
      "Epoch [4/10], Step [77/750], Loss: 0.0168\n",
      "Epoch [4/10], Step [78/750], Loss: 0.0683\n",
      "Epoch [4/10], Step [79/750], Loss: 0.0815\n",
      "Epoch [4/10], Step [80/750], Loss: 0.1749\n",
      "Epoch [4/10], Step [81/750], Loss: 0.0159\n",
      "Epoch [4/10], Step [82/750], Loss: 0.0296\n",
      "Epoch [4/10], Step [83/750], Loss: 0.0833\n",
      "Epoch [4/10], Step [84/750], Loss: 0.0164\n",
      "Epoch [4/10], Step [85/750], Loss: 0.0163\n",
      "Epoch [4/10], Step [86/750], Loss: 0.0498\n",
      "Epoch [4/10], Step [87/750], Loss: 0.0862\n",
      "Epoch [4/10], Step [88/750], Loss: 0.0165\n",
      "Epoch [4/10], Step [89/750], Loss: 0.0089\n",
      "Epoch [4/10], Step [90/750], Loss: 0.0655\n",
      "Epoch [4/10], Step [91/750], Loss: 0.0367\n",
      "Epoch [4/10], Step [92/750], Loss: 0.0161\n",
      "Epoch [4/10], Step [93/750], Loss: 0.0951\n",
      "Epoch [4/10], Step [94/750], Loss: 0.0223\n",
      "Epoch [4/10], Step [95/750], Loss: 0.0265\n",
      "Epoch [4/10], Step [96/750], Loss: 0.0347\n",
      "Epoch [4/10], Step [97/750], Loss: 0.0782\n",
      "Epoch [4/10], Step [98/750], Loss: 0.0195\n",
      "Epoch [4/10], Step [99/750], Loss: 0.0468\n",
      "Epoch [4/10], Step [100/750], Loss: 0.0057\n",
      "Epoch [4/10], Step [101/750], Loss: 0.0423\n",
      "Epoch [4/10], Step [102/750], Loss: 0.0065\n",
      "Epoch [4/10], Step [103/750], Loss: 0.0270\n",
      "Epoch [4/10], Step [104/750], Loss: 0.0630\n",
      "Epoch [4/10], Step [105/750], Loss: 0.0508\n",
      "Epoch [4/10], Step [106/750], Loss: 0.0671\n",
      "Epoch [4/10], Step [107/750], Loss: 0.0742\n",
      "Epoch [4/10], Step [108/750], Loss: 0.0270\n",
      "Epoch [4/10], Step [109/750], Loss: 0.0400\n",
      "Epoch [4/10], Step [110/750], Loss: 0.0917\n",
      "Epoch [4/10], Step [111/750], Loss: 0.0303\n",
      "Epoch [4/10], Step [112/750], Loss: 0.0261\n",
      "Epoch [4/10], Step [113/750], Loss: 0.0371\n",
      "Epoch [4/10], Step [114/750], Loss: 0.0740\n",
      "Epoch [4/10], Step [115/750], Loss: 0.1028\n",
      "Epoch [4/10], Step [116/750], Loss: 0.0952\n",
      "Epoch [4/10], Step [117/750], Loss: 0.2151\n",
      "Epoch [4/10], Step [118/750], Loss: 0.1538\n",
      "Epoch [4/10], Step [119/750], Loss: 0.0367\n",
      "Epoch [4/10], Step [120/750], Loss: 0.0748\n",
      "Epoch [4/10], Step [121/750], Loss: 0.0817\n",
      "Epoch [4/10], Step [122/750], Loss: 0.0598\n",
      "Epoch [4/10], Step [123/750], Loss: 0.0915\n",
      "Epoch [4/10], Step [124/750], Loss: 0.0428\n",
      "Epoch [4/10], Step [125/750], Loss: 0.0122\n",
      "Epoch [4/10], Step [126/750], Loss: 0.0894\n",
      "Epoch [4/10], Step [127/750], Loss: 0.1297\n",
      "Epoch [4/10], Step [128/750], Loss: 0.0255\n",
      "Epoch [4/10], Step [129/750], Loss: 0.0493\n",
      "Epoch [4/10], Step [130/750], Loss: 0.1811\n",
      "Epoch [4/10], Step [131/750], Loss: 0.0739\n",
      "Epoch [4/10], Step [132/750], Loss: 0.0528\n",
      "Epoch [4/10], Step [133/750], Loss: 0.0152\n",
      "Epoch [4/10], Step [134/750], Loss: 0.0196\n",
      "Epoch [4/10], Step [135/750], Loss: 0.0825\n",
      "Epoch [4/10], Step [136/750], Loss: 0.0477\n",
      "Epoch [4/10], Step [137/750], Loss: 0.0833\n",
      "Epoch [4/10], Step [138/750], Loss: 0.1160\n",
      "Epoch [4/10], Step [139/750], Loss: 0.0399\n",
      "Epoch [4/10], Step [140/750], Loss: 0.1020\n",
      "Epoch [4/10], Step [141/750], Loss: 0.1343\n",
      "Epoch [4/10], Step [142/750], Loss: 0.0948\n",
      "Epoch [4/10], Step [143/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [144/750], Loss: 0.0277\n",
      "Epoch [4/10], Step [145/750], Loss: 0.0298\n",
      "Epoch [4/10], Step [146/750], Loss: 0.1406\n",
      "Epoch [4/10], Step [147/750], Loss: 0.0356\n",
      "Epoch [4/10], Step [148/750], Loss: 0.0840\n",
      "Epoch [4/10], Step [149/750], Loss: 0.0460\n",
      "Epoch [4/10], Step [150/750], Loss: 0.1015\n",
      "Epoch [4/10], Step [151/750], Loss: 0.0513\n",
      "Epoch [4/10], Step [152/750], Loss: 0.0364\n",
      "Epoch [4/10], Step [153/750], Loss: 0.0232\n",
      "Epoch [4/10], Step [154/750], Loss: 0.0866\n",
      "Epoch [4/10], Step [155/750], Loss: 0.0348\n",
      "Epoch [4/10], Step [156/750], Loss: 0.0220\n",
      "Epoch [4/10], Step [157/750], Loss: 0.0220\n",
      "Epoch [4/10], Step [158/750], Loss: 0.0967\n",
      "Epoch [4/10], Step [159/750], Loss: 0.0555\n",
      "Epoch [4/10], Step [160/750], Loss: 0.1298\n",
      "Epoch [4/10], Step [161/750], Loss: 0.0316\n",
      "Epoch [4/10], Step [162/750], Loss: 0.0256\n",
      "Epoch [4/10], Step [163/750], Loss: 0.1943\n",
      "Epoch [4/10], Step [164/750], Loss: 0.1242\n",
      "Epoch [4/10], Step [165/750], Loss: 0.0221\n",
      "Epoch [4/10], Step [166/750], Loss: 0.0369\n",
      "Epoch [4/10], Step [167/750], Loss: 0.1053\n",
      "Epoch [4/10], Step [168/750], Loss: 0.0621\n",
      "Epoch [4/10], Step [169/750], Loss: 0.0625\n",
      "Epoch [4/10], Step [170/750], Loss: 0.0867\n",
      "Epoch [4/10], Step [171/750], Loss: 0.0348\n",
      "Epoch [4/10], Step [172/750], Loss: 0.0504\n",
      "Epoch [4/10], Step [173/750], Loss: 0.0916\n",
      "Epoch [4/10], Step [174/750], Loss: 0.1000\n",
      "Epoch [4/10], Step [175/750], Loss: 0.0660\n",
      "Epoch [4/10], Step [176/750], Loss: 0.0139\n",
      "Epoch [4/10], Step [177/750], Loss: 0.0239\n",
      "Epoch [4/10], Step [178/750], Loss: 0.1195\n",
      "Epoch [4/10], Step [179/750], Loss: 0.0164\n",
      "Epoch [4/10], Step [180/750], Loss: 0.0344\n",
      "Epoch [4/10], Step [181/750], Loss: 0.1030\n",
      "Epoch [4/10], Step [182/750], Loss: 0.1326\n",
      "Epoch [4/10], Step [183/750], Loss: 0.0716\n",
      "Epoch [4/10], Step [184/750], Loss: 0.1009\n",
      "Epoch [4/10], Step [185/750], Loss: 0.1069\n",
      "Epoch [4/10], Step [186/750], Loss: 0.1469\n",
      "Epoch [4/10], Step [187/750], Loss: 0.0956\n",
      "Epoch [4/10], Step [188/750], Loss: 0.0209\n",
      "Epoch [4/10], Step [189/750], Loss: 0.0940\n",
      "Epoch [4/10], Step [190/750], Loss: 0.0268\n",
      "Epoch [4/10], Step [191/750], Loss: 0.0968\n",
      "Epoch [4/10], Step [192/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [193/750], Loss: 0.0912\n",
      "Epoch [4/10], Step [194/750], Loss: 0.1376\n",
      "Epoch [4/10], Step [195/750], Loss: 0.1002\n",
      "Epoch [4/10], Step [196/750], Loss: 0.0489\n",
      "Epoch [4/10], Step [197/750], Loss: 0.0261\n",
      "Epoch [4/10], Step [198/750], Loss: 0.1347\n",
      "Epoch [4/10], Step [199/750], Loss: 0.0606\n",
      "Epoch [4/10], Step [200/750], Loss: 0.0504\n",
      "Epoch [4/10], Step [201/750], Loss: 0.0832\n",
      "Epoch [4/10], Step [202/750], Loss: 0.0268\n",
      "Epoch [4/10], Step [203/750], Loss: 0.1388\n",
      "Epoch [4/10], Step [204/750], Loss: 0.0179\n",
      "Epoch [4/10], Step [205/750], Loss: 0.0303\n",
      "Epoch [4/10], Step [206/750], Loss: 0.0735\n",
      "Epoch [4/10], Step [207/750], Loss: 0.0442\n",
      "Epoch [4/10], Step [208/750], Loss: 0.0385\n",
      "Epoch [4/10], Step [209/750], Loss: 0.1115\n",
      "Epoch [4/10], Step [210/750], Loss: 0.0718\n",
      "Epoch [4/10], Step [211/750], Loss: 0.1708\n",
      "Epoch [4/10], Step [212/750], Loss: 0.1198\n",
      "Epoch [4/10], Step [213/750], Loss: 0.0935\n",
      "Epoch [4/10], Step [214/750], Loss: 0.0293\n",
      "Epoch [4/10], Step [215/750], Loss: 0.0403\n",
      "Epoch [4/10], Step [216/750], Loss: 0.1196\n",
      "Epoch [4/10], Step [217/750], Loss: 0.0901\n",
      "Epoch [4/10], Step [218/750], Loss: 0.0990\n",
      "Epoch [4/10], Step [219/750], Loss: 0.1630\n",
      "Epoch [4/10], Step [220/750], Loss: 0.0603\n",
      "Epoch [4/10], Step [221/750], Loss: 0.0561\n",
      "Epoch [4/10], Step [222/750], Loss: 0.0464\n",
      "Epoch [4/10], Step [223/750], Loss: 0.0826\n",
      "Epoch [4/10], Step [224/750], Loss: 0.0561\n",
      "Epoch [4/10], Step [225/750], Loss: 0.0288\n",
      "Epoch [4/10], Step [226/750], Loss: 0.0326\n",
      "Epoch [4/10], Step [227/750], Loss: 0.0517\n",
      "Epoch [4/10], Step [228/750], Loss: 0.0798\n",
      "Epoch [4/10], Step [229/750], Loss: 0.0403\n",
      "Epoch [4/10], Step [230/750], Loss: 0.0331\n",
      "Epoch [4/10], Step [231/750], Loss: 0.1006\n",
      "Epoch [4/10], Step [232/750], Loss: 0.1039\n",
      "Epoch [4/10], Step [233/750], Loss: 0.0939\n",
      "Epoch [4/10], Step [234/750], Loss: 0.0079\n",
      "Epoch [4/10], Step [235/750], Loss: 0.0086\n",
      "Epoch [4/10], Step [236/750], Loss: 0.1168\n",
      "Epoch [4/10], Step [237/750], Loss: 0.1124\n",
      "Epoch [4/10], Step [238/750], Loss: 0.0550\n",
      "Epoch [4/10], Step [239/750], Loss: 0.0796\n",
      "Epoch [4/10], Step [240/750], Loss: 0.0633\n",
      "Epoch [4/10], Step [241/750], Loss: 0.0323\n",
      "Epoch [4/10], Step [242/750], Loss: 0.0347\n",
      "Epoch [4/10], Step [243/750], Loss: 0.0072\n",
      "Epoch [4/10], Step [244/750], Loss: 0.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [245/750], Loss: 0.0341\n",
      "Epoch [4/10], Step [246/750], Loss: 0.1054\n",
      "Epoch [4/10], Step [247/750], Loss: 0.0167\n",
      "Epoch [4/10], Step [248/750], Loss: 0.0298\n",
      "Epoch [4/10], Step [249/750], Loss: 0.0383\n",
      "Epoch [4/10], Step [250/750], Loss: 0.0439\n",
      "Epoch [4/10], Step [251/750], Loss: 0.1084\n",
      "Epoch [4/10], Step [252/750], Loss: 0.0719\n",
      "Epoch [4/10], Step [253/750], Loss: 0.0494\n",
      "Epoch [4/10], Step [254/750], Loss: 0.0708\n",
      "Epoch [4/10], Step [255/750], Loss: 0.0231\n",
      "Epoch [4/10], Step [256/750], Loss: 0.0529\n",
      "Epoch [4/10], Step [257/750], Loss: 0.1130\n",
      "Epoch [4/10], Step [258/750], Loss: 0.0455\n",
      "Epoch [4/10], Step [259/750], Loss: 0.0902\n",
      "Epoch [4/10], Step [260/750], Loss: 0.0311\n",
      "Epoch [4/10], Step [261/750], Loss: 0.0317\n",
      "Epoch [4/10], Step [262/750], Loss: 0.0601\n",
      "Epoch [4/10], Step [263/750], Loss: 0.0546\n",
      "Epoch [4/10], Step [264/750], Loss: 0.0037\n",
      "Epoch [4/10], Step [265/750], Loss: 0.0791\n",
      "Epoch [4/10], Step [266/750], Loss: 0.0182\n",
      "Epoch [4/10], Step [267/750], Loss: 0.1722\n",
      "Epoch [4/10], Step [268/750], Loss: 0.0064\n",
      "Epoch [4/10], Step [269/750], Loss: 0.0799\n",
      "Epoch [4/10], Step [270/750], Loss: 0.1593\n",
      "Epoch [4/10], Step [271/750], Loss: 0.0392\n",
      "Epoch [4/10], Step [272/750], Loss: 0.0337\n",
      "Epoch [4/10], Step [273/750], Loss: 0.0466\n",
      "Epoch [4/10], Step [274/750], Loss: 0.0146\n",
      "Epoch [4/10], Step [275/750], Loss: 0.1214\n",
      "Epoch [4/10], Step [276/750], Loss: 0.0683\n",
      "Epoch [4/10], Step [277/750], Loss: 0.1247\n",
      "Epoch [4/10], Step [278/750], Loss: 0.0709\n",
      "Epoch [4/10], Step [279/750], Loss: 0.1863\n",
      "Epoch [4/10], Step [280/750], Loss: 0.0507\n",
      "Epoch [4/10], Step [281/750], Loss: 0.0525\n",
      "Epoch [4/10], Step [282/750], Loss: 0.0169\n",
      "Epoch [4/10], Step [283/750], Loss: 0.0945\n",
      "Epoch [4/10], Step [284/750], Loss: 0.1579\n",
      "Epoch [4/10], Step [285/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [286/750], Loss: 0.1238\n",
      "Epoch [4/10], Step [287/750], Loss: 0.2458\n",
      "Epoch [4/10], Step [288/750], Loss: 0.1384\n",
      "Epoch [4/10], Step [289/750], Loss: 0.0867\n",
      "Epoch [4/10], Step [290/750], Loss: 0.0800\n",
      "Epoch [4/10], Step [291/750], Loss: 0.0345\n",
      "Epoch [4/10], Step [292/750], Loss: 0.1783\n",
      "Epoch [4/10], Step [293/750], Loss: 0.1095\n",
      "Epoch [4/10], Step [294/750], Loss: 0.0738\n",
      "Epoch [4/10], Step [295/750], Loss: 0.0155\n",
      "Epoch [4/10], Step [296/750], Loss: 0.0127\n",
      "Epoch [4/10], Step [297/750], Loss: 0.0492\n",
      "Epoch [4/10], Step [298/750], Loss: 0.0451\n",
      "Epoch [4/10], Step [299/750], Loss: 0.2060\n",
      "Epoch [4/10], Step [300/750], Loss: 0.1244\n",
      "Epoch [4/10], Step [301/750], Loss: 0.0702\n",
      "Epoch [4/10], Step [302/750], Loss: 0.0868\n",
      "Epoch [4/10], Step [303/750], Loss: 0.0396\n",
      "Epoch [4/10], Step [304/750], Loss: 0.0478\n",
      "Epoch [4/10], Step [305/750], Loss: 0.0379\n",
      "Epoch [4/10], Step [306/750], Loss: 0.0704\n",
      "Epoch [4/10], Step [307/750], Loss: 0.0387\n",
      "Epoch [4/10], Step [308/750], Loss: 0.0817\n",
      "Epoch [4/10], Step [309/750], Loss: 0.1031\n",
      "Epoch [4/10], Step [310/750], Loss: 0.0394\n",
      "Epoch [4/10], Step [311/750], Loss: 0.1296\n",
      "Epoch [4/10], Step [312/750], Loss: 0.0712\n",
      "Epoch [4/10], Step [313/750], Loss: 0.0187\n",
      "Epoch [4/10], Step [314/750], Loss: 0.0220\n",
      "Epoch [4/10], Step [315/750], Loss: 0.0359\n",
      "Epoch [4/10], Step [316/750], Loss: 0.0241\n",
      "Epoch [4/10], Step [317/750], Loss: 0.0383\n",
      "Epoch [4/10], Step [318/750], Loss: 0.0794\n",
      "Epoch [4/10], Step [319/750], Loss: 0.0072\n",
      "Epoch [4/10], Step [320/750], Loss: 0.0959\n",
      "Epoch [4/10], Step [321/750], Loss: 0.0381\n",
      "Epoch [4/10], Step [322/750], Loss: 0.0754\n",
      "Epoch [4/10], Step [323/750], Loss: 0.0241\n",
      "Epoch [4/10], Step [324/750], Loss: 0.0912\n",
      "Epoch [4/10], Step [325/750], Loss: 0.1211\n",
      "Epoch [4/10], Step [326/750], Loss: 0.0424\n",
      "Epoch [4/10], Step [327/750], Loss: 0.0388\n",
      "Epoch [4/10], Step [328/750], Loss: 0.0636\n",
      "Epoch [4/10], Step [329/750], Loss: 0.0248\n",
      "Epoch [4/10], Step [330/750], Loss: 0.0279\n",
      "Epoch [4/10], Step [331/750], Loss: 0.0852\n",
      "Epoch [4/10], Step [332/750], Loss: 0.0657\n",
      "Epoch [4/10], Step [333/750], Loss: 0.0763\n",
      "Epoch [4/10], Step [334/750], Loss: 0.0690\n",
      "Epoch [4/10], Step [335/750], Loss: 0.1313\n",
      "Epoch [4/10], Step [336/750], Loss: 0.1432\n",
      "Epoch [4/10], Step [337/750], Loss: 0.0054\n",
      "Epoch [4/10], Step [338/750], Loss: 0.0611\n",
      "Epoch [4/10], Step [339/750], Loss: 0.1124\n",
      "Epoch [4/10], Step [340/750], Loss: 0.0210\n",
      "Epoch [4/10], Step [341/750], Loss: 0.1409\n",
      "Epoch [4/10], Step [342/750], Loss: 0.1512\n",
      "Epoch [4/10], Step [343/750], Loss: 0.0188\n",
      "Epoch [4/10], Step [344/750], Loss: 0.1001\n",
      "Epoch [4/10], Step [345/750], Loss: 0.0222\n",
      "Epoch [4/10], Step [346/750], Loss: 0.0743\n",
      "Epoch [4/10], Step [347/750], Loss: 0.0498\n",
      "Epoch [4/10], Step [348/750], Loss: 0.0439\n",
      "Epoch [4/10], Step [349/750], Loss: 0.0404\n",
      "Epoch [4/10], Step [350/750], Loss: 0.0570\n",
      "Epoch [4/10], Step [351/750], Loss: 0.0426\n",
      "Epoch [4/10], Step [352/750], Loss: 0.0834\n",
      "Epoch [4/10], Step [353/750], Loss: 0.0990\n",
      "Epoch [4/10], Step [354/750], Loss: 0.0470\n",
      "Epoch [4/10], Step [355/750], Loss: 0.0263\n",
      "Epoch [4/10], Step [356/750], Loss: 0.0438\n",
      "Epoch [4/10], Step [357/750], Loss: 0.0630\n",
      "Epoch [4/10], Step [358/750], Loss: 0.0921\n",
      "Epoch [4/10], Step [359/750], Loss: 0.0236\n",
      "Epoch [4/10], Step [360/750], Loss: 0.1066\n",
      "Epoch [4/10], Step [361/750], Loss: 0.0716\n",
      "Epoch [4/10], Step [362/750], Loss: 0.1569\n",
      "Epoch [4/10], Step [363/750], Loss: 0.0688\n",
      "Epoch [4/10], Step [364/750], Loss: 0.0577\n",
      "Epoch [4/10], Step [365/750], Loss: 0.0415\n",
      "Epoch [4/10], Step [366/750], Loss: 0.0904\n",
      "Epoch [4/10], Step [367/750], Loss: 0.0636\n",
      "Epoch [4/10], Step [368/750], Loss: 0.0393\n",
      "Epoch [4/10], Step [369/750], Loss: 0.0615\n",
      "Epoch [4/10], Step [370/750], Loss: 0.0501\n",
      "Epoch [4/10], Step [371/750], Loss: 0.0595\n",
      "Epoch [4/10], Step [372/750], Loss: 0.0845\n",
      "Epoch [4/10], Step [373/750], Loss: 0.0214\n",
      "Epoch [4/10], Step [374/750], Loss: 0.0958\n",
      "Epoch [4/10], Step [375/750], Loss: 0.0760\n",
      "Epoch [4/10], Step [376/750], Loss: 0.0470\n",
      "Epoch [4/10], Step [377/750], Loss: 0.0983\n",
      "Epoch [4/10], Step [378/750], Loss: 0.1042\n",
      "Epoch [4/10], Step [379/750], Loss: 0.0780\n",
      "Epoch [4/10], Step [380/750], Loss: 0.0648\n",
      "Epoch [4/10], Step [381/750], Loss: 0.0368\n",
      "Epoch [4/10], Step [382/750], Loss: 0.0415\n",
      "Epoch [4/10], Step [383/750], Loss: 0.1255\n",
      "Epoch [4/10], Step [384/750], Loss: 0.0494\n",
      "Epoch [4/10], Step [385/750], Loss: 0.1131\n",
      "Epoch [4/10], Step [386/750], Loss: 0.0447\n",
      "Epoch [4/10], Step [387/750], Loss: 0.0830\n",
      "Epoch [4/10], Step [388/750], Loss: 0.0791\n",
      "Epoch [4/10], Step [389/750], Loss: 0.1932\n",
      "Epoch [4/10], Step [390/750], Loss: 0.1913\n",
      "Epoch [4/10], Step [391/750], Loss: 0.2330\n",
      "Epoch [4/10], Step [392/750], Loss: 0.0209\n",
      "Epoch [4/10], Step [393/750], Loss: 0.0254\n",
      "Epoch [4/10], Step [394/750], Loss: 0.1755\n",
      "Epoch [4/10], Step [395/750], Loss: 0.0333\n",
      "Epoch [4/10], Step [396/750], Loss: 0.0764\n",
      "Epoch [4/10], Step [397/750], Loss: 0.0326\n",
      "Epoch [4/10], Step [398/750], Loss: 0.0830\n",
      "Epoch [4/10], Step [399/750], Loss: 0.0541\n",
      "Epoch [4/10], Step [400/750], Loss: 0.0593\n",
      "Epoch [4/10], Step [401/750], Loss: 0.0415\n",
      "Epoch [4/10], Step [402/750], Loss: 0.1490\n",
      "Epoch [4/10], Step [403/750], Loss: 0.0086\n",
      "Epoch [4/10], Step [404/750], Loss: 0.0268\n",
      "Epoch [4/10], Step [405/750], Loss: 0.1186\n",
      "Epoch [4/10], Step [406/750], Loss: 0.0776\n",
      "Epoch [4/10], Step [407/750], Loss: 0.0798\n",
      "Epoch [4/10], Step [408/750], Loss: 0.0480\n",
      "Epoch [4/10], Step [409/750], Loss: 0.0292\n",
      "Epoch [4/10], Step [410/750], Loss: 0.1415\n",
      "Epoch [4/10], Step [411/750], Loss: 0.0594\n",
      "Epoch [4/10], Step [412/750], Loss: 0.1911\n",
      "Epoch [4/10], Step [413/750], Loss: 0.0718\n",
      "Epoch [4/10], Step [414/750], Loss: 0.1392\n",
      "Epoch [4/10], Step [415/750], Loss: 0.0805\n",
      "Epoch [4/10], Step [416/750], Loss: 0.0555\n",
      "Epoch [4/10], Step [417/750], Loss: 0.1197\n",
      "Epoch [4/10], Step [418/750], Loss: 0.0845\n",
      "Epoch [4/10], Step [419/750], Loss: 0.1430\n",
      "Epoch [4/10], Step [420/750], Loss: 0.1699\n",
      "Epoch [4/10], Step [421/750], Loss: 0.0927\n",
      "Epoch [4/10], Step [422/750], Loss: 0.0326\n",
      "Epoch [4/10], Step [423/750], Loss: 0.0320\n",
      "Epoch [4/10], Step [424/750], Loss: 0.0213\n",
      "Epoch [4/10], Step [425/750], Loss: 0.0447\n",
      "Epoch [4/10], Step [426/750], Loss: 0.1212\n",
      "Epoch [4/10], Step [427/750], Loss: 0.0363\n",
      "Epoch [4/10], Step [428/750], Loss: 0.1240\n",
      "Epoch [4/10], Step [429/750], Loss: 0.0432\n",
      "Epoch [4/10], Step [430/750], Loss: 0.0443\n",
      "Epoch [4/10], Step [431/750], Loss: 0.0747\n",
      "Epoch [4/10], Step [432/750], Loss: 0.2382\n",
      "Epoch [4/10], Step [433/750], Loss: 0.0177\n",
      "Epoch [4/10], Step [434/750], Loss: 0.0629\n",
      "Epoch [4/10], Step [435/750], Loss: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [436/750], Loss: 0.0339\n",
      "Epoch [4/10], Step [437/750], Loss: 0.0351\n",
      "Epoch [4/10], Step [438/750], Loss: 0.0585\n",
      "Epoch [4/10], Step [439/750], Loss: 0.0400\n",
      "Epoch [4/10], Step [440/750], Loss: 0.1338\n",
      "Epoch [4/10], Step [441/750], Loss: 0.0442\n",
      "Epoch [4/10], Step [442/750], Loss: 0.0862\n",
      "Epoch [4/10], Step [443/750], Loss: 0.0107\n",
      "Epoch [4/10], Step [444/750], Loss: 0.0418\n",
      "Epoch [4/10], Step [445/750], Loss: 0.0233\n",
      "Epoch [4/10], Step [446/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [447/750], Loss: 0.0701\n",
      "Epoch [4/10], Step [448/750], Loss: 0.1420\n",
      "Epoch [4/10], Step [449/750], Loss: 0.0276\n",
      "Epoch [4/10], Step [450/750], Loss: 0.0435\n",
      "Epoch [4/10], Step [451/750], Loss: 0.1216\n",
      "Epoch [4/10], Step [452/750], Loss: 0.0458\n",
      "Epoch [4/10], Step [453/750], Loss: 0.1182\n",
      "Epoch [4/10], Step [454/750], Loss: 0.0283\n",
      "Epoch [4/10], Step [455/750], Loss: 0.0081\n",
      "Epoch [4/10], Step [456/750], Loss: 0.0383\n",
      "Epoch [4/10], Step [457/750], Loss: 0.0208\n",
      "Epoch [4/10], Step [458/750], Loss: 0.1644\n",
      "Epoch [4/10], Step [459/750], Loss: 0.0651\n",
      "Epoch [4/10], Step [460/750], Loss: 0.0167\n",
      "Epoch [4/10], Step [461/750], Loss: 0.1122\n",
      "Epoch [4/10], Step [462/750], Loss: 0.1191\n",
      "Epoch [4/10], Step [463/750], Loss: 0.0287\n",
      "Epoch [4/10], Step [464/750], Loss: 0.1157\n",
      "Epoch [4/10], Step [465/750], Loss: 0.0350\n",
      "Epoch [4/10], Step [466/750], Loss: 0.0245\n",
      "Epoch [4/10], Step [467/750], Loss: 0.0223\n",
      "Epoch [4/10], Step [468/750], Loss: 0.0586\n",
      "Epoch [4/10], Step [469/750], Loss: 0.0884\n",
      "Epoch [4/10], Step [470/750], Loss: 0.0921\n",
      "Epoch [4/10], Step [471/750], Loss: 0.1199\n",
      "Epoch [4/10], Step [472/750], Loss: 0.0998\n",
      "Epoch [4/10], Step [473/750], Loss: 0.0997\n",
      "Epoch [4/10], Step [474/750], Loss: 0.0372\n",
      "Epoch [4/10], Step [475/750], Loss: 0.0122\n",
      "Epoch [4/10], Step [476/750], Loss: 0.0820\n",
      "Epoch [4/10], Step [477/750], Loss: 0.0294\n",
      "Epoch [4/10], Step [478/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [479/750], Loss: 0.0335\n",
      "Epoch [4/10], Step [480/750], Loss: 0.0420\n",
      "Epoch [4/10], Step [481/750], Loss: 0.0221\n",
      "Epoch [4/10], Step [482/750], Loss: 0.1437\n",
      "Epoch [4/10], Step [483/750], Loss: 0.1922\n",
      "Epoch [4/10], Step [484/750], Loss: 0.1171\n",
      "Epoch [4/10], Step [485/750], Loss: 0.0299\n",
      "Epoch [4/10], Step [486/750], Loss: 0.1324\n",
      "Epoch [4/10], Step [487/750], Loss: 0.0412\n",
      "Epoch [4/10], Step [488/750], Loss: 0.1017\n",
      "Epoch [4/10], Step [489/750], Loss: 0.1435\n",
      "Epoch [4/10], Step [490/750], Loss: 0.2560\n",
      "Epoch [4/10], Step [491/750], Loss: 0.3884\n",
      "Epoch [4/10], Step [492/750], Loss: 0.0236\n",
      "Epoch [4/10], Step [493/750], Loss: 0.0969\n",
      "Epoch [4/10], Step [494/750], Loss: 0.2087\n",
      "Epoch [4/10], Step [495/750], Loss: 0.1390\n",
      "Epoch [4/10], Step [496/750], Loss: 0.1162\n",
      "Epoch [4/10], Step [497/750], Loss: 0.0330\n",
      "Epoch [4/10], Step [498/750], Loss: 0.0531\n",
      "Epoch [4/10], Step [499/750], Loss: 0.1070\n",
      "Epoch [4/10], Step [500/750], Loss: 0.0626\n",
      "Epoch [4/10], Step [501/750], Loss: 0.0918\n",
      "Epoch [4/10], Step [502/750], Loss: 0.0852\n",
      "Epoch [4/10], Step [503/750], Loss: 0.0361\n",
      "Epoch [4/10], Step [504/750], Loss: 0.0357\n",
      "Epoch [4/10], Step [505/750], Loss: 0.0203\n",
      "Epoch [4/10], Step [506/750], Loss: 0.0146\n",
      "Epoch [4/10], Step [507/750], Loss: 0.1788\n",
      "Epoch [4/10], Step [508/750], Loss: 0.1303\n",
      "Epoch [4/10], Step [509/750], Loss: 0.2044\n",
      "Epoch [4/10], Step [510/750], Loss: 0.0424\n",
      "Epoch [4/10], Step [511/750], Loss: 0.0489\n",
      "Epoch [4/10], Step [512/750], Loss: 0.0358\n",
      "Epoch [4/10], Step [513/750], Loss: 0.0439\n",
      "Epoch [4/10], Step [514/750], Loss: 0.2345\n",
      "Epoch [4/10], Step [515/750], Loss: 0.0749\n",
      "Epoch [4/10], Step [516/750], Loss: 0.0876\n",
      "Epoch [4/10], Step [517/750], Loss: 0.0933\n",
      "Epoch [4/10], Step [518/750], Loss: 0.0299\n",
      "Epoch [4/10], Step [519/750], Loss: 0.0704\n",
      "Epoch [4/10], Step [520/750], Loss: 0.0181\n",
      "Epoch [4/10], Step [521/750], Loss: 0.0787\n",
      "Epoch [4/10], Step [522/750], Loss: 0.0154\n",
      "Epoch [4/10], Step [523/750], Loss: 0.0518\n",
      "Epoch [4/10], Step [524/750], Loss: 0.0142\n",
      "Epoch [4/10], Step [525/750], Loss: 0.0601\n",
      "Epoch [4/10], Step [526/750], Loss: 0.1260\n",
      "Epoch [4/10], Step [527/750], Loss: 0.1572\n",
      "Epoch [4/10], Step [528/750], Loss: 0.0223\n",
      "Epoch [4/10], Step [529/750], Loss: 0.0118\n",
      "Epoch [4/10], Step [530/750], Loss: 0.0891\n",
      "Epoch [4/10], Step [531/750], Loss: 0.0724\n",
      "Epoch [4/10], Step [532/750], Loss: 0.0556\n",
      "Epoch [4/10], Step [533/750], Loss: 0.0314\n",
      "Epoch [4/10], Step [534/750], Loss: 0.1519\n",
      "Epoch [4/10], Step [535/750], Loss: 0.0733\n",
      "Epoch [4/10], Step [536/750], Loss: 0.0185\n",
      "Epoch [4/10], Step [537/750], Loss: 0.0973\n",
      "Epoch [4/10], Step [538/750], Loss: 0.0258\n",
      "Epoch [4/10], Step [539/750], Loss: 0.0243\n",
      "Epoch [4/10], Step [540/750], Loss: 0.0654\n",
      "Epoch [4/10], Step [541/750], Loss: 0.0404\n",
      "Epoch [4/10], Step [542/750], Loss: 0.1498\n",
      "Epoch [4/10], Step [543/750], Loss: 0.0044\n",
      "Epoch [4/10], Step [544/750], Loss: 0.0567\n",
      "Epoch [4/10], Step [545/750], Loss: 0.0224\n",
      "Epoch [4/10], Step [546/750], Loss: 0.0848\n",
      "Epoch [4/10], Step [547/750], Loss: 0.1968\n",
      "Epoch [4/10], Step [548/750], Loss: 0.0716\n",
      "Epoch [4/10], Step [549/750], Loss: 0.0190\n",
      "Epoch [4/10], Step [550/750], Loss: 0.0096\n",
      "Epoch [4/10], Step [551/750], Loss: 0.0488\n",
      "Epoch [4/10], Step [552/750], Loss: 0.1333\n",
      "Epoch [4/10], Step [553/750], Loss: 0.0560\n",
      "Epoch [4/10], Step [554/750], Loss: 0.0497\n",
      "Epoch [4/10], Step [555/750], Loss: 0.0677\n",
      "Epoch [4/10], Step [556/750], Loss: 0.0784\n",
      "Epoch [4/10], Step [557/750], Loss: 0.0090\n",
      "Epoch [4/10], Step [558/750], Loss: 0.0216\n",
      "Epoch [4/10], Step [559/750], Loss: 0.0464\n",
      "Epoch [4/10], Step [560/750], Loss: 0.0552\n",
      "Epoch [4/10], Step [561/750], Loss: 0.0194\n",
      "Epoch [4/10], Step [562/750], Loss: 0.0704\n",
      "Epoch [4/10], Step [563/750], Loss: 0.0950\n",
      "Epoch [4/10], Step [564/750], Loss: 0.0329\n",
      "Epoch [4/10], Step [565/750], Loss: 0.0277\n",
      "Epoch [4/10], Step [566/750], Loss: 0.0386\n",
      "Epoch [4/10], Step [567/750], Loss: 0.0148\n",
      "Epoch [4/10], Step [568/750], Loss: 0.2256\n",
      "Epoch [4/10], Step [569/750], Loss: 0.1015\n",
      "Epoch [4/10], Step [570/750], Loss: 0.1135\n",
      "Epoch [4/10], Step [571/750], Loss: 0.0593\n",
      "Epoch [4/10], Step [572/750], Loss: 0.0132\n",
      "Epoch [4/10], Step [573/750], Loss: 0.1075\n",
      "Epoch [4/10], Step [574/750], Loss: 0.0739\n",
      "Epoch [4/10], Step [575/750], Loss: 0.0145\n",
      "Epoch [4/10], Step [576/750], Loss: 0.0670\n",
      "Epoch [4/10], Step [577/750], Loss: 0.1554\n",
      "Epoch [4/10], Step [578/750], Loss: 0.0632\n",
      "Epoch [4/10], Step [579/750], Loss: 0.0348\n",
      "Epoch [4/10], Step [580/750], Loss: 0.0632\n",
      "Epoch [4/10], Step [581/750], Loss: 0.0504\n",
      "Epoch [4/10], Step [582/750], Loss: 0.1015\n",
      "Epoch [4/10], Step [583/750], Loss: 0.1071\n",
      "Epoch [4/10], Step [584/750], Loss: 0.0620\n",
      "Epoch [4/10], Step [585/750], Loss: 0.0571\n",
      "Epoch [4/10], Step [586/750], Loss: 0.0768\n",
      "Epoch [4/10], Step [587/750], Loss: 0.0346\n",
      "Epoch [4/10], Step [588/750], Loss: 0.0399\n",
      "Epoch [4/10], Step [589/750], Loss: 0.0309\n",
      "Epoch [4/10], Step [590/750], Loss: 0.0214\n",
      "Epoch [4/10], Step [591/750], Loss: 0.1510\n",
      "Epoch [4/10], Step [592/750], Loss: 0.0582\n",
      "Epoch [4/10], Step [593/750], Loss: 0.0581\n",
      "Epoch [4/10], Step [594/750], Loss: 0.0592\n",
      "Epoch [4/10], Step [595/750], Loss: 0.0569\n",
      "Epoch [4/10], Step [596/750], Loss: 0.0710\n",
      "Epoch [4/10], Step [597/750], Loss: 0.0996\n",
      "Epoch [4/10], Step [598/750], Loss: 0.1078\n",
      "Epoch [4/10], Step [599/750], Loss: 0.1116\n",
      "Epoch [4/10], Step [600/750], Loss: 0.0324\n",
      "Epoch [4/10], Step [601/750], Loss: 0.0160\n",
      "Epoch [4/10], Step [602/750], Loss: 0.0758\n",
      "Epoch [4/10], Step [603/750], Loss: 0.0398\n",
      "Epoch [4/10], Step [604/750], Loss: 0.0872\n",
      "Epoch [4/10], Step [605/750], Loss: 0.0302\n",
      "Epoch [4/10], Step [606/750], Loss: 0.1254\n",
      "Epoch [4/10], Step [607/750], Loss: 0.0148\n",
      "Epoch [4/10], Step [608/750], Loss: 0.0193\n",
      "Epoch [4/10], Step [609/750], Loss: 0.1307\n",
      "Epoch [4/10], Step [610/750], Loss: 0.1075\n",
      "Epoch [4/10], Step [611/750], Loss: 0.0089\n",
      "Epoch [4/10], Step [612/750], Loss: 0.2214\n",
      "Epoch [4/10], Step [613/750], Loss: 0.0503\n",
      "Epoch [4/10], Step [614/750], Loss: 0.0292\n",
      "Epoch [4/10], Step [615/750], Loss: 0.0530\n",
      "Epoch [4/10], Step [616/750], Loss: 0.0204\n",
      "Epoch [4/10], Step [617/750], Loss: 0.1510\n",
      "Epoch [4/10], Step [618/750], Loss: 0.1828\n",
      "Epoch [4/10], Step [619/750], Loss: 0.0165\n",
      "Epoch [4/10], Step [620/750], Loss: 0.1652\n",
      "Epoch [4/10], Step [621/750], Loss: 0.0268\n",
      "Epoch [4/10], Step [622/750], Loss: 0.1061\n",
      "Epoch [4/10], Step [623/750], Loss: 0.0211\n",
      "Epoch [4/10], Step [624/750], Loss: 0.0778\n",
      "Epoch [4/10], Step [625/750], Loss: 0.0226\n",
      "Epoch [4/10], Step [626/750], Loss: 0.0635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [627/750], Loss: 0.0718\n",
      "Epoch [4/10], Step [628/750], Loss: 0.0498\n",
      "Epoch [4/10], Step [629/750], Loss: 0.0972\n",
      "Epoch [4/10], Step [630/750], Loss: 0.0535\n",
      "Epoch [4/10], Step [631/750], Loss: 0.0165\n",
      "Epoch [4/10], Step [632/750], Loss: 0.0103\n",
      "Epoch [4/10], Step [633/750], Loss: 0.0725\n",
      "Epoch [4/10], Step [634/750], Loss: 0.0090\n",
      "Epoch [4/10], Step [635/750], Loss: 0.0108\n",
      "Epoch [4/10], Step [636/750], Loss: 0.1171\n",
      "Epoch [4/10], Step [637/750], Loss: 0.0476\n",
      "Epoch [4/10], Step [638/750], Loss: 0.0780\n",
      "Epoch [4/10], Step [639/750], Loss: 0.2204\n",
      "Epoch [4/10], Step [640/750], Loss: 0.0590\n",
      "Epoch [4/10], Step [641/750], Loss: 0.1360\n",
      "Epoch [4/10], Step [642/750], Loss: 0.0419\n",
      "Epoch [4/10], Step [643/750], Loss: 0.1596\n",
      "Epoch [4/10], Step [644/750], Loss: 0.0929\n",
      "Epoch [4/10], Step [645/750], Loss: 0.0615\n",
      "Epoch [4/10], Step [646/750], Loss: 0.0777\n",
      "Epoch [4/10], Step [647/750], Loss: 0.2229\n",
      "Epoch [4/10], Step [648/750], Loss: 0.0485\n",
      "Epoch [4/10], Step [649/750], Loss: 0.0942\n",
      "Epoch [4/10], Step [650/750], Loss: 0.0173\n",
      "Epoch [4/10], Step [651/750], Loss: 0.0403\n",
      "Epoch [4/10], Step [652/750], Loss: 0.0155\n",
      "Epoch [4/10], Step [653/750], Loss: 0.1721\n",
      "Epoch [4/10], Step [654/750], Loss: 0.0447\n",
      "Epoch [4/10], Step [655/750], Loss: 0.0206\n",
      "Epoch [4/10], Step [656/750], Loss: 0.1103\n",
      "Epoch [4/10], Step [657/750], Loss: 0.2011\n",
      "Epoch [4/10], Step [658/750], Loss: 0.1392\n",
      "Epoch [4/10], Step [659/750], Loss: 0.0507\n",
      "Epoch [4/10], Step [660/750], Loss: 0.0339\n",
      "Epoch [4/10], Step [661/750], Loss: 0.0857\n",
      "Epoch [4/10], Step [662/750], Loss: 0.0568\n",
      "Epoch [4/10], Step [663/750], Loss: 0.0713\n",
      "Epoch [4/10], Step [664/750], Loss: 0.0560\n",
      "Epoch [4/10], Step [665/750], Loss: 0.0306\n",
      "Epoch [4/10], Step [666/750], Loss: 0.0721\n",
      "Epoch [4/10], Step [667/750], Loss: 0.1324\n",
      "Epoch [4/10], Step [668/750], Loss: 0.1553\n",
      "Epoch [4/10], Step [669/750], Loss: 0.0982\n",
      "Epoch [4/10], Step [670/750], Loss: 0.0936\n",
      "Epoch [4/10], Step [671/750], Loss: 0.0735\n",
      "Epoch [4/10], Step [672/750], Loss: 0.0807\n",
      "Epoch [4/10], Step [673/750], Loss: 0.1193\n",
      "Epoch [4/10], Step [674/750], Loss: 0.0166\n",
      "Epoch [4/10], Step [675/750], Loss: 0.1702\n",
      "Epoch [4/10], Step [676/750], Loss: 0.1925\n",
      "Epoch [4/10], Step [677/750], Loss: 0.0632\n",
      "Epoch [4/10], Step [678/750], Loss: 0.0408\n",
      "Epoch [4/10], Step [679/750], Loss: 0.0920\n",
      "Epoch [4/10], Step [680/750], Loss: 0.0211\n",
      "Epoch [4/10], Step [681/750], Loss: 0.1534\n",
      "Epoch [4/10], Step [682/750], Loss: 0.0492\n",
      "Epoch [4/10], Step [683/750], Loss: 0.0573\n",
      "Epoch [4/10], Step [684/750], Loss: 0.0527\n",
      "Epoch [4/10], Step [685/750], Loss: 0.1010\n",
      "Epoch [4/10], Step [686/750], Loss: 0.0985\n",
      "Epoch [4/10], Step [687/750], Loss: 0.0766\n",
      "Epoch [4/10], Step [688/750], Loss: 0.0563\n",
      "Epoch [4/10], Step [689/750], Loss: 0.0901\n",
      "Epoch [4/10], Step [690/750], Loss: 0.0524\n",
      "Epoch [4/10], Step [691/750], Loss: 0.0680\n",
      "Epoch [4/10], Step [692/750], Loss: 0.1476\n",
      "Epoch [4/10], Step [693/750], Loss: 0.2040\n",
      "Epoch [4/10], Step [694/750], Loss: 0.1104\n",
      "Epoch [4/10], Step [695/750], Loss: 0.0260\n",
      "Epoch [4/10], Step [696/750], Loss: 0.0673\n",
      "Epoch [4/10], Step [697/750], Loss: 0.0315\n",
      "Epoch [4/10], Step [698/750], Loss: 0.0686\n",
      "Epoch [4/10], Step [699/750], Loss: 0.0434\n",
      "Epoch [4/10], Step [700/750], Loss: 0.0635\n",
      "Epoch [4/10], Step [701/750], Loss: 0.0893\n",
      "Epoch [4/10], Step [702/750], Loss: 0.1020\n",
      "Epoch [4/10], Step [703/750], Loss: 0.1129\n",
      "Epoch [4/10], Step [704/750], Loss: 0.1360\n",
      "Epoch [4/10], Step [705/750], Loss: 0.0519\n",
      "Epoch [4/10], Step [706/750], Loss: 0.1199\n",
      "Epoch [4/10], Step [707/750], Loss: 0.0403\n",
      "Epoch [4/10], Step [708/750], Loss: 0.1113\n",
      "Epoch [4/10], Step [709/750], Loss: 0.0309\n",
      "Epoch [4/10], Step [710/750], Loss: 0.0391\n",
      "Epoch [4/10], Step [711/750], Loss: 0.0766\n",
      "Epoch [4/10], Step [712/750], Loss: 0.1171\n",
      "Epoch [4/10], Step [713/750], Loss: 0.0624\n",
      "Epoch [4/10], Step [714/750], Loss: 0.0524\n",
      "Epoch [4/10], Step [715/750], Loss: 0.0140\n",
      "Epoch [4/10], Step [716/750], Loss: 0.0464\n",
      "Epoch [4/10], Step [717/750], Loss: 0.0869\n",
      "Epoch [4/10], Step [718/750], Loss: 0.0683\n",
      "Epoch [4/10], Step [719/750], Loss: 0.1269\n",
      "Epoch [4/10], Step [720/750], Loss: 0.0524\n",
      "Epoch [4/10], Step [721/750], Loss: 0.1531\n",
      "Epoch [4/10], Step [722/750], Loss: 0.0548\n",
      "Epoch [4/10], Step [723/750], Loss: 0.1944\n",
      "Epoch [4/10], Step [724/750], Loss: 0.0521\n",
      "Epoch [4/10], Step [725/750], Loss: 0.1098\n",
      "Epoch [4/10], Step [726/750], Loss: 0.0656\n",
      "Epoch [4/10], Step [727/750], Loss: 0.0341\n",
      "Epoch [4/10], Step [728/750], Loss: 0.1045\n",
      "Epoch [4/10], Step [729/750], Loss: 0.1673\n",
      "Epoch [4/10], Step [730/750], Loss: 0.0075\n",
      "Epoch [4/10], Step [731/750], Loss: 0.1423\n",
      "Epoch [4/10], Step [732/750], Loss: 0.1093\n",
      "Epoch [4/10], Step [733/750], Loss: 0.0119\n",
      "Epoch [4/10], Step [734/750], Loss: 0.1054\n",
      "Epoch [4/10], Step [735/750], Loss: 0.0392\n",
      "Epoch [4/10], Step [736/750], Loss: 0.0308\n",
      "Epoch [4/10], Step [737/750], Loss: 0.1359\n",
      "Epoch [4/10], Step [738/750], Loss: 0.0323\n",
      "Epoch [4/10], Step [739/750], Loss: 0.0534\n",
      "Epoch [4/10], Step [740/750], Loss: 0.0485\n",
      "Epoch [4/10], Step [741/750], Loss: 0.0416\n",
      "Epoch [4/10], Step [742/750], Loss: 0.0579\n",
      "Epoch [4/10], Step [743/750], Loss: 0.0477\n",
      "Epoch [4/10], Step [744/750], Loss: 0.0093\n",
      "Epoch [4/10], Step [745/750], Loss: 0.0550\n",
      "Epoch [4/10], Step [746/750], Loss: 0.0678\n",
      "Epoch [4/10], Step [747/750], Loss: 0.0271\n",
      "Epoch [4/10], Step [748/750], Loss: 0.1665\n",
      "Epoch [4/10], Step [749/750], Loss: 0.0920\n",
      "Epoch [4/10], Step [750/750], Loss: 0.0492\n",
      "\n",
      "\n",
      "Epoch [5/10], Step [1/750], Loss: 0.0074\n",
      "Epoch [5/10], Step [2/750], Loss: 0.0277\n",
      "Epoch [5/10], Step [3/750], Loss: 0.0070\n",
      "Epoch [5/10], Step [4/750], Loss: 0.1276\n",
      "Epoch [5/10], Step [5/750], Loss: 0.0655\n",
      "Epoch [5/10], Step [6/750], Loss: 0.0512\n",
      "Epoch [5/10], Step [7/750], Loss: 0.0407\n",
      "Epoch [5/10], Step [8/750], Loss: 0.0587\n",
      "Epoch [5/10], Step [9/750], Loss: 0.1228\n",
      "Epoch [5/10], Step [10/750], Loss: 0.0234\n",
      "Epoch [5/10], Step [11/750], Loss: 0.0394\n",
      "Epoch [5/10], Step [12/750], Loss: 0.0684\n",
      "Epoch [5/10], Step [13/750], Loss: 0.0266\n",
      "Epoch [5/10], Step [14/750], Loss: 0.0456\n",
      "Epoch [5/10], Step [15/750], Loss: 0.0257\n",
      "Epoch [5/10], Step [16/750], Loss: 0.0485\n",
      "Epoch [5/10], Step [17/750], Loss: 0.0571\n",
      "Epoch [5/10], Step [18/750], Loss: 0.0166\n",
      "Epoch [5/10], Step [19/750], Loss: 0.0111\n",
      "Epoch [5/10], Step [20/750], Loss: 0.0204\n",
      "Epoch [5/10], Step [21/750], Loss: 0.0900\n",
      "Epoch [5/10], Step [22/750], Loss: 0.0504\n",
      "Epoch [5/10], Step [23/750], Loss: 0.0202\n",
      "Epoch [5/10], Step [24/750], Loss: 0.0313\n",
      "Epoch [5/10], Step [25/750], Loss: 0.0175\n",
      "Epoch [5/10], Step [26/750], Loss: 0.0286\n",
      "Epoch [5/10], Step [27/750], Loss: 0.0413\n",
      "Epoch [5/10], Step [28/750], Loss: 0.0926\n",
      "Epoch [5/10], Step [29/750], Loss: 0.0567\n",
      "Epoch [5/10], Step [30/750], Loss: 0.0885\n",
      "Epoch [5/10], Step [31/750], Loss: 0.0154\n",
      "Epoch [5/10], Step [32/750], Loss: 0.0740\n",
      "Epoch [5/10], Step [33/750], Loss: 0.0082\n",
      "Epoch [5/10], Step [34/750], Loss: 0.0249\n",
      "Epoch [5/10], Step [35/750], Loss: 0.0440\n",
      "Epoch [5/10], Step [36/750], Loss: 0.0651\n",
      "Epoch [5/10], Step [37/750], Loss: 0.0208\n",
      "Epoch [5/10], Step [38/750], Loss: 0.0641\n",
      "Epoch [5/10], Step [39/750], Loss: 0.1186\n",
      "Epoch [5/10], Step [40/750], Loss: 0.0323\n",
      "Epoch [5/10], Step [41/750], Loss: 0.0339\n",
      "Epoch [5/10], Step [42/750], Loss: 0.0186\n",
      "Epoch [5/10], Step [43/750], Loss: 0.1343\n",
      "Epoch [5/10], Step [44/750], Loss: 0.1127\n",
      "Epoch [5/10], Step [45/750], Loss: 0.0090\n",
      "Epoch [5/10], Step [46/750], Loss: 0.0177\n",
      "Epoch [5/10], Step [47/750], Loss: 0.0438\n",
      "Epoch [5/10], Step [48/750], Loss: 0.0153\n",
      "Epoch [5/10], Step [49/750], Loss: 0.0564\n",
      "Epoch [5/10], Step [50/750], Loss: 0.0409\n",
      "Epoch [5/10], Step [51/750], Loss: 0.0296\n",
      "Epoch [5/10], Step [52/750], Loss: 0.0594\n",
      "Epoch [5/10], Step [53/750], Loss: 0.0715\n",
      "Epoch [5/10], Step [54/750], Loss: 0.0090\n",
      "Epoch [5/10], Step [55/750], Loss: 0.0067\n",
      "Epoch [5/10], Step [56/750], Loss: 0.0198\n",
      "Epoch [5/10], Step [57/750], Loss: 0.0367\n",
      "Epoch [5/10], Step [58/750], Loss: 0.0709\n",
      "Epoch [5/10], Step [59/750], Loss: 0.0371\n",
      "Epoch [5/10], Step [60/750], Loss: 0.1728\n",
      "Epoch [5/10], Step [61/750], Loss: 0.0598\n",
      "Epoch [5/10], Step [62/750], Loss: 0.0903\n",
      "Epoch [5/10], Step [63/750], Loss: 0.1013\n",
      "Epoch [5/10], Step [64/750], Loss: 0.0643\n",
      "Epoch [5/10], Step [65/750], Loss: 0.0747\n",
      "Epoch [5/10], Step [66/750], Loss: 0.1095\n",
      "Epoch [5/10], Step [67/750], Loss: 0.0724\n",
      "Epoch [5/10], Step [68/750], Loss: 0.0494\n",
      "Epoch [5/10], Step [69/750], Loss: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [70/750], Loss: 0.0203\n",
      "Epoch [5/10], Step [71/750], Loss: 0.1048\n",
      "Epoch [5/10], Step [72/750], Loss: 0.0160\n",
      "Epoch [5/10], Step [73/750], Loss: 0.1446\n",
      "Epoch [5/10], Step [74/750], Loss: 0.0385\n",
      "Epoch [5/10], Step [75/750], Loss: 0.0254\n",
      "Epoch [5/10], Step [76/750], Loss: 0.0207\n",
      "Epoch [5/10], Step [77/750], Loss: 0.0298\n",
      "Epoch [5/10], Step [78/750], Loss: 0.1090\n",
      "Epoch [5/10], Step [79/750], Loss: 0.0160\n",
      "Epoch [5/10], Step [80/750], Loss: 0.1147\n",
      "Epoch [5/10], Step [81/750], Loss: 0.1475\n",
      "Epoch [5/10], Step [82/750], Loss: 0.0292\n",
      "Epoch [5/10], Step [83/750], Loss: 0.0493\n",
      "Epoch [5/10], Step [84/750], Loss: 0.0324\n",
      "Epoch [5/10], Step [85/750], Loss: 0.0058\n",
      "Epoch [5/10], Step [86/750], Loss: 0.0085\n",
      "Epoch [5/10], Step [87/750], Loss: 0.0300\n",
      "Epoch [5/10], Step [88/750], Loss: 0.0074\n",
      "Epoch [5/10], Step [89/750], Loss: 0.0801\n",
      "Epoch [5/10], Step [90/750], Loss: 0.1711\n",
      "Epoch [5/10], Step [91/750], Loss: 0.0501\n",
      "Epoch [5/10], Step [92/750], Loss: 0.0162\n",
      "Epoch [5/10], Step [93/750], Loss: 0.0227\n",
      "Epoch [5/10], Step [94/750], Loss: 0.0695\n",
      "Epoch [5/10], Step [95/750], Loss: 0.0131\n",
      "Epoch [5/10], Step [96/750], Loss: 0.0298\n",
      "Epoch [5/10], Step [97/750], Loss: 0.1120\n",
      "Epoch [5/10], Step [98/750], Loss: 0.0593\n",
      "Epoch [5/10], Step [99/750], Loss: 0.0726\n",
      "Epoch [5/10], Step [100/750], Loss: 0.0178\n",
      "Epoch [5/10], Step [101/750], Loss: 0.1115\n",
      "Epoch [5/10], Step [102/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [103/750], Loss: 0.0360\n",
      "Epoch [5/10], Step [104/750], Loss: 0.0219\n",
      "Epoch [5/10], Step [105/750], Loss: 0.0090\n",
      "Epoch [5/10], Step [106/750], Loss: 0.0777\n",
      "Epoch [5/10], Step [107/750], Loss: 0.0408\n",
      "Epoch [5/10], Step [108/750], Loss: 0.0113\n",
      "Epoch [5/10], Step [109/750], Loss: 0.0712\n",
      "Epoch [5/10], Step [110/750], Loss: 0.0557\n",
      "Epoch [5/10], Step [111/750], Loss: 0.0261\n",
      "Epoch [5/10], Step [112/750], Loss: 0.0780\n",
      "Epoch [5/10], Step [113/750], Loss: 0.1380\n",
      "Epoch [5/10], Step [114/750], Loss: 0.0846\n",
      "Epoch [5/10], Step [115/750], Loss: 0.0392\n",
      "Epoch [5/10], Step [116/750], Loss: 0.0740\n",
      "Epoch [5/10], Step [117/750], Loss: 0.0892\n",
      "Epoch [5/10], Step [118/750], Loss: 0.0161\n",
      "Epoch [5/10], Step [119/750], Loss: 0.0048\n",
      "Epoch [5/10], Step [120/750], Loss: 0.0859\n",
      "Epoch [5/10], Step [121/750], Loss: 0.0204\n",
      "Epoch [5/10], Step [122/750], Loss: 0.0470\n",
      "Epoch [5/10], Step [123/750], Loss: 0.0899\n",
      "Epoch [5/10], Step [124/750], Loss: 0.1411\n",
      "Epoch [5/10], Step [125/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [126/750], Loss: 0.0252\n",
      "Epoch [5/10], Step [127/750], Loss: 0.0528\n",
      "Epoch [5/10], Step [128/750], Loss: 0.0061\n",
      "Epoch [5/10], Step [129/750], Loss: 0.0632\n",
      "Epoch [5/10], Step [130/750], Loss: 0.0159\n",
      "Epoch [5/10], Step [131/750], Loss: 0.0065\n",
      "Epoch [5/10], Step [132/750], Loss: 0.0604\n",
      "Epoch [5/10], Step [133/750], Loss: 0.0447\n",
      "Epoch [5/10], Step [134/750], Loss: 0.0758\n",
      "Epoch [5/10], Step [135/750], Loss: 0.0136\n",
      "Epoch [5/10], Step [136/750], Loss: 0.0190\n",
      "Epoch [5/10], Step [137/750], Loss: 0.0775\n",
      "Epoch [5/10], Step [138/750], Loss: 0.0493\n",
      "Epoch [5/10], Step [139/750], Loss: 0.0931\n",
      "Epoch [5/10], Step [140/750], Loss: 0.1244\n",
      "Epoch [5/10], Step [141/750], Loss: 0.0260\n",
      "Epoch [5/10], Step [142/750], Loss: 0.0766\n",
      "Epoch [5/10], Step [143/750], Loss: 0.0454\n",
      "Epoch [5/10], Step [144/750], Loss: 0.0314\n",
      "Epoch [5/10], Step [145/750], Loss: 0.0637\n",
      "Epoch [5/10], Step [146/750], Loss: 0.0503\n",
      "Epoch [5/10], Step [147/750], Loss: 0.0763\n",
      "Epoch [5/10], Step [148/750], Loss: 0.0139\n",
      "Epoch [5/10], Step [149/750], Loss: 0.0608\n",
      "Epoch [5/10], Step [150/750], Loss: 0.0440\n",
      "Epoch [5/10], Step [151/750], Loss: 0.1017\n",
      "Epoch [5/10], Step [152/750], Loss: 0.0407\n",
      "Epoch [5/10], Step [153/750], Loss: 0.0774\n",
      "Epoch [5/10], Step [154/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [155/750], Loss: 0.0280\n",
      "Epoch [5/10], Step [156/750], Loss: 0.0505\n",
      "Epoch [5/10], Step [157/750], Loss: 0.0333\n",
      "Epoch [5/10], Step [158/750], Loss: 0.0319\n",
      "Epoch [5/10], Step [159/750], Loss: 0.0445\n",
      "Epoch [5/10], Step [160/750], Loss: 0.0617\n",
      "Epoch [5/10], Step [161/750], Loss: 0.0225\n",
      "Epoch [5/10], Step [162/750], Loss: 0.0233\n",
      "Epoch [5/10], Step [163/750], Loss: 0.0332\n",
      "Epoch [5/10], Step [164/750], Loss: 0.0749\n",
      "Epoch [5/10], Step [165/750], Loss: 0.0240\n",
      "Epoch [5/10], Step [166/750], Loss: 0.0363\n",
      "Epoch [5/10], Step [167/750], Loss: 0.1560\n",
      "Epoch [5/10], Step [168/750], Loss: 0.0571\n",
      "Epoch [5/10], Step [169/750], Loss: 0.0723\n",
      "Epoch [5/10], Step [170/750], Loss: 0.0377\n",
      "Epoch [5/10], Step [171/750], Loss: 0.0236\n",
      "Epoch [5/10], Step [172/750], Loss: 0.0909\n",
      "Epoch [5/10], Step [173/750], Loss: 0.0426\n",
      "Epoch [5/10], Step [174/750], Loss: 0.0775\n",
      "Epoch [5/10], Step [175/750], Loss: 0.0141\n",
      "Epoch [5/10], Step [176/750], Loss: 0.0475\n",
      "Epoch [5/10], Step [177/750], Loss: 0.0343\n",
      "Epoch [5/10], Step [178/750], Loss: 0.0486\n",
      "Epoch [5/10], Step [179/750], Loss: 0.0434\n",
      "Epoch [5/10], Step [180/750], Loss: 0.0314\n",
      "Epoch [5/10], Step [181/750], Loss: 0.0871\n",
      "Epoch [5/10], Step [182/750], Loss: 0.0304\n",
      "Epoch [5/10], Step [183/750], Loss: 0.0412\n",
      "Epoch [5/10], Step [184/750], Loss: 0.0917\n",
      "Epoch [5/10], Step [185/750], Loss: 0.0696\n",
      "Epoch [5/10], Step [186/750], Loss: 0.0445\n",
      "Epoch [5/10], Step [187/750], Loss: 0.0264\n",
      "Epoch [5/10], Step [188/750], Loss: 0.0168\n",
      "Epoch [5/10], Step [189/750], Loss: 0.0657\n",
      "Epoch [5/10], Step [190/750], Loss: 0.0346\n",
      "Epoch [5/10], Step [191/750], Loss: 0.0101\n",
      "Epoch [5/10], Step [192/750], Loss: 0.0882\n",
      "Epoch [5/10], Step [193/750], Loss: 0.2141\n",
      "Epoch [5/10], Step [194/750], Loss: 0.0408\n",
      "Epoch [5/10], Step [195/750], Loss: 0.0225\n",
      "Epoch [5/10], Step [196/750], Loss: 0.0200\n",
      "Epoch [5/10], Step [197/750], Loss: 0.0586\n",
      "Epoch [5/10], Step [198/750], Loss: 0.0822\n",
      "Epoch [5/10], Step [199/750], Loss: 0.0356\n",
      "Epoch [5/10], Step [200/750], Loss: 0.0475\n",
      "Epoch [5/10], Step [201/750], Loss: 0.0491\n",
      "Epoch [5/10], Step [202/750], Loss: 0.0042\n",
      "Epoch [5/10], Step [203/750], Loss: 0.0094\n",
      "Epoch [5/10], Step [204/750], Loss: 0.0596\n",
      "Epoch [5/10], Step [205/750], Loss: 0.0486\n",
      "Epoch [5/10], Step [206/750], Loss: 0.1458\n",
      "Epoch [5/10], Step [207/750], Loss: 0.0214\n",
      "Epoch [5/10], Step [208/750], Loss: 0.0344\n",
      "Epoch [5/10], Step [209/750], Loss: 0.0425\n",
      "Epoch [5/10], Step [210/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [211/750], Loss: 0.0264\n",
      "Epoch [5/10], Step [212/750], Loss: 0.0101\n",
      "Epoch [5/10], Step [213/750], Loss: 0.0277\n",
      "Epoch [5/10], Step [214/750], Loss: 0.0937\n",
      "Epoch [5/10], Step [215/750], Loss: 0.0436\n",
      "Epoch [5/10], Step [216/750], Loss: 0.0598\n",
      "Epoch [5/10], Step [217/750], Loss: 0.0143\n",
      "Epoch [5/10], Step [218/750], Loss: 0.0143\n",
      "Epoch [5/10], Step [219/750], Loss: 0.1534\n",
      "Epoch [5/10], Step [220/750], Loss: 0.0327\n",
      "Epoch [5/10], Step [221/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [222/750], Loss: 0.1400\n",
      "Epoch [5/10], Step [223/750], Loss: 0.0905\n",
      "Epoch [5/10], Step [224/750], Loss: 0.0332\n",
      "Epoch [5/10], Step [225/750], Loss: 0.0207\n",
      "Epoch [5/10], Step [226/750], Loss: 0.0459\n",
      "Epoch [5/10], Step [227/750], Loss: 0.0122\n",
      "Epoch [5/10], Step [228/750], Loss: 0.0816\n",
      "Epoch [5/10], Step [229/750], Loss: 0.0186\n",
      "Epoch [5/10], Step [230/750], Loss: 0.0429\n",
      "Epoch [5/10], Step [231/750], Loss: 0.0099\n",
      "Epoch [5/10], Step [232/750], Loss: 0.1248\n",
      "Epoch [5/10], Step [233/750], Loss: 0.0532\n",
      "Epoch [5/10], Step [234/750], Loss: 0.1651\n",
      "Epoch [5/10], Step [235/750], Loss: 0.0759\n",
      "Epoch [5/10], Step [236/750], Loss: 0.1437\n",
      "Epoch [5/10], Step [237/750], Loss: 0.1323\n",
      "Epoch [5/10], Step [238/750], Loss: 0.1280\n",
      "Epoch [5/10], Step [239/750], Loss: 0.0254\n",
      "Epoch [5/10], Step [240/750], Loss: 0.1023\n",
      "Epoch [5/10], Step [241/750], Loss: 0.0080\n",
      "Epoch [5/10], Step [242/750], Loss: 0.0607\n",
      "Epoch [5/10], Step [243/750], Loss: 0.0236\n",
      "Epoch [5/10], Step [244/750], Loss: 0.1106\n",
      "Epoch [5/10], Step [245/750], Loss: 0.0512\n",
      "Epoch [5/10], Step [246/750], Loss: 0.0198\n",
      "Epoch [5/10], Step [247/750], Loss: 0.0693\n",
      "Epoch [5/10], Step [248/750], Loss: 0.0353\n",
      "Epoch [5/10], Step [249/750], Loss: 0.0483\n",
      "Epoch [5/10], Step [250/750], Loss: 0.0336\n",
      "Epoch [5/10], Step [251/750], Loss: 0.0222\n",
      "Epoch [5/10], Step [252/750], Loss: 0.0977\n",
      "Epoch [5/10], Step [253/750], Loss: 0.0602\n",
      "Epoch [5/10], Step [254/750], Loss: 0.0300\n",
      "Epoch [5/10], Step [255/750], Loss: 0.0525\n",
      "Epoch [5/10], Step [256/750], Loss: 0.0250\n",
      "Epoch [5/10], Step [257/750], Loss: 0.2497\n",
      "Epoch [5/10], Step [258/750], Loss: 0.0206\n",
      "Epoch [5/10], Step [259/750], Loss: 0.0950\n",
      "Epoch [5/10], Step [260/750], Loss: 0.0453\n",
      "Epoch [5/10], Step [261/750], Loss: 0.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [262/750], Loss: 0.1285\n",
      "Epoch [5/10], Step [263/750], Loss: 0.0286\n",
      "Epoch [5/10], Step [264/750], Loss: 0.0787\n",
      "Epoch [5/10], Step [265/750], Loss: 0.0179\n",
      "Epoch [5/10], Step [266/750], Loss: 0.0315\n",
      "Epoch [5/10], Step [267/750], Loss: 0.0452\n",
      "Epoch [5/10], Step [268/750], Loss: 0.0095\n",
      "Epoch [5/10], Step [269/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [270/750], Loss: 0.0489\n",
      "Epoch [5/10], Step [271/750], Loss: 0.0819\n",
      "Epoch [5/10], Step [272/750], Loss: 0.0251\n",
      "Epoch [5/10], Step [273/750], Loss: 0.0099\n",
      "Epoch [5/10], Step [274/750], Loss: 0.0080\n",
      "Epoch [5/10], Step [275/750], Loss: 0.0962\n",
      "Epoch [5/10], Step [276/750], Loss: 0.0120\n",
      "Epoch [5/10], Step [277/750], Loss: 0.0288\n",
      "Epoch [5/10], Step [278/750], Loss: 0.0110\n",
      "Epoch [5/10], Step [279/750], Loss: 0.0249\n",
      "Epoch [5/10], Step [280/750], Loss: 0.0422\n",
      "Epoch [5/10], Step [281/750], Loss: 0.0224\n",
      "Epoch [5/10], Step [282/750], Loss: 0.1028\n",
      "Epoch [5/10], Step [283/750], Loss: 0.0413\n",
      "Epoch [5/10], Step [284/750], Loss: 0.0180\n",
      "Epoch [5/10], Step [285/750], Loss: 0.0625\n",
      "Epoch [5/10], Step [286/750], Loss: 0.0425\n",
      "Epoch [5/10], Step [287/750], Loss: 0.0115\n",
      "Epoch [5/10], Step [288/750], Loss: 0.1110\n",
      "Epoch [5/10], Step [289/750], Loss: 0.0040\n",
      "Epoch [5/10], Step [290/750], Loss: 0.0434\n",
      "Epoch [5/10], Step [291/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [292/750], Loss: 0.0105\n",
      "Epoch [5/10], Step [293/750], Loss: 0.0358\n",
      "Epoch [5/10], Step [294/750], Loss: 0.0411\n",
      "Epoch [5/10], Step [295/750], Loss: 0.0251\n",
      "Epoch [5/10], Step [296/750], Loss: 0.0330\n",
      "Epoch [5/10], Step [297/750], Loss: 0.0051\n",
      "Epoch [5/10], Step [298/750], Loss: 0.0621\n",
      "Epoch [5/10], Step [299/750], Loss: 0.0118\n",
      "Epoch [5/10], Step [300/750], Loss: 0.0072\n",
      "Epoch [5/10], Step [301/750], Loss: 0.0623\n",
      "Epoch [5/10], Step [302/750], Loss: 0.0843\n",
      "Epoch [5/10], Step [303/750], Loss: 0.0363\n",
      "Epoch [5/10], Step [304/750], Loss: 0.0984\n",
      "Epoch [5/10], Step [305/750], Loss: 0.0546\n",
      "Epoch [5/10], Step [306/750], Loss: 0.0217\n",
      "Epoch [5/10], Step [307/750], Loss: 0.0652\n",
      "Epoch [5/10], Step [308/750], Loss: 0.1566\n",
      "Epoch [5/10], Step [309/750], Loss: 0.0349\n",
      "Epoch [5/10], Step [310/750], Loss: 0.0706\n",
      "Epoch [5/10], Step [311/750], Loss: 0.0580\n",
      "Epoch [5/10], Step [312/750], Loss: 0.0232\n",
      "Epoch [5/10], Step [313/750], Loss: 0.0680\n",
      "Epoch [5/10], Step [314/750], Loss: 0.0328\n",
      "Epoch [5/10], Step [315/750], Loss: 0.0275\n",
      "Epoch [5/10], Step [316/750], Loss: 0.0915\n",
      "Epoch [5/10], Step [317/750], Loss: 0.0535\n",
      "Epoch [5/10], Step [318/750], Loss: 0.0300\n",
      "Epoch [5/10], Step [319/750], Loss: 0.1450\n",
      "Epoch [5/10], Step [320/750], Loss: 0.0700\n",
      "Epoch [5/10], Step [321/750], Loss: 0.0948\n",
      "Epoch [5/10], Step [322/750], Loss: 0.0067\n",
      "Epoch [5/10], Step [323/750], Loss: 0.0766\n",
      "Epoch [5/10], Step [324/750], Loss: 0.1073\n",
      "Epoch [5/10], Step [325/750], Loss: 0.1414\n",
      "Epoch [5/10], Step [326/750], Loss: 0.1809\n",
      "Epoch [5/10], Step [327/750], Loss: 0.0089\n",
      "Epoch [5/10], Step [328/750], Loss: 0.0229\n",
      "Epoch [5/10], Step [329/750], Loss: 0.0265\n",
      "Epoch [5/10], Step [330/750], Loss: 0.0235\n",
      "Epoch [5/10], Step [331/750], Loss: 0.0420\n",
      "Epoch [5/10], Step [332/750], Loss: 0.0928\n",
      "Epoch [5/10], Step [333/750], Loss: 0.0260\n",
      "Epoch [5/10], Step [334/750], Loss: 0.0931\n",
      "Epoch [5/10], Step [335/750], Loss: 0.1856\n",
      "Epoch [5/10], Step [336/750], Loss: 0.0281\n",
      "Epoch [5/10], Step [337/750], Loss: 0.0352\n",
      "Epoch [5/10], Step [338/750], Loss: 0.0347\n",
      "Epoch [5/10], Step [339/750], Loss: 0.1497\n",
      "Epoch [5/10], Step [340/750], Loss: 0.0355\n",
      "Epoch [5/10], Step [341/750], Loss: 0.0893\n",
      "Epoch [5/10], Step [342/750], Loss: 0.0366\n",
      "Epoch [5/10], Step [343/750], Loss: 0.1633\n",
      "Epoch [5/10], Step [344/750], Loss: 0.0118\n",
      "Epoch [5/10], Step [345/750], Loss: 0.0450\n",
      "Epoch [5/10], Step [346/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [347/750], Loss: 0.0278\n",
      "Epoch [5/10], Step [348/750], Loss: 0.0112\n",
      "Epoch [5/10], Step [349/750], Loss: 0.0288\n",
      "Epoch [5/10], Step [350/750], Loss: 0.1052\n",
      "Epoch [5/10], Step [351/750], Loss: 0.0111\n",
      "Epoch [5/10], Step [352/750], Loss: 0.0308\n",
      "Epoch [5/10], Step [353/750], Loss: 0.0495\n",
      "Epoch [5/10], Step [354/750], Loss: 0.0750\n",
      "Epoch [5/10], Step [355/750], Loss: 0.0215\n",
      "Epoch [5/10], Step [356/750], Loss: 0.1088\n",
      "Epoch [5/10], Step [357/750], Loss: 0.0485\n",
      "Epoch [5/10], Step [358/750], Loss: 0.0274\n",
      "Epoch [5/10], Step [359/750], Loss: 0.0943\n",
      "Epoch [5/10], Step [360/750], Loss: 0.1205\n",
      "Epoch [5/10], Step [361/750], Loss: 0.0757\n",
      "Epoch [5/10], Step [362/750], Loss: 0.0084\n",
      "Epoch [5/10], Step [363/750], Loss: 0.0785\n",
      "Epoch [5/10], Step [364/750], Loss: 0.1571\n",
      "Epoch [5/10], Step [365/750], Loss: 0.0356\n",
      "Epoch [5/10], Step [366/750], Loss: 0.0837\n",
      "Epoch [5/10], Step [367/750], Loss: 0.0743\n",
      "Epoch [5/10], Step [368/750], Loss: 0.0366\n",
      "Epoch [5/10], Step [369/750], Loss: 0.0598\n",
      "Epoch [5/10], Step [370/750], Loss: 0.0281\n",
      "Epoch [5/10], Step [371/750], Loss: 0.0660\n",
      "Epoch [5/10], Step [372/750], Loss: 0.0248\n",
      "Epoch [5/10], Step [373/750], Loss: 0.0647\n",
      "Epoch [5/10], Step [374/750], Loss: 0.0132\n",
      "Epoch [5/10], Step [375/750], Loss: 0.1301\n",
      "Epoch [5/10], Step [376/750], Loss: 0.0814\n",
      "Epoch [5/10], Step [377/750], Loss: 0.0932\n",
      "Epoch [5/10], Step [378/750], Loss: 0.1270\n",
      "Epoch [5/10], Step [379/750], Loss: 0.0570\n",
      "Epoch [5/10], Step [380/750], Loss: 0.2157\n",
      "Epoch [5/10], Step [381/750], Loss: 0.0928\n",
      "Epoch [5/10], Step [382/750], Loss: 0.0825\n",
      "Epoch [5/10], Step [383/750], Loss: 0.1926\n",
      "Epoch [5/10], Step [384/750], Loss: 0.0520\n",
      "Epoch [5/10], Step [385/750], Loss: 0.1637\n",
      "Epoch [5/10], Step [386/750], Loss: 0.0379\n",
      "Epoch [5/10], Step [387/750], Loss: 0.1191\n",
      "Epoch [5/10], Step [388/750], Loss: 0.0382\n",
      "Epoch [5/10], Step [389/750], Loss: 0.0715\n",
      "Epoch [5/10], Step [390/750], Loss: 0.1155\n",
      "Epoch [5/10], Step [391/750], Loss: 0.0391\n",
      "Epoch [5/10], Step [392/750], Loss: 0.0628\n",
      "Epoch [5/10], Step [393/750], Loss: 0.0978\n",
      "Epoch [5/10], Step [394/750], Loss: 0.0795\n",
      "Epoch [5/10], Step [395/750], Loss: 0.1581\n",
      "Epoch [5/10], Step [396/750], Loss: 0.1048\n",
      "Epoch [5/10], Step [397/750], Loss: 0.0695\n",
      "Epoch [5/10], Step [398/750], Loss: 0.0975\n",
      "Epoch [5/10], Step [399/750], Loss: 0.0130\n",
      "Epoch [5/10], Step [400/750], Loss: 0.0151\n",
      "Epoch [5/10], Step [401/750], Loss: 0.0774\n",
      "Epoch [5/10], Step [402/750], Loss: 0.0672\n",
      "Epoch [5/10], Step [403/750], Loss: 0.0438\n",
      "Epoch [5/10], Step [404/750], Loss: 0.0785\n",
      "Epoch [5/10], Step [405/750], Loss: 0.0851\n",
      "Epoch [5/10], Step [406/750], Loss: 0.0464\n",
      "Epoch [5/10], Step [407/750], Loss: 0.0283\n",
      "Epoch [5/10], Step [408/750], Loss: 0.1666\n",
      "Epoch [5/10], Step [409/750], Loss: 0.0525\n",
      "Epoch [5/10], Step [410/750], Loss: 0.0400\n",
      "Epoch [5/10], Step [411/750], Loss: 0.1075\n",
      "Epoch [5/10], Step [412/750], Loss: 0.0152\n",
      "Epoch [5/10], Step [413/750], Loss: 0.0768\n",
      "Epoch [5/10], Step [414/750], Loss: 0.0244\n",
      "Epoch [5/10], Step [415/750], Loss: 0.1211\n",
      "Epoch [5/10], Step [416/750], Loss: 0.0100\n",
      "Epoch [5/10], Step [417/750], Loss: 0.0885\n",
      "Epoch [5/10], Step [418/750], Loss: 0.1024\n",
      "Epoch [5/10], Step [419/750], Loss: 0.0568\n",
      "Epoch [5/10], Step [420/750], Loss: 0.0294\n",
      "Epoch [5/10], Step [421/750], Loss: 0.1610\n",
      "Epoch [5/10], Step [422/750], Loss: 0.0693\n",
      "Epoch [5/10], Step [423/750], Loss: 0.0508\n",
      "Epoch [5/10], Step [424/750], Loss: 0.0644\n",
      "Epoch [5/10], Step [425/750], Loss: 0.1073\n",
      "Epoch [5/10], Step [426/750], Loss: 0.1249\n",
      "Epoch [5/10], Step [427/750], Loss: 0.1609\n",
      "Epoch [5/10], Step [428/750], Loss: 0.1969\n",
      "Epoch [5/10], Step [429/750], Loss: 0.0963\n",
      "Epoch [5/10], Step [430/750], Loss: 0.0751\n",
      "Epoch [5/10], Step [431/750], Loss: 0.1015\n",
      "Epoch [5/10], Step [432/750], Loss: 0.0599\n",
      "Epoch [5/10], Step [433/750], Loss: 0.0463\n",
      "Epoch [5/10], Step [434/750], Loss: 0.0749\n",
      "Epoch [5/10], Step [435/750], Loss: 0.1178\n",
      "Epoch [5/10], Step [436/750], Loss: 0.0746\n",
      "Epoch [5/10], Step [437/750], Loss: 0.0531\n",
      "Epoch [5/10], Step [438/750], Loss: 0.0262\n",
      "Epoch [5/10], Step [439/750], Loss: 0.0390\n",
      "Epoch [5/10], Step [440/750], Loss: 0.1132\n",
      "Epoch [5/10], Step [441/750], Loss: 0.0416\n",
      "Epoch [5/10], Step [442/750], Loss: 0.0291\n",
      "Epoch [5/10], Step [443/750], Loss: 0.0069\n",
      "Epoch [5/10], Step [444/750], Loss: 0.0142\n",
      "Epoch [5/10], Step [445/750], Loss: 0.0671\n",
      "Epoch [5/10], Step [446/750], Loss: 0.0850\n",
      "Epoch [5/10], Step [447/750], Loss: 0.0311\n",
      "Epoch [5/10], Step [448/750], Loss: 0.1816\n",
      "Epoch [5/10], Step [449/750], Loss: 0.0486\n",
      "Epoch [5/10], Step [450/750], Loss: 0.0246\n",
      "Epoch [5/10], Step [451/750], Loss: 0.0643\n",
      "Epoch [5/10], Step [452/750], Loss: 0.1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [453/750], Loss: 0.0806\n",
      "Epoch [5/10], Step [454/750], Loss: 0.0558\n",
      "Epoch [5/10], Step [455/750], Loss: 0.1134\n",
      "Epoch [5/10], Step [456/750], Loss: 0.0421\n",
      "Epoch [5/10], Step [457/750], Loss: 0.1411\n",
      "Epoch [5/10], Step [458/750], Loss: 0.1483\n",
      "Epoch [5/10], Step [459/750], Loss: 0.0349\n",
      "Epoch [5/10], Step [460/750], Loss: 0.1286\n",
      "Epoch [5/10], Step [461/750], Loss: 0.1214\n",
      "Epoch [5/10], Step [462/750], Loss: 0.0738\n",
      "Epoch [5/10], Step [463/750], Loss: 0.0887\n",
      "Epoch [5/10], Step [464/750], Loss: 0.0225\n",
      "Epoch [5/10], Step [465/750], Loss: 0.1286\n",
      "Epoch [5/10], Step [466/750], Loss: 0.0360\n",
      "Epoch [5/10], Step [467/750], Loss: 0.0333\n",
      "Epoch [5/10], Step [468/750], Loss: 0.0515\n",
      "Epoch [5/10], Step [469/750], Loss: 0.0995\n",
      "Epoch [5/10], Step [470/750], Loss: 0.0321\n",
      "Epoch [5/10], Step [471/750], Loss: 0.0680\n",
      "Epoch [5/10], Step [472/750], Loss: 0.0615\n",
      "Epoch [5/10], Step [473/750], Loss: 0.1677\n",
      "Epoch [5/10], Step [474/750], Loss: 0.0195\n",
      "Epoch [5/10], Step [475/750], Loss: 0.0628\n",
      "Epoch [5/10], Step [476/750], Loss: 0.1100\n",
      "Epoch [5/10], Step [477/750], Loss: 0.1040\n",
      "Epoch [5/10], Step [478/750], Loss: 0.0195\n",
      "Epoch [5/10], Step [479/750], Loss: 0.0156\n",
      "Epoch [5/10], Step [480/750], Loss: 0.0731\n",
      "Epoch [5/10], Step [481/750], Loss: 0.0937\n",
      "Epoch [5/10], Step [482/750], Loss: 0.1059\n",
      "Epoch [5/10], Step [483/750], Loss: 0.0480\n",
      "Epoch [5/10], Step [484/750], Loss: 0.0557\n",
      "Epoch [5/10], Step [485/750], Loss: 0.0238\n",
      "Epoch [5/10], Step [486/750], Loss: 0.1501\n",
      "Epoch [5/10], Step [487/750], Loss: 0.0340\n",
      "Epoch [5/10], Step [488/750], Loss: 0.0295\n",
      "Epoch [5/10], Step [489/750], Loss: 0.1080\n",
      "Epoch [5/10], Step [490/750], Loss: 0.0513\n",
      "Epoch [5/10], Step [491/750], Loss: 0.0129\n",
      "Epoch [5/10], Step [492/750], Loss: 0.0196\n",
      "Epoch [5/10], Step [493/750], Loss: 0.0288\n",
      "Epoch [5/10], Step [494/750], Loss: 0.1224\n",
      "Epoch [5/10], Step [495/750], Loss: 0.0674\n",
      "Epoch [5/10], Step [496/750], Loss: 0.0407\n",
      "Epoch [5/10], Step [497/750], Loss: 0.0373\n",
      "Epoch [5/10], Step [498/750], Loss: 0.0402\n",
      "Epoch [5/10], Step [499/750], Loss: 0.1241\n",
      "Epoch [5/10], Step [500/750], Loss: 0.0240\n",
      "Epoch [5/10], Step [501/750], Loss: 0.0657\n",
      "Epoch [5/10], Step [502/750], Loss: 0.0702\n",
      "Epoch [5/10], Step [503/750], Loss: 0.0416\n",
      "Epoch [5/10], Step [504/750], Loss: 0.0107\n",
      "Epoch [5/10], Step [505/750], Loss: 0.0873\n",
      "Epoch [5/10], Step [506/750], Loss: 0.1176\n",
      "Epoch [5/10], Step [507/750], Loss: 0.0501\n",
      "Epoch [5/10], Step [508/750], Loss: 0.0083\n",
      "Epoch [5/10], Step [509/750], Loss: 0.0555\n",
      "Epoch [5/10], Step [510/750], Loss: 0.1073\n",
      "Epoch [5/10], Step [511/750], Loss: 0.0207\n",
      "Epoch [5/10], Step [512/750], Loss: 0.0877\n",
      "Epoch [5/10], Step [513/750], Loss: 0.1120\n",
      "Epoch [5/10], Step [514/750], Loss: 0.0291\n",
      "Epoch [5/10], Step [515/750], Loss: 0.0162\n",
      "Epoch [5/10], Step [516/750], Loss: 0.0130\n",
      "Epoch [5/10], Step [517/750], Loss: 0.0559\n",
      "Epoch [5/10], Step [518/750], Loss: 0.1249\n",
      "Epoch [5/10], Step [519/750], Loss: 0.0889\n",
      "Epoch [5/10], Step [520/750], Loss: 0.0560\n",
      "Epoch [5/10], Step [521/750], Loss: 0.0193\n",
      "Epoch [5/10], Step [522/750], Loss: 0.0719\n",
      "Epoch [5/10], Step [523/750], Loss: 0.1318\n",
      "Epoch [5/10], Step [524/750], Loss: 0.2227\n",
      "Epoch [5/10], Step [525/750], Loss: 0.1269\n",
      "Epoch [5/10], Step [526/750], Loss: 0.1294\n",
      "Epoch [5/10], Step [527/750], Loss: 0.0714\n",
      "Epoch [5/10], Step [528/750], Loss: 0.0800\n",
      "Epoch [5/10], Step [529/750], Loss: 0.1372\n",
      "Epoch [5/10], Step [530/750], Loss: 0.1948\n",
      "Epoch [5/10], Step [531/750], Loss: 0.0390\n",
      "Epoch [5/10], Step [532/750], Loss: 0.0371\n",
      "Epoch [5/10], Step [533/750], Loss: 0.0975\n",
      "Epoch [5/10], Step [534/750], Loss: 0.0141\n",
      "Epoch [5/10], Step [535/750], Loss: 0.0173\n",
      "Epoch [5/10], Step [536/750], Loss: 0.0375\n",
      "Epoch [5/10], Step [537/750], Loss: 0.1805\n",
      "Epoch [5/10], Step [538/750], Loss: 0.0871\n",
      "Epoch [5/10], Step [539/750], Loss: 0.0461\n",
      "Epoch [5/10], Step [540/750], Loss: 0.1523\n",
      "Epoch [5/10], Step [541/750], Loss: 0.0299\n",
      "Epoch [5/10], Step [542/750], Loss: 0.1301\n",
      "Epoch [5/10], Step [543/750], Loss: 0.0077\n",
      "Epoch [5/10], Step [544/750], Loss: 0.0372\n",
      "Epoch [5/10], Step [545/750], Loss: 0.2028\n",
      "Epoch [5/10], Step [546/750], Loss: 0.0391\n",
      "Epoch [5/10], Step [547/750], Loss: 0.0821\n",
      "Epoch [5/10], Step [548/750], Loss: 0.0845\n",
      "Epoch [5/10], Step [549/750], Loss: 0.0699\n",
      "Epoch [5/10], Step [550/750], Loss: 0.0361\n",
      "Epoch [5/10], Step [551/750], Loss: 0.1014\n",
      "Epoch [5/10], Step [552/750], Loss: 0.0392\n",
      "Epoch [5/10], Step [553/750], Loss: 0.0521\n",
      "Epoch [5/10], Step [554/750], Loss: 0.0318\n",
      "Epoch [5/10], Step [555/750], Loss: 0.1439\n",
      "Epoch [5/10], Step [556/750], Loss: 0.0464\n",
      "Epoch [5/10], Step [557/750], Loss: 0.0389\n",
      "Epoch [5/10], Step [558/750], Loss: 0.0213\n",
      "Epoch [5/10], Step [559/750], Loss: 0.0179\n",
      "Epoch [5/10], Step [560/750], Loss: 0.0757\n",
      "Epoch [5/10], Step [561/750], Loss: 0.0811\n",
      "Epoch [5/10], Step [562/750], Loss: 0.0677\n",
      "Epoch [5/10], Step [563/750], Loss: 0.0165\n",
      "Epoch [5/10], Step [564/750], Loss: 0.0391\n",
      "Epoch [5/10], Step [565/750], Loss: 0.1594\n",
      "Epoch [5/10], Step [566/750], Loss: 0.0799\n",
      "Epoch [5/10], Step [567/750], Loss: 0.0743\n",
      "Epoch [5/10], Step [568/750], Loss: 0.0328\n",
      "Epoch [5/10], Step [569/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [570/750], Loss: 0.1601\n",
      "Epoch [5/10], Step [571/750], Loss: 0.0635\n",
      "Epoch [5/10], Step [572/750], Loss: 0.0238\n",
      "Epoch [5/10], Step [573/750], Loss: 0.0128\n",
      "Epoch [5/10], Step [574/750], Loss: 0.0415\n",
      "Epoch [5/10], Step [575/750], Loss: 0.0177\n",
      "Epoch [5/10], Step [576/750], Loss: 0.0634\n",
      "Epoch [5/10], Step [577/750], Loss: 0.1262\n",
      "Epoch [5/10], Step [578/750], Loss: 0.0695\n",
      "Epoch [5/10], Step [579/750], Loss: 0.1078\n",
      "Epoch [5/10], Step [580/750], Loss: 0.1376\n",
      "Epoch [5/10], Step [581/750], Loss: 0.0945\n",
      "Epoch [5/10], Step [582/750], Loss: 0.0332\n",
      "Epoch [5/10], Step [583/750], Loss: 0.0492\n",
      "Epoch [5/10], Step [584/750], Loss: 0.0370\n",
      "Epoch [5/10], Step [585/750], Loss: 0.0484\n",
      "Epoch [5/10], Step [586/750], Loss: 0.1005\n",
      "Epoch [5/10], Step [587/750], Loss: 0.0702\n",
      "Epoch [5/10], Step [588/750], Loss: 0.1067\n",
      "Epoch [5/10], Step [589/750], Loss: 0.0690\n",
      "Epoch [5/10], Step [590/750], Loss: 0.0861\n",
      "Epoch [5/10], Step [591/750], Loss: 0.0362\n",
      "Epoch [5/10], Step [592/750], Loss: 0.0456\n",
      "Epoch [5/10], Step [593/750], Loss: 0.0111\n",
      "Epoch [5/10], Step [594/750], Loss: 0.1686\n",
      "Epoch [5/10], Step [595/750], Loss: 0.0531\n",
      "Epoch [5/10], Step [596/750], Loss: 0.0693\n",
      "Epoch [5/10], Step [597/750], Loss: 0.2085\n",
      "Epoch [5/10], Step [598/750], Loss: 0.0557\n",
      "Epoch [5/10], Step [599/750], Loss: 0.0057\n",
      "Epoch [5/10], Step [600/750], Loss: 0.0149\n",
      "Epoch [5/10], Step [601/750], Loss: 0.1358\n",
      "Epoch [5/10], Step [602/750], Loss: 0.0596\n",
      "Epoch [5/10], Step [603/750], Loss: 0.0253\n",
      "Epoch [5/10], Step [604/750], Loss: 0.0730\n",
      "Epoch [5/10], Step [605/750], Loss: 0.0537\n",
      "Epoch [5/10], Step [606/750], Loss: 0.1016\n",
      "Epoch [5/10], Step [607/750], Loss: 0.1788\n",
      "Epoch [5/10], Step [608/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [609/750], Loss: 0.1074\n",
      "Epoch [5/10], Step [610/750], Loss: 0.1794\n",
      "Epoch [5/10], Step [611/750], Loss: 0.0163\n",
      "Epoch [5/10], Step [612/750], Loss: 0.1150\n",
      "Epoch [5/10], Step [613/750], Loss: 0.0254\n",
      "Epoch [5/10], Step [614/750], Loss: 0.0136\n",
      "Epoch [5/10], Step [615/750], Loss: 0.0676\n",
      "Epoch [5/10], Step [616/750], Loss: 0.1040\n",
      "Epoch [5/10], Step [617/750], Loss: 0.2091\n",
      "Epoch [5/10], Step [618/750], Loss: 0.1281\n",
      "Epoch [5/10], Step [619/750], Loss: 0.0413\n",
      "Epoch [5/10], Step [620/750], Loss: 0.0596\n",
      "Epoch [5/10], Step [621/750], Loss: 0.0983\n",
      "Epoch [5/10], Step [622/750], Loss: 0.0365\n",
      "Epoch [5/10], Step [623/750], Loss: 0.0555\n",
      "Epoch [5/10], Step [624/750], Loss: 0.0146\n",
      "Epoch [5/10], Step [625/750], Loss: 0.0366\n",
      "Epoch [5/10], Step [626/750], Loss: 0.0152\n",
      "Epoch [5/10], Step [627/750], Loss: 0.1005\n",
      "Epoch [5/10], Step [628/750], Loss: 0.0183\n",
      "Epoch [5/10], Step [629/750], Loss: 0.1295\n",
      "Epoch [5/10], Step [630/750], Loss: 0.0916\n",
      "Epoch [5/10], Step [631/750], Loss: 0.0712\n",
      "Epoch [5/10], Step [632/750], Loss: 0.0586\n",
      "Epoch [5/10], Step [633/750], Loss: 0.0667\n",
      "Epoch [5/10], Step [634/750], Loss: 0.0350\n",
      "Epoch [5/10], Step [635/750], Loss: 0.0086\n",
      "Epoch [5/10], Step [636/750], Loss: 0.0686\n",
      "Epoch [5/10], Step [637/750], Loss: 0.1767\n",
      "Epoch [5/10], Step [638/750], Loss: 0.0449\n",
      "Epoch [5/10], Step [639/750], Loss: 0.0308\n",
      "Epoch [5/10], Step [640/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [641/750], Loss: 0.0171\n",
      "Epoch [5/10], Step [642/750], Loss: 0.0123\n",
      "Epoch [5/10], Step [643/750], Loss: 0.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [644/750], Loss: 0.0228\n",
      "Epoch [5/10], Step [645/750], Loss: 0.0513\n",
      "Epoch [5/10], Step [646/750], Loss: 0.0324\n",
      "Epoch [5/10], Step [647/750], Loss: 0.0274\n",
      "Epoch [5/10], Step [648/750], Loss: 0.0142\n",
      "Epoch [5/10], Step [649/750], Loss: 0.0137\n",
      "Epoch [5/10], Step [650/750], Loss: 0.0406\n",
      "Epoch [5/10], Step [651/750], Loss: 0.0938\n",
      "Epoch [5/10], Step [652/750], Loss: 0.0961\n",
      "Epoch [5/10], Step [653/750], Loss: 0.1155\n",
      "Epoch [5/10], Step [654/750], Loss: 0.0583\n",
      "Epoch [5/10], Step [655/750], Loss: 0.0254\n",
      "Epoch [5/10], Step [656/750], Loss: 0.0257\n",
      "Epoch [5/10], Step [657/750], Loss: 0.2384\n",
      "Epoch [5/10], Step [658/750], Loss: 0.0311\n",
      "Epoch [5/10], Step [659/750], Loss: 0.0078\n",
      "Epoch [5/10], Step [660/750], Loss: 0.0785\n",
      "Epoch [5/10], Step [661/750], Loss: 0.0498\n",
      "Epoch [5/10], Step [662/750], Loss: 0.0041\n",
      "Epoch [5/10], Step [663/750], Loss: 0.0559\n",
      "Epoch [5/10], Step [664/750], Loss: 0.0462\n",
      "Epoch [5/10], Step [665/750], Loss: 0.0121\n",
      "Epoch [5/10], Step [666/750], Loss: 0.1031\n",
      "Epoch [5/10], Step [667/750], Loss: 0.0454\n",
      "Epoch [5/10], Step [668/750], Loss: 0.0511\n",
      "Epoch [5/10], Step [669/750], Loss: 0.1990\n",
      "Epoch [5/10], Step [670/750], Loss: 0.1118\n",
      "Epoch [5/10], Step [671/750], Loss: 0.0387\n",
      "Epoch [5/10], Step [672/750], Loss: 0.0156\n",
      "Epoch [5/10], Step [673/750], Loss: 0.1048\n",
      "Epoch [5/10], Step [674/750], Loss: 0.1315\n",
      "Epoch [5/10], Step [675/750], Loss: 0.2327\n",
      "Epoch [5/10], Step [676/750], Loss: 0.0157\n",
      "Epoch [5/10], Step [677/750], Loss: 0.2493\n",
      "Epoch [5/10], Step [678/750], Loss: 0.0159\n",
      "Epoch [5/10], Step [679/750], Loss: 0.0766\n",
      "Epoch [5/10], Step [680/750], Loss: 0.0288\n",
      "Epoch [5/10], Step [681/750], Loss: 0.0302\n",
      "Epoch [5/10], Step [682/750], Loss: 0.0340\n",
      "Epoch [5/10], Step [683/750], Loss: 0.1248\n",
      "Epoch [5/10], Step [684/750], Loss: 0.0696\n",
      "Epoch [5/10], Step [685/750], Loss: 0.1025\n",
      "Epoch [5/10], Step [686/750], Loss: 0.0793\n",
      "Epoch [5/10], Step [687/750], Loss: 0.0717\n",
      "Epoch [5/10], Step [688/750], Loss: 0.0278\n",
      "Epoch [5/10], Step [689/750], Loss: 0.0430\n",
      "Epoch [5/10], Step [690/750], Loss: 0.0857\n",
      "Epoch [5/10], Step [691/750], Loss: 0.0721\n",
      "Epoch [5/10], Step [692/750], Loss: 0.1142\n",
      "Epoch [5/10], Step [693/750], Loss: 0.0829\n",
      "Epoch [5/10], Step [694/750], Loss: 0.0326\n",
      "Epoch [5/10], Step [695/750], Loss: 0.0100\n",
      "Epoch [5/10], Step [696/750], Loss: 0.0247\n",
      "Epoch [5/10], Step [697/750], Loss: 0.1141\n",
      "Epoch [5/10], Step [698/750], Loss: 0.0919\n",
      "Epoch [5/10], Step [699/750], Loss: 0.0460\n",
      "Epoch [5/10], Step [700/750], Loss: 0.0484\n",
      "Epoch [5/10], Step [701/750], Loss: 0.0526\n",
      "Epoch [5/10], Step [702/750], Loss: 0.1726\n",
      "Epoch [5/10], Step [703/750], Loss: 0.0347\n",
      "Epoch [5/10], Step [704/750], Loss: 0.0369\n",
      "Epoch [5/10], Step [705/750], Loss: 0.0176\n",
      "Epoch [5/10], Step [706/750], Loss: 0.0640\n",
      "Epoch [5/10], Step [707/750], Loss: 0.0431\n",
      "Epoch [5/10], Step [708/750], Loss: 0.0198\n",
      "Epoch [5/10], Step [709/750], Loss: 0.0537\n",
      "Epoch [5/10], Step [710/750], Loss: 0.0251\n",
      "Epoch [5/10], Step [711/750], Loss: 0.1662\n",
      "Epoch [5/10], Step [712/750], Loss: 0.0215\n",
      "Epoch [5/10], Step [713/750], Loss: 0.0346\n",
      "Epoch [5/10], Step [714/750], Loss: 0.0648\n",
      "Epoch [5/10], Step [715/750], Loss: 0.1829\n",
      "Epoch [5/10], Step [716/750], Loss: 0.1053\n",
      "Epoch [5/10], Step [717/750], Loss: 0.0842\n",
      "Epoch [5/10], Step [718/750], Loss: 0.0706\n",
      "Epoch [5/10], Step [719/750], Loss: 0.0203\n",
      "Epoch [5/10], Step [720/750], Loss: 0.0461\n",
      "Epoch [5/10], Step [721/750], Loss: 0.0766\n",
      "Epoch [5/10], Step [722/750], Loss: 0.0752\n",
      "Epoch [5/10], Step [723/750], Loss: 0.1940\n",
      "Epoch [5/10], Step [724/750], Loss: 0.0168\n",
      "Epoch [5/10], Step [725/750], Loss: 0.0235\n",
      "Epoch [5/10], Step [726/750], Loss: 0.1016\n",
      "Epoch [5/10], Step [727/750], Loss: 0.0813\n",
      "Epoch [5/10], Step [728/750], Loss: 0.0430\n",
      "Epoch [5/10], Step [729/750], Loss: 0.1504\n",
      "Epoch [5/10], Step [730/750], Loss: 0.1826\n",
      "Epoch [5/10], Step [731/750], Loss: 0.0480\n",
      "Epoch [5/10], Step [732/750], Loss: 0.0789\n",
      "Epoch [5/10], Step [733/750], Loss: 0.0960\n",
      "Epoch [5/10], Step [734/750], Loss: 0.0269\n",
      "Epoch [5/10], Step [735/750], Loss: 0.0622\n",
      "Epoch [5/10], Step [736/750], Loss: 0.0525\n",
      "Epoch [5/10], Step [737/750], Loss: 0.0500\n",
      "Epoch [5/10], Step [738/750], Loss: 0.0283\n",
      "Epoch [5/10], Step [739/750], Loss: 0.0424\n",
      "Epoch [5/10], Step [740/750], Loss: 0.0630\n",
      "Epoch [5/10], Step [741/750], Loss: 0.0913\n",
      "Epoch [5/10], Step [742/750], Loss: 0.0470\n",
      "Epoch [5/10], Step [743/750], Loss: 0.0098\n",
      "Epoch [5/10], Step [744/750], Loss: 0.0611\n",
      "Epoch [5/10], Step [745/750], Loss: 0.0585\n",
      "Epoch [5/10], Step [746/750], Loss: 0.1077\n",
      "Epoch [5/10], Step [747/750], Loss: 0.1626\n",
      "Epoch [5/10], Step [748/750], Loss: 0.0074\n",
      "Epoch [5/10], Step [749/750], Loss: 0.1131\n",
      "Epoch [5/10], Step [750/750], Loss: 0.0844\n",
      "\n",
      "\n",
      "Epoch [6/10], Step [1/750], Loss: 0.0186\n",
      "Epoch [6/10], Step [2/750], Loss: 0.0404\n",
      "Epoch [6/10], Step [3/750], Loss: 0.0985\n",
      "Epoch [6/10], Step [4/750], Loss: 0.0218\n",
      "Epoch [6/10], Step [5/750], Loss: 0.0219\n",
      "Epoch [6/10], Step [6/750], Loss: 0.0948\n",
      "Epoch [6/10], Step [7/750], Loss: 0.0862\n",
      "Epoch [6/10], Step [8/750], Loss: 0.0081\n",
      "Epoch [6/10], Step [9/750], Loss: 0.0510\n",
      "Epoch [6/10], Step [10/750], Loss: 0.0422\n",
      "Epoch [6/10], Step [11/750], Loss: 0.0367\n",
      "Epoch [6/10], Step [12/750], Loss: 0.0562\n",
      "Epoch [6/10], Step [13/750], Loss: 0.0510\n",
      "Epoch [6/10], Step [14/750], Loss: 0.0279\n",
      "Epoch [6/10], Step [15/750], Loss: 0.0747\n",
      "Epoch [6/10], Step [16/750], Loss: 0.0047\n",
      "Epoch [6/10], Step [17/750], Loss: 0.0268\n",
      "Epoch [6/10], Step [18/750], Loss: 0.0883\n",
      "Epoch [6/10], Step [19/750], Loss: 0.0263\n",
      "Epoch [6/10], Step [20/750], Loss: 0.0424\n",
      "Epoch [6/10], Step [21/750], Loss: 0.0541\n",
      "Epoch [6/10], Step [22/750], Loss: 0.0068\n",
      "Epoch [6/10], Step [23/750], Loss: 0.1344\n",
      "Epoch [6/10], Step [24/750], Loss: 0.0902\n",
      "Epoch [6/10], Step [25/750], Loss: 0.0182\n",
      "Epoch [6/10], Step [26/750], Loss: 0.0289\n",
      "Epoch [6/10], Step [27/750], Loss: 0.0127\n",
      "Epoch [6/10], Step [28/750], Loss: 0.0112\n",
      "Epoch [6/10], Step [29/750], Loss: 0.0171\n",
      "Epoch [6/10], Step [30/750], Loss: 0.0647\n",
      "Epoch [6/10], Step [31/750], Loss: 0.0824\n",
      "Epoch [6/10], Step [32/750], Loss: 0.0266\n",
      "Epoch [6/10], Step [33/750], Loss: 0.0233\n",
      "Epoch [6/10], Step [34/750], Loss: 0.0460\n",
      "Epoch [6/10], Step [35/750], Loss: 0.0232\n",
      "Epoch [6/10], Step [36/750], Loss: 0.0250\n",
      "Epoch [6/10], Step [37/750], Loss: 0.1210\n",
      "Epoch [6/10], Step [38/750], Loss: 0.0656\n",
      "Epoch [6/10], Step [39/750], Loss: 0.1374\n",
      "Epoch [6/10], Step [40/750], Loss: 0.1135\n",
      "Epoch [6/10], Step [41/750], Loss: 0.0488\n",
      "Epoch [6/10], Step [42/750], Loss: 0.1480\n",
      "Epoch [6/10], Step [43/750], Loss: 0.0486\n",
      "Epoch [6/10], Step [44/750], Loss: 0.0215\n",
      "Epoch [6/10], Step [45/750], Loss: 0.0729\n",
      "Epoch [6/10], Step [46/750], Loss: 0.0824\n",
      "Epoch [6/10], Step [47/750], Loss: 0.0153\n",
      "Epoch [6/10], Step [48/750], Loss: 0.0424\n",
      "Epoch [6/10], Step [49/750], Loss: 0.0625\n",
      "Epoch [6/10], Step [50/750], Loss: 0.0309\n",
      "Epoch [6/10], Step [51/750], Loss: 0.0168\n",
      "Epoch [6/10], Step [52/750], Loss: 0.0558\n",
      "Epoch [6/10], Step [53/750], Loss: 0.0492\n",
      "Epoch [6/10], Step [54/750], Loss: 0.0191\n",
      "Epoch [6/10], Step [55/750], Loss: 0.0493\n",
      "Epoch [6/10], Step [56/750], Loss: 0.0196\n",
      "Epoch [6/10], Step [57/750], Loss: 0.0214\n",
      "Epoch [6/10], Step [58/750], Loss: 0.2237\n",
      "Epoch [6/10], Step [59/750], Loss: 0.0330\n",
      "Epoch [6/10], Step [60/750], Loss: 0.0509\n",
      "Epoch [6/10], Step [61/750], Loss: 0.0731\n",
      "Epoch [6/10], Step [62/750], Loss: 0.0291\n",
      "Epoch [6/10], Step [63/750], Loss: 0.1280\n",
      "Epoch [6/10], Step [64/750], Loss: 0.0463\n",
      "Epoch [6/10], Step [65/750], Loss: 0.0453\n",
      "Epoch [6/10], Step [66/750], Loss: 0.1155\n",
      "Epoch [6/10], Step [67/750], Loss: 0.0463\n",
      "Epoch [6/10], Step [68/750], Loss: 0.0824\n",
      "Epoch [6/10], Step [69/750], Loss: 0.0061\n",
      "Epoch [6/10], Step [70/750], Loss: 0.1263\n",
      "Epoch [6/10], Step [71/750], Loss: 0.0207\n",
      "Epoch [6/10], Step [72/750], Loss: 0.0742\n",
      "Epoch [6/10], Step [73/750], Loss: 0.0254\n",
      "Epoch [6/10], Step [74/750], Loss: 0.0310\n",
      "Epoch [6/10], Step [75/750], Loss: 0.0478\n",
      "Epoch [6/10], Step [76/750], Loss: 0.2034\n",
      "Epoch [6/10], Step [77/750], Loss: 0.0475\n",
      "Epoch [6/10], Step [78/750], Loss: 0.0684\n",
      "Epoch [6/10], Step [79/750], Loss: 0.0381\n",
      "Epoch [6/10], Step [80/750], Loss: 0.0341\n",
      "Epoch [6/10], Step [81/750], Loss: 0.0546\n",
      "Epoch [6/10], Step [82/750], Loss: 0.0390\n",
      "Epoch [6/10], Step [83/750], Loss: 0.0085\n",
      "Epoch [6/10], Step [84/750], Loss: 0.0216\n",
      "Epoch [6/10], Step [85/750], Loss: 0.0230\n",
      "Epoch [6/10], Step [86/750], Loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [87/750], Loss: 0.0499\n",
      "Epoch [6/10], Step [88/750], Loss: 0.0801\n",
      "Epoch [6/10], Step [89/750], Loss: 0.0244\n",
      "Epoch [6/10], Step [90/750], Loss: 0.0109\n",
      "Epoch [6/10], Step [91/750], Loss: 0.0268\n",
      "Epoch [6/10], Step [92/750], Loss: 0.0157\n",
      "Epoch [6/10], Step [93/750], Loss: 0.1235\n",
      "Epoch [6/10], Step [94/750], Loss: 0.0570\n",
      "Epoch [6/10], Step [95/750], Loss: 0.0503\n",
      "Epoch [6/10], Step [96/750], Loss: 0.0346\n",
      "Epoch [6/10], Step [97/750], Loss: 0.0152\n",
      "Epoch [6/10], Step [98/750], Loss: 0.0812\n",
      "Epoch [6/10], Step [99/750], Loss: 0.0500\n",
      "Epoch [6/10], Step [100/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [101/750], Loss: 0.0256\n",
      "Epoch [6/10], Step [102/750], Loss: 0.0794\n",
      "Epoch [6/10], Step [103/750], Loss: 0.0172\n",
      "Epoch [6/10], Step [104/750], Loss: 0.0583\n",
      "Epoch [6/10], Step [105/750], Loss: 0.1039\n",
      "Epoch [6/10], Step [106/750], Loss: 0.0453\n",
      "Epoch [6/10], Step [107/750], Loss: 0.0699\n",
      "Epoch [6/10], Step [108/750], Loss: 0.1111\n",
      "Epoch [6/10], Step [109/750], Loss: 0.0467\n",
      "Epoch [6/10], Step [110/750], Loss: 0.0146\n",
      "Epoch [6/10], Step [111/750], Loss: 0.0038\n",
      "Epoch [6/10], Step [112/750], Loss: 0.0311\n",
      "Epoch [6/10], Step [113/750], Loss: 0.0083\n",
      "Epoch [6/10], Step [114/750], Loss: 0.0485\n",
      "Epoch [6/10], Step [115/750], Loss: 0.0162\n",
      "Epoch [6/10], Step [116/750], Loss: 0.0243\n",
      "Epoch [6/10], Step [117/750], Loss: 0.0600\n",
      "Epoch [6/10], Step [118/750], Loss: 0.0488\n",
      "Epoch [6/10], Step [119/750], Loss: 0.1195\n",
      "Epoch [6/10], Step [120/750], Loss: 0.0096\n",
      "Epoch [6/10], Step [121/750], Loss: 0.0608\n",
      "Epoch [6/10], Step [122/750], Loss: 0.0293\n",
      "Epoch [6/10], Step [123/750], Loss: 0.0671\n",
      "Epoch [6/10], Step [124/750], Loss: 0.0492\n",
      "Epoch [6/10], Step [125/750], Loss: 0.0708\n",
      "Epoch [6/10], Step [126/750], Loss: 0.1285\n",
      "Epoch [6/10], Step [127/750], Loss: 0.0163\n",
      "Epoch [6/10], Step [128/750], Loss: 0.0359\n",
      "Epoch [6/10], Step [129/750], Loss: 0.0205\n",
      "Epoch [6/10], Step [130/750], Loss: 0.1474\n",
      "Epoch [6/10], Step [131/750], Loss: 0.0112\n",
      "Epoch [6/10], Step [132/750], Loss: 0.0540\n",
      "Epoch [6/10], Step [133/750], Loss: 0.0438\n",
      "Epoch [6/10], Step [134/750], Loss: 0.0238\n",
      "Epoch [6/10], Step [135/750], Loss: 0.0295\n",
      "Epoch [6/10], Step [136/750], Loss: 0.0401\n",
      "Epoch [6/10], Step [137/750], Loss: 0.1317\n",
      "Epoch [6/10], Step [138/750], Loss: 0.0668\n",
      "Epoch [6/10], Step [139/750], Loss: 0.0149\n",
      "Epoch [6/10], Step [140/750], Loss: 0.0974\n",
      "Epoch [6/10], Step [141/750], Loss: 0.0895\n",
      "Epoch [6/10], Step [142/750], Loss: 0.0420\n",
      "Epoch [6/10], Step [143/750], Loss: 0.0318\n",
      "Epoch [6/10], Step [144/750], Loss: 0.0074\n",
      "Epoch [6/10], Step [145/750], Loss: 0.0538\n",
      "Epoch [6/10], Step [146/750], Loss: 0.0113\n",
      "Epoch [6/10], Step [147/750], Loss: 0.0239\n",
      "Epoch [6/10], Step [148/750], Loss: 0.0200\n",
      "Epoch [6/10], Step [149/750], Loss: 0.0386\n",
      "Epoch [6/10], Step [150/750], Loss: 0.0410\n",
      "Epoch [6/10], Step [151/750], Loss: 0.0870\n",
      "Epoch [6/10], Step [152/750], Loss: 0.0092\n",
      "Epoch [6/10], Step [153/750], Loss: 0.0463\n",
      "Epoch [6/10], Step [154/750], Loss: 0.2234\n",
      "Epoch [6/10], Step [155/750], Loss: 0.0052\n",
      "Epoch [6/10], Step [156/750], Loss: 0.0447\n",
      "Epoch [6/10], Step [157/750], Loss: 0.0208\n",
      "Epoch [6/10], Step [158/750], Loss: 0.0113\n",
      "Epoch [6/10], Step [159/750], Loss: 0.0336\n",
      "Epoch [6/10], Step [160/750], Loss: 0.0151\n",
      "Epoch [6/10], Step [161/750], Loss: 0.0333\n",
      "Epoch [6/10], Step [162/750], Loss: 0.0214\n",
      "Epoch [6/10], Step [163/750], Loss: 0.0477\n",
      "Epoch [6/10], Step [164/750], Loss: 0.0047\n",
      "Epoch [6/10], Step [165/750], Loss: 0.0460\n",
      "Epoch [6/10], Step [166/750], Loss: 0.0645\n",
      "Epoch [6/10], Step [167/750], Loss: 0.1111\n",
      "Epoch [6/10], Step [168/750], Loss: 0.0757\n",
      "Epoch [6/10], Step [169/750], Loss: 0.1630\n",
      "Epoch [6/10], Step [170/750], Loss: 0.0389\n",
      "Epoch [6/10], Step [171/750], Loss: 0.0301\n",
      "Epoch [6/10], Step [172/750], Loss: 0.0835\n",
      "Epoch [6/10], Step [173/750], Loss: 0.0246\n",
      "Epoch [6/10], Step [174/750], Loss: 0.0244\n",
      "Epoch [6/10], Step [175/750], Loss: 0.0151\n",
      "Epoch [6/10], Step [176/750], Loss: 0.0437\n",
      "Epoch [6/10], Step [177/750], Loss: 0.0408\n",
      "Epoch [6/10], Step [178/750], Loss: 0.0422\n",
      "Epoch [6/10], Step [179/750], Loss: 0.0720\n",
      "Epoch [6/10], Step [180/750], Loss: 0.0850\n",
      "Epoch [6/10], Step [181/750], Loss: 0.0367\n",
      "Epoch [6/10], Step [182/750], Loss: 0.0644\n",
      "Epoch [6/10], Step [183/750], Loss: 0.0656\n",
      "Epoch [6/10], Step [184/750], Loss: 0.0728\n",
      "Epoch [6/10], Step [185/750], Loss: 0.0475\n",
      "Epoch [6/10], Step [186/750], Loss: 0.1304\n",
      "Epoch [6/10], Step [187/750], Loss: 0.0074\n",
      "Epoch [6/10], Step [188/750], Loss: 0.0247\n",
      "Epoch [6/10], Step [189/750], Loss: 0.0403\n",
      "Epoch [6/10], Step [190/750], Loss: 0.0347\n",
      "Epoch [6/10], Step [191/750], Loss: 0.1293\n",
      "Epoch [6/10], Step [192/750], Loss: 0.1297\n",
      "Epoch [6/10], Step [193/750], Loss: 0.0228\n",
      "Epoch [6/10], Step [194/750], Loss: 0.1142\n",
      "Epoch [6/10], Step [195/750], Loss: 0.0719\n",
      "Epoch [6/10], Step [196/750], Loss: 0.0188\n",
      "Epoch [6/10], Step [197/750], Loss: 0.0419\n",
      "Epoch [6/10], Step [198/750], Loss: 0.0472\n",
      "Epoch [6/10], Step [199/750], Loss: 0.0571\n",
      "Epoch [6/10], Step [200/750], Loss: 0.0757\n",
      "Epoch [6/10], Step [201/750], Loss: 0.0968\n",
      "Epoch [6/10], Step [202/750], Loss: 0.1146\n",
      "Epoch [6/10], Step [203/750], Loss: 0.0408\n",
      "Epoch [6/10], Step [204/750], Loss: 0.0151\n",
      "Epoch [6/10], Step [205/750], Loss: 0.0726\n",
      "Epoch [6/10], Step [206/750], Loss: 0.0041\n",
      "Epoch [6/10], Step [207/750], Loss: 0.0437\n",
      "Epoch [6/10], Step [208/750], Loss: 0.0614\n",
      "Epoch [6/10], Step [209/750], Loss: 0.0664\n",
      "Epoch [6/10], Step [210/750], Loss: 0.0415\n",
      "Epoch [6/10], Step [211/750], Loss: 0.0095\n",
      "Epoch [6/10], Step [212/750], Loss: 0.0894\n",
      "Epoch [6/10], Step [213/750], Loss: 0.0478\n",
      "Epoch [6/10], Step [214/750], Loss: 0.0196\n",
      "Epoch [6/10], Step [215/750], Loss: 0.0850\n",
      "Epoch [6/10], Step [216/750], Loss: 0.0756\n",
      "Epoch [6/10], Step [217/750], Loss: 0.1002\n",
      "Epoch [6/10], Step [218/750], Loss: 0.0417\n",
      "Epoch [6/10], Step [219/750], Loss: 0.0170\n",
      "Epoch [6/10], Step [220/750], Loss: 0.0101\n",
      "Epoch [6/10], Step [221/750], Loss: 0.0306\n",
      "Epoch [6/10], Step [222/750], Loss: 0.0174\n",
      "Epoch [6/10], Step [223/750], Loss: 0.1543\n",
      "Epoch [6/10], Step [224/750], Loss: 0.0100\n",
      "Epoch [6/10], Step [225/750], Loss: 0.0291\n",
      "Epoch [6/10], Step [226/750], Loss: 0.0232\n",
      "Epoch [6/10], Step [227/750], Loss: 0.0334\n",
      "Epoch [6/10], Step [228/750], Loss: 0.2307\n",
      "Epoch [6/10], Step [229/750], Loss: 0.0299\n",
      "Epoch [6/10], Step [230/750], Loss: 0.0154\n",
      "Epoch [6/10], Step [231/750], Loss: 0.0532\n",
      "Epoch [6/10], Step [232/750], Loss: 0.1020\n",
      "Epoch [6/10], Step [233/750], Loss: 0.0366\n",
      "Epoch [6/10], Step [234/750], Loss: 0.0284\n",
      "Epoch [6/10], Step [235/750], Loss: 0.0809\n",
      "Epoch [6/10], Step [236/750], Loss: 0.0203\n",
      "Epoch [6/10], Step [237/750], Loss: 0.0108\n",
      "Epoch [6/10], Step [238/750], Loss: 0.0527\n",
      "Epoch [6/10], Step [239/750], Loss: 0.0216\n",
      "Epoch [6/10], Step [240/750], Loss: 0.0300\n",
      "Epoch [6/10], Step [241/750], Loss: 0.0606\n",
      "Epoch [6/10], Step [242/750], Loss: 0.0338\n",
      "Epoch [6/10], Step [243/750], Loss: 0.0696\n",
      "Epoch [6/10], Step [244/750], Loss: 0.0171\n",
      "Epoch [6/10], Step [245/750], Loss: 0.0041\n",
      "Epoch [6/10], Step [246/750], Loss: 0.0327\n",
      "Epoch [6/10], Step [247/750], Loss: 0.0381\n",
      "Epoch [6/10], Step [248/750], Loss: 0.0308\n",
      "Epoch [6/10], Step [249/750], Loss: 0.0865\n",
      "Epoch [6/10], Step [250/750], Loss: 0.0887\n",
      "Epoch [6/10], Step [251/750], Loss: 0.1588\n",
      "Epoch [6/10], Step [252/750], Loss: 0.0564\n",
      "Epoch [6/10], Step [253/750], Loss: 0.0883\n",
      "Epoch [6/10], Step [254/750], Loss: 0.0518\n",
      "Epoch [6/10], Step [255/750], Loss: 0.0555\n",
      "Epoch [6/10], Step [256/750], Loss: 0.0567\n",
      "Epoch [6/10], Step [257/750], Loss: 0.0518\n",
      "Epoch [6/10], Step [258/750], Loss: 0.1328\n",
      "Epoch [6/10], Step [259/750], Loss: 0.0199\n",
      "Epoch [6/10], Step [260/750], Loss: 0.0306\n",
      "Epoch [6/10], Step [261/750], Loss: 0.0173\n",
      "Epoch [6/10], Step [262/750], Loss: 0.1427\n",
      "Epoch [6/10], Step [263/750], Loss: 0.1530\n",
      "Epoch [6/10], Step [264/750], Loss: 0.1049\n",
      "Epoch [6/10], Step [265/750], Loss: 0.0954\n",
      "Epoch [6/10], Step [266/750], Loss: 0.0361\n",
      "Epoch [6/10], Step [267/750], Loss: 0.1693\n",
      "Epoch [6/10], Step [268/750], Loss: 0.0103\n",
      "Epoch [6/10], Step [269/750], Loss: 0.2570\n",
      "Epoch [6/10], Step [270/750], Loss: 0.0536\n",
      "Epoch [6/10], Step [271/750], Loss: 0.1613\n",
      "Epoch [6/10], Step [272/750], Loss: 0.0204\n",
      "Epoch [6/10], Step [273/750], Loss: 0.1173\n",
      "Epoch [6/10], Step [274/750], Loss: 0.0098\n",
      "Epoch [6/10], Step [275/750], Loss: 0.0048\n",
      "Epoch [6/10], Step [276/750], Loss: 0.0435\n",
      "Epoch [6/10], Step [277/750], Loss: 0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [278/750], Loss: 0.0332\n",
      "Epoch [6/10], Step [279/750], Loss: 0.0592\n",
      "Epoch [6/10], Step [280/750], Loss: 0.1393\n",
      "Epoch [6/10], Step [281/750], Loss: 0.0399\n",
      "Epoch [6/10], Step [282/750], Loss: 0.0275\n",
      "Epoch [6/10], Step [283/750], Loss: 0.0501\n",
      "Epoch [6/10], Step [284/750], Loss: 0.0702\n",
      "Epoch [6/10], Step [285/750], Loss: 0.0202\n",
      "Epoch [6/10], Step [286/750], Loss: 0.0706\n",
      "Epoch [6/10], Step [287/750], Loss: 0.0978\n",
      "Epoch [6/10], Step [288/750], Loss: 0.0716\n",
      "Epoch [6/10], Step [289/750], Loss: 0.0144\n",
      "Epoch [6/10], Step [290/750], Loss: 0.0394\n",
      "Epoch [6/10], Step [291/750], Loss: 0.0186\n",
      "Epoch [6/10], Step [292/750], Loss: 0.0907\n",
      "Epoch [6/10], Step [293/750], Loss: 0.1305\n",
      "Epoch [6/10], Step [294/750], Loss: 0.0293\n",
      "Epoch [6/10], Step [295/750], Loss: 0.0271\n",
      "Epoch [6/10], Step [296/750], Loss: 0.0334\n",
      "Epoch [6/10], Step [297/750], Loss: 0.0138\n",
      "Epoch [6/10], Step [298/750], Loss: 0.0301\n",
      "Epoch [6/10], Step [299/750], Loss: 0.0519\n",
      "Epoch [6/10], Step [300/750], Loss: 0.0343\n",
      "Epoch [6/10], Step [301/750], Loss: 0.0159\n",
      "Epoch [6/10], Step [302/750], Loss: 0.0136\n",
      "Epoch [6/10], Step [303/750], Loss: 0.0454\n",
      "Epoch [6/10], Step [304/750], Loss: 0.0406\n",
      "Epoch [6/10], Step [305/750], Loss: 0.0282\n",
      "Epoch [6/10], Step [306/750], Loss: 0.0408\n",
      "Epoch [6/10], Step [307/750], Loss: 0.0240\n",
      "Epoch [6/10], Step [308/750], Loss: 0.0452\n",
      "Epoch [6/10], Step [309/750], Loss: 0.0245\n",
      "Epoch [6/10], Step [310/750], Loss: 0.0711\n",
      "Epoch [6/10], Step [311/750], Loss: 0.0393\n",
      "Epoch [6/10], Step [312/750], Loss: 0.0167\n",
      "Epoch [6/10], Step [313/750], Loss: 0.0330\n",
      "Epoch [6/10], Step [314/750], Loss: 0.0871\n",
      "Epoch [6/10], Step [315/750], Loss: 0.0634\n",
      "Epoch [6/10], Step [316/750], Loss: 0.0700\n",
      "Epoch [6/10], Step [317/750], Loss: 0.0800\n",
      "Epoch [6/10], Step [318/750], Loss: 0.0771\n",
      "Epoch [6/10], Step [319/750], Loss: 0.0302\n",
      "Epoch [6/10], Step [320/750], Loss: 0.0327\n",
      "Epoch [6/10], Step [321/750], Loss: 0.0541\n",
      "Epoch [6/10], Step [322/750], Loss: 0.0608\n",
      "Epoch [6/10], Step [323/750], Loss: 0.0876\n",
      "Epoch [6/10], Step [324/750], Loss: 0.0529\n",
      "Epoch [6/10], Step [325/750], Loss: 0.0668\n",
      "Epoch [6/10], Step [326/750], Loss: 0.0216\n",
      "Epoch [6/10], Step [327/750], Loss: 0.0627\n",
      "Epoch [6/10], Step [328/750], Loss: 0.0283\n",
      "Epoch [6/10], Step [329/750], Loss: 0.0310\n",
      "Epoch [6/10], Step [330/750], Loss: 0.0197\n",
      "Epoch [6/10], Step [331/750], Loss: 0.1288\n",
      "Epoch [6/10], Step [332/750], Loss: 0.0457\n",
      "Epoch [6/10], Step [333/750], Loss: 0.0464\n",
      "Epoch [6/10], Step [334/750], Loss: 0.1213\n",
      "Epoch [6/10], Step [335/750], Loss: 0.0970\n",
      "Epoch [6/10], Step [336/750], Loss: 0.0660\n",
      "Epoch [6/10], Step [337/750], Loss: 0.0660\n",
      "Epoch [6/10], Step [338/750], Loss: 0.0687\n",
      "Epoch [6/10], Step [339/750], Loss: 0.0272\n",
      "Epoch [6/10], Step [340/750], Loss: 0.1244\n",
      "Epoch [6/10], Step [341/750], Loss: 0.2610\n",
      "Epoch [6/10], Step [342/750], Loss: 0.2010\n",
      "Epoch [6/10], Step [343/750], Loss: 0.1499\n",
      "Epoch [6/10], Step [344/750], Loss: 0.0404\n",
      "Epoch [6/10], Step [345/750], Loss: 0.0562\n",
      "Epoch [6/10], Step [346/750], Loss: 0.1374\n",
      "Epoch [6/10], Step [347/750], Loss: 0.0143\n",
      "Epoch [6/10], Step [348/750], Loss: 0.0593\n",
      "Epoch [6/10], Step [349/750], Loss: 0.2169\n",
      "Epoch [6/10], Step [350/750], Loss: 0.0076\n",
      "Epoch [6/10], Step [351/750], Loss: 0.0363\n",
      "Epoch [6/10], Step [352/750], Loss: 0.0247\n",
      "Epoch [6/10], Step [353/750], Loss: 0.0626\n",
      "Epoch [6/10], Step [354/750], Loss: 0.0983\n",
      "Epoch [6/10], Step [355/750], Loss: 0.0586\n",
      "Epoch [6/10], Step [356/750], Loss: 0.0590\n",
      "Epoch [6/10], Step [357/750], Loss: 0.0336\n",
      "Epoch [6/10], Step [358/750], Loss: 0.0495\n",
      "Epoch [6/10], Step [359/750], Loss: 0.0699\n",
      "Epoch [6/10], Step [360/750], Loss: 0.1492\n",
      "Epoch [6/10], Step [361/750], Loss: 0.0235\n",
      "Epoch [6/10], Step [362/750], Loss: 0.1080\n",
      "Epoch [6/10], Step [363/750], Loss: 0.1783\n",
      "Epoch [6/10], Step [364/750], Loss: 0.1203\n",
      "Epoch [6/10], Step [365/750], Loss: 0.0608\n",
      "Epoch [6/10], Step [366/750], Loss: 0.0123\n",
      "Epoch [6/10], Step [367/750], Loss: 0.0546\n",
      "Epoch [6/10], Step [368/750], Loss: 0.0809\n",
      "Epoch [6/10], Step [369/750], Loss: 0.1042\n",
      "Epoch [6/10], Step [370/750], Loss: 0.0147\n",
      "Epoch [6/10], Step [371/750], Loss: 0.0376\n",
      "Epoch [6/10], Step [372/750], Loss: 0.1804\n",
      "Epoch [6/10], Step [373/750], Loss: 0.0634\n",
      "Epoch [6/10], Step [374/750], Loss: 0.0388\n",
      "Epoch [6/10], Step [375/750], Loss: 0.0578\n",
      "Epoch [6/10], Step [376/750], Loss: 0.2671\n",
      "Epoch [6/10], Step [377/750], Loss: 0.0538\n",
      "Epoch [6/10], Step [378/750], Loss: 0.1910\n",
      "Epoch [6/10], Step [379/750], Loss: 0.0293\n",
      "Epoch [6/10], Step [380/750], Loss: 0.0279\n",
      "Epoch [6/10], Step [381/750], Loss: 0.0458\n",
      "Epoch [6/10], Step [382/750], Loss: 0.0531\n",
      "Epoch [6/10], Step [383/750], Loss: 0.2069\n",
      "Epoch [6/10], Step [384/750], Loss: 0.0541\n",
      "Epoch [6/10], Step [385/750], Loss: 0.0193\n",
      "Epoch [6/10], Step [386/750], Loss: 0.0883\n",
      "Epoch [6/10], Step [387/750], Loss: 0.0149\n",
      "Epoch [6/10], Step [388/750], Loss: 0.0466\n",
      "Epoch [6/10], Step [389/750], Loss: 0.1658\n",
      "Epoch [6/10], Step [390/750], Loss: 0.1316\n",
      "Epoch [6/10], Step [391/750], Loss: 0.0686\n",
      "Epoch [6/10], Step [392/750], Loss: 0.0771\n",
      "Epoch [6/10], Step [393/750], Loss: 0.1095\n",
      "Epoch [6/10], Step [394/750], Loss: 0.0341\n",
      "Epoch [6/10], Step [395/750], Loss: 0.2257\n",
      "Epoch [6/10], Step [396/750], Loss: 0.0162\n",
      "Epoch [6/10], Step [397/750], Loss: 0.0809\n",
      "Epoch [6/10], Step [398/750], Loss: 0.0233\n",
      "Epoch [6/10], Step [399/750], Loss: 0.0061\n",
      "Epoch [6/10], Step [400/750], Loss: 0.0860\n",
      "Epoch [6/10], Step [401/750], Loss: 0.0473\n",
      "Epoch [6/10], Step [402/750], Loss: 0.0191\n",
      "Epoch [6/10], Step [403/750], Loss: 0.0134\n",
      "Epoch [6/10], Step [404/750], Loss: 0.0120\n",
      "Epoch [6/10], Step [405/750], Loss: 0.0860\n",
      "Epoch [6/10], Step [406/750], Loss: 0.0472\n",
      "Epoch [6/10], Step [407/750], Loss: 0.0545\n",
      "Epoch [6/10], Step [408/750], Loss: 0.0182\n",
      "Epoch [6/10], Step [409/750], Loss: 0.0773\n",
      "Epoch [6/10], Step [410/750], Loss: 0.0757\n",
      "Epoch [6/10], Step [411/750], Loss: 0.0324\n",
      "Epoch [6/10], Step [412/750], Loss: 0.0715\n",
      "Epoch [6/10], Step [413/750], Loss: 0.0186\n",
      "Epoch [6/10], Step [414/750], Loss: 0.0147\n",
      "Epoch [6/10], Step [415/750], Loss: 0.0666\n",
      "Epoch [6/10], Step [416/750], Loss: 0.0134\n",
      "Epoch [6/10], Step [417/750], Loss: 0.0705\n",
      "Epoch [6/10], Step [418/750], Loss: 0.1449\n",
      "Epoch [6/10], Step [419/750], Loss: 0.0412\n",
      "Epoch [6/10], Step [420/750], Loss: 0.0714\n",
      "Epoch [6/10], Step [421/750], Loss: 0.0894\n",
      "Epoch [6/10], Step [422/750], Loss: 0.0725\n",
      "Epoch [6/10], Step [423/750], Loss: 0.0458\n",
      "Epoch [6/10], Step [424/750], Loss: 0.0481\n",
      "Epoch [6/10], Step [425/750], Loss: 0.0964\n",
      "Epoch [6/10], Step [426/750], Loss: 0.0396\n",
      "Epoch [6/10], Step [427/750], Loss: 0.0579\n",
      "Epoch [6/10], Step [428/750], Loss: 0.1501\n",
      "Epoch [6/10], Step [429/750], Loss: 0.0245\n",
      "Epoch [6/10], Step [430/750], Loss: 0.1330\n",
      "Epoch [6/10], Step [431/750], Loss: 0.0952\n",
      "Epoch [6/10], Step [432/750], Loss: 0.0583\n",
      "Epoch [6/10], Step [433/750], Loss: 0.0643\n",
      "Epoch [6/10], Step [434/750], Loss: 0.0922\n",
      "Epoch [6/10], Step [435/750], Loss: 0.1274\n",
      "Epoch [6/10], Step [436/750], Loss: 0.0323\n",
      "Epoch [6/10], Step [437/750], Loss: 0.0642\n",
      "Epoch [6/10], Step [438/750], Loss: 0.0076\n",
      "Epoch [6/10], Step [439/750], Loss: 0.1185\n",
      "Epoch [6/10], Step [440/750], Loss: 0.0392\n",
      "Epoch [6/10], Step [441/750], Loss: 0.0341\n",
      "Epoch [6/10], Step [442/750], Loss: 0.0941\n",
      "Epoch [6/10], Step [443/750], Loss: 0.1183\n",
      "Epoch [6/10], Step [444/750], Loss: 0.0462\n",
      "Epoch [6/10], Step [445/750], Loss: 0.0046\n",
      "Epoch [6/10], Step [446/750], Loss: 0.0592\n",
      "Epoch [6/10], Step [447/750], Loss: 0.0519\n",
      "Epoch [6/10], Step [448/750], Loss: 0.0335\n",
      "Epoch [6/10], Step [449/750], Loss: 0.0521\n",
      "Epoch [6/10], Step [450/750], Loss: 0.0550\n",
      "Epoch [6/10], Step [451/750], Loss: 0.0426\n",
      "Epoch [6/10], Step [452/750], Loss: 0.0495\n",
      "Epoch [6/10], Step [453/750], Loss: 0.1439\n",
      "Epoch [6/10], Step [454/750], Loss: 0.0945\n",
      "Epoch [6/10], Step [455/750], Loss: 0.0380\n",
      "Epoch [6/10], Step [456/750], Loss: 0.0796\n",
      "Epoch [6/10], Step [457/750], Loss: 0.0090\n",
      "Epoch [6/10], Step [458/750], Loss: 0.1203\n",
      "Epoch [6/10], Step [459/750], Loss: 0.0739\n",
      "Epoch [6/10], Step [460/750], Loss: 0.0837\n",
      "Epoch [6/10], Step [461/750], Loss: 0.0298\n",
      "Epoch [6/10], Step [462/750], Loss: 0.0384\n",
      "Epoch [6/10], Step [463/750], Loss: 0.0952\n",
      "Epoch [6/10], Step [464/750], Loss: 0.0341\n",
      "Epoch [6/10], Step [465/750], Loss: 0.0777\n",
      "Epoch [6/10], Step [466/750], Loss: 0.0256\n",
      "Epoch [6/10], Step [467/750], Loss: 0.1035\n",
      "Epoch [6/10], Step [468/750], Loss: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [469/750], Loss: 0.0383\n",
      "Epoch [6/10], Step [470/750], Loss: 0.0141\n",
      "Epoch [6/10], Step [471/750], Loss: 0.0523\n",
      "Epoch [6/10], Step [472/750], Loss: 0.1306\n",
      "Epoch [6/10], Step [473/750], Loss: 0.0196\n",
      "Epoch [6/10], Step [474/750], Loss: 0.0508\n",
      "Epoch [6/10], Step [475/750], Loss: 0.0569\n",
      "Epoch [6/10], Step [476/750], Loss: 0.0652\n",
      "Epoch [6/10], Step [477/750], Loss: 0.0808\n",
      "Epoch [6/10], Step [478/750], Loss: 0.1251\n",
      "Epoch [6/10], Step [479/750], Loss: 0.0448\n",
      "Epoch [6/10], Step [480/750], Loss: 0.0657\n",
      "Epoch [6/10], Step [481/750], Loss: 0.0590\n",
      "Epoch [6/10], Step [482/750], Loss: 0.1237\n",
      "Epoch [6/10], Step [483/750], Loss: 0.0047\n",
      "Epoch [6/10], Step [484/750], Loss: 0.0269\n",
      "Epoch [6/10], Step [485/750], Loss: 0.0535\n",
      "Epoch [6/10], Step [486/750], Loss: 0.0458\n",
      "Epoch [6/10], Step [487/750], Loss: 0.0042\n",
      "Epoch [6/10], Step [488/750], Loss: 0.1607\n",
      "Epoch [6/10], Step [489/750], Loss: 0.1752\n",
      "Epoch [6/10], Step [490/750], Loss: 0.0120\n",
      "Epoch [6/10], Step [491/750], Loss: 0.0853\n",
      "Epoch [6/10], Step [492/750], Loss: 0.0163\n",
      "Epoch [6/10], Step [493/750], Loss: 0.1350\n",
      "Epoch [6/10], Step [494/750], Loss: 0.0557\n",
      "Epoch [6/10], Step [495/750], Loss: 0.0560\n",
      "Epoch [6/10], Step [496/750], Loss: 0.0942\n",
      "Epoch [6/10], Step [497/750], Loss: 0.0252\n",
      "Epoch [6/10], Step [498/750], Loss: 0.0770\n",
      "Epoch [6/10], Step [499/750], Loss: 0.1605\n",
      "Epoch [6/10], Step [500/750], Loss: 0.0792\n",
      "Epoch [6/10], Step [501/750], Loss: 0.0218\n",
      "Epoch [6/10], Step [502/750], Loss: 0.1440\n",
      "Epoch [6/10], Step [503/750], Loss: 0.0368\n",
      "Epoch [6/10], Step [504/750], Loss: 0.0654\n",
      "Epoch [6/10], Step [505/750], Loss: 0.0660\n",
      "Epoch [6/10], Step [506/750], Loss: 0.0359\n",
      "Epoch [6/10], Step [507/750], Loss: 0.0547\n",
      "Epoch [6/10], Step [508/750], Loss: 0.0718\n",
      "Epoch [6/10], Step [509/750], Loss: 0.0180\n",
      "Epoch [6/10], Step [510/750], Loss: 0.0313\n",
      "Epoch [6/10], Step [511/750], Loss: 0.0397\n",
      "Epoch [6/10], Step [512/750], Loss: 0.1643\n",
      "Epoch [6/10], Step [513/750], Loss: 0.0273\n",
      "Epoch [6/10], Step [514/750], Loss: 0.0187\n",
      "Epoch [6/10], Step [515/750], Loss: 0.0448\n",
      "Epoch [6/10], Step [516/750], Loss: 0.2083\n",
      "Epoch [6/10], Step [517/750], Loss: 0.0173\n",
      "Epoch [6/10], Step [518/750], Loss: 0.0243\n",
      "Epoch [6/10], Step [519/750], Loss: 0.0208\n",
      "Epoch [6/10], Step [520/750], Loss: 0.0659\n",
      "Epoch [6/10], Step [521/750], Loss: 0.0477\n",
      "Epoch [6/10], Step [522/750], Loss: 0.0845\n",
      "Epoch [6/10], Step [523/750], Loss: 0.1636\n",
      "Epoch [6/10], Step [524/750], Loss: 0.1194\n",
      "Epoch [6/10], Step [525/750], Loss: 0.0101\n",
      "Epoch [6/10], Step [526/750], Loss: 0.0941\n",
      "Epoch [6/10], Step [527/750], Loss: 0.0464\n",
      "Epoch [6/10], Step [528/750], Loss: 0.1779\n",
      "Epoch [6/10], Step [529/750], Loss: 0.0469\n",
      "Epoch [6/10], Step [530/750], Loss: 0.0169\n",
      "Epoch [6/10], Step [531/750], Loss: 0.0939\n",
      "Epoch [6/10], Step [532/750], Loss: 0.0419\n",
      "Epoch [6/10], Step [533/750], Loss: 0.0580\n",
      "Epoch [6/10], Step [534/750], Loss: 0.0189\n",
      "Epoch [6/10], Step [535/750], Loss: 0.0401\n",
      "Epoch [6/10], Step [536/750], Loss: 0.0528\n",
      "Epoch [6/10], Step [537/750], Loss: 0.1401\n",
      "Epoch [6/10], Step [538/750], Loss: 0.0117\n",
      "Epoch [6/10], Step [539/750], Loss: 0.0632\n",
      "Epoch [6/10], Step [540/750], Loss: 0.2463\n",
      "Epoch [6/10], Step [541/750], Loss: 0.0259\n",
      "Epoch [6/10], Step [542/750], Loss: 0.0064\n",
      "Epoch [6/10], Step [543/750], Loss: 0.0138\n",
      "Epoch [6/10], Step [544/750], Loss: 0.0305\n",
      "Epoch [6/10], Step [545/750], Loss: 0.1415\n",
      "Epoch [6/10], Step [546/750], Loss: 0.0731\n",
      "Epoch [6/10], Step [547/750], Loss: 0.0139\n",
      "Epoch [6/10], Step [548/750], Loss: 0.0605\n",
      "Epoch [6/10], Step [549/750], Loss: 0.0076\n",
      "Epoch [6/10], Step [550/750], Loss: 0.0127\n",
      "Epoch [6/10], Step [551/750], Loss: 0.0686\n",
      "Epoch [6/10], Step [552/750], Loss: 0.0846\n",
      "Epoch [6/10], Step [553/750], Loss: 0.0752\n",
      "Epoch [6/10], Step [554/750], Loss: 0.0067\n",
      "Epoch [6/10], Step [555/750], Loss: 0.0182\n",
      "Epoch [6/10], Step [556/750], Loss: 0.0554\n",
      "Epoch [6/10], Step [557/750], Loss: 0.0178\n",
      "Epoch [6/10], Step [558/750], Loss: 0.1900\n",
      "Epoch [6/10], Step [559/750], Loss: 0.1442\n",
      "Epoch [6/10], Step [560/750], Loss: 0.0476\n",
      "Epoch [6/10], Step [561/750], Loss: 0.1657\n",
      "Epoch [6/10], Step [562/750], Loss: 0.0327\n",
      "Epoch [6/10], Step [563/750], Loss: 0.1031\n",
      "Epoch [6/10], Step [564/750], Loss: 0.0727\n",
      "Epoch [6/10], Step [565/750], Loss: 0.0116\n",
      "Epoch [6/10], Step [566/750], Loss: 0.0618\n",
      "Epoch [6/10], Step [567/750], Loss: 0.1462\n",
      "Epoch [6/10], Step [568/750], Loss: 0.0442\n",
      "Epoch [6/10], Step [569/750], Loss: 0.0572\n",
      "Epoch [6/10], Step [570/750], Loss: 0.0177\n",
      "Epoch [6/10], Step [571/750], Loss: 0.0662\n",
      "Epoch [6/10], Step [572/750], Loss: 0.0215\n",
      "Epoch [6/10], Step [573/750], Loss: 0.1326\n",
      "Epoch [6/10], Step [574/750], Loss: 0.0493\n",
      "Epoch [6/10], Step [575/750], Loss: 0.0092\n",
      "Epoch [6/10], Step [576/750], Loss: 0.1218\n",
      "Epoch [6/10], Step [577/750], Loss: 0.0453\n",
      "Epoch [6/10], Step [578/750], Loss: 0.0301\n",
      "Epoch [6/10], Step [579/750], Loss: 0.0927\n",
      "Epoch [6/10], Step [580/750], Loss: 0.0709\n",
      "Epoch [6/10], Step [581/750], Loss: 0.0468\n",
      "Epoch [6/10], Step [582/750], Loss: 0.0802\n",
      "Epoch [6/10], Step [583/750], Loss: 0.0076\n",
      "Epoch [6/10], Step [584/750], Loss: 0.0436\n",
      "Epoch [6/10], Step [585/750], Loss: 0.0124\n",
      "Epoch [6/10], Step [586/750], Loss: 0.1150\n",
      "Epoch [6/10], Step [587/750], Loss: 0.0161\n",
      "Epoch [6/10], Step [588/750], Loss: 0.0354\n",
      "Epoch [6/10], Step [589/750], Loss: 0.0825\n",
      "Epoch [6/10], Step [590/750], Loss: 0.0951\n",
      "Epoch [6/10], Step [591/750], Loss: 0.0459\n",
      "Epoch [6/10], Step [592/750], Loss: 0.1261\n",
      "Epoch [6/10], Step [593/750], Loss: 0.0990\n",
      "Epoch [6/10], Step [594/750], Loss: 0.0637\n",
      "Epoch [6/10], Step [595/750], Loss: 0.0041\n",
      "Epoch [6/10], Step [596/750], Loss: 0.1193\n",
      "Epoch [6/10], Step [597/750], Loss: 0.0676\n",
      "Epoch [6/10], Step [598/750], Loss: 0.0576\n",
      "Epoch [6/10], Step [599/750], Loss: 0.0036\n",
      "Epoch [6/10], Step [600/750], Loss: 0.0742\n",
      "Epoch [6/10], Step [601/750], Loss: 0.0534\n",
      "Epoch [6/10], Step [602/750], Loss: 0.0143\n",
      "Epoch [6/10], Step [603/750], Loss: 0.0739\n",
      "Epoch [6/10], Step [604/750], Loss: 0.0529\n",
      "Epoch [6/10], Step [605/750], Loss: 0.0089\n",
      "Epoch [6/10], Step [606/750], Loss: 0.0166\n",
      "Epoch [6/10], Step [607/750], Loss: 0.0759\n",
      "Epoch [6/10], Step [608/750], Loss: 0.0615\n",
      "Epoch [6/10], Step [609/750], Loss: 0.1054\n",
      "Epoch [6/10], Step [610/750], Loss: 0.0664\n",
      "Epoch [6/10], Step [611/750], Loss: 0.1769\n",
      "Epoch [6/10], Step [612/750], Loss: 0.1273\n",
      "Epoch [6/10], Step [613/750], Loss: 0.0352\n",
      "Epoch [6/10], Step [614/750], Loss: 0.0105\n",
      "Epoch [6/10], Step [615/750], Loss: 0.0575\n",
      "Epoch [6/10], Step [616/750], Loss: 0.1457\n",
      "Epoch [6/10], Step [617/750], Loss: 0.0931\n",
      "Epoch [6/10], Step [618/750], Loss: 0.1174\n",
      "Epoch [6/10], Step [619/750], Loss: 0.0430\n",
      "Epoch [6/10], Step [620/750], Loss: 0.0266\n",
      "Epoch [6/10], Step [621/750], Loss: 0.0298\n",
      "Epoch [6/10], Step [622/750], Loss: 0.0289\n",
      "Epoch [6/10], Step [623/750], Loss: 0.1098\n",
      "Epoch [6/10], Step [624/750], Loss: 0.0933\n",
      "Epoch [6/10], Step [625/750], Loss: 0.0604\n",
      "Epoch [6/10], Step [626/750], Loss: 0.0423\n",
      "Epoch [6/10], Step [627/750], Loss: 0.0392\n",
      "Epoch [6/10], Step [628/750], Loss: 0.0246\n",
      "Epoch [6/10], Step [629/750], Loss: 0.0121\n",
      "Epoch [6/10], Step [630/750], Loss: 0.1432\n",
      "Epoch [6/10], Step [631/750], Loss: 0.0631\n",
      "Epoch [6/10], Step [632/750], Loss: 0.3311\n",
      "Epoch [6/10], Step [633/750], Loss: 0.1209\n",
      "Epoch [6/10], Step [634/750], Loss: 0.1207\n",
      "Epoch [6/10], Step [635/750], Loss: 0.1262\n",
      "Epoch [6/10], Step [636/750], Loss: 0.0476\n",
      "Epoch [6/10], Step [637/750], Loss: 0.1406\n",
      "Epoch [6/10], Step [638/750], Loss: 0.0524\n",
      "Epoch [6/10], Step [639/750], Loss: 0.1530\n",
      "Epoch [6/10], Step [640/750], Loss: 0.0181\n",
      "Epoch [6/10], Step [641/750], Loss: 0.0713\n",
      "Epoch [6/10], Step [642/750], Loss: 0.0875\n",
      "Epoch [6/10], Step [643/750], Loss: 0.1183\n",
      "Epoch [6/10], Step [644/750], Loss: 0.0685\n",
      "Epoch [6/10], Step [645/750], Loss: 0.0845\n",
      "Epoch [6/10], Step [646/750], Loss: 0.1622\n",
      "Epoch [6/10], Step [647/750], Loss: 0.1052\n",
      "Epoch [6/10], Step [648/750], Loss: 0.0840\n",
      "Epoch [6/10], Step [649/750], Loss: 0.0243\n",
      "Epoch [6/10], Step [650/750], Loss: 0.0326\n",
      "Epoch [6/10], Step [651/750], Loss: 0.0780\n",
      "Epoch [6/10], Step [652/750], Loss: 0.0470\n",
      "Epoch [6/10], Step [653/750], Loss: 0.0265\n",
      "Epoch [6/10], Step [654/750], Loss: 0.3225\n",
      "Epoch [6/10], Step [655/750], Loss: 0.0194\n",
      "Epoch [6/10], Step [656/750], Loss: 0.0749\n",
      "Epoch [6/10], Step [657/750], Loss: 0.1197\n",
      "Epoch [6/10], Step [658/750], Loss: 0.1330\n",
      "Epoch [6/10], Step [659/750], Loss: 0.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [660/750], Loss: 0.0738\n",
      "Epoch [6/10], Step [661/750], Loss: 0.1035\n",
      "Epoch [6/10], Step [662/750], Loss: 0.0885\n",
      "Epoch [6/10], Step [663/750], Loss: 0.1207\n",
      "Epoch [6/10], Step [664/750], Loss: 0.0317\n",
      "Epoch [6/10], Step [665/750], Loss: 0.0111\n",
      "Epoch [6/10], Step [666/750], Loss: 0.0352\n",
      "Epoch [6/10], Step [667/750], Loss: 0.0267\n",
      "Epoch [6/10], Step [668/750], Loss: 0.0771\n",
      "Epoch [6/10], Step [669/750], Loss: 0.0503\n",
      "Epoch [6/10], Step [670/750], Loss: 0.0416\n",
      "Epoch [6/10], Step [671/750], Loss: 0.0263\n",
      "Epoch [6/10], Step [672/750], Loss: 0.0213\n",
      "Epoch [6/10], Step [673/750], Loss: 0.0723\n",
      "Epoch [6/10], Step [674/750], Loss: 0.0612\n",
      "Epoch [6/10], Step [675/750], Loss: 0.0209\n",
      "Epoch [6/10], Step [676/750], Loss: 0.1593\n",
      "Epoch [6/10], Step [677/750], Loss: 0.0608\n",
      "Epoch [6/10], Step [678/750], Loss: 0.0461\n",
      "Epoch [6/10], Step [679/750], Loss: 0.1360\n",
      "Epoch [6/10], Step [680/750], Loss: 0.0398\n",
      "Epoch [6/10], Step [681/750], Loss: 0.0904\n",
      "Epoch [6/10], Step [682/750], Loss: 0.1497\n",
      "Epoch [6/10], Step [683/750], Loss: 0.0355\n",
      "Epoch [6/10], Step [684/750], Loss: 0.0853\n",
      "Epoch [6/10], Step [685/750], Loss: 0.3128\n",
      "Epoch [6/10], Step [686/750], Loss: 0.0466\n",
      "Epoch [6/10], Step [687/750], Loss: 0.0756\n",
      "Epoch [6/10], Step [688/750], Loss: 0.0692\n",
      "Epoch [6/10], Step [689/750], Loss: 0.0938\n",
      "Epoch [6/10], Step [690/750], Loss: 0.0988\n",
      "Epoch [6/10], Step [691/750], Loss: 0.0242\n",
      "Epoch [6/10], Step [692/750], Loss: 0.2503\n",
      "Epoch [6/10], Step [693/750], Loss: 0.0756\n",
      "Epoch [6/10], Step [694/750], Loss: 0.0574\n",
      "Epoch [6/10], Step [695/750], Loss: 0.0489\n",
      "Epoch [6/10], Step [696/750], Loss: 0.1406\n",
      "Epoch [6/10], Step [697/750], Loss: 0.0352\n",
      "Epoch [6/10], Step [698/750], Loss: 0.0696\n",
      "Epoch [6/10], Step [699/750], Loss: 0.0775\n",
      "Epoch [6/10], Step [700/750], Loss: 0.0662\n",
      "Epoch [6/10], Step [701/750], Loss: 0.0375\n",
      "Epoch [6/10], Step [702/750], Loss: 0.0385\n",
      "Epoch [6/10], Step [703/750], Loss: 0.0062\n",
      "Epoch [6/10], Step [704/750], Loss: 0.0725\n",
      "Epoch [6/10], Step [705/750], Loss: 0.0228\n",
      "Epoch [6/10], Step [706/750], Loss: 0.0209\n",
      "Epoch [6/10], Step [707/750], Loss: 0.0382\n",
      "Epoch [6/10], Step [708/750], Loss: 0.1725\n",
      "Epoch [6/10], Step [709/750], Loss: 0.1604\n",
      "Epoch [6/10], Step [710/750], Loss: 0.0097\n",
      "Epoch [6/10], Step [711/750], Loss: 0.0862\n",
      "Epoch [6/10], Step [712/750], Loss: 0.0215\n",
      "Epoch [6/10], Step [713/750], Loss: 0.1092\n",
      "Epoch [6/10], Step [714/750], Loss: 0.0368\n",
      "Epoch [6/10], Step [715/750], Loss: 0.1304\n",
      "Epoch [6/10], Step [716/750], Loss: 0.0687\n",
      "Epoch [6/10], Step [717/750], Loss: 0.0568\n",
      "Epoch [6/10], Step [718/750], Loss: 0.0396\n",
      "Epoch [6/10], Step [719/750], Loss: 0.0545\n",
      "Epoch [6/10], Step [720/750], Loss: 0.0144\n",
      "Epoch [6/10], Step [721/750], Loss: 0.0508\n",
      "Epoch [6/10], Step [722/750], Loss: 0.0155\n",
      "Epoch [6/10], Step [723/750], Loss: 0.0916\n",
      "Epoch [6/10], Step [724/750], Loss: 0.0090\n",
      "Epoch [6/10], Step [725/750], Loss: 0.0029\n",
      "Epoch [6/10], Step [726/750], Loss: 0.0379\n",
      "Epoch [6/10], Step [727/750], Loss: 0.0252\n",
      "Epoch [6/10], Step [728/750], Loss: 0.0509\n",
      "Epoch [6/10], Step [729/750], Loss: 0.0147\n",
      "Epoch [6/10], Step [730/750], Loss: 0.0222\n",
      "Epoch [6/10], Step [731/750], Loss: 0.0394\n",
      "Epoch [6/10], Step [732/750], Loss: 0.0390\n",
      "Epoch [6/10], Step [733/750], Loss: 0.1091\n",
      "Epoch [6/10], Step [734/750], Loss: 0.0845\n",
      "Epoch [6/10], Step [735/750], Loss: 0.0665\n",
      "Epoch [6/10], Step [736/750], Loss: 0.0128\n",
      "Epoch [6/10], Step [737/750], Loss: 0.0260\n",
      "Epoch [6/10], Step [738/750], Loss: 0.0624\n",
      "Epoch [6/10], Step [739/750], Loss: 0.0863\n",
      "Epoch [6/10], Step [740/750], Loss: 0.0631\n",
      "Epoch [6/10], Step [741/750], Loss: 0.0203\n",
      "Epoch [6/10], Step [742/750], Loss: 0.0678\n",
      "Epoch [6/10], Step [743/750], Loss: 0.0613\n",
      "Epoch [6/10], Step [744/750], Loss: 0.0323\n",
      "Epoch [6/10], Step [745/750], Loss: 0.0999\n",
      "Epoch [6/10], Step [746/750], Loss: 0.1726\n",
      "Epoch [6/10], Step [747/750], Loss: 0.0271\n",
      "Epoch [6/10], Step [748/750], Loss: 0.0382\n",
      "Epoch [6/10], Step [749/750], Loss: 0.0481\n",
      "Epoch [6/10], Step [750/750], Loss: 0.0315\n",
      "\n",
      "\n",
      "Epoch [7/10], Step [1/750], Loss: 0.0597\n",
      "Epoch [7/10], Step [2/750], Loss: 0.0395\n",
      "Epoch [7/10], Step [3/750], Loss: 0.0388\n",
      "Epoch [7/10], Step [4/750], Loss: 0.0136\n",
      "Epoch [7/10], Step [5/750], Loss: 0.0118\n",
      "Epoch [7/10], Step [6/750], Loss: 0.0675\n",
      "Epoch [7/10], Step [7/750], Loss: 0.0195\n",
      "Epoch [7/10], Step [8/750], Loss: 0.0624\n",
      "Epoch [7/10], Step [9/750], Loss: 0.1468\n",
      "Epoch [7/10], Step [10/750], Loss: 0.0210\n",
      "Epoch [7/10], Step [11/750], Loss: 0.0893\n",
      "Epoch [7/10], Step [12/750], Loss: 0.0329\n",
      "Epoch [7/10], Step [13/750], Loss: 0.0565\n",
      "Epoch [7/10], Step [14/750], Loss: 0.0378\n",
      "Epoch [7/10], Step [15/750], Loss: 0.0356\n",
      "Epoch [7/10], Step [16/750], Loss: 0.0174\n",
      "Epoch [7/10], Step [17/750], Loss: 0.0244\n",
      "Epoch [7/10], Step [18/750], Loss: 0.1170\n",
      "Epoch [7/10], Step [19/750], Loss: 0.0159\n",
      "Epoch [7/10], Step [20/750], Loss: 0.0555\n",
      "Epoch [7/10], Step [21/750], Loss: 0.0208\n",
      "Epoch [7/10], Step [22/750], Loss: 0.0054\n",
      "Epoch [7/10], Step [23/750], Loss: 0.0145\n",
      "Epoch [7/10], Step [24/750], Loss: 0.0695\n",
      "Epoch [7/10], Step [25/750], Loss: 0.0080\n",
      "Epoch [7/10], Step [26/750], Loss: 0.0107\n",
      "Epoch [7/10], Step [27/750], Loss: 0.0057\n",
      "Epoch [7/10], Step [28/750], Loss: 0.0285\n",
      "Epoch [7/10], Step [29/750], Loss: 0.0415\n",
      "Epoch [7/10], Step [30/750], Loss: 0.0135\n",
      "Epoch [7/10], Step [31/750], Loss: 0.0983\n",
      "Epoch [7/10], Step [32/750], Loss: 0.1256\n",
      "Epoch [7/10], Step [33/750], Loss: 0.0053\n",
      "Epoch [7/10], Step [34/750], Loss: 0.0258\n",
      "Epoch [7/10], Step [35/750], Loss: 0.0438\n",
      "Epoch [7/10], Step [36/750], Loss: 0.0883\n",
      "Epoch [7/10], Step [37/750], Loss: 0.0073\n",
      "Epoch [7/10], Step [38/750], Loss: 0.0113\n",
      "Epoch [7/10], Step [39/750], Loss: 0.0335\n",
      "Epoch [7/10], Step [40/750], Loss: 0.0260\n",
      "Epoch [7/10], Step [41/750], Loss: 0.0943\n",
      "Epoch [7/10], Step [42/750], Loss: 0.0384\n",
      "Epoch [7/10], Step [43/750], Loss: 0.0243\n",
      "Epoch [7/10], Step [44/750], Loss: 0.0341\n",
      "Epoch [7/10], Step [45/750], Loss: 0.0522\n",
      "Epoch [7/10], Step [46/750], Loss: 0.0189\n",
      "Epoch [7/10], Step [47/750], Loss: 0.0370\n",
      "Epoch [7/10], Step [48/750], Loss: 0.0813\n",
      "Epoch [7/10], Step [49/750], Loss: 0.0819\n",
      "Epoch [7/10], Step [50/750], Loss: 0.0202\n",
      "Epoch [7/10], Step [51/750], Loss: 0.0605\n",
      "Epoch [7/10], Step [52/750], Loss: 0.0118\n",
      "Epoch [7/10], Step [53/750], Loss: 0.0081\n",
      "Epoch [7/10], Step [54/750], Loss: 0.0268\n",
      "Epoch [7/10], Step [55/750], Loss: 0.0788\n",
      "Epoch [7/10], Step [56/750], Loss: 0.0928\n",
      "Epoch [7/10], Step [57/750], Loss: 0.0834\n",
      "Epoch [7/10], Step [58/750], Loss: 0.0278\n",
      "Epoch [7/10], Step [59/750], Loss: 0.0606\n",
      "Epoch [7/10], Step [60/750], Loss: 0.0039\n",
      "Epoch [7/10], Step [61/750], Loss: 0.0369\n",
      "Epoch [7/10], Step [62/750], Loss: 0.0433\n",
      "Epoch [7/10], Step [63/750], Loss: 0.1320\n",
      "Epoch [7/10], Step [64/750], Loss: 0.0384\n",
      "Epoch [7/10], Step [65/750], Loss: 0.0933\n",
      "Epoch [7/10], Step [66/750], Loss: 0.0465\n",
      "Epoch [7/10], Step [67/750], Loss: 0.0454\n",
      "Epoch [7/10], Step [68/750], Loss: 0.0364\n",
      "Epoch [7/10], Step [69/750], Loss: 0.0279\n",
      "Epoch [7/10], Step [70/750], Loss: 0.0234\n",
      "Epoch [7/10], Step [71/750], Loss: 0.0424\n",
      "Epoch [7/10], Step [72/750], Loss: 0.0782\n",
      "Epoch [7/10], Step [73/750], Loss: 0.0338\n",
      "Epoch [7/10], Step [74/750], Loss: 0.0215\n",
      "Epoch [7/10], Step [75/750], Loss: 0.0396\n",
      "Epoch [7/10], Step [76/750], Loss: 0.0558\n",
      "Epoch [7/10], Step [77/750], Loss: 0.0974\n",
      "Epoch [7/10], Step [78/750], Loss: 0.0970\n",
      "Epoch [7/10], Step [79/750], Loss: 0.0660\n",
      "Epoch [7/10], Step [80/750], Loss: 0.0512\n",
      "Epoch [7/10], Step [81/750], Loss: 0.0274\n",
      "Epoch [7/10], Step [82/750], Loss: 0.2707\n",
      "Epoch [7/10], Step [83/750], Loss: 0.0713\n",
      "Epoch [7/10], Step [84/750], Loss: 0.0251\n",
      "Epoch [7/10], Step [85/750], Loss: 0.0356\n",
      "Epoch [7/10], Step [86/750], Loss: 0.0559\n",
      "Epoch [7/10], Step [87/750], Loss: 0.0636\n",
      "Epoch [7/10], Step [88/750], Loss: 0.0808\n",
      "Epoch [7/10], Step [89/750], Loss: 0.0484\n",
      "Epoch [7/10], Step [90/750], Loss: 0.1388\n",
      "Epoch [7/10], Step [91/750], Loss: 0.0341\n",
      "Epoch [7/10], Step [92/750], Loss: 0.0053\n",
      "Epoch [7/10], Step [93/750], Loss: 0.0616\n",
      "Epoch [7/10], Step [94/750], Loss: 0.0549\n",
      "Epoch [7/10], Step [95/750], Loss: 0.0110\n",
      "Epoch [7/10], Step [96/750], Loss: 0.1455\n",
      "Epoch [7/10], Step [97/750], Loss: 0.0208\n",
      "Epoch [7/10], Step [98/750], Loss: 0.1773\n",
      "Epoch [7/10], Step [99/750], Loss: 0.0288\n",
      "Epoch [7/10], Step [100/750], Loss: 0.0255\n",
      "Epoch [7/10], Step [101/750], Loss: 0.0183\n",
      "Epoch [7/10], Step [102/750], Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [103/750], Loss: 0.0510\n",
      "Epoch [7/10], Step [104/750], Loss: 0.0863\n",
      "Epoch [7/10], Step [105/750], Loss: 0.1711\n",
      "Epoch [7/10], Step [106/750], Loss: 0.1567\n",
      "Epoch [7/10], Step [107/750], Loss: 0.0358\n",
      "Epoch [7/10], Step [108/750], Loss: 0.0557\n",
      "Epoch [7/10], Step [109/750], Loss: 0.0538\n",
      "Epoch [7/10], Step [110/750], Loss: 0.0232\n",
      "Epoch [7/10], Step [111/750], Loss: 0.1031\n",
      "Epoch [7/10], Step [112/750], Loss: 0.0484\n",
      "Epoch [7/10], Step [113/750], Loss: 0.0539\n",
      "Epoch [7/10], Step [114/750], Loss: 0.0107\n",
      "Epoch [7/10], Step [115/750], Loss: 0.1037\n",
      "Epoch [7/10], Step [116/750], Loss: 0.1453\n",
      "Epoch [7/10], Step [117/750], Loss: 0.0728\n",
      "Epoch [7/10], Step [118/750], Loss: 0.0663\n",
      "Epoch [7/10], Step [119/750], Loss: 0.0747\n",
      "Epoch [7/10], Step [120/750], Loss: 0.0445\n",
      "Epoch [7/10], Step [121/750], Loss: 0.0822\n",
      "Epoch [7/10], Step [122/750], Loss: 0.0388\n",
      "Epoch [7/10], Step [123/750], Loss: 0.1208\n",
      "Epoch [7/10], Step [124/750], Loss: 0.1179\n",
      "Epoch [7/10], Step [125/750], Loss: 0.0258\n",
      "Epoch [7/10], Step [126/750], Loss: 0.0288\n",
      "Epoch [7/10], Step [127/750], Loss: 0.0258\n",
      "Epoch [7/10], Step [128/750], Loss: 0.0430\n",
      "Epoch [7/10], Step [129/750], Loss: 0.0475\n",
      "Epoch [7/10], Step [130/750], Loss: 0.1122\n",
      "Epoch [7/10], Step [131/750], Loss: 0.0912\n",
      "Epoch [7/10], Step [132/750], Loss: 0.0638\n",
      "Epoch [7/10], Step [133/750], Loss: 0.0454\n",
      "Epoch [7/10], Step [134/750], Loss: 0.0813\n",
      "Epoch [7/10], Step [135/750], Loss: 0.0657\n",
      "Epoch [7/10], Step [136/750], Loss: 0.0941\n",
      "Epoch [7/10], Step [137/750], Loss: 0.0615\n",
      "Epoch [7/10], Step [138/750], Loss: 0.0246\n",
      "Epoch [7/10], Step [139/750], Loss: 0.0860\n",
      "Epoch [7/10], Step [140/750], Loss: 0.0472\n",
      "Epoch [7/10], Step [141/750], Loss: 0.0782\n",
      "Epoch [7/10], Step [142/750], Loss: 0.0449\n",
      "Epoch [7/10], Step [143/750], Loss: 0.0790\n",
      "Epoch [7/10], Step [144/750], Loss: 0.1234\n",
      "Epoch [7/10], Step [145/750], Loss: 0.0366\n",
      "Epoch [7/10], Step [146/750], Loss: 0.0505\n",
      "Epoch [7/10], Step [147/750], Loss: 0.0499\n",
      "Epoch [7/10], Step [148/750], Loss: 0.0844\n",
      "Epoch [7/10], Step [149/750], Loss: 0.0607\n",
      "Epoch [7/10], Step [150/750], Loss: 0.1167\n",
      "Epoch [7/10], Step [151/750], Loss: 0.0899\n",
      "Epoch [7/10], Step [152/750], Loss: 0.0194\n",
      "Epoch [7/10], Step [153/750], Loss: 0.0819\n",
      "Epoch [7/10], Step [154/750], Loss: 0.0165\n",
      "Epoch [7/10], Step [155/750], Loss: 0.0266\n",
      "Epoch [7/10], Step [156/750], Loss: 0.0141\n",
      "Epoch [7/10], Step [157/750], Loss: 0.0095\n",
      "Epoch [7/10], Step [158/750], Loss: 0.0327\n",
      "Epoch [7/10], Step [159/750], Loss: 0.0331\n",
      "Epoch [7/10], Step [160/750], Loss: 0.1413\n",
      "Epoch [7/10], Step [161/750], Loss: 0.1375\n",
      "Epoch [7/10], Step [162/750], Loss: 0.1157\n",
      "Epoch [7/10], Step [163/750], Loss: 0.0696\n",
      "Epoch [7/10], Step [164/750], Loss: 0.0323\n",
      "Epoch [7/10], Step [165/750], Loss: 0.0215\n",
      "Epoch [7/10], Step [166/750], Loss: 0.0438\n",
      "Epoch [7/10], Step [167/750], Loss: 0.0217\n",
      "Epoch [7/10], Step [168/750], Loss: 0.0554\n",
      "Epoch [7/10], Step [169/750], Loss: 0.0415\n",
      "Epoch [7/10], Step [170/750], Loss: 0.0521\n",
      "Epoch [7/10], Step [171/750], Loss: 0.1148\n",
      "Epoch [7/10], Step [172/750], Loss: 0.0352\n",
      "Epoch [7/10], Step [173/750], Loss: 0.0485\n",
      "Epoch [7/10], Step [174/750], Loss: 0.0352\n",
      "Epoch [7/10], Step [175/750], Loss: 0.0401\n",
      "Epoch [7/10], Step [176/750], Loss: 0.0769\n",
      "Epoch [7/10], Step [177/750], Loss: 0.0038\n",
      "Epoch [7/10], Step [178/750], Loss: 0.0486\n",
      "Epoch [7/10], Step [179/750], Loss: 0.0523\n",
      "Epoch [7/10], Step [180/750], Loss: 0.0078\n",
      "Epoch [7/10], Step [181/750], Loss: 0.0257\n",
      "Epoch [7/10], Step [182/750], Loss: 0.0406\n",
      "Epoch [7/10], Step [183/750], Loss: 0.1065\n",
      "Epoch [7/10], Step [184/750], Loss: 0.0650\n",
      "Epoch [7/10], Step [185/750], Loss: 0.0496\n",
      "Epoch [7/10], Step [186/750], Loss: 0.0316\n",
      "Epoch [7/10], Step [187/750], Loss: 0.0680\n",
      "Epoch [7/10], Step [188/750], Loss: 0.0824\n",
      "Epoch [7/10], Step [189/750], Loss: 0.0982\n",
      "Epoch [7/10], Step [190/750], Loss: 0.0774\n",
      "Epoch [7/10], Step [191/750], Loss: 0.0371\n",
      "Epoch [7/10], Step [192/750], Loss: 0.0721\n",
      "Epoch [7/10], Step [193/750], Loss: 0.0105\n",
      "Epoch [7/10], Step [194/750], Loss: 0.0556\n",
      "Epoch [7/10], Step [195/750], Loss: 0.0244\n",
      "Epoch [7/10], Step [196/750], Loss: 0.0257\n",
      "Epoch [7/10], Step [197/750], Loss: 0.0053\n",
      "Epoch [7/10], Step [198/750], Loss: 0.1088\n",
      "Epoch [7/10], Step [199/750], Loss: 0.0895\n",
      "Epoch [7/10], Step [200/750], Loss: 0.0361\n",
      "Epoch [7/10], Step [201/750], Loss: 0.0129\n",
      "Epoch [7/10], Step [202/750], Loss: 0.0071\n",
      "Epoch [7/10], Step [203/750], Loss: 0.0956\n",
      "Epoch [7/10], Step [204/750], Loss: 0.0144\n",
      "Epoch [7/10], Step [205/750], Loss: 0.0301\n",
      "Epoch [7/10], Step [206/750], Loss: 0.0493\n",
      "Epoch [7/10], Step [207/750], Loss: 0.0378\n",
      "Epoch [7/10], Step [208/750], Loss: 0.0178\n",
      "Epoch [7/10], Step [209/750], Loss: 0.0521\n",
      "Epoch [7/10], Step [210/750], Loss: 0.0185\n",
      "Epoch [7/10], Step [211/750], Loss: 0.0429\n",
      "Epoch [7/10], Step [212/750], Loss: 0.1659\n",
      "Epoch [7/10], Step [213/750], Loss: 0.0598\n",
      "Epoch [7/10], Step [214/750], Loss: 0.0544\n",
      "Epoch [7/10], Step [215/750], Loss: 0.2223\n",
      "Epoch [7/10], Step [216/750], Loss: 0.1146\n",
      "Epoch [7/10], Step [217/750], Loss: 0.0132\n",
      "Epoch [7/10], Step [218/750], Loss: 0.2129\n",
      "Epoch [7/10], Step [219/750], Loss: 0.0852\n",
      "Epoch [7/10], Step [220/750], Loss: 0.0479\n",
      "Epoch [7/10], Step [221/750], Loss: 0.0945\n",
      "Epoch [7/10], Step [222/750], Loss: 0.0195\n",
      "Epoch [7/10], Step [223/750], Loss: 0.0176\n",
      "Epoch [7/10], Step [224/750], Loss: 0.1480\n",
      "Epoch [7/10], Step [225/750], Loss: 0.0378\n",
      "Epoch [7/10], Step [226/750], Loss: 0.2209\n",
      "Epoch [7/10], Step [227/750], Loss: 0.0615\n",
      "Epoch [7/10], Step [228/750], Loss: 0.0474\n",
      "Epoch [7/10], Step [229/750], Loss: 0.0565\n",
      "Epoch [7/10], Step [230/750], Loss: 0.0096\n",
      "Epoch [7/10], Step [231/750], Loss: 0.0743\n",
      "Epoch [7/10], Step [232/750], Loss: 0.0751\n",
      "Epoch [7/10], Step [233/750], Loss: 0.0160\n",
      "Epoch [7/10], Step [234/750], Loss: 0.0889\n",
      "Epoch [7/10], Step [235/750], Loss: 0.0080\n",
      "Epoch [7/10], Step [236/750], Loss: 0.0385\n",
      "Epoch [7/10], Step [237/750], Loss: 0.0298\n",
      "Epoch [7/10], Step [238/750], Loss: 0.0814\n",
      "Epoch [7/10], Step [239/750], Loss: 0.0183\n",
      "Epoch [7/10], Step [240/750], Loss: 0.1405\n",
      "Epoch [7/10], Step [241/750], Loss: 0.1816\n",
      "Epoch [7/10], Step [242/750], Loss: 0.0441\n",
      "Epoch [7/10], Step [243/750], Loss: 0.0775\n",
      "Epoch [7/10], Step [244/750], Loss: 0.1112\n",
      "Epoch [7/10], Step [245/750], Loss: 0.1277\n",
      "Epoch [7/10], Step [246/750], Loss: 0.0987\n",
      "Epoch [7/10], Step [247/750], Loss: 0.1451\n",
      "Epoch [7/10], Step [248/750], Loss: 0.0992\n",
      "Epoch [7/10], Step [249/750], Loss: 0.1156\n",
      "Epoch [7/10], Step [250/750], Loss: 0.0472\n",
      "Epoch [7/10], Step [251/750], Loss: 0.0946\n",
      "Epoch [7/10], Step [252/750], Loss: 0.0259\n",
      "Epoch [7/10], Step [253/750], Loss: 0.0426\n",
      "Epoch [7/10], Step [254/750], Loss: 0.0343\n",
      "Epoch [7/10], Step [255/750], Loss: 0.0943\n",
      "Epoch [7/10], Step [256/750], Loss: 0.1504\n",
      "Epoch [7/10], Step [257/750], Loss: 0.0911\n",
      "Epoch [7/10], Step [258/750], Loss: 0.0968\n",
      "Epoch [7/10], Step [259/750], Loss: 0.0801\n",
      "Epoch [7/10], Step [260/750], Loss: 0.0401\n",
      "Epoch [7/10], Step [261/750], Loss: 0.0199\n",
      "Epoch [7/10], Step [262/750], Loss: 0.0432\n",
      "Epoch [7/10], Step [263/750], Loss: 0.1416\n",
      "Epoch [7/10], Step [264/750], Loss: 0.0708\n",
      "Epoch [7/10], Step [265/750], Loss: 0.1814\n",
      "Epoch [7/10], Step [266/750], Loss: 0.1046\n",
      "Epoch [7/10], Step [267/750], Loss: 0.0756\n",
      "Epoch [7/10], Step [268/750], Loss: 0.0261\n",
      "Epoch [7/10], Step [269/750], Loss: 0.0793\n",
      "Epoch [7/10], Step [270/750], Loss: 0.0187\n",
      "Epoch [7/10], Step [271/750], Loss: 0.0952\n",
      "Epoch [7/10], Step [272/750], Loss: 0.0175\n",
      "Epoch [7/10], Step [273/750], Loss: 0.1037\n",
      "Epoch [7/10], Step [274/750], Loss: 0.2070\n",
      "Epoch [7/10], Step [275/750], Loss: 0.1519\n",
      "Epoch [7/10], Step [276/750], Loss: 0.0366\n",
      "Epoch [7/10], Step [277/750], Loss: 0.0220\n",
      "Epoch [7/10], Step [278/750], Loss: 0.0194\n",
      "Epoch [7/10], Step [279/750], Loss: 0.1424\n",
      "Epoch [7/10], Step [280/750], Loss: 0.0996\n",
      "Epoch [7/10], Step [281/750], Loss: 0.0251\n",
      "Epoch [7/10], Step [282/750], Loss: 0.0188\n",
      "Epoch [7/10], Step [283/750], Loss: 0.1110\n",
      "Epoch [7/10], Step [284/750], Loss: 0.0188\n",
      "Epoch [7/10], Step [285/750], Loss: 0.0436\n",
      "Epoch [7/10], Step [286/750], Loss: 0.0275\n",
      "Epoch [7/10], Step [287/750], Loss: 0.0163\n",
      "Epoch [7/10], Step [288/750], Loss: 0.0267\n",
      "Epoch [7/10], Step [289/750], Loss: 0.0263\n",
      "Epoch [7/10], Step [290/750], Loss: 0.1561\n",
      "Epoch [7/10], Step [291/750], Loss: 0.1527\n",
      "Epoch [7/10], Step [292/750], Loss: 0.0440\n",
      "Epoch [7/10], Step [293/750], Loss: 0.0627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [294/750], Loss: 0.0671\n",
      "Epoch [7/10], Step [295/750], Loss: 0.0575\n",
      "Epoch [7/10], Step [296/750], Loss: 0.0549\n",
      "Epoch [7/10], Step [297/750], Loss: 0.0346\n",
      "Epoch [7/10], Step [298/750], Loss: 0.1738\n",
      "Epoch [7/10], Step [299/750], Loss: 0.0256\n",
      "Epoch [7/10], Step [300/750], Loss: 0.0173\n",
      "Epoch [7/10], Step [301/750], Loss: 0.0385\n",
      "Epoch [7/10], Step [302/750], Loss: 0.1693\n",
      "Epoch [7/10], Step [303/750], Loss: 0.0703\n",
      "Epoch [7/10], Step [304/750], Loss: 0.0883\n",
      "Epoch [7/10], Step [305/750], Loss: 0.0752\n",
      "Epoch [7/10], Step [306/750], Loss: 0.0579\n",
      "Epoch [7/10], Step [307/750], Loss: 0.0666\n",
      "Epoch [7/10], Step [308/750], Loss: 0.1468\n",
      "Epoch [7/10], Step [309/750], Loss: 0.1249\n",
      "Epoch [7/10], Step [310/750], Loss: 0.0072\n",
      "Epoch [7/10], Step [311/750], Loss: 0.2109\n",
      "Epoch [7/10], Step [312/750], Loss: 0.0630\n",
      "Epoch [7/10], Step [313/750], Loss: 0.0303\n",
      "Epoch [7/10], Step [314/750], Loss: 0.0632\n",
      "Epoch [7/10], Step [315/750], Loss: 0.0387\n",
      "Epoch [7/10], Step [316/750], Loss: 0.0341\n",
      "Epoch [7/10], Step [317/750], Loss: 0.0491\n",
      "Epoch [7/10], Step [318/750], Loss: 0.1312\n",
      "Epoch [7/10], Step [319/750], Loss: 0.0427\n",
      "Epoch [7/10], Step [320/750], Loss: 0.0309\n",
      "Epoch [7/10], Step [321/750], Loss: 0.0132\n",
      "Epoch [7/10], Step [322/750], Loss: 0.0092\n",
      "Epoch [7/10], Step [323/750], Loss: 0.0867\n",
      "Epoch [7/10], Step [324/750], Loss: 0.0261\n",
      "Epoch [7/10], Step [325/750], Loss: 0.0279\n",
      "Epoch [7/10], Step [326/750], Loss: 0.0467\n",
      "Epoch [7/10], Step [327/750], Loss: 0.0598\n",
      "Epoch [7/10], Step [328/750], Loss: 0.0083\n",
      "Epoch [7/10], Step [329/750], Loss: 0.0244\n",
      "Epoch [7/10], Step [330/750], Loss: 0.0665\n",
      "Epoch [7/10], Step [331/750], Loss: 0.0521\n",
      "Epoch [7/10], Step [332/750], Loss: 0.0113\n",
      "Epoch [7/10], Step [333/750], Loss: 0.0108\n",
      "Epoch [7/10], Step [334/750], Loss: 0.0263\n",
      "Epoch [7/10], Step [335/750], Loss: 0.0318\n",
      "Epoch [7/10], Step [336/750], Loss: 0.0530\n",
      "Epoch [7/10], Step [337/750], Loss: 0.0484\n",
      "Epoch [7/10], Step [338/750], Loss: 0.0465\n",
      "Epoch [7/10], Step [339/750], Loss: 0.0674\n",
      "Epoch [7/10], Step [340/750], Loss: 0.0201\n",
      "Epoch [7/10], Step [341/750], Loss: 0.0542\n",
      "Epoch [7/10], Step [342/750], Loss: 0.2092\n",
      "Epoch [7/10], Step [343/750], Loss: 0.0510\n",
      "Epoch [7/10], Step [344/750], Loss: 0.0619\n",
      "Epoch [7/10], Step [345/750], Loss: 0.0363\n",
      "Epoch [7/10], Step [346/750], Loss: 0.0531\n",
      "Epoch [7/10], Step [347/750], Loss: 0.0040\n",
      "Epoch [7/10], Step [348/750], Loss: 0.0081\n",
      "Epoch [7/10], Step [349/750], Loss: 0.0430\n",
      "Epoch [7/10], Step [350/750], Loss: 0.0235\n",
      "Epoch [7/10], Step [351/750], Loss: 0.0168\n",
      "Epoch [7/10], Step [352/750], Loss: 0.0254\n",
      "Epoch [7/10], Step [353/750], Loss: 0.0139\n",
      "Epoch [7/10], Step [354/750], Loss: 0.0823\n",
      "Epoch [7/10], Step [355/750], Loss: 0.0571\n",
      "Epoch [7/10], Step [356/750], Loss: 0.0732\n",
      "Epoch [7/10], Step [357/750], Loss: 0.1019\n",
      "Epoch [7/10], Step [358/750], Loss: 0.0804\n",
      "Epoch [7/10], Step [359/750], Loss: 0.0281\n",
      "Epoch [7/10], Step [360/750], Loss: 0.0770\n",
      "Epoch [7/10], Step [361/750], Loss: 0.0193\n",
      "Epoch [7/10], Step [362/750], Loss: 0.0466\n",
      "Epoch [7/10], Step [363/750], Loss: 0.1404\n",
      "Epoch [7/10], Step [364/750], Loss: 0.0900\n",
      "Epoch [7/10], Step [365/750], Loss: 0.0305\n",
      "Epoch [7/10], Step [366/750], Loss: 0.0763\n",
      "Epoch [7/10], Step [367/750], Loss: 0.0373\n",
      "Epoch [7/10], Step [368/750], Loss: 0.0235\n",
      "Epoch [7/10], Step [369/750], Loss: 0.0811\n",
      "Epoch [7/10], Step [370/750], Loss: 0.0127\n",
      "Epoch [7/10], Step [371/750], Loss: 0.1359\n",
      "Epoch [7/10], Step [372/750], Loss: 0.0114\n",
      "Epoch [7/10], Step [373/750], Loss: 0.0790\n",
      "Epoch [7/10], Step [374/750], Loss: 0.0180\n",
      "Epoch [7/10], Step [375/750], Loss: 0.0630\n",
      "Epoch [7/10], Step [376/750], Loss: 0.1993\n",
      "Epoch [7/10], Step [377/750], Loss: 0.1324\n",
      "Epoch [7/10], Step [378/750], Loss: 0.0837\n",
      "Epoch [7/10], Step [379/750], Loss: 0.0590\n",
      "Epoch [7/10], Step [380/750], Loss: 0.0252\n",
      "Epoch [7/10], Step [381/750], Loss: 0.0242\n",
      "Epoch [7/10], Step [382/750], Loss: 0.2009\n",
      "Epoch [7/10], Step [383/750], Loss: 0.0437\n",
      "Epoch [7/10], Step [384/750], Loss: 0.0952\n",
      "Epoch [7/10], Step [385/750], Loss: 0.0327\n",
      "Epoch [7/10], Step [386/750], Loss: 0.0490\n",
      "Epoch [7/10], Step [387/750], Loss: 0.0304\n",
      "Epoch [7/10], Step [388/750], Loss: 0.0242\n",
      "Epoch [7/10], Step [389/750], Loss: 0.0604\n",
      "Epoch [7/10], Step [390/750], Loss: 0.0699\n",
      "Epoch [7/10], Step [391/750], Loss: 0.0061\n",
      "Epoch [7/10], Step [392/750], Loss: 0.0821\n",
      "Epoch [7/10], Step [393/750], Loss: 0.0840\n",
      "Epoch [7/10], Step [394/750], Loss: 0.1351\n",
      "Epoch [7/10], Step [395/750], Loss: 0.0314\n",
      "Epoch [7/10], Step [396/750], Loss: 0.0167\n",
      "Epoch [7/10], Step [397/750], Loss: 0.0372\n",
      "Epoch [7/10], Step [398/750], Loss: 0.0593\n",
      "Epoch [7/10], Step [399/750], Loss: 0.1440\n",
      "Epoch [7/10], Step [400/750], Loss: 0.0493\n",
      "Epoch [7/10], Step [401/750], Loss: 0.0095\n",
      "Epoch [7/10], Step [402/750], Loss: 0.0141\n",
      "Epoch [7/10], Step [403/750], Loss: 0.0308\n",
      "Epoch [7/10], Step [404/750], Loss: 0.1250\n",
      "Epoch [7/10], Step [405/750], Loss: 0.0430\n",
      "Epoch [7/10], Step [406/750], Loss: 0.0155\n",
      "Epoch [7/10], Step [407/750], Loss: 0.0674\n",
      "Epoch [7/10], Step [408/750], Loss: 0.0082\n",
      "Epoch [7/10], Step [409/750], Loss: 0.0158\n",
      "Epoch [7/10], Step [410/750], Loss: 0.0397\n",
      "Epoch [7/10], Step [411/750], Loss: 0.0227\n",
      "Epoch [7/10], Step [412/750], Loss: 0.0675\n",
      "Epoch [7/10], Step [413/750], Loss: 0.0141\n",
      "Epoch [7/10], Step [414/750], Loss: 0.1381\n",
      "Epoch [7/10], Step [415/750], Loss: 0.0272\n",
      "Epoch [7/10], Step [416/750], Loss: 0.0242\n",
      "Epoch [7/10], Step [417/750], Loss: 0.0197\n",
      "Epoch [7/10], Step [418/750], Loss: 0.0237\n",
      "Epoch [7/10], Step [419/750], Loss: 0.0839\n",
      "Epoch [7/10], Step [420/750], Loss: 0.0281\n",
      "Epoch [7/10], Step [421/750], Loss: 0.1273\n",
      "Epoch [7/10], Step [422/750], Loss: 0.0591\n",
      "Epoch [7/10], Step [423/750], Loss: 0.0499\n",
      "Epoch [7/10], Step [424/750], Loss: 0.0081\n",
      "Epoch [7/10], Step [425/750], Loss: 0.0924\n",
      "Epoch [7/10], Step [426/750], Loss: 0.1809\n",
      "Epoch [7/10], Step [427/750], Loss: 0.0900\n",
      "Epoch [7/10], Step [428/750], Loss: 0.0081\n",
      "Epoch [7/10], Step [429/750], Loss: 0.1581\n",
      "Epoch [7/10], Step [430/750], Loss: 0.0998\n",
      "Epoch [7/10], Step [431/750], Loss: 0.0692\n",
      "Epoch [7/10], Step [432/750], Loss: 0.0864\n",
      "Epoch [7/10], Step [433/750], Loss: 0.1846\n",
      "Epoch [7/10], Step [434/750], Loss: 0.0340\n",
      "Epoch [7/10], Step [435/750], Loss: 0.0423\n",
      "Epoch [7/10], Step [436/750], Loss: 0.0344\n",
      "Epoch [7/10], Step [437/750], Loss: 0.0483\n",
      "Epoch [7/10], Step [438/750], Loss: 0.0619\n",
      "Epoch [7/10], Step [439/750], Loss: 0.0328\n",
      "Epoch [7/10], Step [440/750], Loss: 0.0743\n",
      "Epoch [7/10], Step [441/750], Loss: 0.0908\n",
      "Epoch [7/10], Step [442/750], Loss: 0.0099\n",
      "Epoch [7/10], Step [443/750], Loss: 0.0626\n",
      "Epoch [7/10], Step [444/750], Loss: 0.1139\n",
      "Epoch [7/10], Step [445/750], Loss: 0.0853\n",
      "Epoch [7/10], Step [446/750], Loss: 0.0185\n",
      "Epoch [7/10], Step [447/750], Loss: 0.0629\n",
      "Epoch [7/10], Step [448/750], Loss: 0.0067\n",
      "Epoch [7/10], Step [449/750], Loss: 0.0426\n",
      "Epoch [7/10], Step [450/750], Loss: 0.1563\n",
      "Epoch [7/10], Step [451/750], Loss: 0.0109\n",
      "Epoch [7/10], Step [452/750], Loss: 0.0207\n",
      "Epoch [7/10], Step [453/750], Loss: 0.2281\n",
      "Epoch [7/10], Step [454/750], Loss: 0.1187\n",
      "Epoch [7/10], Step [455/750], Loss: 0.1282\n",
      "Epoch [7/10], Step [456/750], Loss: 0.0780\n",
      "Epoch [7/10], Step [457/750], Loss: 0.0975\n",
      "Epoch [7/10], Step [458/750], Loss: 0.1671\n",
      "Epoch [7/10], Step [459/750], Loss: 0.1624\n",
      "Epoch [7/10], Step [460/750], Loss: 0.0379\n",
      "Epoch [7/10], Step [461/750], Loss: 0.1351\n",
      "Epoch [7/10], Step [462/750], Loss: 0.0519\n",
      "Epoch [7/10], Step [463/750], Loss: 0.1260\n",
      "Epoch [7/10], Step [464/750], Loss: 0.2230\n",
      "Epoch [7/10], Step [465/750], Loss: 0.0620\n",
      "Epoch [7/10], Step [466/750], Loss: 0.0380\n",
      "Epoch [7/10], Step [467/750], Loss: 0.3629\n",
      "Epoch [7/10], Step [468/750], Loss: 0.0318\n",
      "Epoch [7/10], Step [469/750], Loss: 0.1172\n",
      "Epoch [7/10], Step [470/750], Loss: 0.0465\n",
      "Epoch [7/10], Step [471/750], Loss: 0.1029\n",
      "Epoch [7/10], Step [472/750], Loss: 0.1783\n",
      "Epoch [7/10], Step [473/750], Loss: 0.2102\n",
      "Epoch [7/10], Step [474/750], Loss: 0.0685\n",
      "Epoch [7/10], Step [475/750], Loss: 0.0190\n",
      "Epoch [7/10], Step [476/750], Loss: 0.0130\n",
      "Epoch [7/10], Step [477/750], Loss: 0.0214\n",
      "Epoch [7/10], Step [478/750], Loss: 0.0357\n",
      "Epoch [7/10], Step [479/750], Loss: 0.1993\n",
      "Epoch [7/10], Step [480/750], Loss: 0.0172\n",
      "Epoch [7/10], Step [481/750], Loss: 0.0337\n",
      "Epoch [7/10], Step [482/750], Loss: 0.1710\n",
      "Epoch [7/10], Step [483/750], Loss: 0.1136\n",
      "Epoch [7/10], Step [484/750], Loss: 0.0550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [485/750], Loss: 0.0607\n",
      "Epoch [7/10], Step [486/750], Loss: 0.0383\n",
      "Epoch [7/10], Step [487/750], Loss: 0.0808\n",
      "Epoch [7/10], Step [488/750], Loss: 0.1641\n",
      "Epoch [7/10], Step [489/750], Loss: 0.0148\n",
      "Epoch [7/10], Step [490/750], Loss: 0.0834\n",
      "Epoch [7/10], Step [491/750], Loss: 0.0647\n",
      "Epoch [7/10], Step [492/750], Loss: 0.1129\n",
      "Epoch [7/10], Step [493/750], Loss: 0.0257\n",
      "Epoch [7/10], Step [494/750], Loss: 0.0529\n",
      "Epoch [7/10], Step [495/750], Loss: 0.0415\n",
      "Epoch [7/10], Step [496/750], Loss: 0.0246\n",
      "Epoch [7/10], Step [497/750], Loss: 0.0275\n",
      "Epoch [7/10], Step [498/750], Loss: 0.0963\n",
      "Epoch [7/10], Step [499/750], Loss: 0.0862\n",
      "Epoch [7/10], Step [500/750], Loss: 0.1068\n",
      "Epoch [7/10], Step [501/750], Loss: 0.0240\n",
      "Epoch [7/10], Step [502/750], Loss: 0.1154\n",
      "Epoch [7/10], Step [503/750], Loss: 0.0411\n",
      "Epoch [7/10], Step [504/750], Loss: 0.0177\n",
      "Epoch [7/10], Step [505/750], Loss: 0.0697\n",
      "Epoch [7/10], Step [506/750], Loss: 0.1271\n",
      "Epoch [7/10], Step [507/750], Loss: 0.1093\n",
      "Epoch [7/10], Step [508/750], Loss: 0.0432\n",
      "Epoch [7/10], Step [509/750], Loss: 0.1099\n",
      "Epoch [7/10], Step [510/750], Loss: 0.1228\n",
      "Epoch [7/10], Step [511/750], Loss: 0.0366\n",
      "Epoch [7/10], Step [512/750], Loss: 0.0645\n",
      "Epoch [7/10], Step [513/750], Loss: 0.0662\n",
      "Epoch [7/10], Step [514/750], Loss: 0.0756\n",
      "Epoch [7/10], Step [515/750], Loss: 0.0425\n",
      "Epoch [7/10], Step [516/750], Loss: 0.0512\n",
      "Epoch [7/10], Step [517/750], Loss: 0.1383\n",
      "Epoch [7/10], Step [518/750], Loss: 0.0242\n",
      "Epoch [7/10], Step [519/750], Loss: 0.0513\n",
      "Epoch [7/10], Step [520/750], Loss: 0.0193\n",
      "Epoch [7/10], Step [521/750], Loss: 0.0177\n",
      "Epoch [7/10], Step [522/750], Loss: 0.1534\n",
      "Epoch [7/10], Step [523/750], Loss: 0.0370\n",
      "Epoch [7/10], Step [524/750], Loss: 0.0972\n",
      "Epoch [7/10], Step [525/750], Loss: 0.1127\n",
      "Epoch [7/10], Step [526/750], Loss: 0.0381\n",
      "Epoch [7/10], Step [527/750], Loss: 0.0484\n",
      "Epoch [7/10], Step [528/750], Loss: 0.0969\n",
      "Epoch [7/10], Step [529/750], Loss: 0.0509\n",
      "Epoch [7/10], Step [530/750], Loss: 0.0394\n",
      "Epoch [7/10], Step [531/750], Loss: 0.0587\n",
      "Epoch [7/10], Step [532/750], Loss: 0.0269\n",
      "Epoch [7/10], Step [533/750], Loss: 0.0236\n",
      "Epoch [7/10], Step [534/750], Loss: 0.0820\n",
      "Epoch [7/10], Step [535/750], Loss: 0.0060\n",
      "Epoch [7/10], Step [536/750], Loss: 0.0210\n",
      "Epoch [7/10], Step [537/750], Loss: 0.0468\n",
      "Epoch [7/10], Step [538/750], Loss: 0.0316\n",
      "Epoch [7/10], Step [539/750], Loss: 0.0619\n",
      "Epoch [7/10], Step [540/750], Loss: 0.0953\n",
      "Epoch [7/10], Step [541/750], Loss: 0.0537\n",
      "Epoch [7/10], Step [542/750], Loss: 0.0508\n",
      "Epoch [7/10], Step [543/750], Loss: 0.0181\n",
      "Epoch [7/10], Step [544/750], Loss: 0.0566\n",
      "Epoch [7/10], Step [545/750], Loss: 0.0838\n",
      "Epoch [7/10], Step [546/750], Loss: 0.0199\n",
      "Epoch [7/10], Step [547/750], Loss: 0.0907\n",
      "Epoch [7/10], Step [548/750], Loss: 0.1342\n",
      "Epoch [7/10], Step [549/750], Loss: 0.1085\n",
      "Epoch [7/10], Step [550/750], Loss: 0.1613\n",
      "Epoch [7/10], Step [551/750], Loss: 0.0615\n",
      "Epoch [7/10], Step [552/750], Loss: 0.0213\n",
      "Epoch [7/10], Step [553/750], Loss: 0.0791\n",
      "Epoch [7/10], Step [554/750], Loss: 0.0393\n",
      "Epoch [7/10], Step [555/750], Loss: 0.1030\n",
      "Epoch [7/10], Step [556/750], Loss: 0.1078\n",
      "Epoch [7/10], Step [557/750], Loss: 0.0259\n",
      "Epoch [7/10], Step [558/750], Loss: 0.0406\n",
      "Epoch [7/10], Step [559/750], Loss: 0.0734\n",
      "Epoch [7/10], Step [560/750], Loss: 0.1294\n",
      "Epoch [7/10], Step [561/750], Loss: 0.0724\n",
      "Epoch [7/10], Step [562/750], Loss: 0.0793\n",
      "Epoch [7/10], Step [563/750], Loss: 0.0296\n",
      "Epoch [7/10], Step [564/750], Loss: 0.0213\n",
      "Epoch [7/10], Step [565/750], Loss: 0.0491\n",
      "Epoch [7/10], Step [566/750], Loss: 0.0548\n",
      "Epoch [7/10], Step [567/750], Loss: 0.0678\n",
      "Epoch [7/10], Step [568/750], Loss: 0.0370\n",
      "Epoch [7/10], Step [569/750], Loss: 0.0577\n",
      "Epoch [7/10], Step [570/750], Loss: 0.1147\n",
      "Epoch [7/10], Step [571/750], Loss: 0.0576\n",
      "Epoch [7/10], Step [572/750], Loss: 0.0189\n",
      "Epoch [7/10], Step [573/750], Loss: 0.0804\n",
      "Epoch [7/10], Step [574/750], Loss: 0.0527\n",
      "Epoch [7/10], Step [575/750], Loss: 0.0526\n",
      "Epoch [7/10], Step [576/750], Loss: 0.0889\n",
      "Epoch [7/10], Step [577/750], Loss: 0.0348\n",
      "Epoch [7/10], Step [578/750], Loss: 0.0462\n",
      "Epoch [7/10], Step [579/750], Loss: 0.0135\n",
      "Epoch [7/10], Step [580/750], Loss: 0.1794\n",
      "Epoch [7/10], Step [581/750], Loss: 0.0380\n",
      "Epoch [7/10], Step [582/750], Loss: 0.1034\n",
      "Epoch [7/10], Step [583/750], Loss: 0.0477\n",
      "Epoch [7/10], Step [584/750], Loss: 0.0396\n",
      "Epoch [7/10], Step [585/750], Loss: 0.0150\n",
      "Epoch [7/10], Step [586/750], Loss: 0.0498\n",
      "Epoch [7/10], Step [587/750], Loss: 0.0655\n",
      "Epoch [7/10], Step [588/750], Loss: 0.0938\n",
      "Epoch [7/10], Step [589/750], Loss: 0.0046\n",
      "Epoch [7/10], Step [590/750], Loss: 0.0176\n",
      "Epoch [7/10], Step [591/750], Loss: 0.0302\n",
      "Epoch [7/10], Step [592/750], Loss: 0.0370\n",
      "Epoch [7/10], Step [593/750], Loss: 0.1124\n",
      "Epoch [7/10], Step [594/750], Loss: 0.1472\n",
      "Epoch [7/10], Step [595/750], Loss: 0.1333\n",
      "Epoch [7/10], Step [596/750], Loss: 0.0789\n",
      "Epoch [7/10], Step [597/750], Loss: 0.1454\n",
      "Epoch [7/10], Step [598/750], Loss: 0.0279\n",
      "Epoch [7/10], Step [599/750], Loss: 0.0239\n",
      "Epoch [7/10], Step [600/750], Loss: 0.0288\n",
      "Epoch [7/10], Step [601/750], Loss: 0.0107\n",
      "Epoch [7/10], Step [602/750], Loss: 0.0492\n",
      "Epoch [7/10], Step [603/750], Loss: 0.0361\n",
      "Epoch [7/10], Step [604/750], Loss: 0.0539\n",
      "Epoch [7/10], Step [605/750], Loss: 0.1080\n",
      "Epoch [7/10], Step [606/750], Loss: 0.0433\n",
      "Epoch [7/10], Step [607/750], Loss: 0.0279\n",
      "Epoch [7/10], Step [608/750], Loss: 0.0197\n",
      "Epoch [7/10], Step [609/750], Loss: 0.1219\n",
      "Epoch [7/10], Step [610/750], Loss: 0.0909\n",
      "Epoch [7/10], Step [611/750], Loss: 0.0227\n",
      "Epoch [7/10], Step [612/750], Loss: 0.0656\n",
      "Epoch [7/10], Step [613/750], Loss: 0.0951\n",
      "Epoch [7/10], Step [614/750], Loss: 0.0393\n",
      "Epoch [7/10], Step [615/750], Loss: 0.0097\n",
      "Epoch [7/10], Step [616/750], Loss: 0.0466\n",
      "Epoch [7/10], Step [617/750], Loss: 0.0464\n",
      "Epoch [7/10], Step [618/750], Loss: 0.0338\n",
      "Epoch [7/10], Step [619/750], Loss: 0.0337\n",
      "Epoch [7/10], Step [620/750], Loss: 0.1671\n",
      "Epoch [7/10], Step [621/750], Loss: 0.0630\n",
      "Epoch [7/10], Step [622/750], Loss: 0.0482\n",
      "Epoch [7/10], Step [623/750], Loss: 0.0089\n",
      "Epoch [7/10], Step [624/750], Loss: 0.0288\n",
      "Epoch [7/10], Step [625/750], Loss: 0.1299\n",
      "Epoch [7/10], Step [626/750], Loss: 0.1232\n",
      "Epoch [7/10], Step [627/750], Loss: 0.0581\n",
      "Epoch [7/10], Step [628/750], Loss: 0.0609\n",
      "Epoch [7/10], Step [629/750], Loss: 0.0121\n",
      "Epoch [7/10], Step [630/750], Loss: 0.0491\n",
      "Epoch [7/10], Step [631/750], Loss: 0.0933\n",
      "Epoch [7/10], Step [632/750], Loss: 0.1041\n",
      "Epoch [7/10], Step [633/750], Loss: 0.1054\n",
      "Epoch [7/10], Step [634/750], Loss: 0.0250\n",
      "Epoch [7/10], Step [635/750], Loss: 0.0571\n",
      "Epoch [7/10], Step [636/750], Loss: 0.0532\n",
      "Epoch [7/10], Step [637/750], Loss: 0.0891\n",
      "Epoch [7/10], Step [638/750], Loss: 0.0460\n",
      "Epoch [7/10], Step [639/750], Loss: 0.0948\n",
      "Epoch [7/10], Step [640/750], Loss: 0.1266\n",
      "Epoch [7/10], Step [641/750], Loss: 0.0568\n",
      "Epoch [7/10], Step [642/750], Loss: 0.0332\n",
      "Epoch [7/10], Step [643/750], Loss: 0.1958\n",
      "Epoch [7/10], Step [644/750], Loss: 0.0052\n",
      "Epoch [7/10], Step [645/750], Loss: 0.0372\n",
      "Epoch [7/10], Step [646/750], Loss: 0.2019\n",
      "Epoch [7/10], Step [647/750], Loss: 0.0321\n",
      "Epoch [7/10], Step [648/750], Loss: 0.0232\n",
      "Epoch [7/10], Step [649/750], Loss: 0.1191\n",
      "Epoch [7/10], Step [650/750], Loss: 0.0951\n",
      "Epoch [7/10], Step [651/750], Loss: 0.0072\n",
      "Epoch [7/10], Step [652/750], Loss: 0.0570\n",
      "Epoch [7/10], Step [653/750], Loss: 0.0338\n",
      "Epoch [7/10], Step [654/750], Loss: 0.0403\n",
      "Epoch [7/10], Step [655/750], Loss: 0.0778\n",
      "Epoch [7/10], Step [656/750], Loss: 0.0267\n",
      "Epoch [7/10], Step [657/750], Loss: 0.0479\n",
      "Epoch [7/10], Step [658/750], Loss: 0.0849\n",
      "Epoch [7/10], Step [659/750], Loss: 0.0699\n",
      "Epoch [7/10], Step [660/750], Loss: 0.0771\n",
      "Epoch [7/10], Step [661/750], Loss: 0.0233\n",
      "Epoch [7/10], Step [662/750], Loss: 0.0147\n",
      "Epoch [7/10], Step [663/750], Loss: 0.0260\n",
      "Epoch [7/10], Step [664/750], Loss: 0.0351\n",
      "Epoch [7/10], Step [665/750], Loss: 0.0364\n",
      "Epoch [7/10], Step [666/750], Loss: 0.0695\n",
      "Epoch [7/10], Step [667/750], Loss: 0.0365\n",
      "Epoch [7/10], Step [668/750], Loss: 0.1649\n",
      "Epoch [7/10], Step [669/750], Loss: 0.2533\n",
      "Epoch [7/10], Step [670/750], Loss: 0.0718\n",
      "Epoch [7/10], Step [671/750], Loss: 0.0680\n",
      "Epoch [7/10], Step [672/750], Loss: 0.0427\n",
      "Epoch [7/10], Step [673/750], Loss: 0.0155\n",
      "Epoch [7/10], Step [674/750], Loss: 0.0723\n",
      "Epoch [7/10], Step [675/750], Loss: 0.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [676/750], Loss: 0.1005\n",
      "Epoch [7/10], Step [677/750], Loss: 0.2078\n",
      "Epoch [7/10], Step [678/750], Loss: 0.1947\n",
      "Epoch [7/10], Step [679/750], Loss: 0.0318\n",
      "Epoch [7/10], Step [680/750], Loss: 0.0295\n",
      "Epoch [7/10], Step [681/750], Loss: 0.0301\n",
      "Epoch [7/10], Step [682/750], Loss: 0.0816\n",
      "Epoch [7/10], Step [683/750], Loss: 0.0348\n",
      "Epoch [7/10], Step [684/750], Loss: 0.0612\n",
      "Epoch [7/10], Step [685/750], Loss: 0.1163\n",
      "Epoch [7/10], Step [686/750], Loss: 0.0582\n",
      "Epoch [7/10], Step [687/750], Loss: 0.1960\n",
      "Epoch [7/10], Step [688/750], Loss: 0.0308\n",
      "Epoch [7/10], Step [689/750], Loss: 0.0296\n",
      "Epoch [7/10], Step [690/750], Loss: 0.0337\n",
      "Epoch [7/10], Step [691/750], Loss: 0.0166\n",
      "Epoch [7/10], Step [692/750], Loss: 0.1106\n",
      "Epoch [7/10], Step [693/750], Loss: 0.1619\n",
      "Epoch [7/10], Step [694/750], Loss: 0.0595\n",
      "Epoch [7/10], Step [695/750], Loss: 0.0259\n",
      "Epoch [7/10], Step [696/750], Loss: 0.0197\n",
      "Epoch [7/10], Step [697/750], Loss: 0.0553\n",
      "Epoch [7/10], Step [698/750], Loss: 0.0331\n",
      "Epoch [7/10], Step [699/750], Loss: 0.1048\n",
      "Epoch [7/10], Step [700/750], Loss: 0.0563\n",
      "Epoch [7/10], Step [701/750], Loss: 0.0078\n",
      "Epoch [7/10], Step [702/750], Loss: 0.0375\n",
      "Epoch [7/10], Step [703/750], Loss: 0.0117\n",
      "Epoch [7/10], Step [704/750], Loss: 0.0209\n",
      "Epoch [7/10], Step [705/750], Loss: 0.0608\n",
      "Epoch [7/10], Step [706/750], Loss: 0.0617\n",
      "Epoch [7/10], Step [707/750], Loss: 0.0361\n",
      "Epoch [7/10], Step [708/750], Loss: 0.0261\n",
      "Epoch [7/10], Step [709/750], Loss: 0.0431\n",
      "Epoch [7/10], Step [710/750], Loss: 0.1227\n",
      "Epoch [7/10], Step [711/750], Loss: 0.0204\n",
      "Epoch [7/10], Step [712/750], Loss: 0.0871\n",
      "Epoch [7/10], Step [713/750], Loss: 0.0191\n",
      "Epoch [7/10], Step [714/750], Loss: 0.0057\n",
      "Epoch [7/10], Step [715/750], Loss: 0.0110\n",
      "Epoch [7/10], Step [716/750], Loss: 0.0833\n",
      "Epoch [7/10], Step [717/750], Loss: 0.1570\n",
      "Epoch [7/10], Step [718/750], Loss: 0.1131\n",
      "Epoch [7/10], Step [719/750], Loss: 0.0523\n",
      "Epoch [7/10], Step [720/750], Loss: 0.0227\n",
      "Epoch [7/10], Step [721/750], Loss: 0.1036\n",
      "Epoch [7/10], Step [722/750], Loss: 0.0347\n",
      "Epoch [7/10], Step [723/750], Loss: 0.0108\n",
      "Epoch [7/10], Step [724/750], Loss: 0.1053\n",
      "Epoch [7/10], Step [725/750], Loss: 0.0121\n",
      "Epoch [7/10], Step [726/750], Loss: 0.0577\n",
      "Epoch [7/10], Step [727/750], Loss: 0.0077\n",
      "Epoch [7/10], Step [728/750], Loss: 0.0349\n",
      "Epoch [7/10], Step [729/750], Loss: 0.0327\n",
      "Epoch [7/10], Step [730/750], Loss: 0.0505\n",
      "Epoch [7/10], Step [731/750], Loss: 0.0233\n",
      "Epoch [7/10], Step [732/750], Loss: 0.0217\n",
      "Epoch [7/10], Step [733/750], Loss: 0.0120\n",
      "Epoch [7/10], Step [734/750], Loss: 0.0489\n",
      "Epoch [7/10], Step [735/750], Loss: 0.0120\n",
      "Epoch [7/10], Step [736/750], Loss: 0.0589\n",
      "Epoch [7/10], Step [737/750], Loss: 0.1319\n",
      "Epoch [7/10], Step [738/750], Loss: 0.0223\n",
      "Epoch [7/10], Step [739/750], Loss: 0.0181\n",
      "Epoch [7/10], Step [740/750], Loss: 0.0306\n",
      "Epoch [7/10], Step [741/750], Loss: 0.0670\n",
      "Epoch [7/10], Step [742/750], Loss: 0.0582\n",
      "Epoch [7/10], Step [743/750], Loss: 0.0647\n",
      "Epoch [7/10], Step [744/750], Loss: 0.1368\n",
      "Epoch [7/10], Step [745/750], Loss: 0.0036\n",
      "Epoch [7/10], Step [746/750], Loss: 0.0424\n",
      "Epoch [7/10], Step [747/750], Loss: 0.0519\n",
      "Epoch [7/10], Step [748/750], Loss: 0.2144\n",
      "Epoch [7/10], Step [749/750], Loss: 0.0095\n",
      "Epoch [7/10], Step [750/750], Loss: 0.0342\n",
      "\n",
      "\n",
      "Epoch [8/10], Step [1/750], Loss: 0.0926\n",
      "Epoch [8/10], Step [2/750], Loss: 0.0705\n",
      "Epoch [8/10], Step [3/750], Loss: 0.1297\n",
      "Epoch [8/10], Step [4/750], Loss: 0.0464\n",
      "Epoch [8/10], Step [5/750], Loss: 0.0172\n",
      "Epoch [8/10], Step [6/750], Loss: 0.1059\n",
      "Epoch [8/10], Step [7/750], Loss: 0.1332\n",
      "Epoch [8/10], Step [8/750], Loss: 0.1252\n",
      "Epoch [8/10], Step [9/750], Loss: 0.0653\n",
      "Epoch [8/10], Step [10/750], Loss: 0.0389\n",
      "Epoch [8/10], Step [11/750], Loss: 0.0112\n",
      "Epoch [8/10], Step [12/750], Loss: 0.0173\n",
      "Epoch [8/10], Step [13/750], Loss: 0.0089\n",
      "Epoch [8/10], Step [14/750], Loss: 0.0395\n",
      "Epoch [8/10], Step [15/750], Loss: 0.1271\n",
      "Epoch [8/10], Step [16/750], Loss: 0.0602\n",
      "Epoch [8/10], Step [17/750], Loss: 0.0130\n",
      "Epoch [8/10], Step [18/750], Loss: 0.0113\n",
      "Epoch [8/10], Step [19/750], Loss: 0.0369\n",
      "Epoch [8/10], Step [20/750], Loss: 0.0717\n",
      "Epoch [8/10], Step [21/750], Loss: 0.0597\n",
      "Epoch [8/10], Step [22/750], Loss: 0.0611\n",
      "Epoch [8/10], Step [23/750], Loss: 0.1538\n",
      "Epoch [8/10], Step [24/750], Loss: 0.0381\n",
      "Epoch [8/10], Step [25/750], Loss: 0.0844\n",
      "Epoch [8/10], Step [26/750], Loss: 0.0251\n",
      "Epoch [8/10], Step [27/750], Loss: 0.0795\n",
      "Epoch [8/10], Step [28/750], Loss: 0.0944\n",
      "Epoch [8/10], Step [29/750], Loss: 0.0315\n",
      "Epoch [8/10], Step [30/750], Loss: 0.0433\n",
      "Epoch [8/10], Step [31/750], Loss: 0.0238\n",
      "Epoch [8/10], Step [32/750], Loss: 0.0029\n",
      "Epoch [8/10], Step [33/750], Loss: 0.0534\n",
      "Epoch [8/10], Step [34/750], Loss: 0.0929\n",
      "Epoch [8/10], Step [35/750], Loss: 0.0263\n",
      "Epoch [8/10], Step [36/750], Loss: 0.0859\n",
      "Epoch [8/10], Step [37/750], Loss: 0.0089\n",
      "Epoch [8/10], Step [38/750], Loss: 0.0316\n",
      "Epoch [8/10], Step [39/750], Loss: 0.0209\n",
      "Epoch [8/10], Step [40/750], Loss: 0.0161\n",
      "Epoch [8/10], Step [41/750], Loss: 0.1202\n",
      "Epoch [8/10], Step [42/750], Loss: 0.0173\n",
      "Epoch [8/10], Step [43/750], Loss: 0.0323\n",
      "Epoch [8/10], Step [44/750], Loss: 0.0700\n",
      "Epoch [8/10], Step [45/750], Loss: 0.0080\n",
      "Epoch [8/10], Step [46/750], Loss: 0.0832\n",
      "Epoch [8/10], Step [47/750], Loss: 0.0337\n",
      "Epoch [8/10], Step [48/750], Loss: 0.0077\n",
      "Epoch [8/10], Step [49/750], Loss: 0.0377\n",
      "Epoch [8/10], Step [50/750], Loss: 0.0447\n",
      "Epoch [8/10], Step [51/750], Loss: 0.0947\n",
      "Epoch [8/10], Step [52/750], Loss: 0.0898\n",
      "Epoch [8/10], Step [53/750], Loss: 0.0392\n",
      "Epoch [8/10], Step [54/750], Loss: 0.1013\n",
      "Epoch [8/10], Step [55/750], Loss: 0.0471\n",
      "Epoch [8/10], Step [56/750], Loss: 0.0514\n",
      "Epoch [8/10], Step [57/750], Loss: 0.0802\n",
      "Epoch [8/10], Step [58/750], Loss: 0.0876\n",
      "Epoch [8/10], Step [59/750], Loss: 0.0781\n",
      "Epoch [8/10], Step [60/750], Loss: 0.0066\n",
      "Epoch [8/10], Step [61/750], Loss: 0.0570\n",
      "Epoch [8/10], Step [62/750], Loss: 0.0559\n",
      "Epoch [8/10], Step [63/750], Loss: 0.0624\n",
      "Epoch [8/10], Step [64/750], Loss: 0.0691\n",
      "Epoch [8/10], Step [65/750], Loss: 0.0067\n",
      "Epoch [8/10], Step [66/750], Loss: 0.0192\n",
      "Epoch [8/10], Step [67/750], Loss: 0.0623\n",
      "Epoch [8/10], Step [68/750], Loss: 0.0424\n",
      "Epoch [8/10], Step [69/750], Loss: 0.0439\n",
      "Epoch [8/10], Step [70/750], Loss: 0.0333\n",
      "Epoch [8/10], Step [71/750], Loss: 0.0761\n",
      "Epoch [8/10], Step [72/750], Loss: 0.0435\n",
      "Epoch [8/10], Step [73/750], Loss: 0.0232\n",
      "Epoch [8/10], Step [74/750], Loss: 0.0311\n",
      "Epoch [8/10], Step [75/750], Loss: 0.0284\n",
      "Epoch [8/10], Step [76/750], Loss: 0.0754\n",
      "Epoch [8/10], Step [77/750], Loss: 0.0285\n",
      "Epoch [8/10], Step [78/750], Loss: 0.0834\n",
      "Epoch [8/10], Step [79/750], Loss: 0.0428\n",
      "Epoch [8/10], Step [80/750], Loss: 0.0068\n",
      "Epoch [8/10], Step [81/750], Loss: 0.0755\n",
      "Epoch [8/10], Step [82/750], Loss: 0.0428\n",
      "Epoch [8/10], Step [83/750], Loss: 0.0647\n",
      "Epoch [8/10], Step [84/750], Loss: 0.0077\n",
      "Epoch [8/10], Step [85/750], Loss: 0.1244\n",
      "Epoch [8/10], Step [86/750], Loss: 0.0092\n",
      "Epoch [8/10], Step [87/750], Loss: 0.0769\n",
      "Epoch [8/10], Step [88/750], Loss: 0.0257\n",
      "Epoch [8/10], Step [89/750], Loss: 0.0531\n",
      "Epoch [8/10], Step [90/750], Loss: 0.1045\n",
      "Epoch [8/10], Step [91/750], Loss: 0.0920\n",
      "Epoch [8/10], Step [92/750], Loss: 0.2161\n",
      "Epoch [8/10], Step [93/750], Loss: 0.0338\n",
      "Epoch [8/10], Step [94/750], Loss: 0.1609\n",
      "Epoch [8/10], Step [95/750], Loss: 0.0371\n",
      "Epoch [8/10], Step [96/750], Loss: 0.0895\n",
      "Epoch [8/10], Step [97/750], Loss: 0.1131\n",
      "Epoch [8/10], Step [98/750], Loss: 0.0395\n",
      "Epoch [8/10], Step [99/750], Loss: 0.0745\n",
      "Epoch [8/10], Step [100/750], Loss: 0.0812\n",
      "Epoch [8/10], Step [101/750], Loss: 0.0070\n",
      "Epoch [8/10], Step [102/750], Loss: 0.0517\n",
      "Epoch [8/10], Step [103/750], Loss: 0.0113\n",
      "Epoch [8/10], Step [104/750], Loss: 0.0759\n",
      "Epoch [8/10], Step [105/750], Loss: 0.1258\n",
      "Epoch [8/10], Step [106/750], Loss: 0.0373\n",
      "Epoch [8/10], Step [107/750], Loss: 0.0298\n",
      "Epoch [8/10], Step [108/750], Loss: 0.1193\n",
      "Epoch [8/10], Step [109/750], Loss: 0.0537\n",
      "Epoch [8/10], Step [110/750], Loss: 0.0639\n",
      "Epoch [8/10], Step [111/750], Loss: 0.0419\n",
      "Epoch [8/10], Step [112/750], Loss: 0.0207\n",
      "Epoch [8/10], Step [113/750], Loss: 0.0332\n",
      "Epoch [8/10], Step [114/750], Loss: 0.2092\n",
      "Epoch [8/10], Step [115/750], Loss: 0.0269\n",
      "Epoch [8/10], Step [116/750], Loss: 0.0214\n",
      "Epoch [8/10], Step [117/750], Loss: 0.0284\n",
      "Epoch [8/10], Step [118/750], Loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [119/750], Loss: 0.0062\n",
      "Epoch [8/10], Step [120/750], Loss: 0.0553\n",
      "Epoch [8/10], Step [121/750], Loss: 0.0542\n",
      "Epoch [8/10], Step [122/750], Loss: 0.0089\n",
      "Epoch [8/10], Step [123/750], Loss: 0.1794\n",
      "Epoch [8/10], Step [124/750], Loss: 0.0203\n",
      "Epoch [8/10], Step [125/750], Loss: 0.0477\n",
      "Epoch [8/10], Step [126/750], Loss: 0.0432\n",
      "Epoch [8/10], Step [127/750], Loss: 0.0942\n",
      "Epoch [8/10], Step [128/750], Loss: 0.0432\n",
      "Epoch [8/10], Step [129/750], Loss: 0.1801\n",
      "Epoch [8/10], Step [130/750], Loss: 0.0990\n",
      "Epoch [8/10], Step [131/750], Loss: 0.0183\n",
      "Epoch [8/10], Step [132/750], Loss: 0.0827\n",
      "Epoch [8/10], Step [133/750], Loss: 0.0538\n",
      "Epoch [8/10], Step [134/750], Loss: 0.0139\n",
      "Epoch [8/10], Step [135/750], Loss: 0.0278\n",
      "Epoch [8/10], Step [136/750], Loss: 0.0312\n",
      "Epoch [8/10], Step [137/750], Loss: 0.1256\n",
      "Epoch [8/10], Step [138/750], Loss: 0.0102\n",
      "Epoch [8/10], Step [139/750], Loss: 0.0363\n",
      "Epoch [8/10], Step [140/750], Loss: 0.0039\n",
      "Epoch [8/10], Step [141/750], Loss: 0.1003\n",
      "Epoch [8/10], Step [142/750], Loss: 0.0295\n",
      "Epoch [8/10], Step [143/750], Loss: 0.0209\n",
      "Epoch [8/10], Step [144/750], Loss: 0.0953\n",
      "Epoch [8/10], Step [145/750], Loss: 0.0238\n",
      "Epoch [8/10], Step [146/750], Loss: 0.0238\n",
      "Epoch [8/10], Step [147/750], Loss: 0.0190\n",
      "Epoch [8/10], Step [148/750], Loss: 0.0283\n",
      "Epoch [8/10], Step [149/750], Loss: 0.0201\n",
      "Epoch [8/10], Step [150/750], Loss: 0.1277\n",
      "Epoch [8/10], Step [151/750], Loss: 0.0732\n",
      "Epoch [8/10], Step [152/750], Loss: 0.1517\n",
      "Epoch [8/10], Step [153/750], Loss: 0.0106\n",
      "Epoch [8/10], Step [154/750], Loss: 0.0319\n",
      "Epoch [8/10], Step [155/750], Loss: 0.0517\n",
      "Epoch [8/10], Step [156/750], Loss: 0.0823\n",
      "Epoch [8/10], Step [157/750], Loss: 0.0133\n",
      "Epoch [8/10], Step [158/750], Loss: 0.0379\n",
      "Epoch [8/10], Step [159/750], Loss: 0.0383\n",
      "Epoch [8/10], Step [160/750], Loss: 0.0134\n",
      "Epoch [8/10], Step [161/750], Loss: 0.0126\n",
      "Epoch [8/10], Step [162/750], Loss: 0.0180\n",
      "Epoch [8/10], Step [163/750], Loss: 0.0906\n",
      "Epoch [8/10], Step [164/750], Loss: 0.0374\n",
      "Epoch [8/10], Step [165/750], Loss: 0.0324\n",
      "Epoch [8/10], Step [166/750], Loss: 0.0129\n",
      "Epoch [8/10], Step [167/750], Loss: 0.0114\n",
      "Epoch [8/10], Step [168/750], Loss: 0.0433\n",
      "Epoch [8/10], Step [169/750], Loss: 0.0035\n",
      "Epoch [8/10], Step [170/750], Loss: 0.1863\n",
      "Epoch [8/10], Step [171/750], Loss: 0.0202\n",
      "Epoch [8/10], Step [172/750], Loss: 0.0860\n",
      "Epoch [8/10], Step [173/750], Loss: 0.0305\n",
      "Epoch [8/10], Step [174/750], Loss: 0.0090\n",
      "Epoch [8/10], Step [175/750], Loss: 0.0337\n",
      "Epoch [8/10], Step [176/750], Loss: 0.0662\n",
      "Epoch [8/10], Step [177/750], Loss: 0.0115\n",
      "Epoch [8/10], Step [178/750], Loss: 0.0350\n",
      "Epoch [8/10], Step [179/750], Loss: 0.0364\n",
      "Epoch [8/10], Step [180/750], Loss: 0.0454\n",
      "Epoch [8/10], Step [181/750], Loss: 0.0985\n",
      "Epoch [8/10], Step [182/750], Loss: 0.1632\n",
      "Epoch [8/10], Step [183/750], Loss: 0.1607\n",
      "Epoch [8/10], Step [184/750], Loss: 0.0560\n",
      "Epoch [8/10], Step [185/750], Loss: 0.0097\n",
      "Epoch [8/10], Step [186/750], Loss: 0.0559\n",
      "Epoch [8/10], Step [187/750], Loss: 0.0154\n",
      "Epoch [8/10], Step [188/750], Loss: 0.0317\n",
      "Epoch [8/10], Step [189/750], Loss: 0.0559\n",
      "Epoch [8/10], Step [190/750], Loss: 0.0768\n",
      "Epoch [8/10], Step [191/750], Loss: 0.0598\n",
      "Epoch [8/10], Step [192/750], Loss: 0.0308\n",
      "Epoch [8/10], Step [193/750], Loss: 0.0362\n",
      "Epoch [8/10], Step [194/750], Loss: 0.0371\n",
      "Epoch [8/10], Step [195/750], Loss: 0.0881\n",
      "Epoch [8/10], Step [196/750], Loss: 0.0853\n",
      "Epoch [8/10], Step [197/750], Loss: 0.0311\n",
      "Epoch [8/10], Step [198/750], Loss: 0.0178\n",
      "Epoch [8/10], Step [199/750], Loss: 0.0546\n",
      "Epoch [8/10], Step [200/750], Loss: 0.0378\n",
      "Epoch [8/10], Step [201/750], Loss: 0.0716\n",
      "Epoch [8/10], Step [202/750], Loss: 0.0131\n",
      "Epoch [8/10], Step [203/750], Loss: 0.0772\n",
      "Epoch [8/10], Step [204/750], Loss: 0.0884\n",
      "Epoch [8/10], Step [205/750], Loss: 0.0419\n",
      "Epoch [8/10], Step [206/750], Loss: 0.0471\n",
      "Epoch [8/10], Step [207/750], Loss: 0.0069\n",
      "Epoch [8/10], Step [208/750], Loss: 0.0072\n",
      "Epoch [8/10], Step [209/750], Loss: 0.0319\n",
      "Epoch [8/10], Step [210/750], Loss: 0.0498\n",
      "Epoch [8/10], Step [211/750], Loss: 0.0737\n",
      "Epoch [8/10], Step [212/750], Loss: 0.0498\n",
      "Epoch [8/10], Step [213/750], Loss: 0.0265\n",
      "Epoch [8/10], Step [214/750], Loss: 0.0183\n",
      "Epoch [8/10], Step [215/750], Loss: 0.1157\n",
      "Epoch [8/10], Step [216/750], Loss: 0.0576\n",
      "Epoch [8/10], Step [217/750], Loss: 0.0803\n",
      "Epoch [8/10], Step [218/750], Loss: 0.0784\n",
      "Epoch [8/10], Step [219/750], Loss: 0.0568\n",
      "Epoch [8/10], Step [220/750], Loss: 0.0232\n",
      "Epoch [8/10], Step [221/750], Loss: 0.0576\n",
      "Epoch [8/10], Step [222/750], Loss: 0.0405\n",
      "Epoch [8/10], Step [223/750], Loss: 0.0636\n",
      "Epoch [8/10], Step [224/750], Loss: 0.1266\n",
      "Epoch [8/10], Step [225/750], Loss: 0.0142\n",
      "Epoch [8/10], Step [226/750], Loss: 0.0052\n",
      "Epoch [8/10], Step [227/750], Loss: 0.0359\n",
      "Epoch [8/10], Step [228/750], Loss: 0.0132\n",
      "Epoch [8/10], Step [229/750], Loss: 0.0415\n",
      "Epoch [8/10], Step [230/750], Loss: 0.0739\n",
      "Epoch [8/10], Step [231/750], Loss: 0.0203\n",
      "Epoch [8/10], Step [232/750], Loss: 0.1330\n",
      "Epoch [8/10], Step [233/750], Loss: 0.1531\n",
      "Epoch [8/10], Step [234/750], Loss: 0.0846\n",
      "Epoch [8/10], Step [235/750], Loss: 0.0095\n",
      "Epoch [8/10], Step [236/750], Loss: 0.0083\n",
      "Epoch [8/10], Step [237/750], Loss: 0.0576\n",
      "Epoch [8/10], Step [238/750], Loss: 0.1570\n",
      "Epoch [8/10], Step [239/750], Loss: 0.1149\n",
      "Epoch [8/10], Step [240/750], Loss: 0.0401\n",
      "Epoch [8/10], Step [241/750], Loss: 0.1477\n",
      "Epoch [8/10], Step [242/750], Loss: 0.0339\n",
      "Epoch [8/10], Step [243/750], Loss: 0.0522\n",
      "Epoch [8/10], Step [244/750], Loss: 0.0168\n",
      "Epoch [8/10], Step [245/750], Loss: 0.0230\n",
      "Epoch [8/10], Step [246/750], Loss: 0.0967\n",
      "Epoch [8/10], Step [247/750], Loss: 0.0424\n",
      "Epoch [8/10], Step [248/750], Loss: 0.0499\n",
      "Epoch [8/10], Step [249/750], Loss: 0.1665\n",
      "Epoch [8/10], Step [250/750], Loss: 0.0566\n",
      "Epoch [8/10], Step [251/750], Loss: 0.0714\n",
      "Epoch [8/10], Step [252/750], Loss: 0.0346\n",
      "Epoch [8/10], Step [253/750], Loss: 0.0642\n",
      "Epoch [8/10], Step [254/750], Loss: 0.0035\n",
      "Epoch [8/10], Step [255/750], Loss: 0.0603\n",
      "Epoch [8/10], Step [256/750], Loss: 0.0620\n",
      "Epoch [8/10], Step [257/750], Loss: 0.0071\n",
      "Epoch [8/10], Step [258/750], Loss: 0.0373\n",
      "Epoch [8/10], Step [259/750], Loss: 0.0232\n",
      "Epoch [8/10], Step [260/750], Loss: 0.0054\n",
      "Epoch [8/10], Step [261/750], Loss: 0.0275\n",
      "Epoch [8/10], Step [262/750], Loss: 0.0116\n",
      "Epoch [8/10], Step [263/750], Loss: 0.0447\n",
      "Epoch [8/10], Step [264/750], Loss: 0.0416\n",
      "Epoch [8/10], Step [265/750], Loss: 0.0466\n",
      "Epoch [8/10], Step [266/750], Loss: 0.0638\n",
      "Epoch [8/10], Step [267/750], Loss: 0.0070\n",
      "Epoch [8/10], Step [268/750], Loss: 0.0653\n",
      "Epoch [8/10], Step [269/750], Loss: 0.0331\n",
      "Epoch [8/10], Step [270/750], Loss: 0.0335\n",
      "Epoch [8/10], Step [271/750], Loss: 0.0679\n",
      "Epoch [8/10], Step [272/750], Loss: 0.0029\n",
      "Epoch [8/10], Step [273/750], Loss: 0.0308\n",
      "Epoch [8/10], Step [274/750], Loss: 0.0243\n",
      "Epoch [8/10], Step [275/750], Loss: 0.0360\n",
      "Epoch [8/10], Step [276/750], Loss: 0.0099\n",
      "Epoch [8/10], Step [277/750], Loss: 0.0526\n",
      "Epoch [8/10], Step [278/750], Loss: 0.0087\n",
      "Epoch [8/10], Step [279/750], Loss: 0.0718\n",
      "Epoch [8/10], Step [280/750], Loss: 0.0706\n",
      "Epoch [8/10], Step [281/750], Loss: 0.0174\n",
      "Epoch [8/10], Step [282/750], Loss: 0.0246\n",
      "Epoch [8/10], Step [283/750], Loss: 0.1396\n",
      "Epoch [8/10], Step [284/750], Loss: 0.0883\n",
      "Epoch [8/10], Step [285/750], Loss: 0.0908\n",
      "Epoch [8/10], Step [286/750], Loss: 0.0242\n",
      "Epoch [8/10], Step [287/750], Loss: 0.0053\n",
      "Epoch [8/10], Step [288/750], Loss: 0.0813\n",
      "Epoch [8/10], Step [289/750], Loss: 0.0497\n",
      "Epoch [8/10], Step [290/750], Loss: 0.1027\n",
      "Epoch [8/10], Step [291/750], Loss: 0.0252\n",
      "Epoch [8/10], Step [292/750], Loss: 0.2227\n",
      "Epoch [8/10], Step [293/750], Loss: 0.0256\n",
      "Epoch [8/10], Step [294/750], Loss: 0.0353\n",
      "Epoch [8/10], Step [295/750], Loss: 0.0314\n",
      "Epoch [8/10], Step [296/750], Loss: 0.0980\n",
      "Epoch [8/10], Step [297/750], Loss: 0.0365\n",
      "Epoch [8/10], Step [298/750], Loss: 0.0130\n",
      "Epoch [8/10], Step [299/750], Loss: 0.0223\n",
      "Epoch [8/10], Step [300/750], Loss: 0.0974\n",
      "Epoch [8/10], Step [301/750], Loss: 0.0719\n",
      "Epoch [8/10], Step [302/750], Loss: 0.0417\n",
      "Epoch [8/10], Step [303/750], Loss: 0.0300\n",
      "Epoch [8/10], Step [304/750], Loss: 0.0940\n",
      "Epoch [8/10], Step [305/750], Loss: 0.2261\n",
      "Epoch [8/10], Step [306/750], Loss: 0.1302\n",
      "Epoch [8/10], Step [307/750], Loss: 0.0073\n",
      "Epoch [8/10], Step [308/750], Loss: 0.0760\n",
      "Epoch [8/10], Step [309/750], Loss: 0.1104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [310/750], Loss: 0.0094\n",
      "Epoch [8/10], Step [311/750], Loss: 0.0746\n",
      "Epoch [8/10], Step [312/750], Loss: 0.0356\n",
      "Epoch [8/10], Step [313/750], Loss: 0.0202\n",
      "Epoch [8/10], Step [314/750], Loss: 0.0291\n",
      "Epoch [8/10], Step [315/750], Loss: 0.0271\n",
      "Epoch [8/10], Step [316/750], Loss: 0.0422\n",
      "Epoch [8/10], Step [317/750], Loss: 0.0263\n",
      "Epoch [8/10], Step [318/750], Loss: 0.2242\n",
      "Epoch [8/10], Step [319/750], Loss: 0.0921\n",
      "Epoch [8/10], Step [320/750], Loss: 0.0606\n",
      "Epoch [8/10], Step [321/750], Loss: 0.1026\n",
      "Epoch [8/10], Step [322/750], Loss: 0.1298\n",
      "Epoch [8/10], Step [323/750], Loss: 0.0353\n",
      "Epoch [8/10], Step [324/750], Loss: 0.0093\n",
      "Epoch [8/10], Step [325/750], Loss: 0.0127\n",
      "Epoch [8/10], Step [326/750], Loss: 0.0279\n",
      "Epoch [8/10], Step [327/750], Loss: 0.1508\n",
      "Epoch [8/10], Step [328/750], Loss: 0.0332\n",
      "Epoch [8/10], Step [329/750], Loss: 0.0342\n",
      "Epoch [8/10], Step [330/750], Loss: 0.0746\n",
      "Epoch [8/10], Step [331/750], Loss: 0.0858\n",
      "Epoch [8/10], Step [332/750], Loss: 0.0176\n",
      "Epoch [8/10], Step [333/750], Loss: 0.1444\n",
      "Epoch [8/10], Step [334/750], Loss: 0.0559\n",
      "Epoch [8/10], Step [335/750], Loss: 0.0190\n",
      "Epoch [8/10], Step [336/750], Loss: 0.0651\n",
      "Epoch [8/10], Step [337/750], Loss: 0.1540\n",
      "Epoch [8/10], Step [338/750], Loss: 0.0331\n",
      "Epoch [8/10], Step [339/750], Loss: 0.0447\n",
      "Epoch [8/10], Step [340/750], Loss: 0.0421\n",
      "Epoch [8/10], Step [341/750], Loss: 0.0296\n",
      "Epoch [8/10], Step [342/750], Loss: 0.0173\n",
      "Epoch [8/10], Step [343/750], Loss: 0.0833\n",
      "Epoch [8/10], Step [344/750], Loss: 0.0431\n",
      "Epoch [8/10], Step [345/750], Loss: 0.0158\n",
      "Epoch [8/10], Step [346/750], Loss: 0.0309\n",
      "Epoch [8/10], Step [347/750], Loss: 0.0385\n",
      "Epoch [8/10], Step [348/750], Loss: 0.0225\n",
      "Epoch [8/10], Step [349/750], Loss: 0.0361\n",
      "Epoch [8/10], Step [350/750], Loss: 0.1037\n",
      "Epoch [8/10], Step [351/750], Loss: 0.0117\n",
      "Epoch [8/10], Step [352/750], Loss: 0.0759\n",
      "Epoch [8/10], Step [353/750], Loss: 0.0235\n",
      "Epoch [8/10], Step [354/750], Loss: 0.0123\n",
      "Epoch [8/10], Step [355/750], Loss: 0.0729\n",
      "Epoch [8/10], Step [356/750], Loss: 0.0161\n",
      "Epoch [8/10], Step [357/750], Loss: 0.0096\n",
      "Epoch [8/10], Step [358/750], Loss: 0.0975\n",
      "Epoch [8/10], Step [359/750], Loss: 0.1010\n",
      "Epoch [8/10], Step [360/750], Loss: 0.0683\n",
      "Epoch [8/10], Step [361/750], Loss: 0.0122\n",
      "Epoch [8/10], Step [362/750], Loss: 0.0220\n",
      "Epoch [8/10], Step [363/750], Loss: 0.0063\n",
      "Epoch [8/10], Step [364/750], Loss: 0.0251\n",
      "Epoch [8/10], Step [365/750], Loss: 0.0087\n",
      "Epoch [8/10], Step [366/750], Loss: 0.0484\n",
      "Epoch [8/10], Step [367/750], Loss: 0.0497\n",
      "Epoch [8/10], Step [368/750], Loss: 0.0960\n",
      "Epoch [8/10], Step [369/750], Loss: 0.0374\n",
      "Epoch [8/10], Step [370/750], Loss: 0.0037\n",
      "Epoch [8/10], Step [371/750], Loss: 0.0591\n",
      "Epoch [8/10], Step [372/750], Loss: 0.0144\n",
      "Epoch [8/10], Step [373/750], Loss: 0.0086\n",
      "Epoch [8/10], Step [374/750], Loss: 0.0730\n",
      "Epoch [8/10], Step [375/750], Loss: 0.0115\n",
      "Epoch [8/10], Step [376/750], Loss: 0.0072\n",
      "Epoch [8/10], Step [377/750], Loss: 0.0366\n",
      "Epoch [8/10], Step [378/750], Loss: 0.0301\n",
      "Epoch [8/10], Step [379/750], Loss: 0.0867\n",
      "Epoch [8/10], Step [380/750], Loss: 0.0194\n",
      "Epoch [8/10], Step [381/750], Loss: 0.0049\n",
      "Epoch [8/10], Step [382/750], Loss: 0.0231\n",
      "Epoch [8/10], Step [383/750], Loss: 0.0945\n",
      "Epoch [8/10], Step [384/750], Loss: 0.0177\n",
      "Epoch [8/10], Step [385/750], Loss: 0.0074\n",
      "Epoch [8/10], Step [386/750], Loss: 0.0607\n",
      "Epoch [8/10], Step [387/750], Loss: 0.0075\n",
      "Epoch [8/10], Step [388/750], Loss: 0.0114\n",
      "Epoch [8/10], Step [389/750], Loss: 0.0491\n",
      "Epoch [8/10], Step [390/750], Loss: 0.0223\n",
      "Epoch [8/10], Step [391/750], Loss: 0.0024\n",
      "Epoch [8/10], Step [392/750], Loss: 0.0771\n",
      "Epoch [8/10], Step [393/750], Loss: 0.0184\n",
      "Epoch [8/10], Step [394/750], Loss: 0.0273\n",
      "Epoch [8/10], Step [395/750], Loss: 0.0105\n",
      "Epoch [8/10], Step [396/750], Loss: 0.0140\n",
      "Epoch [8/10], Step [397/750], Loss: 0.0483\n",
      "Epoch [8/10], Step [398/750], Loss: 0.0908\n",
      "Epoch [8/10], Step [399/750], Loss: 0.0310\n",
      "Epoch [8/10], Step [400/750], Loss: 0.0238\n",
      "Epoch [8/10], Step [401/750], Loss: 0.0804\n",
      "Epoch [8/10], Step [402/750], Loss: 0.0430\n",
      "Epoch [8/10], Step [403/750], Loss: 0.0738\n",
      "Epoch [8/10], Step [404/750], Loss: 0.1815\n",
      "Epoch [8/10], Step [405/750], Loss: 0.0948\n",
      "Epoch [8/10], Step [406/750], Loss: 0.0338\n",
      "Epoch [8/10], Step [407/750], Loss: 0.0460\n",
      "Epoch [8/10], Step [408/750], Loss: 0.0047\n",
      "Epoch [8/10], Step [409/750], Loss: 0.0364\n",
      "Epoch [8/10], Step [410/750], Loss: 0.0495\n",
      "Epoch [8/10], Step [411/750], Loss: 0.3425\n",
      "Epoch [8/10], Step [412/750], Loss: 0.0288\n",
      "Epoch [8/10], Step [413/750], Loss: 0.1359\n",
      "Epoch [8/10], Step [414/750], Loss: 0.1263\n",
      "Epoch [8/10], Step [415/750], Loss: 0.0218\n",
      "Epoch [8/10], Step [416/750], Loss: 0.1272\n",
      "Epoch [8/10], Step [417/750], Loss: 0.1166\n",
      "Epoch [8/10], Step [418/750], Loss: 0.0379\n",
      "Epoch [8/10], Step [419/750], Loss: 0.0076\n",
      "Epoch [8/10], Step [420/750], Loss: 0.0376\n",
      "Epoch [8/10], Step [421/750], Loss: 0.0364\n",
      "Epoch [8/10], Step [422/750], Loss: 0.0732\n",
      "Epoch [8/10], Step [423/750], Loss: 0.0234\n",
      "Epoch [8/10], Step [424/750], Loss: 0.0215\n",
      "Epoch [8/10], Step [425/750], Loss: 0.0189\n",
      "Epoch [8/10], Step [426/750], Loss: 0.0868\n",
      "Epoch [8/10], Step [427/750], Loss: 0.0403\n",
      "Epoch [8/10], Step [428/750], Loss: 0.0767\n",
      "Epoch [8/10], Step [429/750], Loss: 0.0647\n",
      "Epoch [8/10], Step [430/750], Loss: 0.0818\n",
      "Epoch [8/10], Step [431/750], Loss: 0.0747\n",
      "Epoch [8/10], Step [432/750], Loss: 0.0394\n",
      "Epoch [8/10], Step [433/750], Loss: 0.0067\n",
      "Epoch [8/10], Step [434/750], Loss: 0.0109\n",
      "Epoch [8/10], Step [435/750], Loss: 0.0236\n",
      "Epoch [8/10], Step [436/750], Loss: 0.0390\n",
      "Epoch [8/10], Step [437/750], Loss: 0.0723\n",
      "Epoch [8/10], Step [438/750], Loss: 0.0694\n",
      "Epoch [8/10], Step [439/750], Loss: 0.0542\n",
      "Epoch [8/10], Step [440/750], Loss: 0.0696\n",
      "Epoch [8/10], Step [441/750], Loss: 0.0435\n",
      "Epoch [8/10], Step [442/750], Loss: 0.0406\n",
      "Epoch [8/10], Step [443/750], Loss: 0.0344\n",
      "Epoch [8/10], Step [444/750], Loss: 0.0468\n",
      "Epoch [8/10], Step [445/750], Loss: 0.0283\n",
      "Epoch [8/10], Step [446/750], Loss: 0.1965\n",
      "Epoch [8/10], Step [447/750], Loss: 0.0441\n",
      "Epoch [8/10], Step [448/750], Loss: 0.0789\n",
      "Epoch [8/10], Step [449/750], Loss: 0.0902\n",
      "Epoch [8/10], Step [450/750], Loss: 0.0657\n",
      "Epoch [8/10], Step [451/750], Loss: 0.0911\n",
      "Epoch [8/10], Step [452/750], Loss: 0.0184\n",
      "Epoch [8/10], Step [453/750], Loss: 0.0352\n",
      "Epoch [8/10], Step [454/750], Loss: 0.0861\n",
      "Epoch [8/10], Step [455/750], Loss: 0.1132\n",
      "Epoch [8/10], Step [456/750], Loss: 0.0494\n",
      "Epoch [8/10], Step [457/750], Loss: 0.0101\n",
      "Epoch [8/10], Step [458/750], Loss: 0.0749\n",
      "Epoch [8/10], Step [459/750], Loss: 0.0924\n",
      "Epoch [8/10], Step [460/750], Loss: 0.0686\n",
      "Epoch [8/10], Step [461/750], Loss: 0.0224\n",
      "Epoch [8/10], Step [462/750], Loss: 0.1013\n",
      "Epoch [8/10], Step [463/750], Loss: 0.0448\n",
      "Epoch [8/10], Step [464/750], Loss: 0.1440\n",
      "Epoch [8/10], Step [465/750], Loss: 0.0381\n",
      "Epoch [8/10], Step [466/750], Loss: 0.0836\n",
      "Epoch [8/10], Step [467/750], Loss: 0.0479\n",
      "Epoch [8/10], Step [468/750], Loss: 0.0195\n",
      "Epoch [8/10], Step [469/750], Loss: 0.2475\n",
      "Epoch [8/10], Step [470/750], Loss: 0.0306\n",
      "Epoch [8/10], Step [471/750], Loss: 0.1978\n",
      "Epoch [8/10], Step [472/750], Loss: 0.0519\n",
      "Epoch [8/10], Step [473/750], Loss: 0.0076\n",
      "Epoch [8/10], Step [474/750], Loss: 0.0171\n",
      "Epoch [8/10], Step [475/750], Loss: 0.0044\n",
      "Epoch [8/10], Step [476/750], Loss: 0.0508\n",
      "Epoch [8/10], Step [477/750], Loss: 0.0661\n",
      "Epoch [8/10], Step [478/750], Loss: 0.0414\n",
      "Epoch [8/10], Step [479/750], Loss: 0.0240\n",
      "Epoch [8/10], Step [480/750], Loss: 0.0430\n",
      "Epoch [8/10], Step [481/750], Loss: 0.1955\n",
      "Epoch [8/10], Step [482/750], Loss: 0.0151\n",
      "Epoch [8/10], Step [483/750], Loss: 0.0271\n",
      "Epoch [8/10], Step [484/750], Loss: 0.0483\n",
      "Epoch [8/10], Step [485/750], Loss: 0.0915\n",
      "Epoch [8/10], Step [486/750], Loss: 0.0663\n",
      "Epoch [8/10], Step [487/750], Loss: 0.0450\n",
      "Epoch [8/10], Step [488/750], Loss: 0.0420\n",
      "Epoch [8/10], Step [489/750], Loss: 0.0903\n",
      "Epoch [8/10], Step [490/750], Loss: 0.0448\n",
      "Epoch [8/10], Step [491/750], Loss: 0.0152\n",
      "Epoch [8/10], Step [492/750], Loss: 0.0270\n",
      "Epoch [8/10], Step [493/750], Loss: 0.0307\n",
      "Epoch [8/10], Step [494/750], Loss: 0.0316\n",
      "Epoch [8/10], Step [495/750], Loss: 0.0308\n",
      "Epoch [8/10], Step [496/750], Loss: 0.0552\n",
      "Epoch [8/10], Step [497/750], Loss: 0.0288\n",
      "Epoch [8/10], Step [498/750], Loss: 0.0758\n",
      "Epoch [8/10], Step [499/750], Loss: 0.0395\n",
      "Epoch [8/10], Step [500/750], Loss: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [501/750], Loss: 0.0226\n",
      "Epoch [8/10], Step [502/750], Loss: 0.0268\n",
      "Epoch [8/10], Step [503/750], Loss: 0.0058\n",
      "Epoch [8/10], Step [504/750], Loss: 0.0396\n",
      "Epoch [8/10], Step [505/750], Loss: 0.0151\n",
      "Epoch [8/10], Step [506/750], Loss: 0.0839\n",
      "Epoch [8/10], Step [507/750], Loss: 0.0823\n",
      "Epoch [8/10], Step [508/750], Loss: 0.0335\n",
      "Epoch [8/10], Step [509/750], Loss: 0.0944\n",
      "Epoch [8/10], Step [510/750], Loss: 0.0626\n",
      "Epoch [8/10], Step [511/750], Loss: 0.2077\n",
      "Epoch [8/10], Step [512/750], Loss: 0.0313\n",
      "Epoch [8/10], Step [513/750], Loss: 0.0081\n",
      "Epoch [8/10], Step [514/750], Loss: 0.0763\n",
      "Epoch [8/10], Step [515/750], Loss: 0.0458\n",
      "Epoch [8/10], Step [516/750], Loss: 0.0332\n",
      "Epoch [8/10], Step [517/750], Loss: 0.0507\n",
      "Epoch [8/10], Step [518/750], Loss: 0.0839\n",
      "Epoch [8/10], Step [519/750], Loss: 0.1484\n",
      "Epoch [8/10], Step [520/750], Loss: 0.0177\n",
      "Epoch [8/10], Step [521/750], Loss: 0.0578\n",
      "Epoch [8/10], Step [522/750], Loss: 0.0084\n",
      "Epoch [8/10], Step [523/750], Loss: 0.0553\n",
      "Epoch [8/10], Step [524/750], Loss: 0.0879\n",
      "Epoch [8/10], Step [525/750], Loss: 0.0432\n",
      "Epoch [8/10], Step [526/750], Loss: 0.0377\n",
      "Epoch [8/10], Step [527/750], Loss: 0.1023\n",
      "Epoch [8/10], Step [528/750], Loss: 0.0133\n",
      "Epoch [8/10], Step [529/750], Loss: 0.0213\n",
      "Epoch [8/10], Step [530/750], Loss: 0.0957\n",
      "Epoch [8/10], Step [531/750], Loss: 0.0505\n",
      "Epoch [8/10], Step [532/750], Loss: 0.0405\n",
      "Epoch [8/10], Step [533/750], Loss: 0.0481\n",
      "Epoch [8/10], Step [534/750], Loss: 0.0925\n",
      "Epoch [8/10], Step [535/750], Loss: 0.0663\n",
      "Epoch [8/10], Step [536/750], Loss: 0.0111\n",
      "Epoch [8/10], Step [537/750], Loss: 0.1193\n",
      "Epoch [8/10], Step [538/750], Loss: 0.0182\n",
      "Epoch [8/10], Step [539/750], Loss: 0.0222\n",
      "Epoch [8/10], Step [540/750], Loss: 0.0294\n",
      "Epoch [8/10], Step [541/750], Loss: 0.0173\n",
      "Epoch [8/10], Step [542/750], Loss: 0.0285\n",
      "Epoch [8/10], Step [543/750], Loss: 0.0201\n",
      "Epoch [8/10], Step [544/750], Loss: 0.1033\n",
      "Epoch [8/10], Step [545/750], Loss: 0.0074\n",
      "Epoch [8/10], Step [546/750], Loss: 0.0066\n",
      "Epoch [8/10], Step [547/750], Loss: 0.0372\n",
      "Epoch [8/10], Step [548/750], Loss: 0.2039\n",
      "Epoch [8/10], Step [549/750], Loss: 0.0395\n",
      "Epoch [8/10], Step [550/750], Loss: 0.1777\n",
      "Epoch [8/10], Step [551/750], Loss: 0.0973\n",
      "Epoch [8/10], Step [552/750], Loss: 0.0560\n",
      "Epoch [8/10], Step [553/750], Loss: 0.1302\n",
      "Epoch [8/10], Step [554/750], Loss: 0.1265\n",
      "Epoch [8/10], Step [555/750], Loss: 0.0353\n",
      "Epoch [8/10], Step [556/750], Loss: 0.0339\n",
      "Epoch [8/10], Step [557/750], Loss: 0.0776\n",
      "Epoch [8/10], Step [558/750], Loss: 0.1444\n",
      "Epoch [8/10], Step [559/750], Loss: 0.0960\n",
      "Epoch [8/10], Step [560/750], Loss: 0.0447\n",
      "Epoch [8/10], Step [561/750], Loss: 0.0503\n",
      "Epoch [8/10], Step [562/750], Loss: 0.0586\n",
      "Epoch [8/10], Step [563/750], Loss: 0.1075\n",
      "Epoch [8/10], Step [564/750], Loss: 0.0627\n",
      "Epoch [8/10], Step [565/750], Loss: 0.0318\n",
      "Epoch [8/10], Step [566/750], Loss: 0.0737\n",
      "Epoch [8/10], Step [567/750], Loss: 0.0818\n",
      "Epoch [8/10], Step [568/750], Loss: 0.0119\n",
      "Epoch [8/10], Step [569/750], Loss: 0.0179\n",
      "Epoch [8/10], Step [570/750], Loss: 0.1339\n",
      "Epoch [8/10], Step [571/750], Loss: 0.0794\n",
      "Epoch [8/10], Step [572/750], Loss: 0.0369\n",
      "Epoch [8/10], Step [573/750], Loss: 0.0454\n",
      "Epoch [8/10], Step [574/750], Loss: 0.0251\n",
      "Epoch [8/10], Step [575/750], Loss: 0.0595\n",
      "Epoch [8/10], Step [576/750], Loss: 0.0980\n",
      "Epoch [8/10], Step [577/750], Loss: 0.0517\n",
      "Epoch [8/10], Step [578/750], Loss: 0.0228\n",
      "Epoch [8/10], Step [579/750], Loss: 0.0542\n",
      "Epoch [8/10], Step [580/750], Loss: 0.0076\n",
      "Epoch [8/10], Step [581/750], Loss: 0.0560\n",
      "Epoch [8/10], Step [582/750], Loss: 0.1010\n",
      "Epoch [8/10], Step [583/750], Loss: 0.0208\n",
      "Epoch [8/10], Step [584/750], Loss: 0.0440\n",
      "Epoch [8/10], Step [585/750], Loss: 0.0093\n",
      "Epoch [8/10], Step [586/750], Loss: 0.0990\n",
      "Epoch [8/10], Step [587/750], Loss: 0.0247\n",
      "Epoch [8/10], Step [588/750], Loss: 0.0830\n",
      "Epoch [8/10], Step [589/750], Loss: 0.0774\n",
      "Epoch [8/10], Step [590/750], Loss: 0.0519\n",
      "Epoch [8/10], Step [591/750], Loss: 0.0642\n",
      "Epoch [8/10], Step [592/750], Loss: 0.0494\n",
      "Epoch [8/10], Step [593/750], Loss: 0.1103\n",
      "Epoch [8/10], Step [594/750], Loss: 0.0824\n",
      "Epoch [8/10], Step [595/750], Loss: 0.0515\n",
      "Epoch [8/10], Step [596/750], Loss: 0.0411\n",
      "Epoch [8/10], Step [597/750], Loss: 0.0915\n",
      "Epoch [8/10], Step [598/750], Loss: 0.0829\n",
      "Epoch [8/10], Step [599/750], Loss: 0.3399\n",
      "Epoch [8/10], Step [600/750], Loss: 0.0966\n",
      "Epoch [8/10], Step [601/750], Loss: 0.0815\n",
      "Epoch [8/10], Step [602/750], Loss: 0.2366\n",
      "Epoch [8/10], Step [603/750], Loss: 0.1591\n",
      "Epoch [8/10], Step [604/750], Loss: 0.0197\n",
      "Epoch [8/10], Step [605/750], Loss: 0.0073\n",
      "Epoch [8/10], Step [606/750], Loss: 0.0148\n",
      "Epoch [8/10], Step [607/750], Loss: 0.0428\n",
      "Epoch [8/10], Step [608/750], Loss: 0.0865\n",
      "Epoch [8/10], Step [609/750], Loss: 0.1809\n",
      "Epoch [8/10], Step [610/750], Loss: 0.0936\n",
      "Epoch [8/10], Step [611/750], Loss: 0.0603\n",
      "Epoch [8/10], Step [612/750], Loss: 0.0644\n",
      "Epoch [8/10], Step [613/750], Loss: 0.0226\n",
      "Epoch [8/10], Step [614/750], Loss: 0.1252\n",
      "Epoch [8/10], Step [615/750], Loss: 0.0522\n",
      "Epoch [8/10], Step [616/750], Loss: 0.0253\n",
      "Epoch [8/10], Step [617/750], Loss: 0.3024\n",
      "Epoch [8/10], Step [618/750], Loss: 0.1284\n",
      "Epoch [8/10], Step [619/750], Loss: 0.1476\n",
      "Epoch [8/10], Step [620/750], Loss: 0.1356\n",
      "Epoch [8/10], Step [621/750], Loss: 0.0779\n",
      "Epoch [8/10], Step [622/750], Loss: 0.1313\n",
      "Epoch [8/10], Step [623/750], Loss: 0.1477\n",
      "Epoch [8/10], Step [624/750], Loss: 0.0789\n",
      "Epoch [8/10], Step [625/750], Loss: 0.1367\n",
      "Epoch [8/10], Step [626/750], Loss: 0.1005\n",
      "Epoch [8/10], Step [627/750], Loss: 0.1178\n",
      "Epoch [8/10], Step [628/750], Loss: 0.0454\n",
      "Epoch [8/10], Step [629/750], Loss: 0.0484\n",
      "Epoch [8/10], Step [630/750], Loss: 0.0610\n",
      "Epoch [8/10], Step [631/750], Loss: 0.1220\n",
      "Epoch [8/10], Step [632/750], Loss: 0.0573\n",
      "Epoch [8/10], Step [633/750], Loss: 0.1265\n",
      "Epoch [8/10], Step [634/750], Loss: 0.0569\n",
      "Epoch [8/10], Step [635/750], Loss: 0.0602\n",
      "Epoch [8/10], Step [636/750], Loss: 0.1451\n",
      "Epoch [8/10], Step [637/750], Loss: 0.0599\n",
      "Epoch [8/10], Step [638/750], Loss: 0.1400\n",
      "Epoch [8/10], Step [639/750], Loss: 0.0660\n",
      "Epoch [8/10], Step [640/750], Loss: 0.0218\n",
      "Epoch [8/10], Step [641/750], Loss: 0.0813\n",
      "Epoch [8/10], Step [642/750], Loss: 0.0459\n",
      "Epoch [8/10], Step [643/750], Loss: 0.0223\n",
      "Epoch [8/10], Step [644/750], Loss: 0.0989\n",
      "Epoch [8/10], Step [645/750], Loss: 0.0145\n",
      "Epoch [8/10], Step [646/750], Loss: 0.0211\n",
      "Epoch [8/10], Step [647/750], Loss: 0.1024\n",
      "Epoch [8/10], Step [648/750], Loss: 0.0629\n",
      "Epoch [8/10], Step [649/750], Loss: 0.0372\n",
      "Epoch [8/10], Step [650/750], Loss: 0.0146\n",
      "Epoch [8/10], Step [651/750], Loss: 0.1019\n",
      "Epoch [8/10], Step [652/750], Loss: 0.1960\n",
      "Epoch [8/10], Step [653/750], Loss: 0.0365\n",
      "Epoch [8/10], Step [654/750], Loss: 0.0230\n",
      "Epoch [8/10], Step [655/750], Loss: 0.0637\n",
      "Epoch [8/10], Step [656/750], Loss: 0.0354\n",
      "Epoch [8/10], Step [657/750], Loss: 0.0765\n",
      "Epoch [8/10], Step [658/750], Loss: 0.0552\n",
      "Epoch [8/10], Step [659/750], Loss: 0.0212\n",
      "Epoch [8/10], Step [660/750], Loss: 0.0157\n",
      "Epoch [8/10], Step [661/750], Loss: 0.0432\n",
      "Epoch [8/10], Step [662/750], Loss: 0.1138\n",
      "Epoch [8/10], Step [663/750], Loss: 0.0486\n",
      "Epoch [8/10], Step [664/750], Loss: 0.1054\n",
      "Epoch [8/10], Step [665/750], Loss: 0.0448\n",
      "Epoch [8/10], Step [666/750], Loss: 0.0460\n",
      "Epoch [8/10], Step [667/750], Loss: 0.0118\n",
      "Epoch [8/10], Step [668/750], Loss: 0.0272\n",
      "Epoch [8/10], Step [669/750], Loss: 0.1400\n",
      "Epoch [8/10], Step [670/750], Loss: 0.0042\n",
      "Epoch [8/10], Step [671/750], Loss: 0.0158\n",
      "Epoch [8/10], Step [672/750], Loss: 0.0412\n",
      "Epoch [8/10], Step [673/750], Loss: 0.1002\n",
      "Epoch [8/10], Step [674/750], Loss: 0.0828\n",
      "Epoch [8/10], Step [675/750], Loss: 0.0393\n",
      "Epoch [8/10], Step [676/750], Loss: 0.0938\n",
      "Epoch [8/10], Step [677/750], Loss: 0.1123\n",
      "Epoch [8/10], Step [678/750], Loss: 0.1164\n",
      "Epoch [8/10], Step [679/750], Loss: 0.0168\n",
      "Epoch [8/10], Step [680/750], Loss: 0.0745\n",
      "Epoch [8/10], Step [681/750], Loss: 0.2289\n",
      "Epoch [8/10], Step [682/750], Loss: 0.0171\n",
      "Epoch [8/10], Step [683/750], Loss: 0.1276\n",
      "Epoch [8/10], Step [684/750], Loss: 0.0684\n",
      "Epoch [8/10], Step [685/750], Loss: 0.0841\n",
      "Epoch [8/10], Step [686/750], Loss: 0.0420\n",
      "Epoch [8/10], Step [687/750], Loss: 0.0641\n",
      "Epoch [8/10], Step [688/750], Loss: 0.1674\n",
      "Epoch [8/10], Step [689/750], Loss: 0.0195\n",
      "Epoch [8/10], Step [690/750], Loss: 0.0332\n",
      "Epoch [8/10], Step [691/750], Loss: 0.0645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [692/750], Loss: 0.0450\n",
      "Epoch [8/10], Step [693/750], Loss: 0.0579\n",
      "Epoch [8/10], Step [694/750], Loss: 0.0992\n",
      "Epoch [8/10], Step [695/750], Loss: 0.1158\n",
      "Epoch [8/10], Step [696/750], Loss: 0.0222\n",
      "Epoch [8/10], Step [697/750], Loss: 0.1154\n",
      "Epoch [8/10], Step [698/750], Loss: 0.0531\n",
      "Epoch [8/10], Step [699/750], Loss: 0.0348\n",
      "Epoch [8/10], Step [700/750], Loss: 0.0729\n",
      "Epoch [8/10], Step [701/750], Loss: 0.1992\n",
      "Epoch [8/10], Step [702/750], Loss: 0.0387\n",
      "Epoch [8/10], Step [703/750], Loss: 0.0351\n",
      "Epoch [8/10], Step [704/750], Loss: 0.1112\n",
      "Epoch [8/10], Step [705/750], Loss: 0.0952\n",
      "Epoch [8/10], Step [706/750], Loss: 0.1516\n",
      "Epoch [8/10], Step [707/750], Loss: 0.0558\n",
      "Epoch [8/10], Step [708/750], Loss: 0.1738\n",
      "Epoch [8/10], Step [709/750], Loss: 0.1203\n",
      "Epoch [8/10], Step [710/750], Loss: 0.0307\n",
      "Epoch [8/10], Step [711/750], Loss: 0.1050\n",
      "Epoch [8/10], Step [712/750], Loss: 0.0718\n",
      "Epoch [8/10], Step [713/750], Loss: 0.0694\n",
      "Epoch [8/10], Step [714/750], Loss: 0.0712\n",
      "Epoch [8/10], Step [715/750], Loss: 0.0482\n",
      "Epoch [8/10], Step [716/750], Loss: 0.0846\n",
      "Epoch [8/10], Step [717/750], Loss: 0.0715\n",
      "Epoch [8/10], Step [718/750], Loss: 0.0174\n",
      "Epoch [8/10], Step [719/750], Loss: 0.0821\n",
      "Epoch [8/10], Step [720/750], Loss: 0.0045\n",
      "Epoch [8/10], Step [721/750], Loss: 0.0466\n",
      "Epoch [8/10], Step [722/750], Loss: 0.0147\n",
      "Epoch [8/10], Step [723/750], Loss: 0.0610\n",
      "Epoch [8/10], Step [724/750], Loss: 0.0422\n",
      "Epoch [8/10], Step [725/750], Loss: 0.0262\n",
      "Epoch [8/10], Step [726/750], Loss: 0.0197\n",
      "Epoch [8/10], Step [727/750], Loss: 0.0813\n",
      "Epoch [8/10], Step [728/750], Loss: 0.0857\n",
      "Epoch [8/10], Step [729/750], Loss: 0.1504\n",
      "Epoch [8/10], Step [730/750], Loss: 0.1148\n",
      "Epoch [8/10], Step [731/750], Loss: 0.0126\n",
      "Epoch [8/10], Step [732/750], Loss: 0.1105\n",
      "Epoch [8/10], Step [733/750], Loss: 0.0254\n",
      "Epoch [8/10], Step [734/750], Loss: 0.0576\n",
      "Epoch [8/10], Step [735/750], Loss: 0.0452\n",
      "Epoch [8/10], Step [736/750], Loss: 0.0500\n",
      "Epoch [8/10], Step [737/750], Loss: 0.0427\n",
      "Epoch [8/10], Step [738/750], Loss: 0.0768\n",
      "Epoch [8/10], Step [739/750], Loss: 0.0488\n",
      "Epoch [8/10], Step [740/750], Loss: 0.0504\n",
      "Epoch [8/10], Step [741/750], Loss: 0.0518\n",
      "Epoch [8/10], Step [742/750], Loss: 0.0258\n",
      "Epoch [8/10], Step [743/750], Loss: 0.0637\n",
      "Epoch [8/10], Step [744/750], Loss: 0.0713\n",
      "Epoch [8/10], Step [745/750], Loss: 0.0713\n",
      "Epoch [8/10], Step [746/750], Loss: 0.1161\n",
      "Epoch [8/10], Step [747/750], Loss: 0.0241\n",
      "Epoch [8/10], Step [748/750], Loss: 0.2057\n",
      "Epoch [8/10], Step [749/750], Loss: 0.0126\n",
      "Epoch [8/10], Step [750/750], Loss: 0.0817\n",
      "\n",
      "\n",
      "Epoch [9/10], Step [1/750], Loss: 0.0079\n",
      "Epoch [9/10], Step [2/750], Loss: 0.0476\n",
      "Epoch [9/10], Step [3/750], Loss: 0.0749\n",
      "Epoch [9/10], Step [4/750], Loss: 0.0283\n",
      "Epoch [9/10], Step [5/750], Loss: 0.0286\n",
      "Epoch [9/10], Step [6/750], Loss: 0.0306\n",
      "Epoch [9/10], Step [7/750], Loss: 0.0140\n",
      "Epoch [9/10], Step [8/750], Loss: 0.0813\n",
      "Epoch [9/10], Step [9/750], Loss: 0.0359\n",
      "Epoch [9/10], Step [10/750], Loss: 0.0397\n",
      "Epoch [9/10], Step [11/750], Loss: 0.1322\n",
      "Epoch [9/10], Step [12/750], Loss: 0.0043\n",
      "Epoch [9/10], Step [13/750], Loss: 0.0791\n",
      "Epoch [9/10], Step [14/750], Loss: 0.0113\n",
      "Epoch [9/10], Step [15/750], Loss: 0.0202\n",
      "Epoch [9/10], Step [16/750], Loss: 0.0381\n",
      "Epoch [9/10], Step [17/750], Loss: 0.0168\n",
      "Epoch [9/10], Step [18/750], Loss: 0.0561\n",
      "Epoch [9/10], Step [19/750], Loss: 0.0442\n",
      "Epoch [9/10], Step [20/750], Loss: 0.0963\n",
      "Epoch [9/10], Step [21/750], Loss: 0.0571\n",
      "Epoch [9/10], Step [22/750], Loss: 0.0968\n",
      "Epoch [9/10], Step [23/750], Loss: 0.0599\n",
      "Epoch [9/10], Step [24/750], Loss: 0.0651\n",
      "Epoch [9/10], Step [25/750], Loss: 0.0385\n",
      "Epoch [9/10], Step [26/750], Loss: 0.0612\n",
      "Epoch [9/10], Step [27/750], Loss: 0.1259\n",
      "Epoch [9/10], Step [28/750], Loss: 0.1558\n",
      "Epoch [9/10], Step [29/750], Loss: 0.0204\n",
      "Epoch [9/10], Step [30/750], Loss: 0.0560\n",
      "Epoch [9/10], Step [31/750], Loss: 0.0605\n",
      "Epoch [9/10], Step [32/750], Loss: 0.0409\n",
      "Epoch [9/10], Step [33/750], Loss: 0.0189\n",
      "Epoch [9/10], Step [34/750], Loss: 0.1066\n",
      "Epoch [9/10], Step [35/750], Loss: 0.1011\n",
      "Epoch [9/10], Step [36/750], Loss: 0.0547\n",
      "Epoch [9/10], Step [37/750], Loss: 0.0041\n",
      "Epoch [9/10], Step [38/750], Loss: 0.1344\n",
      "Epoch [9/10], Step [39/750], Loss: 0.0844\n",
      "Epoch [9/10], Step [40/750], Loss: 0.0874\n",
      "Epoch [9/10], Step [41/750], Loss: 0.1493\n",
      "Epoch [9/10], Step [42/750], Loss: 0.0558\n",
      "Epoch [9/10], Step [43/750], Loss: 0.1310\n",
      "Epoch [9/10], Step [44/750], Loss: 0.0420\n",
      "Epoch [9/10], Step [45/750], Loss: 0.0565\n",
      "Epoch [9/10], Step [46/750], Loss: 0.0870\n",
      "Epoch [9/10], Step [47/750], Loss: 0.1175\n",
      "Epoch [9/10], Step [48/750], Loss: 0.0804\n",
      "Epoch [9/10], Step [49/750], Loss: 0.1451\n",
      "Epoch [9/10], Step [50/750], Loss: 0.0771\n",
      "Epoch [9/10], Step [51/750], Loss: 0.0980\n",
      "Epoch [9/10], Step [52/750], Loss: 0.0215\n",
      "Epoch [9/10], Step [53/750], Loss: 0.0546\n",
      "Epoch [9/10], Step [54/750], Loss: 0.1069\n",
      "Epoch [9/10], Step [55/750], Loss: 0.0689\n",
      "Epoch [9/10], Step [56/750], Loss: 0.0433\n",
      "Epoch [9/10], Step [57/750], Loss: 0.0317\n",
      "Epoch [9/10], Step [58/750], Loss: 0.0330\n",
      "Epoch [9/10], Step [59/750], Loss: 0.0399\n",
      "Epoch [9/10], Step [60/750], Loss: 0.0728\n",
      "Epoch [9/10], Step [61/750], Loss: 0.0534\n",
      "Epoch [9/10], Step [62/750], Loss: 0.0308\n",
      "Epoch [9/10], Step [63/750], Loss: 0.0574\n",
      "Epoch [9/10], Step [64/750], Loss: 0.0247\n",
      "Epoch [9/10], Step [65/750], Loss: 0.0188\n",
      "Epoch [9/10], Step [66/750], Loss: 0.0104\n",
      "Epoch [9/10], Step [67/750], Loss: 0.0406\n",
      "Epoch [9/10], Step [68/750], Loss: 0.0628\n",
      "Epoch [9/10], Step [69/750], Loss: 0.0450\n",
      "Epoch [9/10], Step [70/750], Loss: 0.0393\n",
      "Epoch [9/10], Step [71/750], Loss: 0.0678\n",
      "Epoch [9/10], Step [72/750], Loss: 0.0665\n",
      "Epoch [9/10], Step [73/750], Loss: 0.0159\n",
      "Epoch [9/10], Step [74/750], Loss: 0.0505\n",
      "Epoch [9/10], Step [75/750], Loss: 0.0505\n",
      "Epoch [9/10], Step [76/750], Loss: 0.0127\n",
      "Epoch [9/10], Step [77/750], Loss: 0.1164\n",
      "Epoch [9/10], Step [78/750], Loss: 0.0319\n",
      "Epoch [9/10], Step [79/750], Loss: 0.0182\n",
      "Epoch [9/10], Step [80/750], Loss: 0.1427\n",
      "Epoch [9/10], Step [81/750], Loss: 0.0710\n",
      "Epoch [9/10], Step [82/750], Loss: 0.1150\n",
      "Epoch [9/10], Step [83/750], Loss: 0.0961\n",
      "Epoch [9/10], Step [84/750], Loss: 0.0586\n",
      "Epoch [9/10], Step [85/750], Loss: 0.0341\n",
      "Epoch [9/10], Step [86/750], Loss: 0.0466\n",
      "Epoch [9/10], Step [87/750], Loss: 0.0326\n",
      "Epoch [9/10], Step [88/750], Loss: 0.0717\n",
      "Epoch [9/10], Step [89/750], Loss: 0.0971\n",
      "Epoch [9/10], Step [90/750], Loss: 0.0106\n",
      "Epoch [9/10], Step [91/750], Loss: 0.0590\n",
      "Epoch [9/10], Step [92/750], Loss: 0.0575\n",
      "Epoch [9/10], Step [93/750], Loss: 0.0937\n",
      "Epoch [9/10], Step [94/750], Loss: 0.0515\n",
      "Epoch [9/10], Step [95/750], Loss: 0.1202\n",
      "Epoch [9/10], Step [96/750], Loss: 0.0516\n",
      "Epoch [9/10], Step [97/750], Loss: 0.0213\n",
      "Epoch [9/10], Step [98/750], Loss: 0.1029\n",
      "Epoch [9/10], Step [99/750], Loss: 0.0091\n",
      "Epoch [9/10], Step [100/750], Loss: 0.0128\n",
      "Epoch [9/10], Step [101/750], Loss: 0.0628\n",
      "Epoch [9/10], Step [102/750], Loss: 0.0788\n",
      "Epoch [9/10], Step [103/750], Loss: 0.0054\n",
      "Epoch [9/10], Step [104/750], Loss: 0.0795\n",
      "Epoch [9/10], Step [105/750], Loss: 0.1113\n",
      "Epoch [9/10], Step [106/750], Loss: 0.0210\n",
      "Epoch [9/10], Step [107/750], Loss: 0.0296\n",
      "Epoch [9/10], Step [108/750], Loss: 0.0265\n",
      "Epoch [9/10], Step [109/750], Loss: 0.1058\n",
      "Epoch [9/10], Step [110/750], Loss: 0.0392\n",
      "Epoch [9/10], Step [111/750], Loss: 0.0752\n",
      "Epoch [9/10], Step [112/750], Loss: 0.0197\n",
      "Epoch [9/10], Step [113/750], Loss: 0.0244\n",
      "Epoch [9/10], Step [114/750], Loss: 0.1313\n",
      "Epoch [9/10], Step [115/750], Loss: 0.0047\n",
      "Epoch [9/10], Step [116/750], Loss: 0.0599\n",
      "Epoch [9/10], Step [117/750], Loss: 0.0192\n",
      "Epoch [9/10], Step [118/750], Loss: 0.1050\n",
      "Epoch [9/10], Step [119/750], Loss: 0.0132\n",
      "Epoch [9/10], Step [120/750], Loss: 0.0056\n",
      "Epoch [9/10], Step [121/750], Loss: 0.0242\n",
      "Epoch [9/10], Step [122/750], Loss: 0.0267\n",
      "Epoch [9/10], Step [123/750], Loss: 0.0569\n",
      "Epoch [9/10], Step [124/750], Loss: 0.0345\n",
      "Epoch [9/10], Step [125/750], Loss: 0.0132\n",
      "Epoch [9/10], Step [126/750], Loss: 0.0128\n",
      "Epoch [9/10], Step [127/750], Loss: 0.0131\n",
      "Epoch [9/10], Step [128/750], Loss: 0.0154\n",
      "Epoch [9/10], Step [129/750], Loss: 0.0052\n",
      "Epoch [9/10], Step [130/750], Loss: 0.0161\n",
      "Epoch [9/10], Step [131/750], Loss: 0.1106\n",
      "Epoch [9/10], Step [132/750], Loss: 0.1732\n",
      "Epoch [9/10], Step [133/750], Loss: 0.0340\n",
      "Epoch [9/10], Step [134/750], Loss: 0.0561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [135/750], Loss: 0.0590\n",
      "Epoch [9/10], Step [136/750], Loss: 0.0725\n",
      "Epoch [9/10], Step [137/750], Loss: 0.0896\n",
      "Epoch [9/10], Step [138/750], Loss: 0.1479\n",
      "Epoch [9/10], Step [139/750], Loss: 0.1110\n",
      "Epoch [9/10], Step [140/750], Loss: 0.0524\n",
      "Epoch [9/10], Step [141/750], Loss: 0.0654\n",
      "Epoch [9/10], Step [142/750], Loss: 0.0340\n",
      "Epoch [9/10], Step [143/750], Loss: 0.0722\n",
      "Epoch [9/10], Step [144/750], Loss: 0.0176\n",
      "Epoch [9/10], Step [145/750], Loss: 0.0732\n",
      "Epoch [9/10], Step [146/750], Loss: 0.0343\n",
      "Epoch [9/10], Step [147/750], Loss: 0.0278\n",
      "Epoch [9/10], Step [148/750], Loss: 0.0267\n",
      "Epoch [9/10], Step [149/750], Loss: 0.0469\n",
      "Epoch [9/10], Step [150/750], Loss: 0.0934\n",
      "Epoch [9/10], Step [151/750], Loss: 0.0251\n",
      "Epoch [9/10], Step [152/750], Loss: 0.0748\n",
      "Epoch [9/10], Step [153/750], Loss: 0.0269\n",
      "Epoch [9/10], Step [154/750], Loss: 0.0967\n",
      "Epoch [9/10], Step [155/750], Loss: 0.0079\n",
      "Epoch [9/10], Step [156/750], Loss: 0.0207\n",
      "Epoch [9/10], Step [157/750], Loss: 0.0281\n",
      "Epoch [9/10], Step [158/750], Loss: 0.0340\n",
      "Epoch [9/10], Step [159/750], Loss: 0.0242\n",
      "Epoch [9/10], Step [160/750], Loss: 0.0748\n",
      "Epoch [9/10], Step [161/750], Loss: 0.0384\n",
      "Epoch [9/10], Step [162/750], Loss: 0.0511\n",
      "Epoch [9/10], Step [163/750], Loss: 0.0089\n",
      "Epoch [9/10], Step [164/750], Loss: 0.0037\n",
      "Epoch [9/10], Step [165/750], Loss: 0.0527\n",
      "Epoch [9/10], Step [166/750], Loss: 0.0459\n",
      "Epoch [9/10], Step [167/750], Loss: 0.0184\n",
      "Epoch [9/10], Step [168/750], Loss: 0.0407\n",
      "Epoch [9/10], Step [169/750], Loss: 0.0576\n",
      "Epoch [9/10], Step [170/750], Loss: 0.0329\n",
      "Epoch [9/10], Step [171/750], Loss: 0.0260\n",
      "Epoch [9/10], Step [172/750], Loss: 0.0179\n",
      "Epoch [9/10], Step [173/750], Loss: 0.0227\n",
      "Epoch [9/10], Step [174/750], Loss: 0.0563\n",
      "Epoch [9/10], Step [175/750], Loss: 0.0263\n",
      "Epoch [9/10], Step [176/750], Loss: 0.0114\n",
      "Epoch [9/10], Step [177/750], Loss: 0.0091\n",
      "Epoch [9/10], Step [178/750], Loss: 0.0149\n",
      "Epoch [9/10], Step [179/750], Loss: 0.0035\n",
      "Epoch [9/10], Step [180/750], Loss: 0.0228\n",
      "Epoch [9/10], Step [181/750], Loss: 0.0365\n",
      "Epoch [9/10], Step [182/750], Loss: 0.0860\n",
      "Epoch [9/10], Step [183/750], Loss: 0.1115\n",
      "Epoch [9/10], Step [184/750], Loss: 0.0099\n",
      "Epoch [9/10], Step [185/750], Loss: 0.0204\n",
      "Epoch [9/10], Step [186/750], Loss: 0.0462\n",
      "Epoch [9/10], Step [187/750], Loss: 0.0819\n",
      "Epoch [9/10], Step [188/750], Loss: 0.0048\n",
      "Epoch [9/10], Step [189/750], Loss: 0.0421\n",
      "Epoch [9/10], Step [190/750], Loss: 0.0178\n",
      "Epoch [9/10], Step [191/750], Loss: 0.0219\n",
      "Epoch [9/10], Step [192/750], Loss: 0.1154\n",
      "Epoch [9/10], Step [193/750], Loss: 0.0681\n",
      "Epoch [9/10], Step [194/750], Loss: 0.1050\n",
      "Epoch [9/10], Step [195/750], Loss: 0.0316\n",
      "Epoch [9/10], Step [196/750], Loss: 0.0552\n",
      "Epoch [9/10], Step [197/750], Loss: 0.0460\n",
      "Epoch [9/10], Step [198/750], Loss: 0.0903\n",
      "Epoch [9/10], Step [199/750], Loss: 0.1121\n",
      "Epoch [9/10], Step [200/750], Loss: 0.0342\n",
      "Epoch [9/10], Step [201/750], Loss: 0.0148\n",
      "Epoch [9/10], Step [202/750], Loss: 0.0302\n",
      "Epoch [9/10], Step [203/750], Loss: 0.0252\n",
      "Epoch [9/10], Step [204/750], Loss: 0.0174\n",
      "Epoch [9/10], Step [205/750], Loss: 0.0708\n",
      "Epoch [9/10], Step [206/750], Loss: 0.0299\n",
      "Epoch [9/10], Step [207/750], Loss: 0.0497\n",
      "Epoch [9/10], Step [208/750], Loss: 0.0513\n",
      "Epoch [9/10], Step [209/750], Loss: 0.0408\n",
      "Epoch [9/10], Step [210/750], Loss: 0.0762\n",
      "Epoch [9/10], Step [211/750], Loss: 0.0100\n",
      "Epoch [9/10], Step [212/750], Loss: 0.0087\n",
      "Epoch [9/10], Step [213/750], Loss: 0.0420\n",
      "Epoch [9/10], Step [214/750], Loss: 0.0764\n",
      "Epoch [9/10], Step [215/750], Loss: 0.0100\n",
      "Epoch [9/10], Step [216/750], Loss: 0.0404\n",
      "Epoch [9/10], Step [217/750], Loss: 0.0446\n",
      "Epoch [9/10], Step [218/750], Loss: 0.0688\n",
      "Epoch [9/10], Step [219/750], Loss: 0.0342\n",
      "Epoch [9/10], Step [220/750], Loss: 0.0908\n",
      "Epoch [9/10], Step [221/750], Loss: 0.0563\n",
      "Epoch [9/10], Step [222/750], Loss: 0.0151\n",
      "Epoch [9/10], Step [223/750], Loss: 0.1398\n",
      "Epoch [9/10], Step [224/750], Loss: 0.1396\n",
      "Epoch [9/10], Step [225/750], Loss: 0.0552\n",
      "Epoch [9/10], Step [226/750], Loss: 0.0240\n",
      "Epoch [9/10], Step [227/750], Loss: 0.0070\n",
      "Epoch [9/10], Step [228/750], Loss: 0.0898\n",
      "Epoch [9/10], Step [229/750], Loss: 0.0392\n",
      "Epoch [9/10], Step [230/750], Loss: 0.0602\n",
      "Epoch [9/10], Step [231/750], Loss: 0.0535\n",
      "Epoch [9/10], Step [232/750], Loss: 0.0717\n",
      "Epoch [9/10], Step [233/750], Loss: 0.0499\n",
      "Epoch [9/10], Step [234/750], Loss: 0.0882\n",
      "Epoch [9/10], Step [235/750], Loss: 0.0634\n",
      "Epoch [9/10], Step [236/750], Loss: 0.1240\n",
      "Epoch [9/10], Step [237/750], Loss: 0.1365\n",
      "Epoch [9/10], Step [238/750], Loss: 0.1124\n",
      "Epoch [9/10], Step [239/750], Loss: 0.0386\n",
      "Epoch [9/10], Step [240/750], Loss: 0.0092\n",
      "Epoch [9/10], Step [241/750], Loss: 0.0513\n",
      "Epoch [9/10], Step [242/750], Loss: 0.0671\n",
      "Epoch [9/10], Step [243/750], Loss: 0.0220\n",
      "Epoch [9/10], Step [244/750], Loss: 0.0095\n",
      "Epoch [9/10], Step [245/750], Loss: 0.0056\n",
      "Epoch [9/10], Step [246/750], Loss: 0.2245\n",
      "Epoch [9/10], Step [247/750], Loss: 0.1670\n",
      "Epoch [9/10], Step [248/750], Loss: 0.0470\n",
      "Epoch [9/10], Step [249/750], Loss: 0.0226\n",
      "Epoch [9/10], Step [250/750], Loss: 0.0296\n",
      "Epoch [9/10], Step [251/750], Loss: 0.0224\n",
      "Epoch [9/10], Step [252/750], Loss: 0.0914\n",
      "Epoch [9/10], Step [253/750], Loss: 0.0022\n",
      "Epoch [9/10], Step [254/750], Loss: 0.0124\n",
      "Epoch [9/10], Step [255/750], Loss: 0.0830\n",
      "Epoch [9/10], Step [256/750], Loss: 0.0551\n",
      "Epoch [9/10], Step [257/750], Loss: 0.0148\n",
      "Epoch [9/10], Step [258/750], Loss: 0.0597\n",
      "Epoch [9/10], Step [259/750], Loss: 0.1177\n",
      "Epoch [9/10], Step [260/750], Loss: 0.0559\n",
      "Epoch [9/10], Step [261/750], Loss: 0.1255\n",
      "Epoch [9/10], Step [262/750], Loss: 0.0270\n",
      "Epoch [9/10], Step [263/750], Loss: 0.0159\n",
      "Epoch [9/10], Step [264/750], Loss: 0.0163\n",
      "Epoch [9/10], Step [265/750], Loss: 0.0283\n",
      "Epoch [9/10], Step [266/750], Loss: 0.0214\n",
      "Epoch [9/10], Step [267/750], Loss: 0.0517\n",
      "Epoch [9/10], Step [268/750], Loss: 0.0484\n",
      "Epoch [9/10], Step [269/750], Loss: 0.0711\n",
      "Epoch [9/10], Step [270/750], Loss: 0.0091\n",
      "Epoch [9/10], Step [271/750], Loss: 0.0687\n",
      "Epoch [9/10], Step [272/750], Loss: 0.0458\n",
      "Epoch [9/10], Step [273/750], Loss: 0.0408\n",
      "Epoch [9/10], Step [274/750], Loss: 0.0830\n",
      "Epoch [9/10], Step [275/750], Loss: 0.0246\n",
      "Epoch [9/10], Step [276/750], Loss: 0.0292\n",
      "Epoch [9/10], Step [277/750], Loss: 0.0102\n",
      "Epoch [9/10], Step [278/750], Loss: 0.0449\n",
      "Epoch [9/10], Step [279/750], Loss: 0.0182\n",
      "Epoch [9/10], Step [280/750], Loss: 0.0661\n",
      "Epoch [9/10], Step [281/750], Loss: 0.0293\n",
      "Epoch [9/10], Step [282/750], Loss: 0.0178\n",
      "Epoch [9/10], Step [283/750], Loss: 0.0087\n",
      "Epoch [9/10], Step [284/750], Loss: 0.1165\n",
      "Epoch [9/10], Step [285/750], Loss: 0.0088\n",
      "Epoch [9/10], Step [286/750], Loss: 0.0104\n",
      "Epoch [9/10], Step [287/750], Loss: 0.0493\n",
      "Epoch [9/10], Step [288/750], Loss: 0.1048\n",
      "Epoch [9/10], Step [289/750], Loss: 0.0107\n",
      "Epoch [9/10], Step [290/750], Loss: 0.0334\n",
      "Epoch [9/10], Step [291/750], Loss: 0.0055\n",
      "Epoch [9/10], Step [292/750], Loss: 0.0063\n",
      "Epoch [9/10], Step [293/750], Loss: 0.0594\n",
      "Epoch [9/10], Step [294/750], Loss: 0.0236\n",
      "Epoch [9/10], Step [295/750], Loss: 0.0825\n",
      "Epoch [9/10], Step [296/750], Loss: 0.0257\n",
      "Epoch [9/10], Step [297/750], Loss: 0.0387\n",
      "Epoch [9/10], Step [298/750], Loss: 0.0140\n",
      "Epoch [9/10], Step [299/750], Loss: 0.1470\n",
      "Epoch [9/10], Step [300/750], Loss: 0.0603\n",
      "Epoch [9/10], Step [301/750], Loss: 0.0674\n",
      "Epoch [9/10], Step [302/750], Loss: 0.0431\n",
      "Epoch [9/10], Step [303/750], Loss: 0.0599\n",
      "Epoch [9/10], Step [304/750], Loss: 0.0908\n",
      "Epoch [9/10], Step [305/750], Loss: 0.0104\n",
      "Epoch [9/10], Step [306/750], Loss: 0.0087\n",
      "Epoch [9/10], Step [307/750], Loss: 0.0553\n",
      "Epoch [9/10], Step [308/750], Loss: 0.0715\n",
      "Epoch [9/10], Step [309/750], Loss: 0.0477\n",
      "Epoch [9/10], Step [310/750], Loss: 0.0373\n",
      "Epoch [9/10], Step [311/750], Loss: 0.0520\n",
      "Epoch [9/10], Step [312/750], Loss: 0.0635\n",
      "Epoch [9/10], Step [313/750], Loss: 0.0425\n",
      "Epoch [9/10], Step [314/750], Loss: 0.0403\n",
      "Epoch [9/10], Step [315/750], Loss: 0.0585\n",
      "Epoch [9/10], Step [316/750], Loss: 0.0329\n",
      "Epoch [9/10], Step [317/750], Loss: 0.0534\n",
      "Epoch [9/10], Step [318/750], Loss: 0.0077\n",
      "Epoch [9/10], Step [319/750], Loss: 0.0447\n",
      "Epoch [9/10], Step [320/750], Loss: 0.0087\n",
      "Epoch [9/10], Step [321/750], Loss: 0.0571\n",
      "Epoch [9/10], Step [322/750], Loss: 0.0509\n",
      "Epoch [9/10], Step [323/750], Loss: 0.1017\n",
      "Epoch [9/10], Step [324/750], Loss: 0.0375\n",
      "Epoch [9/10], Step [325/750], Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [326/750], Loss: 0.0138\n",
      "Epoch [9/10], Step [327/750], Loss: 0.0435\n",
      "Epoch [9/10], Step [328/750], Loss: 0.1345\n",
      "Epoch [9/10], Step [329/750], Loss: 0.0220\n",
      "Epoch [9/10], Step [330/750], Loss: 0.0079\n",
      "Epoch [9/10], Step [331/750], Loss: 0.0784\n",
      "Epoch [9/10], Step [332/750], Loss: 0.0543\n",
      "Epoch [9/10], Step [333/750], Loss: 0.0695\n",
      "Epoch [9/10], Step [334/750], Loss: 0.0464\n",
      "Epoch [9/10], Step [335/750], Loss: 0.0503\n",
      "Epoch [9/10], Step [336/750], Loss: 0.0849\n",
      "Epoch [9/10], Step [337/750], Loss: 0.0176\n",
      "Epoch [9/10], Step [338/750], Loss: 0.0343\n",
      "Epoch [9/10], Step [339/750], Loss: 0.0624\n",
      "Epoch [9/10], Step [340/750], Loss: 0.0048\n",
      "Epoch [9/10], Step [341/750], Loss: 0.0129\n",
      "Epoch [9/10], Step [342/750], Loss: 0.0391\n",
      "Epoch [9/10], Step [343/750], Loss: 0.0838\n",
      "Epoch [9/10], Step [344/750], Loss: 0.0382\n",
      "Epoch [9/10], Step [345/750], Loss: 0.0517\n",
      "Epoch [9/10], Step [346/750], Loss: 0.1118\n",
      "Epoch [9/10], Step [347/750], Loss: 0.0462\n",
      "Epoch [9/10], Step [348/750], Loss: 0.0119\n",
      "Epoch [9/10], Step [349/750], Loss: 0.0370\n",
      "Epoch [9/10], Step [350/750], Loss: 0.0055\n",
      "Epoch [9/10], Step [351/750], Loss: 0.0596\n",
      "Epoch [9/10], Step [352/750], Loss: 0.0352\n",
      "Epoch [9/10], Step [353/750], Loss: 0.0049\n",
      "Epoch [9/10], Step [354/750], Loss: 0.0492\n",
      "Epoch [9/10], Step [355/750], Loss: 0.0422\n",
      "Epoch [9/10], Step [356/750], Loss: 0.0148\n",
      "Epoch [9/10], Step [357/750], Loss: 0.0348\n",
      "Epoch [9/10], Step [358/750], Loss: 0.0709\n",
      "Epoch [9/10], Step [359/750], Loss: 0.0186\n",
      "Epoch [9/10], Step [360/750], Loss: 0.0466\n",
      "Epoch [9/10], Step [361/750], Loss: 0.0523\n",
      "Epoch [9/10], Step [362/750], Loss: 0.0181\n",
      "Epoch [9/10], Step [363/750], Loss: 0.0382\n",
      "Epoch [9/10], Step [364/750], Loss: 0.0052\n",
      "Epoch [9/10], Step [365/750], Loss: 0.1155\n",
      "Epoch [9/10], Step [366/750], Loss: 0.0109\n",
      "Epoch [9/10], Step [367/750], Loss: 0.0139\n",
      "Epoch [9/10], Step [368/750], Loss: 0.0089\n",
      "Epoch [9/10], Step [369/750], Loss: 0.0287\n",
      "Epoch [9/10], Step [370/750], Loss: 0.0087\n",
      "Epoch [9/10], Step [371/750], Loss: 0.1076\n",
      "Epoch [9/10], Step [372/750], Loss: 0.0110\n",
      "Epoch [9/10], Step [373/750], Loss: 0.0184\n",
      "Epoch [9/10], Step [374/750], Loss: 0.0397\n",
      "Epoch [9/10], Step [375/750], Loss: 0.0617\n",
      "Epoch [9/10], Step [376/750], Loss: 0.0712\n",
      "Epoch [9/10], Step [377/750], Loss: 0.0367\n",
      "Epoch [9/10], Step [378/750], Loss: 0.0241\n",
      "Epoch [9/10], Step [379/750], Loss: 0.0249\n",
      "Epoch [9/10], Step [380/750], Loss: 0.0012\n",
      "Epoch [9/10], Step [381/750], Loss: 0.0799\n",
      "Epoch [9/10], Step [382/750], Loss: 0.0296\n",
      "Epoch [9/10], Step [383/750], Loss: 0.0553\n",
      "Epoch [9/10], Step [384/750], Loss: 0.0404\n",
      "Epoch [9/10], Step [385/750], Loss: 0.0380\n",
      "Epoch [9/10], Step [386/750], Loss: 0.0377\n",
      "Epoch [9/10], Step [387/750], Loss: 0.0034\n",
      "Epoch [9/10], Step [388/750], Loss: 0.0226\n",
      "Epoch [9/10], Step [389/750], Loss: 0.0154\n",
      "Epoch [9/10], Step [390/750], Loss: 0.0451\n",
      "Epoch [9/10], Step [391/750], Loss: 0.0403\n",
      "Epoch [9/10], Step [392/750], Loss: 0.0614\n",
      "Epoch [9/10], Step [393/750], Loss: 0.0302\n",
      "Epoch [9/10], Step [394/750], Loss: 0.1859\n",
      "Epoch [9/10], Step [395/750], Loss: 0.1009\n",
      "Epoch [9/10], Step [396/750], Loss: 0.0614\n",
      "Epoch [9/10], Step [397/750], Loss: 0.0903\n",
      "Epoch [9/10], Step [398/750], Loss: 0.0948\n",
      "Epoch [9/10], Step [399/750], Loss: 0.0985\n",
      "Epoch [9/10], Step [400/750], Loss: 0.0837\n",
      "Epoch [9/10], Step [401/750], Loss: 0.0122\n",
      "Epoch [9/10], Step [402/750], Loss: 0.0982\n",
      "Epoch [9/10], Step [403/750], Loss: 0.0940\n",
      "Epoch [9/10], Step [404/750], Loss: 0.1568\n",
      "Epoch [9/10], Step [405/750], Loss: 0.0398\n",
      "Epoch [9/10], Step [406/750], Loss: 0.0621\n",
      "Epoch [9/10], Step [407/750], Loss: 0.0509\n",
      "Epoch [9/10], Step [408/750], Loss: 0.0223\n",
      "Epoch [9/10], Step [409/750], Loss: 0.0241\n",
      "Epoch [9/10], Step [410/750], Loss: 0.0266\n",
      "Epoch [9/10], Step [411/750], Loss: 0.0339\n",
      "Epoch [9/10], Step [412/750], Loss: 0.0264\n",
      "Epoch [9/10], Step [413/750], Loss: 0.0655\n",
      "Epoch [9/10], Step [414/750], Loss: 0.0309\n",
      "Epoch [9/10], Step [415/750], Loss: 0.0520\n",
      "Epoch [9/10], Step [416/750], Loss: 0.0296\n",
      "Epoch [9/10], Step [417/750], Loss: 0.0283\n",
      "Epoch [9/10], Step [418/750], Loss: 0.0376\n",
      "Epoch [9/10], Step [419/750], Loss: 0.1772\n",
      "Epoch [9/10], Step [420/750], Loss: 0.0739\n",
      "Epoch [9/10], Step [421/750], Loss: 0.1485\n",
      "Epoch [9/10], Step [422/750], Loss: 0.0491\n",
      "Epoch [9/10], Step [423/750], Loss: 0.0117\n",
      "Epoch [9/10], Step [424/750], Loss: 0.0739\n",
      "Epoch [9/10], Step [425/750], Loss: 0.0257\n",
      "Epoch [9/10], Step [426/750], Loss: 0.0299\n",
      "Epoch [9/10], Step [427/750], Loss: 0.0339\n",
      "Epoch [9/10], Step [428/750], Loss: 0.0155\n",
      "Epoch [9/10], Step [429/750], Loss: 0.0763\n",
      "Epoch [9/10], Step [430/750], Loss: 0.0062\n",
      "Epoch [9/10], Step [431/750], Loss: 0.1731\n",
      "Epoch [9/10], Step [432/750], Loss: 0.0032\n",
      "Epoch [9/10], Step [433/750], Loss: 0.0127\n",
      "Epoch [9/10], Step [434/750], Loss: 0.2081\n",
      "Epoch [9/10], Step [435/750], Loss: 0.0505\n",
      "Epoch [9/10], Step [436/750], Loss: 0.0762\n",
      "Epoch [9/10], Step [437/750], Loss: 0.0125\n",
      "Epoch [9/10], Step [438/750], Loss: 0.0023\n",
      "Epoch [9/10], Step [439/750], Loss: 0.0450\n",
      "Epoch [9/10], Step [440/750], Loss: 0.0889\n",
      "Epoch [9/10], Step [441/750], Loss: 0.0144\n",
      "Epoch [9/10], Step [442/750], Loss: 0.0135\n",
      "Epoch [9/10], Step [443/750], Loss: 0.0473\n",
      "Epoch [9/10], Step [444/750], Loss: 0.0461\n",
      "Epoch [9/10], Step [445/750], Loss: 0.0315\n",
      "Epoch [9/10], Step [446/750], Loss: 0.0680\n",
      "Epoch [9/10], Step [447/750], Loss: 0.0120\n",
      "Epoch [9/10], Step [448/750], Loss: 0.0790\n",
      "Epoch [9/10], Step [449/750], Loss: 0.0101\n",
      "Epoch [9/10], Step [450/750], Loss: 0.0816\n",
      "Epoch [9/10], Step [451/750], Loss: 0.0194\n",
      "Epoch [9/10], Step [452/750], Loss: 0.1072\n",
      "Epoch [9/10], Step [453/750], Loss: 0.1072\n",
      "Epoch [9/10], Step [454/750], Loss: 0.0858\n",
      "Epoch [9/10], Step [455/750], Loss: 0.0266\n",
      "Epoch [9/10], Step [456/750], Loss: 0.0341\n",
      "Epoch [9/10], Step [457/750], Loss: 0.1079\n",
      "Epoch [9/10], Step [458/750], Loss: 0.0555\n",
      "Epoch [9/10], Step [459/750], Loss: 0.0494\n",
      "Epoch [9/10], Step [460/750], Loss: 0.0931\n",
      "Epoch [9/10], Step [461/750], Loss: 0.0174\n",
      "Epoch [9/10], Step [462/750], Loss: 0.0383\n",
      "Epoch [9/10], Step [463/750], Loss: 0.0587\n",
      "Epoch [9/10], Step [464/750], Loss: 0.0939\n",
      "Epoch [9/10], Step [465/750], Loss: 0.1008\n",
      "Epoch [9/10], Step [466/750], Loss: 0.1171\n",
      "Epoch [9/10], Step [467/750], Loss: 0.0841\n",
      "Epoch [9/10], Step [468/750], Loss: 0.0346\n",
      "Epoch [9/10], Step [469/750], Loss: 0.1396\n",
      "Epoch [9/10], Step [470/750], Loss: 0.0303\n",
      "Epoch [9/10], Step [471/750], Loss: 0.0511\n",
      "Epoch [9/10], Step [472/750], Loss: 0.0584\n",
      "Epoch [9/10], Step [473/750], Loss: 0.0181\n",
      "Epoch [9/10], Step [474/750], Loss: 0.0586\n",
      "Epoch [9/10], Step [475/750], Loss: 0.0229\n",
      "Epoch [9/10], Step [476/750], Loss: 0.0142\n",
      "Epoch [9/10], Step [477/750], Loss: 0.0652\n",
      "Epoch [9/10], Step [478/750], Loss: 0.0481\n",
      "Epoch [9/10], Step [479/750], Loss: 0.1716\n",
      "Epoch [9/10], Step [480/750], Loss: 0.0060\n",
      "Epoch [9/10], Step [481/750], Loss: 0.0891\n",
      "Epoch [9/10], Step [482/750], Loss: 0.0218\n",
      "Epoch [9/10], Step [483/750], Loss: 0.0616\n",
      "Epoch [9/10], Step [484/750], Loss: 0.0578\n",
      "Epoch [9/10], Step [485/750], Loss: 0.0297\n",
      "Epoch [9/10], Step [486/750], Loss: 0.1211\n",
      "Epoch [9/10], Step [487/750], Loss: 0.0884\n",
      "Epoch [9/10], Step [488/750], Loss: 0.0759\n",
      "Epoch [9/10], Step [489/750], Loss: 0.0755\n",
      "Epoch [9/10], Step [490/750], Loss: 0.0918\n",
      "Epoch [9/10], Step [491/750], Loss: 0.0839\n",
      "Epoch [9/10], Step [492/750], Loss: 0.0735\n",
      "Epoch [9/10], Step [493/750], Loss: 0.0835\n",
      "Epoch [9/10], Step [494/750], Loss: 0.1175\n",
      "Epoch [9/10], Step [495/750], Loss: 0.0588\n",
      "Epoch [9/10], Step [496/750], Loss: 0.0901\n",
      "Epoch [9/10], Step [497/750], Loss: 0.0079\n",
      "Epoch [9/10], Step [498/750], Loss: 0.0975\n",
      "Epoch [9/10], Step [499/750], Loss: 0.1064\n",
      "Epoch [9/10], Step [500/750], Loss: 0.0912\n",
      "Epoch [9/10], Step [501/750], Loss: 0.0300\n",
      "Epoch [9/10], Step [502/750], Loss: 0.0475\n",
      "Epoch [9/10], Step [503/750], Loss: 0.0304\n",
      "Epoch [9/10], Step [504/750], Loss: 0.0915\n",
      "Epoch [9/10], Step [505/750], Loss: 0.0246\n",
      "Epoch [9/10], Step [506/750], Loss: 0.0445\n",
      "Epoch [9/10], Step [507/750], Loss: 0.0462\n",
      "Epoch [9/10], Step [508/750], Loss: 0.0454\n",
      "Epoch [9/10], Step [509/750], Loss: 0.0550\n",
      "Epoch [9/10], Step [510/750], Loss: 0.1030\n",
      "Epoch [9/10], Step [511/750], Loss: 0.0626\n",
      "Epoch [9/10], Step [512/750], Loss: 0.0522\n",
      "Epoch [9/10], Step [513/750], Loss: 0.0203\n",
      "Epoch [9/10], Step [514/750], Loss: 0.0715\n",
      "Epoch [9/10], Step [515/750], Loss: 0.0484\n",
      "Epoch [9/10], Step [516/750], Loss: 0.1097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [517/750], Loss: 0.0216\n",
      "Epoch [9/10], Step [518/750], Loss: 0.0424\n",
      "Epoch [9/10], Step [519/750], Loss: 0.0041\n",
      "Epoch [9/10], Step [520/750], Loss: 0.0606\n",
      "Epoch [9/10], Step [521/750], Loss: 0.1542\n",
      "Epoch [9/10], Step [522/750], Loss: 0.1264\n",
      "Epoch [9/10], Step [523/750], Loss: 0.0154\n",
      "Epoch [9/10], Step [524/750], Loss: 0.0401\n",
      "Epoch [9/10], Step [525/750], Loss: 0.0090\n",
      "Epoch [9/10], Step [526/750], Loss: 0.0625\n",
      "Epoch [9/10], Step [527/750], Loss: 0.0812\n",
      "Epoch [9/10], Step [528/750], Loss: 0.0123\n",
      "Epoch [9/10], Step [529/750], Loss: 0.0780\n",
      "Epoch [9/10], Step [530/750], Loss: 0.0838\n",
      "Epoch [9/10], Step [531/750], Loss: 0.0899\n",
      "Epoch [9/10], Step [532/750], Loss: 0.0404\n",
      "Epoch [9/10], Step [533/750], Loss: 0.0306\n",
      "Epoch [9/10], Step [534/750], Loss: 0.0346\n",
      "Epoch [9/10], Step [535/750], Loss: 0.0353\n",
      "Epoch [9/10], Step [536/750], Loss: 0.0789\n",
      "Epoch [9/10], Step [537/750], Loss: 0.0486\n",
      "Epoch [9/10], Step [538/750], Loss: 0.1418\n",
      "Epoch [9/10], Step [539/750], Loss: 0.0858\n",
      "Epoch [9/10], Step [540/750], Loss: 0.1587\n",
      "Epoch [9/10], Step [541/750], Loss: 0.0247\n",
      "Epoch [9/10], Step [542/750], Loss: 0.0919\n",
      "Epoch [9/10], Step [543/750], Loss: 0.0894\n",
      "Epoch [9/10], Step [544/750], Loss: 0.1235\n",
      "Epoch [9/10], Step [545/750], Loss: 0.1195\n",
      "Epoch [9/10], Step [546/750], Loss: 0.1126\n",
      "Epoch [9/10], Step [547/750], Loss: 0.0466\n",
      "Epoch [9/10], Step [548/750], Loss: 0.0417\n",
      "Epoch [9/10], Step [549/750], Loss: 0.0824\n",
      "Epoch [9/10], Step [550/750], Loss: 0.0230\n",
      "Epoch [9/10], Step [551/750], Loss: 0.1073\n",
      "Epoch [9/10], Step [552/750], Loss: 0.0605\n",
      "Epoch [9/10], Step [553/750], Loss: 0.0433\n",
      "Epoch [9/10], Step [554/750], Loss: 0.0056\n",
      "Epoch [9/10], Step [555/750], Loss: 0.0899\n",
      "Epoch [9/10], Step [556/750], Loss: 0.1712\n",
      "Epoch [9/10], Step [557/750], Loss: 0.0664\n",
      "Epoch [9/10], Step [558/750], Loss: 0.0928\n",
      "Epoch [9/10], Step [559/750], Loss: 0.0192\n",
      "Epoch [9/10], Step [560/750], Loss: 0.1246\n",
      "Epoch [9/10], Step [561/750], Loss: 0.0797\n",
      "Epoch [9/10], Step [562/750], Loss: 0.0410\n",
      "Epoch [9/10], Step [563/750], Loss: 0.0303\n",
      "Epoch [9/10], Step [564/750], Loss: 0.0055\n",
      "Epoch [9/10], Step [565/750], Loss: 0.0604\n",
      "Epoch [9/10], Step [566/750], Loss: 0.0573\n",
      "Epoch [9/10], Step [567/750], Loss: 0.0242\n",
      "Epoch [9/10], Step [568/750], Loss: 0.1401\n",
      "Epoch [9/10], Step [569/750], Loss: 0.0832\n",
      "Epoch [9/10], Step [570/750], Loss: 0.0740\n",
      "Epoch [9/10], Step [571/750], Loss: 0.0350\n",
      "Epoch [9/10], Step [572/750], Loss: 0.0098\n",
      "Epoch [9/10], Step [573/750], Loss: 0.0105\n",
      "Epoch [9/10], Step [574/750], Loss: 0.0105\n",
      "Epoch [9/10], Step [575/750], Loss: 0.0780\n",
      "Epoch [9/10], Step [576/750], Loss: 0.0508\n",
      "Epoch [9/10], Step [577/750], Loss: 0.0098\n",
      "Epoch [9/10], Step [578/750], Loss: 0.0063\n",
      "Epoch [9/10], Step [579/750], Loss: 0.1222\n",
      "Epoch [9/10], Step [580/750], Loss: 0.0098\n",
      "Epoch [9/10], Step [581/750], Loss: 0.0269\n",
      "Epoch [9/10], Step [582/750], Loss: 0.2138\n",
      "Epoch [9/10], Step [583/750], Loss: 0.1153\n",
      "Epoch [9/10], Step [584/750], Loss: 0.0776\n",
      "Epoch [9/10], Step [585/750], Loss: 0.0504\n",
      "Epoch [9/10], Step [586/750], Loss: 0.0364\n",
      "Epoch [9/10], Step [587/750], Loss: 0.1632\n",
      "Epoch [9/10], Step [588/750], Loss: 0.0566\n",
      "Epoch [9/10], Step [589/750], Loss: 0.0391\n",
      "Epoch [9/10], Step [590/750], Loss: 0.0763\n",
      "Epoch [9/10], Step [591/750], Loss: 0.0748\n",
      "Epoch [9/10], Step [592/750], Loss: 0.0213\n",
      "Epoch [9/10], Step [593/750], Loss: 0.0193\n",
      "Epoch [9/10], Step [594/750], Loss: 0.0244\n",
      "Epoch [9/10], Step [595/750], Loss: 0.0527\n",
      "Epoch [9/10], Step [596/750], Loss: 0.2378\n",
      "Epoch [9/10], Step [597/750], Loss: 0.0584\n",
      "Epoch [9/10], Step [598/750], Loss: 0.0349\n",
      "Epoch [9/10], Step [599/750], Loss: 0.0236\n",
      "Epoch [9/10], Step [600/750], Loss: 0.0414\n",
      "Epoch [9/10], Step [601/750], Loss: 0.0157\n",
      "Epoch [9/10], Step [602/750], Loss: 0.0340\n",
      "Epoch [9/10], Step [603/750], Loss: 0.0233\n",
      "Epoch [9/10], Step [604/750], Loss: 0.0381\n",
      "Epoch [9/10], Step [605/750], Loss: 0.1550\n",
      "Epoch [9/10], Step [606/750], Loss: 0.0228\n",
      "Epoch [9/10], Step [607/750], Loss: 0.0412\n",
      "Epoch [9/10], Step [608/750], Loss: 0.1219\n",
      "Epoch [9/10], Step [609/750], Loss: 0.0189\n",
      "Epoch [9/10], Step [610/750], Loss: 0.0377\n",
      "Epoch [9/10], Step [611/750], Loss: 0.0586\n",
      "Epoch [9/10], Step [612/750], Loss: 0.1042\n",
      "Epoch [9/10], Step [613/750], Loss: 0.0948\n",
      "Epoch [9/10], Step [614/750], Loss: 0.0551\n",
      "Epoch [9/10], Step [615/750], Loss: 0.0276\n",
      "Epoch [9/10], Step [616/750], Loss: 0.0350\n",
      "Epoch [9/10], Step [617/750], Loss: 0.1077\n",
      "Epoch [9/10], Step [618/750], Loss: 0.0121\n",
      "Epoch [9/10], Step [619/750], Loss: 0.0936\n",
      "Epoch [9/10], Step [620/750], Loss: 0.0570\n",
      "Epoch [9/10], Step [621/750], Loss: 0.0291\n",
      "Epoch [9/10], Step [622/750], Loss: 0.0236\n",
      "Epoch [9/10], Step [623/750], Loss: 0.0476\n",
      "Epoch [9/10], Step [624/750], Loss: 0.0686\n",
      "Epoch [9/10], Step [625/750], Loss: 0.0166\n",
      "Epoch [9/10], Step [626/750], Loss: 0.1787\n",
      "Epoch [9/10], Step [627/750], Loss: 0.0698\n",
      "Epoch [9/10], Step [628/750], Loss: 0.1192\n",
      "Epoch [9/10], Step [629/750], Loss: 0.0538\n",
      "Epoch [9/10], Step [630/750], Loss: 0.0947\n",
      "Epoch [9/10], Step [631/750], Loss: 0.0460\n",
      "Epoch [9/10], Step [632/750], Loss: 0.0072\n",
      "Epoch [9/10], Step [633/750], Loss: 0.1701\n",
      "Epoch [9/10], Step [634/750], Loss: 0.0402\n",
      "Epoch [9/10], Step [635/750], Loss: 0.1568\n",
      "Epoch [9/10], Step [636/750], Loss: 0.0445\n",
      "Epoch [9/10], Step [637/750], Loss: 0.1509\n",
      "Epoch [9/10], Step [638/750], Loss: 0.1167\n",
      "Epoch [9/10], Step [639/750], Loss: 0.1565\n",
      "Epoch [9/10], Step [640/750], Loss: 0.0417\n",
      "Epoch [9/10], Step [641/750], Loss: 0.0631\n",
      "Epoch [9/10], Step [642/750], Loss: 0.1015\n",
      "Epoch [9/10], Step [643/750], Loss: 0.0164\n",
      "Epoch [9/10], Step [644/750], Loss: 0.0221\n",
      "Epoch [9/10], Step [645/750], Loss: 0.0461\n",
      "Epoch [9/10], Step [646/750], Loss: 0.0538\n",
      "Epoch [9/10], Step [647/750], Loss: 0.0208\n",
      "Epoch [9/10], Step [648/750], Loss: 0.0208\n",
      "Epoch [9/10], Step [649/750], Loss: 0.0898\n",
      "Epoch [9/10], Step [650/750], Loss: 0.0542\n",
      "Epoch [9/10], Step [651/750], Loss: 0.0350\n",
      "Epoch [9/10], Step [652/750], Loss: 0.0444\n",
      "Epoch [9/10], Step [653/750], Loss: 0.0506\n",
      "Epoch [9/10], Step [654/750], Loss: 0.0552\n",
      "Epoch [9/10], Step [655/750], Loss: 0.0568\n",
      "Epoch [9/10], Step [656/750], Loss: 0.0603\n",
      "Epoch [9/10], Step [657/750], Loss: 0.0351\n",
      "Epoch [9/10], Step [658/750], Loss: 0.1071\n",
      "Epoch [9/10], Step [659/750], Loss: 0.0149\n",
      "Epoch [9/10], Step [660/750], Loss: 0.1645\n",
      "Epoch [9/10], Step [661/750], Loss: 0.1068\n",
      "Epoch [9/10], Step [662/750], Loss: 0.0599\n",
      "Epoch [9/10], Step [663/750], Loss: 0.1859\n",
      "Epoch [9/10], Step [664/750], Loss: 0.0311\n",
      "Epoch [9/10], Step [665/750], Loss: 0.0535\n",
      "Epoch [9/10], Step [666/750], Loss: 0.0408\n",
      "Epoch [9/10], Step [667/750], Loss: 0.0694\n",
      "Epoch [9/10], Step [668/750], Loss: 0.0397\n",
      "Epoch [9/10], Step [669/750], Loss: 0.0497\n",
      "Epoch [9/10], Step [670/750], Loss: 0.0460\n",
      "Epoch [9/10], Step [671/750], Loss: 0.1708\n",
      "Epoch [9/10], Step [672/750], Loss: 0.0831\n",
      "Epoch [9/10], Step [673/750], Loss: 0.0234\n",
      "Epoch [9/10], Step [674/750], Loss: 0.0261\n",
      "Epoch [9/10], Step [675/750], Loss: 0.0342\n",
      "Epoch [9/10], Step [676/750], Loss: 0.0346\n",
      "Epoch [9/10], Step [677/750], Loss: 0.0199\n",
      "Epoch [9/10], Step [678/750], Loss: 0.0346\n",
      "Epoch [9/10], Step [679/750], Loss: 0.0615\n",
      "Epoch [9/10], Step [680/750], Loss: 0.1896\n",
      "Epoch [9/10], Step [681/750], Loss: 0.0927\n",
      "Epoch [9/10], Step [682/750], Loss: 0.0040\n",
      "Epoch [9/10], Step [683/750], Loss: 0.0373\n",
      "Epoch [9/10], Step [684/750], Loss: 0.0949\n",
      "Epoch [9/10], Step [685/750], Loss: 0.1871\n",
      "Epoch [9/10], Step [686/750], Loss: 0.0675\n",
      "Epoch [9/10], Step [687/750], Loss: 0.0694\n",
      "Epoch [9/10], Step [688/750], Loss: 0.0921\n",
      "Epoch [9/10], Step [689/750], Loss: 0.1149\n",
      "Epoch [9/10], Step [690/750], Loss: 0.1216\n",
      "Epoch [9/10], Step [691/750], Loss: 0.0486\n",
      "Epoch [9/10], Step [692/750], Loss: 0.0439\n",
      "Epoch [9/10], Step [693/750], Loss: 0.0818\n",
      "Epoch [9/10], Step [694/750], Loss: 0.1201\n",
      "Epoch [9/10], Step [695/750], Loss: 0.0787\n",
      "Epoch [9/10], Step [696/750], Loss: 0.0615\n",
      "Epoch [9/10], Step [697/750], Loss: 0.0364\n",
      "Epoch [9/10], Step [698/750], Loss: 0.0152\n",
      "Epoch [9/10], Step [699/750], Loss: 0.0260\n",
      "Epoch [9/10], Step [700/750], Loss: 0.0076\n",
      "Epoch [9/10], Step [701/750], Loss: 0.0948\n",
      "Epoch [9/10], Step [702/750], Loss: 0.1465\n",
      "Epoch [9/10], Step [703/750], Loss: 0.0247\n",
      "Epoch [9/10], Step [704/750], Loss: 0.0242\n",
      "Epoch [9/10], Step [705/750], Loss: 0.0509\n",
      "Epoch [9/10], Step [706/750], Loss: 0.1058\n",
      "Epoch [9/10], Step [707/750], Loss: 0.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [708/750], Loss: 0.0358\n",
      "Epoch [9/10], Step [709/750], Loss: 0.0150\n",
      "Epoch [9/10], Step [710/750], Loss: 0.0467\n",
      "Epoch [9/10], Step [711/750], Loss: 0.0607\n",
      "Epoch [9/10], Step [712/750], Loss: 0.0483\n",
      "Epoch [9/10], Step [713/750], Loss: 0.0921\n",
      "Epoch [9/10], Step [714/750], Loss: 0.1217\n",
      "Epoch [9/10], Step [715/750], Loss: 0.0826\n",
      "Epoch [9/10], Step [716/750], Loss: 0.0284\n",
      "Epoch [9/10], Step [717/750], Loss: 0.0772\n",
      "Epoch [9/10], Step [718/750], Loss: 0.0681\n",
      "Epoch [9/10], Step [719/750], Loss: 0.0438\n",
      "Epoch [9/10], Step [720/750], Loss: 0.0695\n",
      "Epoch [9/10], Step [721/750], Loss: 0.0512\n",
      "Epoch [9/10], Step [722/750], Loss: 0.0486\n",
      "Epoch [9/10], Step [723/750], Loss: 0.0650\n",
      "Epoch [9/10], Step [724/750], Loss: 0.0242\n",
      "Epoch [9/10], Step [725/750], Loss: 0.1175\n",
      "Epoch [9/10], Step [726/750], Loss: 0.0112\n",
      "Epoch [9/10], Step [727/750], Loss: 0.0180\n",
      "Epoch [9/10], Step [728/750], Loss: 0.1572\n",
      "Epoch [9/10], Step [729/750], Loss: 0.0324\n",
      "Epoch [9/10], Step [730/750], Loss: 0.0077\n",
      "Epoch [9/10], Step [731/750], Loss: 0.0832\n",
      "Epoch [9/10], Step [732/750], Loss: 0.0450\n",
      "Epoch [9/10], Step [733/750], Loss: 0.0846\n",
      "Epoch [9/10], Step [734/750], Loss: 0.0230\n",
      "Epoch [9/10], Step [735/750], Loss: 0.1161\n",
      "Epoch [9/10], Step [736/750], Loss: 0.0781\n",
      "Epoch [9/10], Step [737/750], Loss: 0.0414\n",
      "Epoch [9/10], Step [738/750], Loss: 0.0445\n",
      "Epoch [9/10], Step [739/750], Loss: 0.0108\n",
      "Epoch [9/10], Step [740/750], Loss: 0.0833\n",
      "Epoch [9/10], Step [741/750], Loss: 0.0446\n",
      "Epoch [9/10], Step [742/750], Loss: 0.0183\n",
      "Epoch [9/10], Step [743/750], Loss: 0.0415\n",
      "Epoch [9/10], Step [744/750], Loss: 0.0126\n",
      "Epoch [9/10], Step [745/750], Loss: 0.0054\n",
      "Epoch [9/10], Step [746/750], Loss: 0.0306\n",
      "Epoch [9/10], Step [747/750], Loss: 0.0699\n",
      "Epoch [9/10], Step [748/750], Loss: 0.0207\n",
      "Epoch [9/10], Step [749/750], Loss: 0.0047\n",
      "Epoch [9/10], Step [750/750], Loss: 0.0414\n",
      "\n",
      "\n",
      "Epoch [10/10], Step [1/750], Loss: 0.0338\n",
      "Epoch [10/10], Step [2/750], Loss: 0.0061\n",
      "Epoch [10/10], Step [3/750], Loss: 0.0079\n",
      "Epoch [10/10], Step [4/750], Loss: 0.0309\n",
      "Epoch [10/10], Step [5/750], Loss: 0.0238\n",
      "Epoch [10/10], Step [6/750], Loss: 0.0883\n",
      "Epoch [10/10], Step [7/750], Loss: 0.0127\n",
      "Epoch [10/10], Step [8/750], Loss: 0.0101\n",
      "Epoch [10/10], Step [9/750], Loss: 0.1226\n",
      "Epoch [10/10], Step [10/750], Loss: 0.0068\n",
      "Epoch [10/10], Step [11/750], Loss: 0.0324\n",
      "Epoch [10/10], Step [12/750], Loss: 0.0876\n",
      "Epoch [10/10], Step [13/750], Loss: 0.0645\n",
      "Epoch [10/10], Step [14/750], Loss: 0.0873\n",
      "Epoch [10/10], Step [15/750], Loss: 0.0458\n",
      "Epoch [10/10], Step [16/750], Loss: 0.0413\n",
      "Epoch [10/10], Step [17/750], Loss: 0.0485\n",
      "Epoch [10/10], Step [18/750], Loss: 0.0360\n",
      "Epoch [10/10], Step [19/750], Loss: 0.0285\n",
      "Epoch [10/10], Step [20/750], Loss: 0.0666\n",
      "Epoch [10/10], Step [21/750], Loss: 0.0143\n",
      "Epoch [10/10], Step [22/750], Loss: 0.0450\n",
      "Epoch [10/10], Step [23/750], Loss: 0.0070\n",
      "Epoch [10/10], Step [24/750], Loss: 0.0237\n",
      "Epoch [10/10], Step [25/750], Loss: 0.0187\n",
      "Epoch [10/10], Step [26/750], Loss: 0.0795\n",
      "Epoch [10/10], Step [27/750], Loss: 0.1061\n",
      "Epoch [10/10], Step [28/750], Loss: 0.0365\n",
      "Epoch [10/10], Step [29/750], Loss: 0.0269\n",
      "Epoch [10/10], Step [30/750], Loss: 0.0661\n",
      "Epoch [10/10], Step [31/750], Loss: 0.0790\n",
      "Epoch [10/10], Step [32/750], Loss: 0.0538\n",
      "Epoch [10/10], Step [33/750], Loss: 0.0235\n",
      "Epoch [10/10], Step [34/750], Loss: 0.1729\n",
      "Epoch [10/10], Step [35/750], Loss: 0.0075\n",
      "Epoch [10/10], Step [36/750], Loss: 0.2074\n",
      "Epoch [10/10], Step [37/750], Loss: 0.0680\n",
      "Epoch [10/10], Step [38/750], Loss: 0.0716\n",
      "Epoch [10/10], Step [39/750], Loss: 0.1070\n",
      "Epoch [10/10], Step [40/750], Loss: 0.0733\n",
      "Epoch [10/10], Step [41/750], Loss: 0.0250\n",
      "Epoch [10/10], Step [42/750], Loss: 0.1282\n",
      "Epoch [10/10], Step [43/750], Loss: 0.0830\n",
      "Epoch [10/10], Step [44/750], Loss: 0.0406\n",
      "Epoch [10/10], Step [45/750], Loss: 0.0587\n",
      "Epoch [10/10], Step [46/750], Loss: 0.0901\n",
      "Epoch [10/10], Step [47/750], Loss: 0.0261\n",
      "Epoch [10/10], Step [48/750], Loss: 0.0716\n",
      "Epoch [10/10], Step [49/750], Loss: 0.0612\n",
      "Epoch [10/10], Step [50/750], Loss: 0.0338\n",
      "Epoch [10/10], Step [51/750], Loss: 0.0224\n",
      "Epoch [10/10], Step [52/750], Loss: 0.1162\n",
      "Epoch [10/10], Step [53/750], Loss: 0.0098\n",
      "Epoch [10/10], Step [54/750], Loss: 0.0773\n",
      "Epoch [10/10], Step [55/750], Loss: 0.0389\n",
      "Epoch [10/10], Step [56/750], Loss: 0.0558\n",
      "Epoch [10/10], Step [57/750], Loss: 0.0195\n",
      "Epoch [10/10], Step [58/750], Loss: 0.0631\n",
      "Epoch [10/10], Step [59/750], Loss: 0.0582\n",
      "Epoch [10/10], Step [60/750], Loss: 0.1387\n",
      "Epoch [10/10], Step [61/750], Loss: 0.0101\n",
      "Epoch [10/10], Step [62/750], Loss: 0.0264\n",
      "Epoch [10/10], Step [63/750], Loss: 0.0361\n",
      "Epoch [10/10], Step [64/750], Loss: 0.0102\n",
      "Epoch [10/10], Step [65/750], Loss: 0.0293\n",
      "Epoch [10/10], Step [66/750], Loss: 0.0897\n",
      "Epoch [10/10], Step [67/750], Loss: 0.0115\n",
      "Epoch [10/10], Step [68/750], Loss: 0.0112\n",
      "Epoch [10/10], Step [69/750], Loss: 0.0191\n",
      "Epoch [10/10], Step [70/750], Loss: 0.0667\n",
      "Epoch [10/10], Step [71/750], Loss: 0.0793\n",
      "Epoch [10/10], Step [72/750], Loss: 0.0051\n",
      "Epoch [10/10], Step [73/750], Loss: 0.0276\n",
      "Epoch [10/10], Step [74/750], Loss: 0.0619\n",
      "Epoch [10/10], Step [75/750], Loss: 0.1727\n",
      "Epoch [10/10], Step [76/750], Loss: 0.0648\n",
      "Epoch [10/10], Step [77/750], Loss: 0.0168\n",
      "Epoch [10/10], Step [78/750], Loss: 0.0219\n",
      "Epoch [10/10], Step [79/750], Loss: 0.0214\n",
      "Epoch [10/10], Step [80/750], Loss: 0.0291\n",
      "Epoch [10/10], Step [81/750], Loss: 0.0241\n",
      "Epoch [10/10], Step [82/750], Loss: 0.0339\n",
      "Epoch [10/10], Step [83/750], Loss: 0.0586\n",
      "Epoch [10/10], Step [84/750], Loss: 0.0348\n",
      "Epoch [10/10], Step [85/750], Loss: 0.0187\n",
      "Epoch [10/10], Step [86/750], Loss: 0.0953\n",
      "Epoch [10/10], Step [87/750], Loss: 0.0519\n",
      "Epoch [10/10], Step [88/750], Loss: 0.0293\n",
      "Epoch [10/10], Step [89/750], Loss: 0.0153\n",
      "Epoch [10/10], Step [90/750], Loss: 0.0081\n",
      "Epoch [10/10], Step [91/750], Loss: 0.0203\n",
      "Epoch [10/10], Step [92/750], Loss: 0.0671\n",
      "Epoch [10/10], Step [93/750], Loss: 0.0829\n",
      "Epoch [10/10], Step [94/750], Loss: 0.0339\n",
      "Epoch [10/10], Step [95/750], Loss: 0.0239\n",
      "Epoch [10/10], Step [96/750], Loss: 0.0588\n",
      "Epoch [10/10], Step [97/750], Loss: 0.1067\n",
      "Epoch [10/10], Step [98/750], Loss: 0.0658\n",
      "Epoch [10/10], Step [99/750], Loss: 0.0736\n",
      "Epoch [10/10], Step [100/750], Loss: 0.0099\n",
      "Epoch [10/10], Step [101/750], Loss: 0.0409\n",
      "Epoch [10/10], Step [102/750], Loss: 0.0916\n",
      "Epoch [10/10], Step [103/750], Loss: 0.0785\n",
      "Epoch [10/10], Step [104/750], Loss: 0.0256\n",
      "Epoch [10/10], Step [105/750], Loss: 0.0084\n",
      "Epoch [10/10], Step [106/750], Loss: 0.0095\n",
      "Epoch [10/10], Step [107/750], Loss: 0.0841\n",
      "Epoch [10/10], Step [108/750], Loss: 0.0340\n",
      "Epoch [10/10], Step [109/750], Loss: 0.0086\n",
      "Epoch [10/10], Step [110/750], Loss: 0.0439\n",
      "Epoch [10/10], Step [111/750], Loss: 0.0267\n",
      "Epoch [10/10], Step [112/750], Loss: 0.0722\n",
      "Epoch [10/10], Step [113/750], Loss: 0.0620\n",
      "Epoch [10/10], Step [114/750], Loss: 0.1600\n",
      "Epoch [10/10], Step [115/750], Loss: 0.0051\n",
      "Epoch [10/10], Step [116/750], Loss: 0.0057\n",
      "Epoch [10/10], Step [117/750], Loss: 0.0714\n",
      "Epoch [10/10], Step [118/750], Loss: 0.0097\n",
      "Epoch [10/10], Step [119/750], Loss: 0.0332\n",
      "Epoch [10/10], Step [120/750], Loss: 0.0281\n",
      "Epoch [10/10], Step [121/750], Loss: 0.0186\n",
      "Epoch [10/10], Step [122/750], Loss: 0.0858\n",
      "Epoch [10/10], Step [123/750], Loss: 0.0274\n",
      "Epoch [10/10], Step [124/750], Loss: 0.0596\n",
      "Epoch [10/10], Step [125/750], Loss: 0.0394\n",
      "Epoch [10/10], Step [126/750], Loss: 0.0891\n",
      "Epoch [10/10], Step [127/750], Loss: 0.0955\n",
      "Epoch [10/10], Step [128/750], Loss: 0.1993\n",
      "Epoch [10/10], Step [129/750], Loss: 0.0209\n",
      "Epoch [10/10], Step [130/750], Loss: 0.0235\n",
      "Epoch [10/10], Step [131/750], Loss: 0.0145\n",
      "Epoch [10/10], Step [132/750], Loss: 0.0498\n",
      "Epoch [10/10], Step [133/750], Loss: 0.0229\n",
      "Epoch [10/10], Step [134/750], Loss: 0.1433\n",
      "Epoch [10/10], Step [135/750], Loss: 0.0502\n",
      "Epoch [10/10], Step [136/750], Loss: 0.0158\n",
      "Epoch [10/10], Step [137/750], Loss: 0.0656\n",
      "Epoch [10/10], Step [138/750], Loss: 0.0443\n",
      "Epoch [10/10], Step [139/750], Loss: 0.0670\n",
      "Epoch [10/10], Step [140/750], Loss: 0.0372\n",
      "Epoch [10/10], Step [141/750], Loss: 0.0189\n",
      "Epoch [10/10], Step [142/750], Loss: 0.0526\n",
      "Epoch [10/10], Step [143/750], Loss: 0.0307\n",
      "Epoch [10/10], Step [144/750], Loss: 0.0751\n",
      "Epoch [10/10], Step [145/750], Loss: 0.0687\n",
      "Epoch [10/10], Step [146/750], Loss: 0.0092\n",
      "Epoch [10/10], Step [147/750], Loss: 0.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [148/750], Loss: 0.0181\n",
      "Epoch [10/10], Step [149/750], Loss: 0.0954\n",
      "Epoch [10/10], Step [150/750], Loss: 0.0383\n",
      "Epoch [10/10], Step [151/750], Loss: 0.0920\n",
      "Epoch [10/10], Step [152/750], Loss: 0.0391\n",
      "Epoch [10/10], Step [153/750], Loss: 0.0311\n",
      "Epoch [10/10], Step [154/750], Loss: 0.0102\n",
      "Epoch [10/10], Step [155/750], Loss: 0.0527\n",
      "Epoch [10/10], Step [156/750], Loss: 0.0168\n",
      "Epoch [10/10], Step [157/750], Loss: 0.1112\n",
      "Epoch [10/10], Step [158/750], Loss: 0.0166\n",
      "Epoch [10/10], Step [159/750], Loss: 0.0247\n",
      "Epoch [10/10], Step [160/750], Loss: 0.0673\n",
      "Epoch [10/10], Step [161/750], Loss: 0.0336\n",
      "Epoch [10/10], Step [162/750], Loss: 0.0854\n",
      "Epoch [10/10], Step [163/750], Loss: 0.0528\n",
      "Epoch [10/10], Step [164/750], Loss: 0.0032\n",
      "Epoch [10/10], Step [165/750], Loss: 0.0176\n",
      "Epoch [10/10], Step [166/750], Loss: 0.1148\n",
      "Epoch [10/10], Step [167/750], Loss: 0.0154\n",
      "Epoch [10/10], Step [168/750], Loss: 0.0522\n",
      "Epoch [10/10], Step [169/750], Loss: 0.0438\n",
      "Epoch [10/10], Step [170/750], Loss: 0.0544\n",
      "Epoch [10/10], Step [171/750], Loss: 0.0594\n",
      "Epoch [10/10], Step [172/750], Loss: 0.0470\n",
      "Epoch [10/10], Step [173/750], Loss: 0.0953\n",
      "Epoch [10/10], Step [174/750], Loss: 0.0211\n",
      "Epoch [10/10], Step [175/750], Loss: 0.0257\n",
      "Epoch [10/10], Step [176/750], Loss: 0.0521\n",
      "Epoch [10/10], Step [177/750], Loss: 0.0400\n",
      "Epoch [10/10], Step [178/750], Loss: 0.0241\n",
      "Epoch [10/10], Step [179/750], Loss: 0.1085\n",
      "Epoch [10/10], Step [180/750], Loss: 0.1344\n",
      "Epoch [10/10], Step [181/750], Loss: 0.0736\n",
      "Epoch [10/10], Step [182/750], Loss: 0.0293\n",
      "Epoch [10/10], Step [183/750], Loss: 0.0175\n",
      "Epoch [10/10], Step [184/750], Loss: 0.0161\n",
      "Epoch [10/10], Step [185/750], Loss: 0.0240\n",
      "Epoch [10/10], Step [186/750], Loss: 0.0219\n",
      "Epoch [10/10], Step [187/750], Loss: 0.1180\n",
      "Epoch [10/10], Step [188/750], Loss: 0.0191\n",
      "Epoch [10/10], Step [189/750], Loss: 0.0498\n",
      "Epoch [10/10], Step [190/750], Loss: 0.0198\n",
      "Epoch [10/10], Step [191/750], Loss: 0.0639\n",
      "Epoch [10/10], Step [192/750], Loss: 0.0680\n",
      "Epoch [10/10], Step [193/750], Loss: 0.0215\n",
      "Epoch [10/10], Step [194/750], Loss: 0.0430\n",
      "Epoch [10/10], Step [195/750], Loss: 0.0678\n",
      "Epoch [10/10], Step [196/750], Loss: 0.0430\n",
      "Epoch [10/10], Step [197/750], Loss: 0.0699\n",
      "Epoch [10/10], Step [198/750], Loss: 0.0503\n",
      "Epoch [10/10], Step [199/750], Loss: 0.0154\n",
      "Epoch [10/10], Step [200/750], Loss: 0.0167\n",
      "Epoch [10/10], Step [201/750], Loss: 0.0123\n",
      "Epoch [10/10], Step [202/750], Loss: 0.0113\n",
      "Epoch [10/10], Step [203/750], Loss: 0.0707\n",
      "Epoch [10/10], Step [204/750], Loss: 0.0208\n",
      "Epoch [10/10], Step [205/750], Loss: 0.0301\n",
      "Epoch [10/10], Step [206/750], Loss: 0.0470\n",
      "Epoch [10/10], Step [207/750], Loss: 0.0658\n",
      "Epoch [10/10], Step [208/750], Loss: 0.0282\n",
      "Epoch [10/10], Step [209/750], Loss: 0.0342\n",
      "Epoch [10/10], Step [210/750], Loss: 0.0736\n",
      "Epoch [10/10], Step [211/750], Loss: 0.0180\n",
      "Epoch [10/10], Step [212/750], Loss: 0.0517\n",
      "Epoch [10/10], Step [213/750], Loss: 0.0810\n",
      "Epoch [10/10], Step [214/750], Loss: 0.1087\n",
      "Epoch [10/10], Step [215/750], Loss: 0.0883\n",
      "Epoch [10/10], Step [216/750], Loss: 0.0166\n",
      "Epoch [10/10], Step [217/750], Loss: 0.0233\n",
      "Epoch [10/10], Step [218/750], Loss: 0.0232\n",
      "Epoch [10/10], Step [219/750], Loss: 0.0150\n",
      "Epoch [10/10], Step [220/750], Loss: 0.1831\n",
      "Epoch [10/10], Step [221/750], Loss: 0.0238\n",
      "Epoch [10/10], Step [222/750], Loss: 0.0529\n",
      "Epoch [10/10], Step [223/750], Loss: 0.0058\n",
      "Epoch [10/10], Step [224/750], Loss: 0.0333\n",
      "Epoch [10/10], Step [225/750], Loss: 0.0895\n",
      "Epoch [10/10], Step [226/750], Loss: 0.0358\n",
      "Epoch [10/10], Step [227/750], Loss: 0.0156\n",
      "Epoch [10/10], Step [228/750], Loss: 0.1236\n",
      "Epoch [10/10], Step [229/750], Loss: 0.0342\n",
      "Epoch [10/10], Step [230/750], Loss: 0.0054\n",
      "Epoch [10/10], Step [231/750], Loss: 0.0976\n",
      "Epoch [10/10], Step [232/750], Loss: 0.2011\n",
      "Epoch [10/10], Step [233/750], Loss: 0.0456\n",
      "Epoch [10/10], Step [234/750], Loss: 0.0269\n",
      "Epoch [10/10], Step [235/750], Loss: 0.0505\n",
      "Epoch [10/10], Step [236/750], Loss: 0.0845\n",
      "Epoch [10/10], Step [237/750], Loss: 0.0589\n",
      "Epoch [10/10], Step [238/750], Loss: 0.0661\n",
      "Epoch [10/10], Step [239/750], Loss: 0.0965\n",
      "Epoch [10/10], Step [240/750], Loss: 0.0328\n",
      "Epoch [10/10], Step [241/750], Loss: 0.0628\n",
      "Epoch [10/10], Step [242/750], Loss: 0.0335\n",
      "Epoch [10/10], Step [243/750], Loss: 0.0131\n",
      "Epoch [10/10], Step [244/750], Loss: 0.0093\n",
      "Epoch [10/10], Step [245/750], Loss: 0.0373\n",
      "Epoch [10/10], Step [246/750], Loss: 0.0362\n",
      "Epoch [10/10], Step [247/750], Loss: 0.0704\n",
      "Epoch [10/10], Step [248/750], Loss: 0.0208\n",
      "Epoch [10/10], Step [249/750], Loss: 0.0884\n",
      "Epoch [10/10], Step [250/750], Loss: 0.0049\n",
      "Epoch [10/10], Step [251/750], Loss: 0.0261\n",
      "Epoch [10/10], Step [252/750], Loss: 0.0873\n",
      "Epoch [10/10], Step [253/750], Loss: 0.0696\n",
      "Epoch [10/10], Step [254/750], Loss: 0.1221\n",
      "Epoch [10/10], Step [255/750], Loss: 0.0429\n",
      "Epoch [10/10], Step [256/750], Loss: 0.0143\n",
      "Epoch [10/10], Step [257/750], Loss: 0.0033\n",
      "Epoch [10/10], Step [258/750], Loss: 0.0545\n",
      "Epoch [10/10], Step [259/750], Loss: 0.0361\n",
      "Epoch [10/10], Step [260/750], Loss: 0.0751\n",
      "Epoch [10/10], Step [261/750], Loss: 0.0320\n",
      "Epoch [10/10], Step [262/750], Loss: 0.0673\n",
      "Epoch [10/10], Step [263/750], Loss: 0.0206\n",
      "Epoch [10/10], Step [264/750], Loss: 0.0211\n",
      "Epoch [10/10], Step [265/750], Loss: 0.0193\n",
      "Epoch [10/10], Step [266/750], Loss: 0.1523\n",
      "Epoch [10/10], Step [267/750], Loss: 0.1127\n",
      "Epoch [10/10], Step [268/750], Loss: 0.0136\n",
      "Epoch [10/10], Step [269/750], Loss: 0.0694\n",
      "Epoch [10/10], Step [270/750], Loss: 0.0203\n",
      "Epoch [10/10], Step [271/750], Loss: 0.0426\n",
      "Epoch [10/10], Step [272/750], Loss: 0.0328\n",
      "Epoch [10/10], Step [273/750], Loss: 0.0462\n",
      "Epoch [10/10], Step [274/750], Loss: 0.0377\n",
      "Epoch [10/10], Step [275/750], Loss: 0.0568\n",
      "Epoch [10/10], Step [276/750], Loss: 0.0424\n",
      "Epoch [10/10], Step [277/750], Loss: 0.0106\n",
      "Epoch [10/10], Step [278/750], Loss: 0.0140\n",
      "Epoch [10/10], Step [279/750], Loss: 0.0208\n",
      "Epoch [10/10], Step [280/750], Loss: 0.0853\n",
      "Epoch [10/10], Step [281/750], Loss: 0.0193\n",
      "Epoch [10/10], Step [282/750], Loss: 0.0181\n",
      "Epoch [10/10], Step [283/750], Loss: 0.0437\n",
      "Epoch [10/10], Step [284/750], Loss: 0.0444\n",
      "Epoch [10/10], Step [285/750], Loss: 0.0265\n",
      "Epoch [10/10], Step [286/750], Loss: 0.0804\n",
      "Epoch [10/10], Step [287/750], Loss: 0.0288\n",
      "Epoch [10/10], Step [288/750], Loss: 0.0643\n",
      "Epoch [10/10], Step [289/750], Loss: 0.1656\n",
      "Epoch [10/10], Step [290/750], Loss: 0.1480\n",
      "Epoch [10/10], Step [291/750], Loss: 0.0789\n",
      "Epoch [10/10], Step [292/750], Loss: 0.0215\n",
      "Epoch [10/10], Step [293/750], Loss: 0.0341\n",
      "Epoch [10/10], Step [294/750], Loss: 0.0567\n",
      "Epoch [10/10], Step [295/750], Loss: 0.0241\n",
      "Epoch [10/10], Step [296/750], Loss: 0.0245\n",
      "Epoch [10/10], Step [297/750], Loss: 0.0053\n",
      "Epoch [10/10], Step [298/750], Loss: 0.0280\n",
      "Epoch [10/10], Step [299/750], Loss: 0.0546\n",
      "Epoch [10/10], Step [300/750], Loss: 0.0371\n",
      "Epoch [10/10], Step [301/750], Loss: 0.0291\n",
      "Epoch [10/10], Step [302/750], Loss: 0.0517\n",
      "Epoch [10/10], Step [303/750], Loss: 0.1037\n",
      "Epoch [10/10], Step [304/750], Loss: 0.0549\n",
      "Epoch [10/10], Step [305/750], Loss: 0.0644\n",
      "Epoch [10/10], Step [306/750], Loss: 0.0208\n",
      "Epoch [10/10], Step [307/750], Loss: 0.1364\n",
      "Epoch [10/10], Step [308/750], Loss: 0.0192\n",
      "Epoch [10/10], Step [309/750], Loss: 0.0974\n",
      "Epoch [10/10], Step [310/750], Loss: 0.0011\n",
      "Epoch [10/10], Step [311/750], Loss: 0.0150\n",
      "Epoch [10/10], Step [312/750], Loss: 0.0770\n",
      "Epoch [10/10], Step [313/750], Loss: 0.0255\n",
      "Epoch [10/10], Step [314/750], Loss: 0.0287\n",
      "Epoch [10/10], Step [315/750], Loss: 0.0266\n",
      "Epoch [10/10], Step [316/750], Loss: 0.0353\n",
      "Epoch [10/10], Step [317/750], Loss: 0.0409\n",
      "Epoch [10/10], Step [318/750], Loss: 0.1474\n",
      "Epoch [10/10], Step [319/750], Loss: 0.0104\n",
      "Epoch [10/10], Step [320/750], Loss: 0.0230\n",
      "Epoch [10/10], Step [321/750], Loss: 0.0064\n",
      "Epoch [10/10], Step [322/750], Loss: 0.0463\n",
      "Epoch [10/10], Step [323/750], Loss: 0.0113\n",
      "Epoch [10/10], Step [324/750], Loss: 0.0044\n",
      "Epoch [10/10], Step [325/750], Loss: 0.0607\n",
      "Epoch [10/10], Step [326/750], Loss: 0.1650\n",
      "Epoch [10/10], Step [327/750], Loss: 0.0346\n",
      "Epoch [10/10], Step [328/750], Loss: 0.0380\n",
      "Epoch [10/10], Step [329/750], Loss: 0.0260\n",
      "Epoch [10/10], Step [330/750], Loss: 0.0271\n",
      "Epoch [10/10], Step [331/750], Loss: 0.0342\n",
      "Epoch [10/10], Step [332/750], Loss: 0.0697\n",
      "Epoch [10/10], Step [333/750], Loss: 0.0741\n",
      "Epoch [10/10], Step [334/750], Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [335/750], Loss: 0.0287\n",
      "Epoch [10/10], Step [336/750], Loss: 0.0466\n",
      "Epoch [10/10], Step [337/750], Loss: 0.0071\n",
      "Epoch [10/10], Step [338/750], Loss: 0.0843\n",
      "Epoch [10/10], Step [339/750], Loss: 0.0960\n",
      "Epoch [10/10], Step [340/750], Loss: 0.0700\n",
      "Epoch [10/10], Step [341/750], Loss: 0.1510\n",
      "Epoch [10/10], Step [342/750], Loss: 0.0439\n",
      "Epoch [10/10], Step [343/750], Loss: 0.0862\n",
      "Epoch [10/10], Step [344/750], Loss: 0.0096\n",
      "Epoch [10/10], Step [345/750], Loss: 0.0092\n",
      "Epoch [10/10], Step [346/750], Loss: 0.0517\n",
      "Epoch [10/10], Step [347/750], Loss: 0.0288\n",
      "Epoch [10/10], Step [348/750], Loss: 0.0826\n",
      "Epoch [10/10], Step [349/750], Loss: 0.0542\n",
      "Epoch [10/10], Step [350/750], Loss: 0.0170\n",
      "Epoch [10/10], Step [351/750], Loss: 0.0769\n",
      "Epoch [10/10], Step [352/750], Loss: 0.1509\n",
      "Epoch [10/10], Step [353/750], Loss: 0.0887\n",
      "Epoch [10/10], Step [354/750], Loss: 0.0616\n",
      "Epoch [10/10], Step [355/750], Loss: 0.1437\n",
      "Epoch [10/10], Step [356/750], Loss: 0.0907\n",
      "Epoch [10/10], Step [357/750], Loss: 0.0207\n",
      "Epoch [10/10], Step [358/750], Loss: 0.0819\n",
      "Epoch [10/10], Step [359/750], Loss: 0.0210\n",
      "Epoch [10/10], Step [360/750], Loss: 0.0555\n",
      "Epoch [10/10], Step [361/750], Loss: 0.0732\n",
      "Epoch [10/10], Step [362/750], Loss: 0.0736\n",
      "Epoch [10/10], Step [363/750], Loss: 0.0592\n",
      "Epoch [10/10], Step [364/750], Loss: 0.0089\n",
      "Epoch [10/10], Step [365/750], Loss: 0.0473\n",
      "Epoch [10/10], Step [366/750], Loss: 0.1646\n",
      "Epoch [10/10], Step [367/750], Loss: 0.0824\n",
      "Epoch [10/10], Step [368/750], Loss: 0.0351\n",
      "Epoch [10/10], Step [369/750], Loss: 0.1452\n",
      "Epoch [10/10], Step [370/750], Loss: 0.0659\n",
      "Epoch [10/10], Step [371/750], Loss: 0.1217\n",
      "Epoch [10/10], Step [372/750], Loss: 0.0222\n",
      "Epoch [10/10], Step [373/750], Loss: 0.0486\n",
      "Epoch [10/10], Step [374/750], Loss: 0.1755\n",
      "Epoch [10/10], Step [375/750], Loss: 0.0613\n",
      "Epoch [10/10], Step [376/750], Loss: 0.0302\n",
      "Epoch [10/10], Step [377/750], Loss: 0.1064\n",
      "Epoch [10/10], Step [378/750], Loss: 0.0659\n",
      "Epoch [10/10], Step [379/750], Loss: 0.0221\n",
      "Epoch [10/10], Step [380/750], Loss: 0.1617\n",
      "Epoch [10/10], Step [381/750], Loss: 0.0792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dac347325ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-c46aa2f17cf8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_epochs, model, loaders)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mb_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6619530e83d2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mx_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mx_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqlayer_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mx_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqlayer_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mx_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqlayer_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\qnn\\torch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[0mreconstructor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                 \u001b[0mreconstructor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstructor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\qnn\\torch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;31m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_qnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_evaluate_qnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\qnn\\torch.py\u001b[0m in \u001b[0;36m_evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqnode_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         }\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         finite_diff = any(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, device, params)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\tape\\tape.py\u001b[0m in \u001b[0;36mexecute_device\u001b[1;34m(self, params, device)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQubitDevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# apply all circuit operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# generate computational basis samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\devices\\default_qubit.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_basis_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# store the pre-rotated state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\devices\\default_qubit_torch.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_device\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\devices\\default_qubit.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_ops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_unitary_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiagonalOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\devices\\default_qubit_torch.py\u001b[0m in \u001b[0;36m_get_unitary_matrix\u001b[1;34m(self, unitary)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 )\n\u001b[0;32m    259\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                 \u001b[0mmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparametric_ops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munitary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0munitary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munitary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiagonalOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pennylane\\devices\\torch_ops.py\u001b[0m in \u001b[0;36mRot\u001b[1;34m(a, b, c, device)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0munitary\u001b[0m \u001b[1;36m2\u001b[0m\u001b[0mx2\u001b[0m \u001b[0mrotation\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mrz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mrz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \"\"\"\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRZ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mRY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRZ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train(num_epochs, hnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ed953a",
   "metadata": {
    "id": "f1ed953a"
   },
   "outputs": [],
   "source": [
    "torch.save(hnn.state_dict(), 'trained_model_24qubits_3_layers_with_strong_entagling.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fully_connected_with_qnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00cd50cc19624ebf946c288dcf96ca77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a0c3aa1494d454b85ce6083f2c98234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ca85bfb648a4586ab15f601f45bd7c2",
      "placeholder": "​",
      "style": "IPY_MODEL_979724284c094071b6c3143666a2a8d5",
      "value": " 0/10 [00:22&lt;?, ?it/s]"
     }
    },
    "0aa6d7245fc747b58457668a840cd66b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0de84b8c5dde45b68b6fe495e3978524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1784bfcf80e54eb1a3b7873cd36494b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fb4ea8439054fbeaab29cbbdd8d8c62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2454c06e04cc44a59af6a54edf771dcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d31e57f44fef4cd99cbda543609a5363",
      "placeholder": "​",
      "style": "IPY_MODEL_f1cb6810b0f0425c925092fd2c564460",
      "value": " 29696/? [00:00&lt;00:00, 779622.51it/s]"
     }
    },
    "2bae88a771624fce8a7195ab2d3790e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3629620f44dc4eec928e8285f4e292c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c55b6cc69fe4e71bfefdfafe172e1f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42c3a0dfb96d4d0a9cbcfbefdb88634a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7381bd873134277869b9bf86f7f6cde",
       "IPY_MODEL_92a84a7a4c1a49fca9c649540174de1a",
       "IPY_MODEL_973a9057772b4a33bebe1c71b2548322"
      ],
      "layout": "IPY_MODEL_fb3c5d28cc434035936450f03eaab7d4"
     }
    },
    "4472460dcaf349e282e8505097ac56db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b9f9045a6a64724b75bed3bdf4825e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d29ed3d913f4c3dadd8aa28ffdf60ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fb4ea8439054fbeaab29cbbdd8d8c62",
      "placeholder": "​",
      "style": "IPY_MODEL_7598f22b00ca4188abd0e988d87c8717",
      "value": ""
     }
    },
    "4ee572a2f86844b38f1475756d831d7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53264b907c324fd2903f6a33df4024eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3629620f44dc4eec928e8285f4e292c7",
      "placeholder": "​",
      "style": "IPY_MODEL_ca79710ed42844eda53edd54ad1cce9e",
      "value": ""
     }
    },
    "585d33ea2f6c4c6f866ab5eaf500a486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4472460dcaf349e282e8505097ac56db",
      "placeholder": "​",
      "style": "IPY_MODEL_00cd50cc19624ebf946c288dcf96ca77",
      "value": " 5120/? [00:00&lt;00:00, 149206.45it/s]"
     }
    },
    "5f557bc2ab954fcdbb3145c5ae1cd1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_831588c036b84ba5919552e1c0ffaf95",
      "placeholder": "​",
      "style": "IPY_MODEL_4b9f9045a6a64724b75bed3bdf4825e5",
      "value": " 9913344/? [00:00&lt;00:00, 18038716.63it/s]"
     }
    },
    "611e4230f7284f56a36e03b6cab128bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "656d789dd50d4d7c95121ee911a0315e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "664e26cb5e91441d8360e652dc6f3f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbeac195f2cf4776b6c95dedda39513c",
      "placeholder": "​",
      "style": "IPY_MODEL_611e4230f7284f56a36e03b6cab128bb",
      "value": ""
     }
    },
    "70629c93466c490cb4d10c7ba2e41d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7081d0216eb6473fae87f7331becfb53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7192858941cb47649969779dc0e63c91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_664e26cb5e91441d8360e652dc6f3f13",
       "IPY_MODEL_ba90ae57f0bf4101b5306b32401f5ca6",
       "IPY_MODEL_585d33ea2f6c4c6f866ab5eaf500a486"
      ],
      "layout": "IPY_MODEL_0de84b8c5dde45b68b6fe495e3978524"
     }
    },
    "739c6da6cd64446686e87fd499fc4e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1784bfcf80e54eb1a3b7873cd36494b1",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae7d8308ff8541d082c143732f92bce6",
      "value": 28881
     }
    },
    "7598f22b00ca4188abd0e988d87c8717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ca85bfb648a4586ab15f601f45bd7c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "831588c036b84ba5919552e1c0ffaf95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b99aefdd9a247678de2cefd312207bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7081d0216eb6473fae87f7331becfb53",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70629c93466c490cb4d10c7ba2e41d62",
      "value": 0
     }
    },
    "9002f4b1af6d4c03b8f53fecdffaa3b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a84a7a4c1a49fca9c649540174de1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bae88a771624fce8a7195ab2d3790e1",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5767d4185754f1f82e22dc55b9b659e",
      "value": 1648877
     }
    },
    "973a9057772b4a33bebe1c71b2548322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcaf3aab2df24777bb896394049144d2",
      "placeholder": "​",
      "style": "IPY_MODEL_656d789dd50d4d7c95121ee911a0315e",
      "value": " 1649664/? [00:00&lt;00:00, 5358482.30it/s]"
     }
    },
    "979724284c094071b6c3143666a2a8d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a0d229daebc428d8d0bea6db980845f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2b522fb50d54cecaead8906ecc2c88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2db74a18ce8412399aba11b3bab930b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa56b1689edb4a75aa4af965407467e6",
       "IPY_MODEL_8b99aefdd9a247678de2cefd312207bb",
       "IPY_MODEL_0a0c3aa1494d454b85ce6083f2c98234"
      ],
      "layout": "IPY_MODEL_9002f4b1af6d4c03b8f53fecdffaa3b0"
     }
    },
    "a5767d4185754f1f82e22dc55b9b659e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa56b1689edb4a75aa4af965407467e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df312d8125694913844f2856ee295e67",
      "placeholder": "​",
      "style": "IPY_MODEL_0aa6d7245fc747b58457668a840cd66b",
      "value": "  0%"
     }
    },
    "ae7d8308ff8541d082c143732f92bce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7381bd873134277869b9bf86f7f6cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee572a2f86844b38f1475756d831d7e",
      "placeholder": "​",
      "style": "IPY_MODEL_a2b522fb50d54cecaead8906ecc2c88f",
      "value": ""
     }
    },
    "ba90ae57f0bf4101b5306b32401f5ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a0d229daebc428d8d0bea6db980845f",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc04c3799392479f84746241eac0c9bc",
      "value": 4542
     }
    },
    "bcaf3aab2df24777bb896394049144d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7dfb28ce1ec490bbbc71bbf8f8bc7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d29ed3d913f4c3dadd8aa28ffdf60ab",
       "IPY_MODEL_739c6da6cd64446686e87fd499fc4e8c",
       "IPY_MODEL_2454c06e04cc44a59af6a54edf771dcf"
      ],
      "layout": "IPY_MODEL_fc29fb7181a64867aa764553a94327cf"
     }
    },
    "ca79710ed42844eda53edd54ad1cce9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d31e57f44fef4cd99cbda543609a5363": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8d21603da7146628c7025db753adeb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbeac195f2cf4776b6c95dedda39513c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc04c3799392479f84746241eac0c9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df312d8125694913844f2856ee295e67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df69f8986a7b46df869d78996f9a92bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53264b907c324fd2903f6a33df4024eb",
       "IPY_MODEL_fe3e249b5f1947ec9fc496ab71992860",
       "IPY_MODEL_5f557bc2ab954fcdbb3145c5ae1cd1fe"
      ],
      "layout": "IPY_MODEL_3c55b6cc69fe4e71bfefdfafe172e1f4"
     }
    },
    "f1cb6810b0f0425c925092fd2c564460": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4bb69ed5dcf45cabca0294b04062d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb3c5d28cc434035936450f03eaab7d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc29fb7181a64867aa764553a94327cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe3e249b5f1947ec9fc496ab71992860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4bb69ed5dcf45cabca0294b04062d68",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8d21603da7146628c7025db753adeb3",
      "value": 9912422
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
